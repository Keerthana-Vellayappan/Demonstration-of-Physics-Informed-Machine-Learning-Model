{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c7ab319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Scientific computing and data manipulation\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.integrate import odeint, solve_ivp\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine learning and deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, LeaveOneOut\n",
    "\n",
    "# Hyperparameter optimization\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8db3b94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping function\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    \n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2af1f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'using cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tells whether the model is running on CPU or GPU\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('using GPU:', torch.cuda.get_device_name()) if torch.cuda.is_available() else 'using cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e67b05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import random\n",
    "\n",
    "# To fix the random seed\n",
    "#seed = 42\n",
    "#torch.manual_seed(seed)\n",
    "#np.random.seed(seed)\n",
    "#random.seed(seed)\n",
    "\n",
    "# Ensure deterministic behavior in PyTorch\n",
    "#torch.backends.cudnn.deterministic = True\n",
    "#torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32db19a1",
   "metadata": {},
   "source": [
    "# DEFINE PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "451e5021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constant parameters\n",
    "\n",
    "R = (6.4*10e-3)/2 # Tubular radius, units: m\n",
    "qp_480 = 1.3 * 10e-4 * 60 # Photon flux, units: moles photons · m-2 · min-1\n",
    "Vr = 4.78 * 10e-6# Reactor volume, units: m3\n",
    "CB = 0.4 # Concentartion of reactant B, units: M\n",
    "\n",
    "# Calculate photon flux at different power ratings\n",
    "\n",
    "# 240 W\n",
    "qp_240 = qp_480*240/480\n",
    "\n",
    "#120 W\n",
    "qp_120 = qp_480*120/480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb27ee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimentally measured parameters\n",
    "\n",
    "phi_n1 = 0.07508614 # Quantum yield, units: mole/Einstien\n",
    "k11 = 0.01953897 # rate constant for formation of species C\n",
    "k21 = 0.11706072 # rate constant for formation of species E\n",
    "\n",
    "# Regressed parameters\n",
    "\n",
    "mpc1 = 94.6*0.02*(1/1000) # photon absorption by photocatalyst\n",
    "ka1 =  324.7*(1/1000) # Napierian molar absorption coefficient of specis A, units: m2/mol\n",
    "kc1 = 345.5*(1/1000) # Napierian molar absorption coefficient of specis C, units: m2/mol "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33257c1",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e37c8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet1\n",
      "Sheet2\n",
      "Sheet3\n",
      "Sheet4\n",
      "Sheet5\n",
      "Sheet6\n",
      "Sheet7\n",
      "Sheet8\n",
      "Sheet9\n"
     ]
    }
   ],
   "source": [
    "# Extract Data from the Excel Data Sheet\n",
    "\n",
    "Y1_list = []\n",
    "Y2_list = []\n",
    "Y3_list = []\n",
    "Input_list = []\n",
    "for i in range(1,10):\n",
    "    name = \"Sheet\" + str(i)\n",
    "    print(name)\n",
    "    raw_input = pd.read_excel(\"Updated_photochemical_Experiment.xlsx\",name)\n",
    "    X=raw_input.values.astype(np.float64)\n",
    "    X1 = X[:,2]\n",
    "    Y1 = X[:,10]\n",
    "    Y2 = X[:,11]\n",
    "    Y3 = X[:,9]\n",
    "    \n",
    "    Y1_list.append(Y1)\n",
    "    Y2_list.append(Y2)\n",
    "    Y3_list.append(Y3)\n",
    "    \n",
    "    Input_list.append([X[0,0],X[0,1],Y1[0],Y2[0],Y3[0]])  #Y1,Y2,Y3 ==1,0,0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c24f5097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN_input shape is (9, 36, 5)\n"
     ]
    }
   ],
   "source": [
    "X_input = np.array(Input_list).reshape(-1,1,5)\n",
    "RNN_input = X_input.repeat(36, axis=1)  # to keep consensus with the shape for RNN_output\n",
    "print(\"RNN_input shape is {}\".format(RNN_input.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94bc526e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN_output shape is (9, 36, 3)\n"
     ]
    }
   ],
   "source": [
    "Y1_output = np.array(Y1_list)\n",
    "Y1_output = Y1_output.reshape(-1, 36, 1)\n",
    "Y2_output = np.array(Y2_list)\n",
    "Y2_output = Y2_output.reshape(-1, 36, 1)\n",
    "Y3_output = np.array(Y3_list)\n",
    "Y3_output = Y3_output.reshape(-1, 36, 1)\n",
    "RNN_output = np.concatenate((Y1_output, Y2_output, Y3_output), axis=2)\n",
    "print(\"RNN_output shape is {}\".format(RNN_output.shape))  # output shape: number of samples x timestep x variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4d6b856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.3 280.    1.    0.    0. ]\n",
      "[6.66666667e-03 2.24000000e+04 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00]\n",
      "[0.29611469 0.69253774 0.01134757]\n",
      "[2.33151041e-02 2.22718238e-02 1.73960109e-05]\n"
     ]
    }
   ],
   "source": [
    "# Normalization\n",
    "\n",
    "scaler_X = preprocessing.StandardScaler().fit(RNN_input.reshape(-1, 5))\n",
    "scaler_y = preprocessing.StandardScaler().fit(RNN_output.reshape(-1, 3))\n",
    "\n",
    "print(scaler_X.mean_)\n",
    "print(scaler_X.var_)\n",
    "print(scaler_y.mean_)\n",
    "print(scaler_y.var_)\n",
    "\n",
    "RNN_input = scaler_X.transform(RNN_input.reshape(-1, 5)).reshape(-1,36,5)\n",
    "RNN_output = scaler_y.transform(RNN_output.reshape(-1, 3)).reshape(-1,36,3)\n",
    "\n",
    "mean_y = torch.from_numpy(scaler_y.mean_).float()\n",
    "std_y = torch.from_numpy(np.sqrt(scaler_y.var_)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be865038",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mean_y,'mean_y.pt')\n",
    "torch.save(std_y,'std_y.pt')\n",
    "np.save('mean_X.npy',scaler_X.mean_)\n",
    "np.save('std_X.npy',np.sqrt(scaler_X.var_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b65ebc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "x_train = RNN_input[:7,:,:]\n",
    "x_test  = RNN_input[7:,:,:]\n",
    "\n",
    "y_train = RNN_output[:7,:,:]\n",
    "y_test =  RNN_output[7:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "945d8c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape is (7, 36, 5), x_test shape is (2, 36, 5)\n",
      "y_train shape is (7, 36, 3), y_test shape is (2, 36, 3)\n"
     ]
    }
   ],
   "source": [
    "############################# Split Train, Test, and Validation dataset ##################################\n",
    "\n",
    "#X_train, x_test, Y_train, y_test = train_test_split(RNN_input, RNN_output, test_size=0.2, random_state=42)\n",
    "\n",
    "#x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42) # 0.25 x 0.8 = 0.2\n",
    "\n",
    "print(f\"x_train shape is {x_train.shape}, x_test shape is {x_test.shape}\")\n",
    "print(f\"y_train shape is {y_train.shape}, y_test shape is {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89f204bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_X = np.load('mean_X.npy')\n",
    "std_X = np.load('std_X.npy')\n",
    "mean_y = torch.load('mean_y.pt')\n",
    "std_y=torch.load('std_y.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9022d46",
   "metadata": {},
   "source": [
    "# GENERATING COLLOCATION POINTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8c00da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating collocation points \n",
    "# u1 = Reactant feed concentration, u2 = Power rating\n",
    "\n",
    "u1_physics_list = np.linspace(0.1, 1, 20)\n",
    "u2_physics_list = np.linspace(100, 1000, 20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c863e9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 out of 20\n",
      "2 out of 20\n",
      "3 out of 20\n",
      "4 out of 20\n",
      "5 out of 20\n",
      "6 out of 20\n",
      "7 out of 20\n",
      "8 out of 20\n",
      "9 out of 20\n",
      "10 out of 20\n",
      "11 out of 20\n",
      "12 out of 20\n",
      "13 out of 20\n",
      "14 out of 20\n",
      "15 out of 20\n",
      "16 out of 20\n",
      "17 out of 20\n",
      "18 out of 20\n",
      "19 out of 20\n",
      "20 out of 20\n"
     ]
    }
   ],
   "source": [
    "u1_physics_input = list()\n",
    "u2_physics_input = list()\n",
    "Y_1_list = []\n",
    "Y_2_list = []\n",
    "Y_3_list = []\n",
    "\n",
    "for num_id, u1 in enumerate(u1_physics_list):\n",
    "    print(f\"{num_id + 1} out of {u1_physics_list.shape[0]}\")    #just to count and keep track\n",
    "    CBi = u1 \n",
    "    \n",
    "    for u2 in u2_physics_list:\n",
    "        F = u2 \n",
    "        \n",
    "        u1_physics_input.append(u1)\n",
    "        u2_physics_input.append(u2)\n",
    "        \n",
    "        Y_1 = 1\n",
    "        Y_2 = 0\n",
    "        Y_3 = 0\n",
    "    \n",
    "        Y_1_list.append(Y_1)\n",
    "        Y_2_list.append(Y_2)\n",
    "        Y_3_list.append(Y_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04628f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN_physics_input_temp shape is (400, 36, 5)\n"
     ]
    }
   ],
   "source": [
    "# collate input \n",
    "\n",
    "u1_physics_input = np.array(u1_physics_input)\n",
    "u1_physics_input = u1_physics_input.reshape(-1,1,1)\n",
    "\n",
    "u2_physics_input = np.array(u2_physics_input)\n",
    "u2_physics_input = u2_physics_input.reshape(-1,1,1)\n",
    "\n",
    "Y_1_list = np.array(Y_1_list)\n",
    "Y_1_list = Y_1_list.reshape(-1,1,1)\n",
    "\n",
    "Y_2_list = np.array(Y_2_list)\n",
    "Y_2_list = Y_2_list.reshape(-1,1,1)\n",
    "\n",
    "Y_3_list = np.array(Y_3_list)\n",
    "Y_3_list = Y_3_list.reshape(-1,1,1)\n",
    "\n",
    "RNN_physics_input_tempc = np.concatenate((u1_physics_input, u2_physics_input, Y_1_list, Y_2_list, Y_3_list), axis=2)\n",
    "\n",
    "\"\"\"\n",
    "    the input to RNN is in the shape [number of samples x timestep x variables], and the input variables are same for every\n",
    "    time step\n",
    "\"\"\"\n",
    "\n",
    "RNN_physics_input_tempc = RNN_physics_input_tempc.repeat(36, axis=1)\n",
    "print(\"RNN_physics_input_temp shape is {}\".format(RNN_physics_input_tempc.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9aa1f5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_physics_input_tempc = scaler_X.transform(RNN_physics_input_tempc.reshape(-1, 5)).reshape(-1,36,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa30dadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_collocation_train\n",
    "x_collocation_train = RNN_physics_input_tempc[:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccde0ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_collocation_train shape is: (400, 36, 5)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_collocation_train shape is: {x_collocation_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa088211",
   "metadata": {},
   "source": [
    "# TRANSFORMING DATA FOR TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "267a0ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_collocation_train = torch.from_numpy(x_collocation_train).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7659da38",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(x_train).float()\n",
    "x_test = torch.from_numpy(x_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c8f3c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.from_numpy(y_train).float()\n",
    "y_test = torch.from_numpy(y_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a4d2ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_physics_test = TensorDataset(x_test, y_test)\n",
    "dataloader_physics_test = DataLoader(dataset_physics_test, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7dee69",
   "metadata": {},
   "source": [
    "# DEFINING RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c94fb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \"Defines a RNN network\"\n",
    "    \n",
    "    def __init__(self, N_INPUT, N_OUTPUT, N_HIDDEN, N_LAYERS):\n",
    "        super(RNN, self).__init__()\n",
    "        self.layers = N_LAYERS\n",
    "        \n",
    "        if isinstance(N_HIDDEN, list):\n",
    "            self.rnn = nn.LSTM(N_INPUT, \n",
    "                                N_HIDDEN[0], \n",
    "                                batch_first=True)\n",
    "            \n",
    "            self.rnn1 = nn.ModuleList(\n",
    "                [nn.LSTM(N_HIDDEN[i], \n",
    "                        N_HIDDEN[i+1],\n",
    "                       batch_first=True) for i in range(N_LAYERS - 1)]\n",
    "            )\n",
    "            \n",
    "            self.output_layer = nn.Linear(N_HIDDEN[-1], N_OUTPUT)\n",
    "            \n",
    "            self.list_flag = True\n",
    "            \n",
    "        else:\n",
    "            self.rnn = nn.LSTM(N_INPUT, \n",
    "                                N_HIDDEN,\n",
    "                                N_LAYERS,\n",
    "                                batch_first=True,\n",
    "                                dropout=0.1)\n",
    "            \n",
    "            self.output_layer = nn.Linear(N_HIDDEN, N_OUTPUT)\n",
    "            \n",
    "            self.list_flag = False                                             \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, _ = self.rnn(x)\n",
    "        \n",
    "        if self.list_flag:\n",
    "            for i in range(self.layers - 1):\n",
    "                x, _ = self.rnn1[i](x)\n",
    "                \n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc9d3a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          1.          2.          3.          4.          5.\n",
      "  5.03586213  5.14649097  5.30111004  5.4649041   5.63867566  5.82331844\n",
      "  6.01982984  6.22932528  6.4530548   6.69242217  6.94900701  7.22459021\n",
      "  7.5211832   7.84106147  8.18680287  8.56133087  8.96796312  9.41046508\n",
      "  9.89310801 10.42072996 10.99879691 11.63345974 13.1008564  13.94961458\n",
      " 14.88695124 15.92250695 17.06627394 18.32828423 19.71819689 21.24480099]\n",
      "[1.         1.         1.         1.         1.         0.03586213\n",
      " 0.11062884 0.15461907 0.16379406 0.17377156 0.18464278 0.1965114\n",
      " 0.20949544 0.22372951 0.23936737 0.25658484 0.2755832  0.29659298\n",
      " 0.31987827 0.3457414  0.374528   0.40663225 0.44250195 0.48264293\n",
      " 0.52762195 0.57806695 0.63466283 1.46739666 0.84875818 0.93733666\n",
      " 1.03555572 1.14376698 1.26201029 1.38991266 1.5266041 ]\n"
     ]
    }
   ],
   "source": [
    "# Adaptive Time Step\n",
    "\n",
    "time = X1\n",
    "print(time)\n",
    "# Compute t_step as before\n",
    "t_step = np.diff(time)\n",
    "print(t_step)\n",
    "t_step = torch.from_numpy(t_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942fd1fd",
   "metadata": {},
   "source": [
    "# RNN and PHYSICS INFORMED RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d944e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, patience, n_epochs, X_collocation_train):\n",
    "    \n",
    "    train_losses, valid_losses = [], []\n",
    "    avg_train_losses, avg_valid_losses = [], []\n",
    "    y_scaled_error = []\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        model.train()\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch, y_batch = x_batch[0].to(device), y_batch[0].to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            NN_outputd = model(x_batch)\n",
    "\n",
    "            # Data-driven loss\n",
    "            loss1 = torch.mean((NN_outputd - y_batch) ** 2)\n",
    "\n",
    "            # Physics-based loss using collocation points\n",
    "            X_col = X_collocation_train.to(device)\n",
    "            NN_output = model(X_col)\n",
    "            CA_in = X_col[:, :, 2] * std_X[2] + mean_X[2]\n",
    "            CC_in = X_col[:, :, 3] * std_X[3] + mean_X[3]\n",
    "            CE_in = X_col[:, :, 4] * std_X[4] + mean_X[4]\n",
    "            CB = 0.4 * 1000  # mol/m3\n",
    "            CAo = X_col[:, :, 0] * std_X[0] + mean_X[0]\n",
    "            CAo = CAo * 1000\n",
    "            qp = 1.3 * 10e-4 * 60 * (X_col[:, :, 1] * std_X[1] + mean_X[1]) / 480\n",
    "            qp = qp.to(device)\n",
    "\n",
    "            NN_output = NN_output * std_y.to(device) + mean_y.to(device)\n",
    "\n",
    "            dCA = torch.cat([\n",
    "                (NN_output[:, 1:2, 0] - CA_in[:, 0:1]) / (2 * t_step[0]),\n",
    "                (NN_output[:, 2:, 0] - NN_output[:, :-2, 0]) / (2 * t_step[0:-1]),\n",
    "                (NN_output[:, -1:, 0] - NN_output[:, -2:-1, 0]) / (t_step[-1])\n",
    "            ], dim=1)\n",
    "\n",
    "            dCC = torch.cat([\n",
    "                (NN_output[:, 1:2, 1] - CC_in[:, 0:1]) / (2 * t_step[0]),\n",
    "                (NN_output[:, 2:, 1] - NN_output[:, :-2, 1]) / (2 * t_step[0:-1]),\n",
    "                (NN_output[:, -1:, 1] - NN_output[:, -2:-1, 1]) / (t_step[-1])\n",
    "            ], dim=1)\n",
    "\n",
    "            dCE = torch.cat([\n",
    "                (NN_output[:, 1:2, 2] - CE_in[:, 0:1]) / (2 * t_step[0]),\n",
    "                (NN_output[:, 2:, 2] - NN_output[:, :-2, 2]) / (2 * t_step[0:-1]),\n",
    "                (NN_output[:, -1:, 2] - NN_output[:, -2:-1, 2]) / (t_step[-1])\n",
    "            ], dim=1)\n",
    "\n",
    "            lossCA = dCA - ((phi_n1/CAo)*(qp/Vr)*(ka1*NN_output[:, :, 0]*CAo/(mpc1+ka1*NN_output[:, :, 0]*CAo+kc1*NN_output[:, :, 1]*CAo))\n",
    "                            *(1-torch.exp(-(mpc1+ka1*NN_output[:, :, 0]*CAo+kc1*NN_output[ :,:, 1]*CAo)*2*R)))\n",
    "            lossCA = torch.mean(lossCA**2)\n",
    "            \n",
    "            lossCC = dCC - ((k11*CB)/(k11*CB+k21)**1)*((phi_n1/CAo)*(qp/Vr)*(ka1*NN_output[:, :, 0]*CAo/(mpc1+ka1*NN_output[:,:, 0]*CAo+kc1*NN_output[ :,:, 1]*CAo))\n",
    "                                                       *(1-torch.exp(-(mpc1+ka1*NN_output[:, :, 0]*CAo+kc1*NN_output[:, :, 1]*CAo)*2*R)))**1\n",
    "            lossCC = torch.mean(lossCC**2)\n",
    "            \n",
    "            lossCE = dCE - (k21/(k11*CB+k21)**1)*((phi_n1/CAo)*(qp/Vr)*(ka1*NN_output[:, :, 0]*CAo/(mpc1+ka1*NN_output[ :,:, 0]*CAo+kc1*NN_output[:,:, 1]*CAo))\n",
    "                                                  *(1-torch.exp(-(mpc1+ka1*NN_output[:, :, 0]*CAo+kc1*NN_output[:, :, 1]*CAo)*2*R)))**1 \n",
    "            lossCE = torch.mean(lossCE**2)\n",
    "\n",
    "            loss = loss1 + lossCA + lossCC + lossCE # manual scaling of physics losses if needed\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        for x_valbatch, y_valbatch in val_loader:\n",
    "            x_valbatch, y_valbatch = x_valbatch[0].to(device), y_valbatch[0].to(device)\n",
    "            NN_outputv = model(x_valbatch)\n",
    "            loss = torch.mean((NN_outputv - y_valbatch) ** 2)\n",
    "\n",
    "            valid_losses.append(loss.item())\n",
    "\n",
    "        # Logging\n",
    "        train_loss = np.mean(train_losses)\n",
    "        valid_loss = np.mean(valid_losses)\n",
    "        avg_train_losses.append(train_loss)\n",
    "        avg_valid_losses.append(valid_loss)\n",
    "\n",
    "        print(f\"[{epoch}/{n_epochs}] train_loss: {train_loss:.5f} valid_loss: {valid_loss:.5f}\")\n",
    "\n",
    "        train_losses, valid_losses = [], []\n",
    "        early_stopping(valid_loss, model)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    # Evaluate best model on validation set once\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    model.eval()\n",
    "\n",
    "    final_predictions = []\n",
    "    final_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_valbatch, y_valbatch in dataloader_physics_test:\n",
    "            x_valbatch, y_valbatch = x_valbatch[0].to(device), y_valbatch[0].to(device)\n",
    "            output = model(x_valbatch)\n",
    "\n",
    "            preds = scaler_y.inverse_transform(output.cpu().numpy().reshape(-1, 3)).reshape(-1, 36, 3)\n",
    "            targets = scaler_y.inverse_transform(y_valbatch.cpu().numpy().reshape(-1, 3)).reshape(-1, 36, 3)\n",
    "\n",
    "            # Compute scaled loss\n",
    "            c1 = np.sum(np.abs(preds[-1, :, 0] - targets[-1, :, 0]))\n",
    "            c2 = np.sum(np.abs(preds[-1, :, 1] - targets[-1, :, 1]))\n",
    "            c3 = np.sum(np.abs(preds[-1, :, 2] - targets[-1, :, 2]))\n",
    "            scaled_loss = (3.377069851 * c1 + 1.443964636 * c2 + 88.12458286 * c3) / 100\n",
    "\n",
    "            y_scaled_error.append(scaled_loss)\n",
    "\n",
    "            final_predictions.append(preds)\n",
    "            final_targets.append(targets)\n",
    "\n",
    "    final_predictions = np.concatenate(final_predictions, axis=0)\n",
    "    final_targets = np.concatenate(final_targets, axis=0)\n",
    "\n",
    "    return model, avg_train_losses, avg_valid_losses, np.mean(avg_valid_losses), y_scaled_error, final_predictions, final_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a53b7b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create loocv procedure\n",
    "from sklearn.model_selection import KFold\n",
    "cv = LeaveOneOut()\n",
    "batch_size = 32\n",
    "k = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7a0a280",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1/7\n",
      "  Training 1/5 for Fold 1\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] train_loss: 0.74820 valid_loss: 2.35704\n",
      "Validation loss decreased (inf --> 2.357038).  Saving model ...\n",
      "[2/100] train_loss: 0.87133 valid_loss: 2.33179\n",
      "Validation loss decreased (2.357038 --> 2.331793).  Saving model ...\n",
      "[3/100] train_loss: 0.98664 valid_loss: 2.31995\n",
      "Validation loss decreased (2.331793 --> 2.319945).  Saving model ...\n",
      "[4/100] train_loss: 0.84847 valid_loss: 2.30629\n",
      "Validation loss decreased (2.319945 --> 2.306294).  Saving model ...\n",
      "[5/100] train_loss: 1.04582 valid_loss: 2.28519\n",
      "Validation loss decreased (2.306294 --> 2.285188).  Saving model ...\n",
      "[6/100] train_loss: 1.04110 valid_loss: 2.26115\n",
      "Validation loss decreased (2.285188 --> 2.261151).  Saving model ...\n",
      "[7/100] train_loss: 0.70499 valid_loss: 2.23694\n",
      "Validation loss decreased (2.261151 --> 2.236940).  Saving model ...\n",
      "[8/100] train_loss: 0.97745 valid_loss: 2.21743\n",
      "Validation loss decreased (2.236940 --> 2.217431).  Saving model ...\n",
      "[9/100] train_loss: 0.97515 valid_loss: 2.20146\n",
      "Validation loss decreased (2.217431 --> 2.201459).  Saving model ...\n",
      "[10/100] train_loss: 0.78005 valid_loss: 2.18604\n",
      "Validation loss decreased (2.201459 --> 2.186042).  Saving model ...\n",
      "[11/100] train_loss: 0.68635 valid_loss: 2.16912\n",
      "Validation loss decreased (2.186042 --> 2.169117).  Saving model ...\n",
      "[12/100] train_loss: 1.01343 valid_loss: 2.14897\n",
      "Validation loss decreased (2.169117 --> 2.148966).  Saving model ...\n",
      "[13/100] train_loss: 0.77727 valid_loss: 2.12964\n",
      "Validation loss decreased (2.148966 --> 2.129638).  Saving model ...\n",
      "[14/100] train_loss: 0.78725 valid_loss: 2.10904\n",
      "Validation loss decreased (2.129638 --> 2.109041).  Saving model ...\n",
      "[15/100] train_loss: 0.78118 valid_loss: 2.08716\n",
      "Validation loss decreased (2.109041 --> 2.087160).  Saving model ...\n",
      "[16/100] train_loss: 0.96128 valid_loss: 2.06781\n",
      "Validation loss decreased (2.087160 --> 2.067811).  Saving model ...\n",
      "[17/100] train_loss: 0.65849 valid_loss: 2.04658\n",
      "Validation loss decreased (2.067811 --> 2.046583).  Saving model ...\n",
      "[18/100] train_loss: 0.75964 valid_loss: 2.02335\n",
      "Validation loss decreased (2.046583 --> 2.023346).  Saving model ...\n",
      "[19/100] train_loss: 0.97748 valid_loss: 1.99578\n",
      "Validation loss decreased (2.023346 --> 1.995780).  Saving model ...\n",
      "[20/100] train_loss: 0.95376 valid_loss: 1.97043\n",
      "Validation loss decreased (1.995780 --> 1.970432).  Saving model ...\n",
      "[21/100] train_loss: 0.73444 valid_loss: 1.94223\n",
      "Validation loss decreased (1.970432 --> 1.942226).  Saving model ...\n",
      "[22/100] train_loss: 0.72496 valid_loss: 1.91082\n",
      "Validation loss decreased (1.942226 --> 1.910823).  Saving model ...\n",
      "[23/100] train_loss: 0.76519 valid_loss: 1.87876\n",
      "Validation loss decreased (1.910823 --> 1.878759).  Saving model ...\n",
      "[24/100] train_loss: 0.70360 valid_loss: 1.84242\n",
      "Validation loss decreased (1.878759 --> 1.842420).  Saving model ...\n",
      "[25/100] train_loss: 0.94341 valid_loss: 1.80778\n",
      "Validation loss decreased (1.842420 --> 1.807777).  Saving model ...\n",
      "[26/100] train_loss: 0.60363 valid_loss: 1.76906\n",
      "Validation loss decreased (1.807777 --> 1.769061).  Saving model ...\n",
      "[27/100] train_loss: 0.93643 valid_loss: 1.73165\n",
      "Validation loss decreased (1.769061 --> 1.731645).  Saving model ...\n",
      "[28/100] train_loss: 0.92219 valid_loss: 1.68414\n",
      "Validation loss decreased (1.731645 --> 1.684139).  Saving model ...\n",
      "[29/100] train_loss: 0.76907 valid_loss: 1.63575\n",
      "Validation loss decreased (1.684139 --> 1.635754).  Saving model ...\n",
      "[30/100] train_loss: 0.92391 valid_loss: 1.58885\n",
      "Validation loss decreased (1.635754 --> 1.588852).  Saving model ...\n",
      "[31/100] train_loss: 0.91836 valid_loss: 1.54356\n",
      "Validation loss decreased (1.588852 --> 1.543565).  Saving model ...\n",
      "[32/100] train_loss: 0.75596 valid_loss: 1.49772\n",
      "Validation loss decreased (1.543565 --> 1.497719).  Saving model ...\n",
      "[33/100] train_loss: 0.75962 valid_loss: 1.45137\n",
      "Validation loss decreased (1.497719 --> 1.451369).  Saving model ...\n",
      "[34/100] train_loss: 0.89939 valid_loss: 1.40756\n",
      "Validation loss decreased (1.451369 --> 1.407556).  Saving model ...\n",
      "[35/100] train_loss: 0.75403 valid_loss: 1.36484\n",
      "Validation loss decreased (1.407556 --> 1.364844).  Saving model ...\n",
      "[36/100] train_loss: 0.75279 valid_loss: 1.32408\n",
      "Validation loss decreased (1.364844 --> 1.324082).  Saving model ...\n",
      "[37/100] train_loss: 0.88172 valid_loss: 1.28716\n",
      "Validation loss decreased (1.324082 --> 1.287159).  Saving model ...\n",
      "[38/100] train_loss: 0.87540 valid_loss: 1.25412\n",
      "Validation loss decreased (1.287159 --> 1.254124).  Saving model ...\n",
      "[39/100] train_loss: 0.74364 valid_loss: 1.22201\n",
      "Validation loss decreased (1.254124 --> 1.222015).  Saving model ...\n",
      "[40/100] train_loss: 0.85974 valid_loss: 1.19451\n",
      "Validation loss decreased (1.222015 --> 1.194515).  Saving model ...\n",
      "[41/100] train_loss: 0.70544 valid_loss: 1.21606\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[42/100] train_loss: 0.75100 valid_loss: 1.23427\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[43/100] train_loss: 0.67076 valid_loss: 1.27190\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[44/100] train_loss: 0.79321 valid_loss: 1.28740\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[45/100] train_loss: 0.78638 valid_loss: 1.28620\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[46/100] train_loss: 0.83305 valid_loss: 1.28446\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[47/100] train_loss: 0.73565 valid_loss: 1.28135\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[48/100] train_loss: 0.60691 valid_loss: 1.27843\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[49/100] train_loss: 0.60501 valid_loss: 1.27511\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[50/100] train_loss: 0.62334 valid_loss: 1.28293\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[51/100] train_loss: 0.72940 valid_loss: 1.28864\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[52/100] train_loss: 0.82598 valid_loss: 1.29325\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[53/100] train_loss: 0.69614 valid_loss: 1.29371\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[54/100] train_loss: 0.82136 valid_loss: 1.29367\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[55/100] train_loss: 0.68326 valid_loss: 1.28948\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[56/100] train_loss: 0.81446 valid_loss: 1.28536\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[57/100] train_loss: 0.60218 valid_loss: 1.27766\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[58/100] train_loss: 0.80440 valid_loss: 1.27049\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[59/100] train_loss: 0.60153 valid_loss: 1.27194\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[60/100] train_loss: 0.59985 valid_loss: 1.26917\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[61/100] train_loss: 0.59857 valid_loss: 1.27429\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[62/100] train_loss: 0.62743 valid_loss: 1.26539\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[63/100] train_loss: 0.59460 valid_loss: 1.26446\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[64/100] train_loss: 0.59139 valid_loss: 1.27060\n",
      "EarlyStopping counter: 24 out of 100\n",
      "[65/100] train_loss: 0.60377 valid_loss: 1.27143\n",
      "EarlyStopping counter: 25 out of 100\n",
      "[66/100] train_loss: 0.63844 valid_loss: 1.26844\n",
      "EarlyStopping counter: 26 out of 100\n",
      "[67/100] train_loss: 0.60469 valid_loss: 1.26062\n",
      "EarlyStopping counter: 27 out of 100\n",
      "[68/100] train_loss: 0.61039 valid_loss: 1.24120\n",
      "EarlyStopping counter: 28 out of 100\n",
      "[69/100] train_loss: 0.69416 valid_loss: 1.22192\n",
      "EarlyStopping counter: 29 out of 100\n",
      "[70/100] train_loss: 0.68903 valid_loss: 1.20329\n",
      "EarlyStopping counter: 30 out of 100\n",
      "[71/100] train_loss: 0.68407 valid_loss: 1.18607\n",
      "Validation loss decreased (1.194515 --> 1.186072).  Saving model ...\n",
      "[72/100] train_loss: 0.68049 valid_loss: 1.17119\n",
      "Validation loss decreased (1.186072 --> 1.171188).  Saving model ...\n",
      "[73/100] train_loss: 0.74643 valid_loss: 1.15754\n",
      "Validation loss decreased (1.171188 --> 1.157539).  Saving model ...\n",
      "[74/100] train_loss: 0.64967 valid_loss: 1.14837\n",
      "Validation loss decreased (1.157539 --> 1.148372).  Saving model ...\n",
      "[75/100] train_loss: 0.67611 valid_loss: 1.14234\n",
      "Validation loss decreased (1.148372 --> 1.142336).  Saving model ...\n",
      "[76/100] train_loss: 0.62117 valid_loss: 1.15080\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[77/100] train_loss: 0.56643 valid_loss: 1.14945\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[78/100] train_loss: 0.66607 valid_loss: 1.14842\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[79/100] train_loss: 0.57012 valid_loss: 1.14547\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[80/100] train_loss: 0.56932 valid_loss: 1.14060\n",
      "Validation loss decreased (1.142336 --> 1.140598).  Saving model ...\n",
      "[81/100] train_loss: 0.60104 valid_loss: 1.15038\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[82/100] train_loss: 0.59414 valid_loss: 1.17277\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[83/100] train_loss: 0.68095 valid_loss: 1.18948\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[84/100] train_loss: 0.59703 valid_loss: 1.20274\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[85/100] train_loss: 0.67408 valid_loss: 1.21104\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[86/100] train_loss: 0.57245 valid_loss: 1.21432\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[87/100] train_loss: 0.57078 valid_loss: 1.21334\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[88/100] train_loss: 0.59891 valid_loss: 1.21291\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[89/100] train_loss: 0.56967 valid_loss: 1.19888\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[90/100] train_loss: 0.72675 valid_loss: 1.18563\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[91/100] train_loss: 0.56182 valid_loss: 1.16136\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[92/100] train_loss: 0.55642 valid_loss: 1.12841\n",
      "Validation loss decreased (1.140598 --> 1.128411).  Saving model ...\n",
      "[93/100] train_loss: 0.72228 valid_loss: 1.09777\n",
      "Validation loss decreased (1.128411 --> 1.097771).  Saving model ...\n",
      "[94/100] train_loss: 0.71991 valid_loss: 1.06928\n",
      "Validation loss decreased (1.097771 --> 1.069277).  Saving model ...\n",
      "[95/100] train_loss: 0.61524 valid_loss: 1.06644\n",
      "Validation loss decreased (1.069277 --> 1.066436).  Saving model ...\n",
      "[96/100] train_loss: 0.61382 valid_loss: 1.08551\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[97/100] train_loss: 0.71196 valid_loss: 1.10293\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[98/100] train_loss: 0.59398 valid_loss: 1.13745\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[99/100] train_loss: 0.55857 valid_loss: 1.16880\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[100/100] train_loss: 0.59980 valid_loss: 1.20383\n",
      "EarlyStopping counter: 5 out of 100\n",
      "  Training 2/5 for Fold 1\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n",
      "[1/100] train_loss: 0.80932 valid_loss: 2.32708\n",
      "Validation loss decreased (inf --> 2.327082).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/100] train_loss: 0.80609 valid_loss: 2.31708\n",
      "Validation loss decreased (2.327082 --> 2.317082).  Saving model ...\n",
      "[3/100] train_loss: 0.91054 valid_loss: 2.30618\n",
      "Validation loss decreased (2.317082 --> 2.306182).  Saving model ...\n",
      "[4/100] train_loss: 0.97733 valid_loss: 2.30052\n",
      "Validation loss decreased (2.306182 --> 2.300520).  Saving model ...\n",
      "[5/100] train_loss: 1.05862 valid_loss: 2.28708\n",
      "Validation loss decreased (2.300520 --> 2.287082).  Saving model ...\n",
      "[6/100] train_loss: 0.88907 valid_loss: 2.27320\n",
      "Validation loss decreased (2.287082 --> 2.273200).  Saving model ...\n",
      "[7/100] train_loss: 0.79669 valid_loss: 2.26094\n",
      "Validation loss decreased (2.273200 --> 2.260936).  Saving model ...\n",
      "[8/100] train_loss: 0.77352 valid_loss: 2.24889\n",
      "Validation loss decreased (2.260936 --> 2.248893).  Saving model ...\n",
      "[9/100] train_loss: 0.73833 valid_loss: 2.23538\n",
      "Validation loss decreased (2.248893 --> 2.235385).  Saving model ...\n",
      "[10/100] train_loss: 0.79246 valid_loss: 2.22316\n",
      "Validation loss decreased (2.235385 --> 2.223156).  Saving model ...\n",
      "[11/100] train_loss: 0.79107 valid_loss: 2.21199\n",
      "Validation loss decreased (2.223156 --> 2.211991).  Saving model ...\n",
      "[12/100] train_loss: 0.76759 valid_loss: 2.20069\n",
      "Validation loss decreased (2.211991 --> 2.200691).  Saving model ...\n",
      "[13/100] train_loss: 1.01866 valid_loss: 2.18627\n",
      "Validation loss decreased (2.200691 --> 2.186273).  Saving model ...\n",
      "[14/100] train_loss: 0.96406 valid_loss: 2.17401\n",
      "Validation loss decreased (2.186273 --> 2.174006).  Saving model ...\n",
      "[15/100] train_loss: 0.76201 valid_loss: 2.16183\n",
      "Validation loss decreased (2.174006 --> 2.161832).  Saving model ...\n",
      "[16/100] train_loss: 0.78451 valid_loss: 2.15046\n",
      "Validation loss decreased (2.161832 --> 2.150463).  Saving model ...\n",
      "[17/100] train_loss: 0.75855 valid_loss: 2.13895\n",
      "Validation loss decreased (2.150463 --> 2.138954).  Saving model ...\n",
      "[18/100] train_loss: 0.75665 valid_loss: 2.12725\n",
      "Validation loss decreased (2.138954 --> 2.127247).  Saving model ...\n",
      "[19/100] train_loss: 0.82590 valid_loss: 2.11378\n",
      "Validation loss decreased (2.127247 --> 2.113781).  Saving model ...\n",
      "[20/100] train_loss: 0.75267 valid_loss: 2.10005\n",
      "Validation loss decreased (2.113781 --> 2.100054).  Saving model ...\n",
      "[21/100] train_loss: 0.77810 valid_loss: 2.08687\n",
      "Validation loss decreased (2.100054 --> 2.086872).  Saving model ...\n",
      "[22/100] train_loss: 0.67704 valid_loss: 2.07143\n",
      "Validation loss decreased (2.086872 --> 2.071430).  Saving model ...\n",
      "[23/100] train_loss: 0.77525 valid_loss: 2.05645\n",
      "Validation loss decreased (2.071430 --> 2.056447).  Saving model ...\n",
      "[24/100] train_loss: 0.77371 valid_loss: 2.04180\n",
      "Validation loss decreased (2.056447 --> 2.041800).  Saving model ...\n",
      "[25/100] train_loss: 0.77212 valid_loss: 2.02736\n",
      "Validation loss decreased (2.041800 --> 2.027359).  Saving model ...\n",
      "[26/100] train_loss: 0.93547 valid_loss: 2.00799\n",
      "Validation loss decreased (2.027359 --> 2.007994).  Saving model ...\n",
      "[27/100] train_loss: 0.92587 valid_loss: 1.98418\n",
      "Validation loss decreased (2.007994 --> 1.984177).  Saving model ...\n",
      "[28/100] train_loss: 0.73420 valid_loss: 1.95973\n",
      "Validation loss decreased (1.984177 --> 1.959728).  Saving model ...\n",
      "[29/100] train_loss: 0.63597 valid_loss: 1.93183\n",
      "Validation loss decreased (1.959728 --> 1.931832).  Saving model ...\n",
      "[30/100] train_loss: 0.76314 valid_loss: 1.90410\n",
      "Validation loss decreased (1.931832 --> 1.904104).  Saving model ...\n",
      "[31/100] train_loss: 0.72418 valid_loss: 1.87510\n",
      "Validation loss decreased (1.904104 --> 1.875102).  Saving model ...\n",
      "[32/100] train_loss: 0.75914 valid_loss: 1.84617\n",
      "Validation loss decreased (1.875102 --> 1.846172).  Saving model ...\n",
      "[33/100] train_loss: 0.60784 valid_loss: 1.81234\n",
      "Validation loss decreased (1.846172 --> 1.812339).  Saving model ...\n",
      "[34/100] train_loss: 0.75492 valid_loss: 1.77894\n",
      "Validation loss decreased (1.812339 --> 1.778939).  Saving model ...\n",
      "[35/100] train_loss: 0.98062 valid_loss: 1.75150\n",
      "Validation loss decreased (1.778939 --> 1.751496).  Saving model ...\n",
      "[36/100] train_loss: 0.97842 valid_loss: 1.73019\n",
      "Validation loss decreased (1.751496 --> 1.730193).  Saving model ...\n",
      "[37/100] train_loss: 0.58748 valid_loss: 1.70518\n",
      "Validation loss decreased (1.730193 --> 1.705181).  Saving model ...\n",
      "[38/100] train_loss: 0.78126 valid_loss: 1.67313\n",
      "Validation loss decreased (1.705181 --> 1.673126).  Saving model ...\n",
      "[39/100] train_loss: 0.76287 valid_loss: 1.63868\n",
      "Validation loss decreased (1.673126 --> 1.638682).  Saving model ...\n",
      "[40/100] train_loss: 0.74144 valid_loss: 1.61332\n",
      "Validation loss decreased (1.638682 --> 1.613321).  Saving model ...\n",
      "[41/100] train_loss: 0.73946 valid_loss: 1.59668\n",
      "Validation loss decreased (1.613321 --> 1.596684).  Saving model ...\n",
      "[42/100] train_loss: 0.96712 valid_loss: 1.59050\n",
      "Validation loss decreased (1.596684 --> 1.590504).  Saving model ...\n",
      "[43/100] train_loss: 0.64253 valid_loss: 1.57695\n",
      "Validation loss decreased (1.590504 --> 1.576947).  Saving model ...\n",
      "[44/100] train_loss: 0.70950 valid_loss: 1.54768\n",
      "Validation loss decreased (1.576947 --> 1.547684).  Saving model ...\n",
      "[45/100] train_loss: 0.68717 valid_loss: 1.51830\n",
      "Validation loss decreased (1.547684 --> 1.518298).  Saving model ...\n",
      "[46/100] train_loss: 0.66403 valid_loss: 1.48514\n",
      "Validation loss decreased (1.518298 --> 1.485141).  Saving model ...\n",
      "[47/100] train_loss: 0.94755 valid_loss: 1.46072\n",
      "Validation loss decreased (1.485141 --> 1.460722).  Saving model ...\n",
      "[48/100] train_loss: 0.66346 valid_loss: 1.43114\n",
      "Validation loss decreased (1.460722 --> 1.431139).  Saving model ...\n",
      "[49/100] train_loss: 0.72977 valid_loss: 1.40548\n",
      "Validation loss decreased (1.431139 --> 1.405478).  Saving model ...\n",
      "[50/100] train_loss: 0.58475 valid_loss: 1.38466\n",
      "Validation loss decreased (1.405478 --> 1.384664).  Saving model ...\n",
      "[51/100] train_loss: 0.65466 valid_loss: 1.36151\n",
      "Validation loss decreased (1.384664 --> 1.361510).  Saving model ...\n",
      "[52/100] train_loss: 0.65503 valid_loss: 1.33555\n",
      "Validation loss decreased (1.361510 --> 1.335548).  Saving model ...\n",
      "[53/100] train_loss: 0.56929 valid_loss: 1.31467\n",
      "Validation loss decreased (1.335548 --> 1.314667).  Saving model ...\n",
      "[54/100] train_loss: 0.92321 valid_loss: 1.29786\n",
      "Validation loss decreased (1.314667 --> 1.297858).  Saving model ...\n",
      "[55/100] train_loss: 0.72801 valid_loss: 1.28260\n",
      "Validation loss decreased (1.297858 --> 1.282601).  Saving model ...\n",
      "[56/100] train_loss: 0.56295 valid_loss: 1.27242\n",
      "Validation loss decreased (1.282601 --> 1.272420).  Saving model ...\n",
      "[57/100] train_loss: 0.72745 valid_loss: 1.26299\n",
      "Validation loss decreased (1.272420 --> 1.262989).  Saving model ...\n",
      "[58/100] train_loss: 0.72712 valid_loss: 1.25392\n",
      "Validation loss decreased (1.262989 --> 1.253924).  Saving model ...\n",
      "[59/100] train_loss: 0.72648 valid_loss: 1.24496\n",
      "Validation loss decreased (1.253924 --> 1.244957).  Saving model ...\n",
      "[60/100] train_loss: 0.66678 valid_loss: 1.23347\n",
      "Validation loss decreased (1.244957 --> 1.233473).  Saving model ...\n",
      "[61/100] train_loss: 0.63642 valid_loss: 1.21493\n",
      "Validation loss decreased (1.233473 --> 1.214932).  Saving model ...\n",
      "[62/100] train_loss: 0.63234 valid_loss: 1.18400\n",
      "Validation loss decreased (1.214932 --> 1.183998).  Saving model ...\n",
      "[63/100] train_loss: 0.61353 valid_loss: 1.15045\n",
      "Validation loss decreased (1.183998 --> 1.150447).  Saving model ...\n",
      "[64/100] train_loss: 0.71297 valid_loss: 1.12143\n",
      "Validation loss decreased (1.150447 --> 1.121427).  Saving model ...\n",
      "[65/100] train_loss: 0.89470 valid_loss: 1.09852\n",
      "Validation loss decreased (1.121427 --> 1.098515).  Saving model ...\n",
      "[66/100] train_loss: 0.70426 valid_loss: 1.07945\n",
      "Validation loss decreased (1.098515 --> 1.079445).  Saving model ...\n",
      "[67/100] train_loss: 0.63313 valid_loss: 1.06189\n",
      "Validation loss decreased (1.079445 --> 1.061893).  Saving model ...\n",
      "[68/100] train_loss: 0.69918 valid_loss: 1.04832\n",
      "Validation loss decreased (1.061893 --> 1.048319).  Saving model ...\n",
      "[69/100] train_loss: 0.87647 valid_loss: 1.03801\n",
      "Validation loss decreased (1.048319 --> 1.038011).  Saving model ...\n",
      "[70/100] train_loss: 0.69634 valid_loss: 1.03136\n",
      "Validation loss decreased (1.038011 --> 1.031356).  Saving model ...\n",
      "[71/100] train_loss: 0.85349 valid_loss: 1.02626\n",
      "Validation loss decreased (1.031356 --> 1.026260).  Saving model ...\n",
      "[72/100] train_loss: 0.70179 valid_loss: 1.03785\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[73/100] train_loss: 0.68082 valid_loss: 1.06238\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[74/100] train_loss: 0.55995 valid_loss: 1.08755\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[75/100] train_loss: 0.62854 valid_loss: 1.10889\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[76/100] train_loss: 0.59886 valid_loss: 1.14020\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[77/100] train_loss: 0.63688 valid_loss: 1.16572\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[78/100] train_loss: 0.58303 valid_loss: 1.17672\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[79/100] train_loss: 0.62352 valid_loss: 1.18222\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[80/100] train_loss: 0.57915 valid_loss: 1.17596\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[81/100] train_loss: 0.58429 valid_loss: 1.16488\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[82/100] train_loss: 0.60389 valid_loss: 1.15377\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[83/100] train_loss: 0.79053 valid_loss: 1.14426\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[84/100] train_loss: 0.66424 valid_loss: 1.13541\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[85/100] train_loss: 0.78326 valid_loss: 1.12801\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[86/100] train_loss: 0.55299 valid_loss: 1.11472\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[87/100] train_loss: 0.55053 valid_loss: 1.09688\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[88/100] train_loss: 0.76647 valid_loss: 1.08119\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[89/100] train_loss: 0.55888 valid_loss: 1.06373\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[90/100] train_loss: 0.54433 valid_loss: 1.04473\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[91/100] train_loss: 0.65513 valid_loss: 1.03068\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[92/100] train_loss: 0.65245 valid_loss: 1.02095\n",
      "Validation loss decreased (1.026260 --> 1.020947).  Saving model ...\n",
      "[93/100] train_loss: 0.53907 valid_loss: 1.01045\n",
      "Validation loss decreased (1.020947 --> 1.010453).  Saving model ...\n",
      "[94/100] train_loss: 0.63259 valid_loss: 1.00887\n",
      "Validation loss decreased (1.010453 --> 1.008873).  Saving model ...\n",
      "[95/100] train_loss: 0.55006 valid_loss: 1.00526\n",
      "Validation loss decreased (1.008873 --> 1.005264).  Saving model ...\n",
      "[96/100] train_loss: 0.55027 valid_loss: 0.99940\n",
      "Validation loss decreased (1.005264 --> 0.999403).  Saving model ...\n",
      "[97/100] train_loss: 0.54908 valid_loss: 0.99147\n",
      "Validation loss decreased (0.999403 --> 0.991470).  Saving model ...\n",
      "[98/100] train_loss: 0.54691 valid_loss: 0.98198\n",
      "Validation loss decreased (0.991470 --> 0.981979).  Saving model ...\n",
      "[99/100] train_loss: 0.52431 valid_loss: 0.96998\n",
      "Validation loss decreased (0.981979 --> 0.969983).  Saving model ...\n",
      "[100/100] train_loss: 0.54235 valid_loss: 0.95809\n",
      "Validation loss decreased (0.969983 --> 0.958095).  Saving model ...\n",
      "  Training 3/5 for Fold 1\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n",
      "[1/100] train_loss: 1.11015 valid_loss: 2.07857\n",
      "Validation loss decreased (inf --> 2.078570).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/100] train_loss: 1.09497 valid_loss: 2.08064\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[3/100] train_loss: 0.98563 valid_loss: 2.07234\n",
      "Validation loss decreased (2.078570 --> 2.072339).  Saving model ...\n",
      "[4/100] train_loss: 0.98348 valid_loss: 2.06026\n",
      "Validation loss decreased (2.072339 --> 2.060263).  Saving model ...\n",
      "[5/100] train_loss: 0.84916 valid_loss: 2.04697\n",
      "Validation loss decreased (2.060263 --> 2.046967).  Saving model ...\n",
      "[6/100] train_loss: 0.77317 valid_loss: 2.03530\n",
      "Validation loss decreased (2.046967 --> 2.035304).  Saving model ...\n",
      "[7/100] train_loss: 0.83874 valid_loss: 2.02224\n",
      "Validation loss decreased (2.035304 --> 2.022241).  Saving model ...\n",
      "[8/100] train_loss: 0.83193 valid_loss: 2.00812\n",
      "Validation loss decreased (2.022241 --> 2.008124).  Saving model ...\n",
      "[9/100] train_loss: 0.76925 valid_loss: 1.99529\n",
      "Validation loss decreased (2.008124 --> 1.995290).  Saving model ...\n",
      "[10/100] train_loss: 0.81669 valid_loss: 1.98124\n",
      "Validation loss decreased (1.995290 --> 1.981238).  Saving model ...\n",
      "[11/100] train_loss: 0.69479 valid_loss: 1.96690\n",
      "Validation loss decreased (1.981238 --> 1.966898).  Saving model ...\n",
      "[12/100] train_loss: 0.81229 valid_loss: 1.95408\n",
      "Validation loss decreased (1.966898 --> 1.954079).  Saving model ...\n",
      "[13/100] train_loss: 0.81105 valid_loss: 1.94256\n",
      "Validation loss decreased (1.954079 --> 1.942564).  Saving model ...\n",
      "[14/100] train_loss: 0.76368 valid_loss: 1.93159\n",
      "Validation loss decreased (1.942564 --> 1.931589).  Saving model ...\n",
      "[15/100] train_loss: 0.80849 valid_loss: 1.92164\n",
      "Validation loss decreased (1.931589 --> 1.921637).  Saving model ...\n",
      "[16/100] train_loss: 0.76132 valid_loss: 1.91195\n",
      "Validation loss decreased (1.921637 --> 1.911949).  Saving model ...\n",
      "[17/100] train_loss: 1.04007 valid_loss: 1.90322\n",
      "Validation loss decreased (1.911949 --> 1.903219).  Saving model ...\n",
      "[18/100] train_loss: 0.76299 valid_loss: 1.89165\n",
      "Validation loss decreased (1.903219 --> 1.891648).  Saving model ...\n",
      "[19/100] train_loss: 0.66141 valid_loss: 1.87864\n",
      "Validation loss decreased (1.891648 --> 1.878636).  Saving model ...\n",
      "[20/100] train_loss: 0.65707 valid_loss: 1.86414\n",
      "Validation loss decreased (1.878636 --> 1.864144).  Saving model ...\n",
      "[21/100] train_loss: 0.65239 valid_loss: 1.84810\n",
      "Validation loss decreased (1.864144 --> 1.848099).  Saving model ...\n",
      "[22/100] train_loss: 0.73339 valid_loss: 1.82889\n",
      "Validation loss decreased (1.848099 --> 1.828894).  Saving model ...\n",
      "[23/100] train_loss: 0.75414 valid_loss: 1.80939\n",
      "Validation loss decreased (1.828894 --> 1.809391).  Saving model ...\n",
      "[24/100] train_loss: 0.71474 valid_loss: 1.78609\n",
      "Validation loss decreased (1.809391 --> 1.786090).  Saving model ...\n",
      "[25/100] train_loss: 1.01224 valid_loss: 1.76335\n",
      "Validation loss decreased (1.786090 --> 1.763349).  Saving model ...\n",
      "[26/100] train_loss: 0.75126 valid_loss: 1.73994\n",
      "Validation loss decreased (1.763349 --> 1.739936).  Saving model ...\n",
      "[27/100] train_loss: 0.90763 valid_loss: 1.71097\n",
      "Validation loss decreased (1.739936 --> 1.710971).  Saving model ...\n",
      "[28/100] train_loss: 0.62243 valid_loss: 1.68168\n",
      "Validation loss decreased (1.710971 --> 1.681677).  Saving model ...\n",
      "[29/100] train_loss: 0.74745 valid_loss: 1.65220\n",
      "Validation loss decreased (1.681677 --> 1.652203).  Saving model ...\n",
      "[30/100] train_loss: 0.88829 valid_loss: 1.61707\n",
      "Validation loss decreased (1.652203 --> 1.617071).  Saving model ...\n",
      "[31/100] train_loss: 0.99474 valid_loss: 1.58260\n",
      "Validation loss decreased (1.617071 --> 1.582602).  Saving model ...\n",
      "[32/100] train_loss: 0.65289 valid_loss: 1.54344\n",
      "Validation loss decreased (1.582602 --> 1.543445).  Saving model ...\n",
      "[33/100] train_loss: 0.86175 valid_loss: 1.49882\n",
      "Validation loss decreased (1.543445 --> 1.498820).  Saving model ...\n",
      "[34/100] train_loss: 0.77922 valid_loss: 1.45772\n",
      "Validation loss decreased (1.498820 --> 1.457723).  Saving model ...\n",
      "[35/100] train_loss: 0.65499 valid_loss: 1.44516\n",
      "Validation loss decreased (1.457723 --> 1.445159).  Saving model ...\n",
      "[36/100] train_loss: 0.65147 valid_loss: 1.44858\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[37/100] train_loss: 0.98411 valid_loss: 1.45121\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[38/100] train_loss: 0.73370 valid_loss: 1.45303\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[39/100] train_loss: 0.97871 valid_loss: 1.45400\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[40/100] train_loss: 0.61935 valid_loss: 1.46256\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[41/100] train_loss: 0.63249 valid_loss: 1.46432\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[42/100] train_loss: 0.82861 valid_loss: 1.45611\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[43/100] train_loss: 0.96341 valid_loss: 1.44776\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[44/100] train_loss: 0.73093 valid_loss: 1.43894\n",
      "Validation loss decreased (1.445159 --> 1.438944).  Saving model ...\n",
      "[45/100] train_loss: 0.60472 valid_loss: 1.43591\n",
      "Validation loss decreased (1.438944 --> 1.435906).  Saving model ...\n",
      "[46/100] train_loss: 0.81309 valid_loss: 1.42261\n",
      "Validation loss decreased (1.435906 --> 1.422608).  Saving model ...\n",
      "[47/100] train_loss: 0.60245 valid_loss: 1.41529\n",
      "Validation loss decreased (1.422608 --> 1.415290).  Saving model ...\n",
      "[48/100] train_loss: 0.79744 valid_loss: 1.39789\n",
      "Validation loss decreased (1.415290 --> 1.397893).  Saving model ...\n",
      "[49/100] train_loss: 0.60156 valid_loss: 1.38722\n",
      "Validation loss decreased (1.397893 --> 1.387224).  Saving model ...\n",
      "[50/100] train_loss: 0.71882 valid_loss: 1.37575\n",
      "Validation loss decreased (1.387224 --> 1.375754).  Saving model ...\n",
      "[51/100] train_loss: 0.94564 valid_loss: 1.36457\n",
      "Validation loss decreased (1.375754 --> 1.364565).  Saving model ...\n",
      "[52/100] train_loss: 0.60056 valid_loss: 1.36019\n",
      "Validation loss decreased (1.364565 --> 1.360192).  Saving model ...\n",
      "[53/100] train_loss: 0.93969 valid_loss: 1.35548\n",
      "Validation loss decreased (1.360192 --> 1.355477).  Saving model ...\n",
      "[54/100] train_loss: 0.70875 valid_loss: 1.34871\n",
      "Validation loss decreased (1.355477 --> 1.348715).  Saving model ...\n",
      "[55/100] train_loss: 0.64372 valid_loss: 1.33523\n",
      "Validation loss decreased (1.348715 --> 1.335229).  Saving model ...\n",
      "[56/100] train_loss: 0.70338 valid_loss: 1.32065\n",
      "Validation loss decreased (1.335229 --> 1.320645).  Saving model ...\n",
      "[57/100] train_loss: 0.63672 valid_loss: 1.30141\n",
      "Validation loss decreased (1.320645 --> 1.301411).  Saving model ...\n",
      "[58/100] train_loss: 0.91645 valid_loss: 1.28461\n",
      "Validation loss decreased (1.301411 --> 1.284613).  Saving model ...\n",
      "[59/100] train_loss: 0.69228 valid_loss: 1.26763\n",
      "Validation loss decreased (1.284613 --> 1.267632).  Saving model ...\n",
      "[60/100] train_loss: 0.90311 valid_loss: 1.25318\n",
      "Validation loss decreased (1.267632 --> 1.253178).  Saving model ...\n",
      "[61/100] train_loss: 0.63341 valid_loss: 1.25349\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[62/100] train_loss: 0.64309 valid_loss: 1.24002\n",
      "Validation loss decreased (1.253178 --> 1.240020).  Saving model ...\n",
      "[63/100] train_loss: 0.74507 valid_loss: 1.22807\n",
      "Validation loss decreased (1.240020 --> 1.228067).  Saving model ...\n",
      "[64/100] train_loss: 0.87199 valid_loss: 1.21713\n",
      "Validation loss decreased (1.228067 --> 1.217126).  Saving model ...\n",
      "[65/100] train_loss: 0.73917 valid_loss: 1.20767\n",
      "Validation loss decreased (1.217126 --> 1.207671).  Saving model ...\n",
      "[66/100] train_loss: 0.85336 valid_loss: 1.19903\n",
      "Validation loss decreased (1.207671 --> 1.199027).  Saving model ...\n",
      "[67/100] train_loss: 0.73208 valid_loss: 1.19180\n",
      "Validation loss decreased (1.199027 --> 1.191799).  Saving model ...\n",
      "[68/100] train_loss: 0.59242 valid_loss: 1.17237\n",
      "Validation loss decreased (1.191799 --> 1.172375).  Saving model ...\n",
      "[69/100] train_loss: 0.65494 valid_loss: 1.15154\n",
      "Validation loss decreased (1.172375 --> 1.151544).  Saving model ...\n",
      "[70/100] train_loss: 0.59021 valid_loss: 1.13166\n",
      "Validation loss decreased (1.151544 --> 1.131658).  Saving model ...\n",
      "[71/100] train_loss: 0.72035 valid_loss: 1.11341\n",
      "Validation loss decreased (1.131658 --> 1.113412).  Saving model ...\n",
      "[72/100] train_loss: 0.64123 valid_loss: 1.09483\n",
      "Validation loss decreased (1.113412 --> 1.094834).  Saving model ...\n",
      "[73/100] train_loss: 0.73775 valid_loss: 1.09508\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[74/100] train_loss: 0.58562 valid_loss: 1.09787\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[75/100] train_loss: 0.72962 valid_loss: 1.10167\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[76/100] train_loss: 0.66285 valid_loss: 1.12032\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[77/100] train_loss: 0.58763 valid_loss: 1.13741\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[78/100] train_loss: 0.64437 valid_loss: 1.14835\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[79/100] train_loss: 0.60735 valid_loss: 1.16880\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[80/100] train_loss: 0.73839 valid_loss: 1.18685\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[81/100] train_loss: 0.73539 valid_loss: 1.20191\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[82/100] train_loss: 0.72943 valid_loss: 1.21370\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[83/100] train_loss: 0.76134 valid_loss: 1.22331\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[84/100] train_loss: 0.75967 valid_loss: 1.23106\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[85/100] train_loss: 0.62436 valid_loss: 1.23480\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[86/100] train_loss: 0.57449 valid_loss: 1.24288\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[87/100] train_loss: 0.62212 valid_loss: 1.24825\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[88/100] train_loss: 0.57086 valid_loss: 1.25713\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[89/100] train_loss: 0.56863 valid_loss: 1.26880\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[90/100] train_loss: 0.69259 valid_loss: 1.27637\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[91/100] train_loss: 0.56422 valid_loss: 1.28600\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[92/100] train_loss: 0.63667 valid_loss: 1.28870\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[93/100] train_loss: 0.68085 valid_loss: 1.28870\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[94/100] train_loss: 0.72169 valid_loss: 1.28874\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[95/100] train_loss: 0.59068 valid_loss: 1.27355\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[96/100] train_loss: 0.56054 valid_loss: 1.26272\n",
      "EarlyStopping counter: 24 out of 100\n",
      "[97/100] train_loss: 0.66598 valid_loss: 1.25337\n",
      "EarlyStopping counter: 25 out of 100\n",
      "[98/100] train_loss: 0.56073 valid_loss: 1.24882\n",
      "EarlyStopping counter: 26 out of 100\n",
      "[99/100] train_loss: 0.62495 valid_loss: 1.25202\n",
      "EarlyStopping counter: 27 out of 100\n",
      "[100/100] train_loss: 0.61923 valid_loss: 1.26192\n",
      "EarlyStopping counter: 28 out of 100\n",
      "  Training 4/5 for Fold 1\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] train_loss: 0.77952 valid_loss: 2.22355\n",
      "Validation loss decreased (inf --> 2.223555).  Saving model ...\n",
      "[2/100] train_loss: 0.99883 valid_loss: 2.20363\n",
      "Validation loss decreased (2.223555 --> 2.203627).  Saving model ...\n",
      "[3/100] train_loss: 0.80122 valid_loss: 2.18711\n",
      "Validation loss decreased (2.203627 --> 2.187114).  Saving model ...\n",
      "[4/100] train_loss: 0.85842 valid_loss: 2.16915\n",
      "Validation loss decreased (2.187114 --> 2.169148).  Saving model ...\n",
      "[5/100] train_loss: 0.70572 valid_loss: 2.14931\n",
      "Validation loss decreased (2.169148 --> 2.149314).  Saving model ...\n",
      "[6/100] train_loss: 1.00678 valid_loss: 2.13554\n",
      "Validation loss decreased (2.149314 --> 2.135543).  Saving model ...\n",
      "[7/100] train_loss: 0.95890 valid_loss: 2.11813\n",
      "Validation loss decreased (2.135543 --> 2.118132).  Saving model ...\n",
      "[8/100] train_loss: 0.69042 valid_loss: 2.09948\n",
      "Validation loss decreased (2.118132 --> 2.099477).  Saving model ...\n",
      "[9/100] train_loss: 0.82781 valid_loss: 2.08036\n",
      "Validation loss decreased (2.099477 --> 2.080363).  Saving model ...\n",
      "[10/100] train_loss: 0.79475 valid_loss: 2.06292\n",
      "Validation loss decreased (2.080363 --> 2.062916).  Saving model ...\n",
      "[11/100] train_loss: 1.00145 valid_loss: 2.04868\n",
      "Validation loss decreased (2.062916 --> 2.048681).  Saving model ...\n",
      "[12/100] train_loss: 0.75826 valid_loss: 2.03446\n",
      "Validation loss decreased (2.048681 --> 2.034459).  Saving model ...\n",
      "[13/100] train_loss: 0.79164 valid_loss: 2.02116\n",
      "Validation loss decreased (2.034459 --> 2.021156).  Saving model ...\n",
      "[14/100] train_loss: 0.66264 valid_loss: 2.00550\n",
      "Validation loss decreased (2.021156 --> 2.005503).  Saving model ...\n",
      "[15/100] train_loss: 0.78936 valid_loss: 1.99061\n",
      "Validation loss decreased (2.005503 --> 1.990613).  Saving model ...\n",
      "[16/100] train_loss: 0.65426 valid_loss: 1.97310\n",
      "Validation loss decreased (1.990613 --> 1.973097).  Saving model ...\n",
      "[17/100] train_loss: 0.64970 valid_loss: 1.95293\n",
      "Validation loss decreased (1.973097 --> 1.952935).  Saving model ...\n",
      "[18/100] train_loss: 0.75099 valid_loss: 1.93210\n",
      "Validation loss decreased (1.952935 --> 1.932104).  Saving model ...\n",
      "[19/100] train_loss: 0.74926 valid_loss: 1.91049\n",
      "Validation loss decreased (1.932104 --> 1.910491).  Saving model ...\n",
      "[20/100] train_loss: 0.89527 valid_loss: 1.88364\n",
      "Validation loss decreased (1.910491 --> 1.883643).  Saving model ...\n",
      "[21/100] train_loss: 0.97832 valid_loss: 1.85943\n",
      "Validation loss decreased (1.883643 --> 1.859433).  Saving model ...\n",
      "[22/100] train_loss: 0.74624 valid_loss: 1.83152\n",
      "Validation loss decreased (1.859433 --> 1.831520).  Saving model ...\n",
      "[23/100] train_loss: 0.97272 valid_loss: 1.80604\n",
      "Validation loss decreased (1.831520 --> 1.806039).  Saving model ...\n",
      "[24/100] train_loss: 0.77665 valid_loss: 1.78082\n",
      "Validation loss decreased (1.806039 --> 1.780820).  Saving model ...\n",
      "[25/100] train_loss: 0.96216 valid_loss: 1.75769\n",
      "Validation loss decreased (1.780820 --> 1.757694).  Saving model ...\n",
      "[26/100] train_loss: 0.85566 valid_loss: 1.72638\n",
      "Validation loss decreased (1.757694 --> 1.726378).  Saving model ...\n",
      "[27/100] train_loss: 0.94902 valid_loss: 1.69721\n",
      "Validation loss decreased (1.726378 --> 1.697213).  Saving model ...\n",
      "[28/100] train_loss: 0.84040 valid_loss: 1.65999\n",
      "Validation loss decreased (1.697213 --> 1.659986).  Saving model ...\n",
      "[29/100] train_loss: 0.82910 valid_loss: 1.61570\n",
      "Validation loss decreased (1.659986 --> 1.615696).  Saving model ...\n",
      "[30/100] train_loss: 0.72736 valid_loss: 1.57242\n",
      "Validation loss decreased (1.615696 --> 1.572423).  Saving model ...\n",
      "[31/100] train_loss: 0.72386 valid_loss: 1.53084\n",
      "Validation loss decreased (1.572423 --> 1.530845).  Saving model ...\n",
      "[32/100] train_loss: 0.76045 valid_loss: 1.49304\n",
      "Validation loss decreased (1.530845 --> 1.493044).  Saving model ...\n",
      "[33/100] train_loss: 0.75833 valid_loss: 1.45038\n",
      "Validation loss decreased (1.493044 --> 1.450379).  Saving model ...\n",
      "[34/100] train_loss: 0.92276 valid_loss: 1.41637\n",
      "Validation loss decreased (1.450379 --> 1.416373).  Saving model ...\n",
      "[35/100] train_loss: 0.70672 valid_loss: 1.38723\n",
      "Validation loss decreased (1.416373 --> 1.387231).  Saving model ...\n",
      "[36/100] train_loss: 0.68617 valid_loss: 1.35461\n",
      "Validation loss decreased (1.387231 --> 1.354609).  Saving model ...\n",
      "[37/100] train_loss: 0.66032 valid_loss: 1.31897\n",
      "Validation loss decreased (1.354609 --> 1.318969).  Saving model ...\n",
      "[38/100] train_loss: 0.74846 valid_loss: 1.29006\n",
      "Validation loss decreased (1.318969 --> 1.290064).  Saving model ...\n",
      "[39/100] train_loss: 0.63472 valid_loss: 1.24709\n",
      "Validation loss decreased (1.290064 --> 1.247091).  Saving model ...\n",
      "[40/100] train_loss: 0.75260 valid_loss: 1.20797\n",
      "Validation loss decreased (1.247091 --> 1.207966).  Saving model ...\n",
      "[41/100] train_loss: 0.75248 valid_loss: 1.17237\n",
      "Validation loss decreased (1.207966 --> 1.172372).  Saving model ...\n",
      "[42/100] train_loss: 0.89653 valid_loss: 1.14129\n",
      "Validation loss decreased (1.172372 --> 1.141293).  Saving model ...\n",
      "[43/100] train_loss: 0.70500 valid_loss: 1.11034\n",
      "Validation loss decreased (1.141293 --> 1.110343).  Saving model ...\n",
      "[44/100] train_loss: 0.87647 valid_loss: 1.08478\n",
      "Validation loss decreased (1.110343 --> 1.084776).  Saving model ...\n",
      "[45/100] train_loss: 0.72864 valid_loss: 1.06348\n",
      "Validation loss decreased (1.084776 --> 1.063482).  Saving model ...\n",
      "[46/100] train_loss: 0.83316 valid_loss: 1.05816\n",
      "Validation loss decreased (1.063482 --> 1.058161).  Saving model ...\n",
      "[47/100] train_loss: 0.60522 valid_loss: 1.05701\n",
      "Validation loss decreased (1.058161 --> 1.057012).  Saving model ...\n",
      "[48/100] train_loss: 0.66748 valid_loss: 1.05927\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[49/100] train_loss: 0.67049 valid_loss: 1.06242\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[50/100] train_loss: 0.74205 valid_loss: 1.06679\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[51/100] train_loss: 0.62703 valid_loss: 1.06545\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[52/100] train_loss: 0.59742 valid_loss: 1.05529\n",
      "Validation loss decreased (1.057012 --> 1.055289).  Saving model ...\n",
      "[53/100] train_loss: 0.74284 valid_loss: 1.04550\n",
      "Validation loss decreased (1.055289 --> 1.045496).  Saving model ...\n",
      "[54/100] train_loss: 0.63057 valid_loss: 1.04816\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[55/100] train_loss: 0.65756 valid_loss: 1.04798\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[56/100] train_loss: 0.73964 valid_loss: 1.04687\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[57/100] train_loss: 0.73743 valid_loss: 1.04472\n",
      "Validation loss decreased (1.045496 --> 1.044723).  Saving model ...\n",
      "[58/100] train_loss: 0.63606 valid_loss: 1.03634\n",
      "Validation loss decreased (1.044723 --> 1.036339).  Saving model ...\n",
      "[59/100] train_loss: 0.62138 valid_loss: 1.04006\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[60/100] train_loss: 0.57936 valid_loss: 1.03853\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[61/100] train_loss: 0.61679 valid_loss: 1.03116\n",
      "Validation loss decreased (1.036339 --> 1.031156).  Saving model ...\n",
      "[62/100] train_loss: 0.71518 valid_loss: 1.02334\n",
      "Validation loss decreased (1.031156 --> 1.023344).  Saving model ...\n",
      "[63/100] train_loss: 0.70881 valid_loss: 1.01556\n",
      "Validation loss decreased (1.023344 --> 1.015560).  Saving model ...\n",
      "[64/100] train_loss: 0.57236 valid_loss: 1.00745\n",
      "Validation loss decreased (1.015560 --> 1.007445).  Saving model ...\n",
      "[65/100] train_loss: 0.81449 valid_loss: 1.00054\n",
      "Validation loss decreased (1.007445 --> 1.000537).  Saving model ...\n",
      "[66/100] train_loss: 0.81118 valid_loss: 0.99468\n",
      "Validation loss decreased (1.000537 --> 0.994683).  Saving model ...\n",
      "[67/100] train_loss: 0.67786 valid_loss: 0.99946\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[68/100] train_loss: 0.56851 valid_loss: 1.00424\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[69/100] train_loss: 0.79083 valid_loss: 1.00842\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[70/100] train_loss: 0.57610 valid_loss: 1.01074\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[71/100] train_loss: 0.64182 valid_loss: 1.01916\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[72/100] train_loss: 0.76794 valid_loss: 1.02641\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[73/100] train_loss: 0.76004 valid_loss: 1.03248\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[74/100] train_loss: 0.68067 valid_loss: 1.03668\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[75/100] train_loss: 0.57499 valid_loss: 1.03904\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[76/100] train_loss: 0.73908 valid_loss: 1.04049\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[77/100] train_loss: 0.73286 valid_loss: 1.04110\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[78/100] train_loss: 0.64247 valid_loss: 1.05619\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[79/100] train_loss: 0.62023 valid_loss: 1.06437\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[80/100] train_loss: 0.57268 valid_loss: 1.06999\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[81/100] train_loss: 0.71475 valid_loss: 1.07456\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[82/100] train_loss: 0.60522 valid_loss: 1.07384\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[83/100] train_loss: 0.62154 valid_loss: 1.08624\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[84/100] train_loss: 0.59169 valid_loss: 1.09530\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[85/100] train_loss: 0.56233 valid_loss: 1.09607\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[86/100] train_loss: 0.70232 valid_loss: 1.09630\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[87/100] train_loss: 0.65307 valid_loss: 1.09528\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[88/100] train_loss: 0.59260 valid_loss: 1.09670\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[89/100] train_loss: 0.55816 valid_loss: 1.09116\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[90/100] train_loss: 0.64667 valid_loss: 1.08716\n",
      "EarlyStopping counter: 24 out of 100\n",
      "[91/100] train_loss: 0.60854 valid_loss: 1.09639\n",
      "EarlyStopping counter: 25 out of 100\n",
      "[92/100] train_loss: 0.60262 valid_loss: 1.11719\n",
      "EarlyStopping counter: 26 out of 100\n",
      "[93/100] train_loss: 0.64282 valid_loss: 1.13794\n",
      "EarlyStopping counter: 27 out of 100\n",
      "[94/100] train_loss: 0.68971 valid_loss: 1.15739\n",
      "EarlyStopping counter: 28 out of 100\n",
      "[95/100] train_loss: 0.57586 valid_loss: 1.16892\n",
      "EarlyStopping counter: 29 out of 100\n",
      "[96/100] train_loss: 0.57101 valid_loss: 1.18919\n",
      "EarlyStopping counter: 30 out of 100\n",
      "[97/100] train_loss: 0.58492 valid_loss: 1.20933\n",
      "EarlyStopping counter: 31 out of 100\n",
      "[98/100] train_loss: 0.68473 valid_loss: 1.22823\n",
      "EarlyStopping counter: 32 out of 100\n",
      "[99/100] train_loss: 0.55531 valid_loss: 1.25286\n",
      "EarlyStopping counter: 33 out of 100\n",
      "[100/100] train_loss: 0.55100 valid_loss: 1.28176\n",
      "EarlyStopping counter: 34 out of 100\n",
      "  Training 5/5 for Fold 1\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n",
      "[1/100] train_loss: 0.97677 valid_loss: 2.10664\n",
      "Validation loss decreased (inf --> 2.106642).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/100] train_loss: 1.03504 valid_loss: 2.09586\n",
      "Validation loss decreased (2.106642 --> 2.095864).  Saving model ...\n",
      "[3/100] train_loss: 0.85491 valid_loss: 2.08354\n",
      "Validation loss decreased (2.095864 --> 2.083536).  Saving model ...\n",
      "[4/100] train_loss: 0.95617 valid_loss: 2.06768\n",
      "Validation loss decreased (2.083536 --> 2.067680).  Saving model ...\n",
      "[5/100] train_loss: 1.02503 valid_loss: 2.05556\n",
      "Validation loss decreased (2.067680 --> 2.055561).  Saving model ...\n",
      "[6/100] train_loss: 0.69468 valid_loss: 2.04215\n",
      "Validation loss decreased (2.055561 --> 2.042149).  Saving model ...\n",
      "[7/100] train_loss: 1.01701 valid_loss: 2.03121\n",
      "Validation loss decreased (2.042149 --> 2.031212).  Saving model ...\n",
      "[8/100] train_loss: 0.94004 valid_loss: 2.01705\n",
      "Validation loss decreased (2.031212 --> 2.017051).  Saving model ...\n",
      "[9/100] train_loss: 0.82880 valid_loss: 2.00206\n",
      "Validation loss decreased (2.017051 --> 2.002064).  Saving model ...\n",
      "[10/100] train_loss: 0.79663 valid_loss: 1.98825\n",
      "Validation loss decreased (2.002064 --> 1.988250).  Saving model ...\n",
      "[11/100] train_loss: 0.81852 valid_loss: 1.97337\n",
      "Validation loss decreased (1.988250 --> 1.973373).  Saving model ...\n",
      "[12/100] train_loss: 0.67077 valid_loss: 1.95725\n",
      "Validation loss decreased (1.973373 --> 1.957253).  Saving model ...\n",
      "[13/100] train_loss: 0.66608 valid_loss: 1.93983\n",
      "Validation loss decreased (1.957253 --> 1.939829).  Saving model ...\n",
      "[14/100] train_loss: 0.99378 valid_loss: 1.92422\n",
      "Validation loss decreased (1.939829 --> 1.924219).  Saving model ...\n",
      "[15/100] train_loss: 0.98959 valid_loss: 1.91007\n",
      "Validation loss decreased (1.924219 --> 1.910070).  Saving model ...\n",
      "[16/100] train_loss: 0.90818 valid_loss: 1.89164\n",
      "Validation loss decreased (1.910070 --> 1.891637).  Saving model ...\n",
      "[17/100] train_loss: 0.97965 valid_loss: 1.87445\n",
      "Validation loss decreased (1.891637 --> 1.874446).  Saving model ...\n",
      "[18/100] train_loss: 0.77556 valid_loss: 1.85501\n",
      "Validation loss decreased (1.874446 --> 1.855014).  Saving model ...\n",
      "[19/100] train_loss: 0.63982 valid_loss: 1.83334\n",
      "Validation loss decreased (1.855014 --> 1.833342).  Saving model ...\n",
      "[20/100] train_loss: 0.74164 valid_loss: 1.81093\n",
      "Validation loss decreased (1.833342 --> 1.810931).  Saving model ...\n",
      "[21/100] train_loss: 0.75433 valid_loss: 1.78544\n",
      "Validation loss decreased (1.810931 --> 1.785436).  Saving model ...\n",
      "[22/100] train_loss: 0.74565 valid_loss: 1.75654\n",
      "Validation loss decreased (1.785436 --> 1.756544).  Saving model ...\n",
      "[23/100] train_loss: 0.73752 valid_loss: 1.72641\n",
      "Validation loss decreased (1.756544 --> 1.726409).  Saving model ...\n",
      "[24/100] train_loss: 0.73583 valid_loss: 1.69494\n",
      "Validation loss decreased (1.726409 --> 1.694939).  Saving model ...\n",
      "[25/100] train_loss: 0.73381 valid_loss: 1.66208\n",
      "Validation loss decreased (1.694939 --> 1.662083).  Saving model ...\n",
      "[26/100] train_loss: 0.73143 valid_loss: 1.62785\n",
      "Validation loss decreased (1.662083 --> 1.627850).  Saving model ...\n",
      "[27/100] train_loss: 0.83813 valid_loss: 1.58610\n",
      "Validation loss decreased (1.627850 --> 1.586103).  Saving model ...\n",
      "[28/100] train_loss: 0.94419 valid_loss: 1.54642\n",
      "Validation loss decreased (1.586103 --> 1.546417).  Saving model ...\n",
      "[29/100] train_loss: 0.68286 valid_loss: 1.50075\n",
      "Validation loss decreased (1.546417 --> 1.500752).  Saving model ...\n",
      "[30/100] train_loss: 0.61595 valid_loss: 1.46401\n",
      "Validation loss decreased (1.500752 --> 1.464009).  Saving model ...\n",
      "[31/100] train_loss: 0.71702 valid_loss: 1.42754\n",
      "Validation loss decreased (1.464009 --> 1.427542).  Saving model ...\n",
      "[32/100] train_loss: 0.71426 valid_loss: 1.39188\n",
      "Validation loss decreased (1.427542 --> 1.391877).  Saving model ...\n",
      "[33/100] train_loss: 0.63482 valid_loss: 1.37804\n",
      "Validation loss decreased (1.391877 --> 1.378041).  Saving model ...\n",
      "[34/100] train_loss: 0.74937 valid_loss: 1.35068\n",
      "Validation loss decreased (1.378041 --> 1.350680).  Saving model ...\n",
      "[35/100] train_loss: 0.70547 valid_loss: 1.32383\n",
      "Validation loss decreased (1.350680 --> 1.323831).  Saving model ...\n",
      "[36/100] train_loss: 0.71855 valid_loss: 1.28814\n",
      "Validation loss decreased (1.323831 --> 1.288141).  Saving model ...\n",
      "[37/100] train_loss: 0.65349 valid_loss: 1.27230\n",
      "Validation loss decreased (1.288141 --> 1.272304).  Saving model ...\n",
      "[38/100] train_loss: 0.69347 valid_loss: 1.25579\n",
      "Validation loss decreased (1.272304 --> 1.255787).  Saving model ...\n",
      "[39/100] train_loss: 0.69043 valid_loss: 1.23857\n",
      "Validation loss decreased (1.255787 --> 1.238566).  Saving model ...\n",
      "[40/100] train_loss: 0.95587 valid_loss: 1.22419\n",
      "Validation loss decreased (1.238566 --> 1.224194).  Saving model ...\n",
      "[41/100] train_loss: 0.95520 valid_loss: 1.21244\n",
      "Validation loss decreased (1.224194 --> 1.212437).  Saving model ...\n",
      "[42/100] train_loss: 0.64467 valid_loss: 1.19012\n",
      "Validation loss decreased (1.212437 --> 1.190122).  Saving model ...\n",
      "[43/100] train_loss: 0.65272 valid_loss: 1.18249\n",
      "Validation loss decreased (1.190122 --> 1.182492).  Saving model ...\n",
      "[44/100] train_loss: 0.74850 valid_loss: 1.17570\n",
      "Validation loss decreased (1.182492 --> 1.175704).  Saving model ...\n",
      "[45/100] train_loss: 0.74719 valid_loss: 1.16954\n",
      "Validation loss decreased (1.175704 --> 1.169540).  Saving model ...\n",
      "[46/100] train_loss: 0.62076 valid_loss: 1.15325\n",
      "Validation loss decreased (1.169540 --> 1.153248).  Saving model ...\n",
      "[47/100] train_loss: 0.74405 valid_loss: 1.13848\n",
      "Validation loss decreased (1.153248 --> 1.138478).  Saving model ...\n",
      "[48/100] train_loss: 0.60442 valid_loss: 1.11665\n",
      "Validation loss decreased (1.138478 --> 1.116649).  Saving model ...\n",
      "[49/100] train_loss: 0.73999 valid_loss: 1.09766\n",
      "Validation loss decreased (1.116649 --> 1.097661).  Saving model ...\n",
      "[50/100] train_loss: 0.63262 valid_loss: 1.07688\n",
      "Validation loss decreased (1.097661 --> 1.076880).  Saving model ...\n",
      "[51/100] train_loss: 0.62506 valid_loss: 1.05600\n",
      "Validation loss decreased (1.076880 --> 1.055997).  Saving model ...\n",
      "[52/100] train_loss: 0.92708 valid_loss: 1.04076\n",
      "Validation loss decreased (1.055997 --> 1.040757).  Saving model ...\n",
      "[53/100] train_loss: 0.58354 valid_loss: 1.02422\n",
      "Validation loss decreased (1.040757 --> 1.024220).  Saving model ...\n",
      "[54/100] train_loss: 0.74037 valid_loss: 1.01966\n",
      "Validation loss decreased (1.024220 --> 1.019657).  Saving model ...\n",
      "[55/100] train_loss: 0.57692 valid_loss: 1.01541\n",
      "Validation loss decreased (1.019657 --> 1.015410).  Saving model ...\n",
      "[56/100] train_loss: 0.57144 valid_loss: 1.01155\n",
      "Validation loss decreased (1.015410 --> 1.011546).  Saving model ...\n",
      "[57/100] train_loss: 0.65776 valid_loss: 1.01271\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[58/100] train_loss: 0.61081 valid_loss: 1.01150\n",
      "Validation loss decreased (1.011546 --> 1.011501).  Saving model ...\n",
      "[59/100] train_loss: 0.57022 valid_loss: 1.00542\n",
      "Validation loss decreased (1.011501 --> 1.005425).  Saving model ...\n",
      "[60/100] train_loss: 0.57118 valid_loss: 0.99366\n",
      "Validation loss decreased (1.005425 --> 0.993658).  Saving model ...\n",
      "[61/100] train_loss: 0.63517 valid_loss: 0.98147\n",
      "Validation loss decreased (0.993658 --> 0.981472).  Saving model ...\n",
      "[62/100] train_loss: 0.85674 valid_loss: 0.97040\n",
      "Validation loss decreased (0.981472 --> 0.970397).  Saving model ...\n",
      "[63/100] train_loss: 0.59933 valid_loss: 0.95604\n",
      "Validation loss decreased (0.970397 --> 0.956043).  Saving model ...\n",
      "[64/100] train_loss: 0.72055 valid_loss: 0.94238\n",
      "Validation loss decreased (0.956043 --> 0.942381).  Saving model ...\n",
      "[65/100] train_loss: 0.55625 valid_loss: 0.92534\n",
      "Validation loss decreased (0.942381 --> 0.925343).  Saving model ...\n",
      "[66/100] train_loss: 0.68356 valid_loss: 0.92854\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[67/100] train_loss: 0.58387 valid_loss: 0.92955\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[68/100] train_loss: 0.55002 valid_loss: 0.92631\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[69/100] train_loss: 0.81882 valid_loss: 0.92298\n",
      "Validation loss decreased (0.925343 --> 0.922985).  Saving model ...\n",
      "[70/100] train_loss: 0.61804 valid_loss: 0.91713\n",
      "Validation loss decreased (0.922985 --> 0.917132).  Saving model ...\n",
      "[71/100] train_loss: 0.61064 valid_loss: 0.91003\n",
      "Validation loss decreased (0.917132 --> 0.910032).  Saving model ...\n",
      "[72/100] train_loss: 0.57656 valid_loss: 0.90365\n",
      "Validation loss decreased (0.910032 --> 0.903649).  Saving model ...\n",
      "[73/100] train_loss: 0.69415 valid_loss: 0.89819\n",
      "Validation loss decreased (0.903649 --> 0.898192).  Saving model ...\n",
      "[74/100] train_loss: 0.60573 valid_loss: 0.89698\n",
      "Validation loss decreased (0.898192 --> 0.896980).  Saving model ...\n",
      "[75/100] train_loss: 0.57514 valid_loss: 0.89699\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[76/100] train_loss: 0.68153 valid_loss: 0.89828\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[77/100] train_loss: 0.73507 valid_loss: 0.91299\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[78/100] train_loss: 0.78600 valid_loss: 0.92698\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[79/100] train_loss: 0.60290 valid_loss: 0.94438\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[80/100] train_loss: 0.59262 valid_loss: 0.96363\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[81/100] train_loss: 0.57174 valid_loss: 0.97991\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[82/100] train_loss: 0.63289 valid_loss: 1.00762\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[83/100] train_loss: 0.71116 valid_loss: 1.03243\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[84/100] train_loss: 0.61819 valid_loss: 1.04934\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[85/100] train_loss: 0.60409 valid_loss: 1.05970\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[86/100] train_loss: 0.58667 valid_loss: 1.07810\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[87/100] train_loss: 0.76107 valid_loss: 1.09446\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[88/100] train_loss: 0.67708 valid_loss: 1.10715\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[89/100] train_loss: 0.66924 valid_loss: 1.11726\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[90/100] train_loss: 0.59978 valid_loss: 1.12068\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[91/100] train_loss: 0.57066 valid_loss: 1.13124\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[92/100] train_loss: 0.56916 valid_loss: 1.14815\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[93/100] train_loss: 0.56526 valid_loss: 1.17084\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[94/100] train_loss: 0.55994 valid_loss: 1.19870\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[95/100] train_loss: 0.77158 valid_loss: 1.22974\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[96/100] train_loss: 0.60126 valid_loss: 1.26215\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[97/100] train_loss: 0.61999 valid_loss: 1.28347\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[98/100] train_loss: 0.59432 valid_loss: 1.30372\n",
      "EarlyStopping counter: 24 out of 100\n",
      "[99/100] train_loss: 0.60589 valid_loss: 1.30342\n",
      "EarlyStopping counter: 25 out of 100\n",
      "[100/100] train_loss: 0.62246 valid_loss: 1.29433\n",
      "EarlyStopping counter: 26 out of 100\n",
      "  Fold 2/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training 1/5 for Fold 2\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n",
      "[1/100] train_loss: 0.78481 valid_loss: 0.96846\n",
      "Validation loss decreased (inf --> 0.968464).  Saving model ...\n",
      "[2/100] train_loss: 0.72352 valid_loss: 0.95960\n",
      "Validation loss decreased (0.968464 --> 0.959595).  Saving model ...\n",
      "[3/100] train_loss: 0.77689 valid_loss: 0.95044\n",
      "Validation loss decreased (0.959595 --> 0.950441).  Saving model ...\n",
      "[4/100] train_loss: 0.77380 valid_loss: 0.94131\n",
      "Validation loss decreased (0.950441 --> 0.941308).  Saving model ...\n",
      "[5/100] train_loss: 1.00704 valid_loss: 0.93913\n",
      "Validation loss decreased (0.941308 --> 0.939128).  Saving model ...\n",
      "[6/100] train_loss: 1.00403 valid_loss: 0.93968\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[7/100] train_loss: 0.84878 valid_loss: 0.94064\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[8/100] train_loss: 0.76930 valid_loss: 0.94041\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[9/100] train_loss: 0.79670 valid_loss: 0.94015\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[10/100] train_loss: 0.98717 valid_loss: 0.94158\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[11/100] train_loss: 0.69398 valid_loss: 0.94213\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[12/100] train_loss: 0.76855 valid_loss: 0.94161\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[13/100] train_loss: 0.79344 valid_loss: 0.94104\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[14/100] train_loss: 0.97099 valid_loss: 0.94197\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[15/100] train_loss: 2.18181 valid_loss: 0.93989\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[16/100] train_loss: 0.81827 valid_loss: 0.93802\n",
      "Validation loss decreased (0.939128 --> 0.938018).  Saving model ...\n",
      "[17/100] train_loss: 0.76669 valid_loss: 0.93559\n",
      "Validation loss decreased (0.938018 --> 0.935590).  Saving model ...\n",
      "[18/100] train_loss: 0.78952 valid_loss: 0.93329\n",
      "Validation loss decreased (0.935590 --> 0.933287).  Saving model ...\n",
      "[19/100] train_loss: 2.11474 valid_loss: 0.92905\n",
      "Validation loss decreased (0.933287 --> 0.929047).  Saving model ...\n",
      "[20/100] train_loss: 0.79797 valid_loss: 0.92515\n",
      "Validation loss decreased (0.929047 --> 0.925145).  Saving model ...\n",
      "[21/100] train_loss: 2.06785 valid_loss: 0.91970\n",
      "Validation loss decreased (0.925145 --> 0.919702).  Saving model ...\n",
      "[22/100] train_loss: 0.78413 valid_loss: 0.91462\n",
      "Validation loss decreased (0.919702 --> 0.914624).  Saving model ...\n",
      "[23/100] train_loss: 0.78581 valid_loss: 0.90982\n",
      "Validation loss decreased (0.914624 --> 0.909818).  Saving model ...\n",
      "[24/100] train_loss: 1.98111 valid_loss: 0.90344\n",
      "Validation loss decreased (0.909818 --> 0.903438).  Saving model ...\n",
      "[25/100] train_loss: 1.94677 valid_loss: 0.89567\n",
      "Validation loss decreased (0.903438 --> 0.895666).  Saving model ...\n",
      "[26/100] train_loss: 1.90644 valid_loss: 0.88656\n",
      "Validation loss decreased (0.895666 --> 0.886557).  Saving model ...\n",
      "[27/100] train_loss: 0.95784 valid_loss: 0.87885\n",
      "Validation loss decreased (0.886557 --> 0.878854).  Saving model ...\n",
      "[28/100] train_loss: 0.75289 valid_loss: 0.87071\n",
      "Validation loss decreased (0.878854 --> 0.870711).  Saving model ...\n",
      "[29/100] train_loss: 0.75105 valid_loss: 0.86211\n",
      "Validation loss decreased (0.870711 --> 0.862109).  Saving model ...\n",
      "[30/100] train_loss: 0.74895 valid_loss: 0.85303\n",
      "Validation loss decreased (0.862109 --> 0.853032).  Saving model ...\n",
      "[31/100] train_loss: 0.61449 valid_loss: 0.84398\n",
      "Validation loss decreased (0.853032 --> 0.843982).  Saving model ...\n",
      "[32/100] train_loss: 0.74425 valid_loss: 0.83434\n",
      "Validation loss decreased (0.843982 --> 0.834339).  Saving model ...\n",
      "[33/100] train_loss: 0.95954 valid_loss: 0.82653\n",
      "Validation loss decreased (0.834339 --> 0.826526).  Saving model ...\n",
      "[34/100] train_loss: 1.57620 valid_loss: 0.81511\n",
      "Validation loss decreased (0.826526 --> 0.815114).  Saving model ...\n",
      "[35/100] train_loss: 0.68189 valid_loss: 0.80346\n",
      "Validation loss decreased (0.815114 --> 0.803456).  Saving model ...\n",
      "[36/100] train_loss: 1.46823 valid_loss: 0.78760\n",
      "Validation loss decreased (0.803456 --> 0.787597).  Saving model ...\n",
      "[37/100] train_loss: 0.95713 valid_loss: 0.77304\n",
      "Validation loss decreased (0.787597 --> 0.773039).  Saving model ...\n",
      "[38/100] train_loss: 0.72846 valid_loss: 0.75699\n",
      "Validation loss decreased (0.773039 --> 0.756986).  Saving model ...\n",
      "[39/100] train_loss: 0.64573 valid_loss: 0.74014\n",
      "Validation loss decreased (0.756986 --> 0.740138).  Saving model ...\n",
      "[40/100] train_loss: 0.95195 valid_loss: 0.72489\n",
      "Validation loss decreased (0.740138 --> 0.724888).  Saving model ...\n",
      "[41/100] train_loss: 1.13712 valid_loss: 0.70221\n",
      "Validation loss decreased (0.724888 --> 0.702213).  Saving model ...\n",
      "[42/100] train_loss: 0.68279 valid_loss: 0.68537\n",
      "Validation loss decreased (0.702213 --> 0.685366).  Saving model ...\n",
      "[43/100] train_loss: 0.76880 valid_loss: 0.66900\n",
      "Validation loss decreased (0.685366 --> 0.668996).  Saving model ...\n",
      "[44/100] train_loss: 0.93871 valid_loss: 0.65476\n",
      "Validation loss decreased (0.668996 --> 0.654758).  Saving model ...\n",
      "[45/100] train_loss: 0.71117 valid_loss: 0.63833\n",
      "Validation loss decreased (0.654758 --> 0.638328).  Saving model ...\n",
      "[46/100] train_loss: 0.65720 valid_loss: 0.62714\n",
      "Validation loss decreased (0.638328 --> 0.627142).  Saving model ...\n",
      "[47/100] train_loss: 0.65753 valid_loss: 0.62129\n",
      "Validation loss decreased (0.627142 --> 0.621289).  Saving model ...\n",
      "[48/100] train_loss: 0.80796 valid_loss: 0.62784\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[49/100] train_loss: 0.91755 valid_loss: 0.63473\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[50/100] train_loss: 0.62772 valid_loss: 0.64177\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[51/100] train_loss: 0.91187 valid_loss: 0.64067\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[52/100] train_loss: 0.90354 valid_loss: 0.64065\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[53/100] train_loss: 0.89754 valid_loss: 0.64154\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[54/100] train_loss: 0.70846 valid_loss: 0.63962\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[55/100] train_loss: 0.88420 valid_loss: 0.63859\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[56/100] train_loss: 0.70907 valid_loss: 0.63470\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[57/100] train_loss: 0.61618 valid_loss: 0.62972\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[58/100] train_loss: 0.84338 valid_loss: 0.61732\n",
      "Validation loss decreased (0.621289 --> 0.617316).  Saving model ...\n",
      "[59/100] train_loss: 0.73664 valid_loss: 0.61586\n",
      "Validation loss decreased (0.617316 --> 0.615865).  Saving model ...\n",
      "[60/100] train_loss: 0.80836 valid_loss: 0.60772\n",
      "Validation loss decreased (0.615865 --> 0.607721).  Saving model ...\n",
      "[61/100] train_loss: 0.75307 valid_loss: 0.59949\n",
      "Validation loss decreased (0.607721 --> 0.599491).  Saving model ...\n",
      "[62/100] train_loss: 0.70247 valid_loss: 0.58915\n",
      "Validation loss decreased (0.599491 --> 0.589148).  Saving model ...\n",
      "[63/100] train_loss: 0.77408 valid_loss: 0.59105\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[64/100] train_loss: 0.61531 valid_loss: 0.59084\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[65/100] train_loss: 0.69626 valid_loss: 0.58771\n",
      "Validation loss decreased (0.589148 --> 0.587710).  Saving model ...\n",
      "[66/100] train_loss: 0.75028 valid_loss: 0.59405\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[67/100] train_loss: 0.69200 valid_loss: 0.59681\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[68/100] train_loss: 0.76025 valid_loss: 0.59315\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[69/100] train_loss: 0.75449 valid_loss: 0.58472\n",
      "Validation loss decreased (0.587710 --> 0.584716).  Saving model ...\n",
      "[70/100] train_loss: 0.71057 valid_loss: 0.58405\n",
      "Validation loss decreased (0.584716 --> 0.584050).  Saving model ...\n",
      "[71/100] train_loss: 0.83814 valid_loss: 0.58339\n",
      "Validation loss decreased (0.584050 --> 0.583395).  Saving model ...\n",
      "[72/100] train_loss: 0.67649 valid_loss: 0.58046\n",
      "Validation loss decreased (0.583395 --> 0.580457).  Saving model ...\n",
      "[73/100] train_loss: 0.75221 valid_loss: 0.57735\n",
      "Validation loss decreased (0.580457 --> 0.577351).  Saving model ...\n",
      "[74/100] train_loss: 0.66998 valid_loss: 0.57298\n",
      "Validation loss decreased (0.577351 --> 0.572984).  Saving model ...\n",
      "[75/100] train_loss: 0.70873 valid_loss: 0.56746\n",
      "Validation loss decreased (0.572984 --> 0.567460).  Saving model ...\n",
      "[76/100] train_loss: 0.69172 valid_loss: 0.56645\n",
      "Validation loss decreased (0.567460 --> 0.566446).  Saving model ...\n",
      "[77/100] train_loss: 0.82942 valid_loss: 0.56529\n",
      "Validation loss decreased (0.566446 --> 0.565287).  Saving model ...\n",
      "[78/100] train_loss: 0.65697 valid_loss: 0.56368\n",
      "Validation loss decreased (0.565287 --> 0.563683).  Saving model ...\n",
      "[79/100] train_loss: 0.65475 valid_loss: 0.56209\n",
      "Validation loss decreased (0.563683 --> 0.562090).  Saving model ...\n",
      "[80/100] train_loss: 0.67121 valid_loss: 0.56280\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[81/100] train_loss: 0.65046 valid_loss: 0.56548\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[82/100] train_loss: 0.74994 valid_loss: 0.57139\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[83/100] train_loss: 0.64944 valid_loss: 0.57520\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[84/100] train_loss: 0.74940 valid_loss: 0.58121\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[85/100] train_loss: 0.68922 valid_loss: 0.57153\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[86/100] train_loss: 0.62996 valid_loss: 0.56668\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[87/100] train_loss: 0.75202 valid_loss: 0.56335\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[88/100] train_loss: 0.62419 valid_loss: 0.56383\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[89/100] train_loss: 0.75366 valid_loss: 0.56532\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[90/100] train_loss: 0.62023 valid_loss: 0.56038\n",
      "Validation loss decreased (0.562090 --> 0.560378).  Saving model ...\n",
      "[91/100] train_loss: 0.76588 valid_loss: 0.55612\n",
      "Validation loss decreased (0.560378 --> 0.556115).  Saving model ...\n",
      "[92/100] train_loss: 0.60810 valid_loss: 0.55585\n",
      "Validation loss decreased (0.556115 --> 0.555854).  Saving model ...\n",
      "[93/100] train_loss: 0.63344 valid_loss: 0.55383\n",
      "Validation loss decreased (0.555854 --> 0.553834).  Saving model ...\n",
      "[94/100] train_loss: 0.59758 valid_loss: 0.55520\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[95/100] train_loss: 0.79022 valid_loss: 0.55606\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[96/100] train_loss: 0.62782 valid_loss: 0.55750\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[97/100] train_loss: 0.78420 valid_loss: 0.55852\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[98/100] train_loss: 0.75900 valid_loss: 0.56104\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[99/100] train_loss: 0.77673 valid_loss: 0.56305\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[100/100] train_loss: 0.77248 valid_loss: 0.56438\n",
      "EarlyStopping counter: 7 out of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training 2/5 for Fold 2\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n",
      "[1/100] train_loss: 0.80101 valid_loss: 0.94978\n",
      "Validation loss decreased (inf --> 0.949784).  Saving model ...\n",
      "[2/100] train_loss: 2.20259 valid_loss: 0.94359\n",
      "Validation loss decreased (0.949784 --> 0.943588).  Saving model ...\n",
      "[3/100] train_loss: 2.17479 valid_loss: 0.93664\n",
      "Validation loss decreased (0.943588 --> 0.936639).  Saving model ...\n",
      "[4/100] train_loss: 0.86179 valid_loss: 0.93175\n",
      "Validation loss decreased (0.936639 --> 0.931752).  Saving model ...\n",
      "[5/100] train_loss: 0.79709 valid_loss: 0.92758\n",
      "Validation loss decreased (0.931752 --> 0.927581).  Saving model ...\n",
      "[6/100] train_loss: 0.76275 valid_loss: 0.92318\n",
      "Validation loss decreased (0.927581 --> 0.923176).  Saving model ...\n",
      "[7/100] train_loss: 0.84086 valid_loss: 0.91965\n",
      "Validation loss decreased (0.923176 --> 0.919647).  Saving model ...\n",
      "[8/100] train_loss: 2.05755 valid_loss: 0.91494\n",
      "Validation loss decreased (0.919647 --> 0.914942).  Saving model ...\n",
      "[9/100] train_loss: 0.79542 valid_loss: 0.91072\n",
      "Validation loss decreased (0.914942 --> 0.910722).  Saving model ...\n",
      "[10/100] train_loss: 2.01422 valid_loss: 0.90551\n",
      "Validation loss decreased (0.910722 --> 0.905512).  Saving model ...\n",
      "[11/100] train_loss: 1.98968 valid_loss: 0.89952\n",
      "Validation loss decreased (0.905512 --> 0.899517).  Saving model ...\n",
      "[12/100] train_loss: 0.79456 valid_loss: 0.89403\n",
      "Validation loss decreased (0.899517 --> 0.894030).  Saving model ...\n",
      "[13/100] train_loss: 0.99886 valid_loss: 0.89035\n",
      "Validation loss decreased (0.894030 --> 0.890348).  Saving model ...\n",
      "[14/100] train_loss: 0.99748 valid_loss: 0.88808\n",
      "Validation loss decreased (0.890348 --> 0.888081).  Saving model ...\n",
      "[15/100] train_loss: 0.67084 valid_loss: 0.88580\n",
      "Validation loss decreased (0.888081 --> 0.885796).  Saving model ...\n",
      "[16/100] train_loss: 0.78675 valid_loss: 0.88375\n",
      "Validation loss decreased (0.885796 --> 0.883749).  Saving model ...\n",
      "[17/100] train_loss: 0.98857 valid_loss: 0.88290\n",
      "Validation loss decreased (0.883749 --> 0.882901).  Saving model ...\n",
      "[18/100] train_loss: 1.83976 valid_loss: 0.88015\n",
      "Validation loss decreased (0.882901 --> 0.880153).  Saving model ...\n",
      "[19/100] train_loss: 1.81633 valid_loss: 0.87581\n",
      "Validation loss decreased (0.880153 --> 0.875813).  Saving model ...\n",
      "[20/100] train_loss: 1.78698 valid_loss: 0.87003\n",
      "Validation loss decreased (0.875813 --> 0.870026).  Saving model ...\n",
      "[21/100] train_loss: 0.64974 valid_loss: 0.86428\n",
      "Validation loss decreased (0.870026 --> 0.864280).  Saving model ...\n",
      "[22/100] train_loss: 0.97497 valid_loss: 0.85980\n",
      "Validation loss decreased (0.864280 --> 0.859796).  Saving model ...\n",
      "[23/100] train_loss: 0.78819 valid_loss: 0.85547\n",
      "Validation loss decreased (0.859796 --> 0.855468).  Saving model ...\n",
      "[24/100] train_loss: 0.63852 valid_loss: 0.85108\n",
      "Validation loss decreased (0.855468 --> 0.851084).  Saving model ...\n",
      "[25/100] train_loss: 0.78645 valid_loss: 0.84684\n",
      "Validation loss decreased (0.851084 --> 0.846842).  Saving model ...\n",
      "[26/100] train_loss: 0.78550 valid_loss: 0.84273\n",
      "Validation loss decreased (0.846842 --> 0.842732).  Saving model ...\n",
      "[27/100] train_loss: 0.62905 valid_loss: 0.83854\n",
      "Validation loss decreased (0.842732 --> 0.838536).  Saving model ...\n",
      "[28/100] train_loss: 0.78345 valid_loss: 0.83445\n",
      "Validation loss decreased (0.838536 --> 0.834448).  Saving model ...\n",
      "[29/100] train_loss: 0.74382 valid_loss: 0.82968\n",
      "Validation loss decreased (0.834448 --> 0.829683).  Saving model ...\n",
      "[30/100] train_loss: 0.78125 valid_loss: 0.82504\n",
      "Validation loss decreased (0.829683 --> 0.825039).  Saving model ...\n",
      "[31/100] train_loss: 1.44807 valid_loss: 0.81668\n",
      "Validation loss decreased (0.825039 --> 0.816684).  Saving model ...\n",
      "[32/100] train_loss: 0.77886 valid_loss: 0.80840\n",
      "Validation loss decreased (0.816684 --> 0.808397).  Saving model ...\n",
      "[33/100] train_loss: 1.35337 valid_loss: 0.79623\n",
      "Validation loss decreased (0.808397 --> 0.796228).  Saving model ...\n",
      "[34/100] train_loss: 0.65978 valid_loss: 0.78351\n",
      "Validation loss decreased (0.796228 --> 0.783512).  Saving model ...\n",
      "[35/100] train_loss: 0.62243 valid_loss: 0.77122\n",
      "Validation loss decreased (0.783512 --> 0.771215).  Saving model ...\n",
      "[36/100] train_loss: 1.14876 valid_loss: 0.75347\n",
      "Validation loss decreased (0.771215 --> 0.753473).  Saving model ...\n",
      "[37/100] train_loss: 0.77203 valid_loss: 0.73492\n",
      "Validation loss decreased (0.753473 --> 0.734920).  Saving model ...\n",
      "[38/100] train_loss: 0.72436 valid_loss: 0.71433\n",
      "Validation loss decreased (0.734920 --> 0.714335).  Saving model ...\n",
      "[39/100] train_loss: 0.91068 valid_loss: 0.68633\n",
      "Validation loss decreased (0.714335 --> 0.686328).  Saving model ...\n",
      "[40/100] train_loss: 0.71732 valid_loss: 0.65468\n",
      "Validation loss decreased (0.686328 --> 0.654684).  Saving model ...\n",
      "[41/100] train_loss: 0.93390 valid_loss: 0.62371\n",
      "Validation loss decreased (0.654684 --> 0.623714).  Saving model ...\n",
      "[42/100] train_loss: 0.95155 valid_loss: 0.61548\n",
      "Validation loss decreased (0.623714 --> 0.615484).  Saving model ...\n",
      "[43/100] train_loss: 0.76782 valid_loss: 0.60846\n",
      "Validation loss decreased (0.615484 --> 0.608458).  Saving model ...\n",
      "[44/100] train_loss: 0.96761 valid_loss: 0.61617\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[45/100] train_loss: 0.70756 valid_loss: 0.62150\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[46/100] train_loss: 0.92206 valid_loss: 0.62741\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[47/100] train_loss: 0.91806 valid_loss: 0.63386\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[48/100] train_loss: 0.91222 valid_loss: 0.64081\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[49/100] train_loss: 0.78669 valid_loss: 0.64325\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[50/100] train_loss: 0.78350 valid_loss: 0.64150\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[51/100] train_loss: 0.89253 valid_loss: 0.64079\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[52/100] train_loss: 0.75959 valid_loss: 0.63978\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[53/100] train_loss: 0.74940 valid_loss: 0.63488\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[54/100] train_loss: 0.71416 valid_loss: 0.62803\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[55/100] train_loss: 0.71396 valid_loss: 0.61942\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[56/100] train_loss: 0.71290 valid_loss: 0.60945\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[57/100] train_loss: 0.60312 valid_loss: 0.60048\n",
      "Validation loss decreased (0.608458 --> 0.600480).  Saving model ...\n",
      "[58/100] train_loss: 0.68454 valid_loss: 0.59154\n",
      "Validation loss decreased (0.600480 --> 0.591537).  Saving model ...\n",
      "[59/100] train_loss: 0.60150 valid_loss: 0.58430\n",
      "Validation loss decreased (0.591537 --> 0.584301).  Saving model ...\n",
      "[60/100] train_loss: 0.85308 valid_loss: 0.57912\n",
      "Validation loss decreased (0.584301 --> 0.579122).  Saving model ...\n",
      "[61/100] train_loss: 0.65836 valid_loss: 0.57622\n",
      "Validation loss decreased (0.579122 --> 0.576220).  Saving model ...\n",
      "[62/100] train_loss: 0.99977 valid_loss: 0.58346\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[63/100] train_loss: 0.59882 valid_loss: 0.59101\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[64/100] train_loss: 0.75451 valid_loss: 0.59823\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[65/100] train_loss: 0.83802 valid_loss: 0.60563\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[66/100] train_loss: 0.85102 valid_loss: 0.62497\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[67/100] train_loss: 0.79360 valid_loss: 0.65330\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[68/100] train_loss: 0.82965 valid_loss: 0.67899\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[69/100] train_loss: 0.64940 valid_loss: 0.69984\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[70/100] train_loss: 0.66441 valid_loss: 0.72086\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[71/100] train_loss: 0.72819 valid_loss: 0.73626\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[72/100] train_loss: 0.76436 valid_loss: 0.74877\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[73/100] train_loss: 0.81818 valid_loss: 0.76021\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[74/100] train_loss: 0.76604 valid_loss: 0.76959\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[75/100] train_loss: 0.76669 valid_loss: 0.77725\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[76/100] train_loss: 0.98861 valid_loss: 0.77513\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[77/100] train_loss: 0.73650 valid_loss: 0.77120\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[78/100] train_loss: 0.73501 valid_loss: 0.76561\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[79/100] train_loss: 0.71521 valid_loss: 0.76012\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[80/100] train_loss: 0.80682 valid_loss: 0.75586\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[81/100] train_loss: 0.60890 valid_loss: 0.75213\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[82/100] train_loss: 0.94726 valid_loss: 0.73979\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[83/100] train_loss: 0.76279 valid_loss: 0.72740\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[84/100] train_loss: 0.76163 valid_loss: 0.71504\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[85/100] train_loss: 0.79779 valid_loss: 0.70403\n",
      "EarlyStopping counter: 24 out of 100\n",
      "[86/100] train_loss: 0.71728 valid_loss: 0.69101\n",
      "EarlyStopping counter: 25 out of 100\n",
      "[87/100] train_loss: 0.80605 valid_loss: 0.66997\n",
      "EarlyStopping counter: 26 out of 100\n",
      "[88/100] train_loss: 0.79119 valid_loss: 0.65052\n",
      "EarlyStopping counter: 27 out of 100\n",
      "[89/100] train_loss: 0.73342 valid_loss: 0.62521\n",
      "EarlyStopping counter: 28 out of 100\n",
      "[90/100] train_loss: 0.75390 valid_loss: 0.60219\n",
      "EarlyStopping counter: 29 out of 100\n",
      "[91/100] train_loss: 0.66938 valid_loss: 0.58811\n",
      "EarlyStopping counter: 30 out of 100\n",
      "[92/100] train_loss: 0.66772 valid_loss: 0.57669\n",
      "EarlyStopping counter: 31 out of 100\n",
      "[93/100] train_loss: 0.70387 valid_loss: 0.57257\n",
      "Validation loss decreased (0.576220 --> 0.572571).  Saving model ...\n",
      "[94/100] train_loss: 0.64240 valid_loss: 0.56931\n",
      "Validation loss decreased (0.572571 --> 0.569305).  Saving model ...\n",
      "[95/100] train_loss: 0.67967 valid_loss: 0.56666\n",
      "Validation loss decreased (0.569305 --> 0.566657).  Saving model ...\n",
      "[96/100] train_loss: 0.67491 valid_loss: 0.56690\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[97/100] train_loss: 0.72840 valid_loss: 0.56753\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[98/100] train_loss: 0.71078 valid_loss: 0.56704\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[99/100] train_loss: 0.66346 valid_loss: 0.56740\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[100/100] train_loss: 0.69673 valid_loss: 0.56763\n",
      "EarlyStopping counter: 5 out of 100\n",
      "  Training 3/5 for Fold 2\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] train_loss: 0.83977 valid_loss: 0.89747\n",
      "Validation loss decreased (inf --> 0.897474).  Saving model ...\n",
      "[2/100] train_loss: 0.80864 valid_loss: 0.89559\n",
      "Validation loss decreased (0.897474 --> 0.895593).  Saving model ...\n",
      "[3/100] train_loss: 1.12665 valid_loss: 0.89770\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[4/100] train_loss: 1.11817 valid_loss: 0.90113\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[5/100] train_loss: 0.82951 valid_loss: 0.90382\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[6/100] train_loss: 0.79097 valid_loss: 0.90580\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[7/100] train_loss: 0.82534 valid_loss: 0.90741\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[8/100] train_loss: 0.78281 valid_loss: 0.90852\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[9/100] train_loss: 1.07784 valid_loss: 0.91091\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[10/100] train_loss: 0.77794 valid_loss: 0.91191\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[11/100] train_loss: 1.06338 valid_loss: 0.91412\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[12/100] train_loss: 0.81628 valid_loss: 0.91611\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[13/100] train_loss: 0.76473 valid_loss: 0.91770\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[14/100] train_loss: 0.67392 valid_loss: 0.91847\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[15/100] train_loss: 0.77643 valid_loss: 0.91799\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[16/100] train_loss: 1.02889 valid_loss: 0.91905\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[17/100] train_loss: 0.80785 valid_loss: 0.91998\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[18/100] train_loss: 0.80618 valid_loss: 0.92077\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[19/100] train_loss: 1.96461 valid_loss: 0.91742\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[20/100] train_loss: 1.00448 valid_loss: 0.91564\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[21/100] train_loss: 1.93083 valid_loss: 0.91092\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[22/100] train_loss: 0.65011 valid_loss: 0.90608\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[23/100] train_loss: 1.88015 valid_loss: 0.89889\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[24/100] train_loss: 0.72334 valid_loss: 0.89190\n",
      "Validation loss decreased (0.895593 --> 0.891898).  Saving model ...\n",
      "[25/100] train_loss: 0.76718 valid_loss: 0.88443\n",
      "Validation loss decreased (0.891898 --> 0.884428).  Saving model ...\n",
      "[26/100] train_loss: 0.71255 valid_loss: 0.87712\n",
      "Validation loss decreased (0.884428 --> 0.877119).  Saving model ...\n",
      "[27/100] train_loss: 0.79642 valid_loss: 0.87012\n",
      "Validation loss decreased (0.877119 --> 0.870121).  Saving model ...\n",
      "[28/100] train_loss: 0.98620 valid_loss: 0.86491\n",
      "Validation loss decreased (0.870121 --> 0.864911).  Saving model ...\n",
      "[29/100] train_loss: 1.69114 valid_loss: 0.85654\n",
      "Validation loss decreased (0.864911 --> 0.856540).  Saving model ...\n",
      "[30/100] train_loss: 0.69076 valid_loss: 0.84809\n",
      "Validation loss decreased (0.856540 --> 0.848091).  Saving model ...\n",
      "[31/100] train_loss: 0.75563 valid_loss: 0.83882\n",
      "Validation loss decreased (0.848091 --> 0.838820).  Saving model ...\n",
      "[32/100] train_loss: 0.75319 valid_loss: 0.82872\n",
      "Validation loss decreased (0.838820 --> 0.828722).  Saving model ...\n",
      "[33/100] train_loss: 0.62282 valid_loss: 0.81884\n",
      "Validation loss decreased (0.828722 --> 0.818843).  Saving model ...\n",
      "[34/100] train_loss: 0.74761 valid_loss: 0.80802\n",
      "Validation loss decreased (0.818843 --> 0.808018).  Saving model ...\n",
      "[35/100] train_loss: 0.78842 valid_loss: 0.79753\n",
      "Validation loss decreased (0.808018 --> 0.797530).  Saving model ...\n",
      "[36/100] train_loss: 0.78752 valid_loss: 0.78737\n",
      "Validation loss decreased (0.797530 --> 0.787366).  Saving model ...\n",
      "[37/100] train_loss: 1.38856 valid_loss: 0.77168\n",
      "Validation loss decreased (0.787366 --> 0.771682).  Saving model ...\n",
      "[38/100] train_loss: 1.33469 valid_loss: 0.75059\n",
      "Validation loss decreased (0.771682 --> 0.750592).  Saving model ...\n",
      "[39/100] train_loss: 0.64331 valid_loss: 0.73108\n",
      "Validation loss decreased (0.750592 --> 0.731075).  Saving model ...\n",
      "[40/100] train_loss: 0.78541 valid_loss: 0.71191\n",
      "Validation loss decreased (0.731075 --> 0.711907).  Saving model ...\n",
      "[41/100] train_loss: 0.72137 valid_loss: 0.69111\n",
      "Validation loss decreased (0.711907 --> 0.691106).  Saving model ...\n",
      "[42/100] train_loss: 0.71679 valid_loss: 0.66896\n",
      "Validation loss decreased (0.691106 --> 0.668961).  Saving model ...\n",
      "[43/100] train_loss: 1.06532 valid_loss: 0.64156\n",
      "Validation loss decreased (0.668961 --> 0.641561).  Saving model ...\n",
      "[44/100] train_loss: 0.75160 valid_loss: 0.62680\n",
      "Validation loss decreased (0.641561 --> 0.626798).  Saving model ...\n",
      "[45/100] train_loss: 0.65885 valid_loss: 0.61573\n",
      "Validation loss decreased (0.626798 --> 0.615727).  Saving model ...\n",
      "[46/100] train_loss: 0.77796 valid_loss: 0.61424\n",
      "Validation loss decreased (0.615727 --> 0.614242).  Saving model ...\n",
      "[47/100] train_loss: 0.95284 valid_loss: 0.60856\n",
      "Validation loss decreased (0.614242 --> 0.608556).  Saving model ...\n",
      "[48/100] train_loss: 0.79309 valid_loss: 0.60470\n",
      "Validation loss decreased (0.608556 --> 0.604702).  Saving model ...\n",
      "[49/100] train_loss: 0.64316 valid_loss: 0.60187\n",
      "Validation loss decreased (0.604702 --> 0.601869).  Saving model ...\n",
      "[50/100] train_loss: 0.98553 valid_loss: 0.60026\n",
      "Validation loss decreased (0.601869 --> 0.600260).  Saving model ...\n",
      "[51/100] train_loss: 0.88186 valid_loss: 0.59462\n",
      "Validation loss decreased (0.600260 --> 0.594622).  Saving model ...\n",
      "[52/100] train_loss: 0.69315 valid_loss: 0.58858\n",
      "Validation loss decreased (0.594622 --> 0.588576).  Saving model ...\n",
      "[53/100] train_loss: 0.83252 valid_loss: 0.58148\n",
      "Validation loss decreased (0.588576 --> 0.581480).  Saving model ...\n",
      "[54/100] train_loss: 0.78490 valid_loss: 0.57729\n",
      "Validation loss decreased (0.581480 --> 0.577286).  Saving model ...\n",
      "[55/100] train_loss: 0.78355 valid_loss: 0.57554\n",
      "Validation loss decreased (0.577286 --> 0.575543).  Saving model ...\n",
      "[56/100] train_loss: 0.75472 valid_loss: 0.57769\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[57/100] train_loss: 0.73075 valid_loss: 0.58659\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[58/100] train_loss: 0.63284 valid_loss: 0.60113\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[59/100] train_loss: 0.67677 valid_loss: 0.62272\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[60/100] train_loss: 0.63305 valid_loss: 0.64783\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[61/100] train_loss: 1.05901 valid_loss: 0.63278\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[62/100] train_loss: 1.00782 valid_loss: 0.60473\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[63/100] train_loss: 0.77040 valid_loss: 0.59229\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[64/100] train_loss: 0.68187 valid_loss: 0.59106\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[65/100] train_loss: 0.68512 valid_loss: 0.59458\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[66/100] train_loss: 0.65295 valid_loss: 0.59964\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[67/100] train_loss: 0.76940 valid_loss: 0.60524\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[68/100] train_loss: 0.88831 valid_loss: 0.61095\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[69/100] train_loss: 0.69924 valid_loss: 0.61966\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[70/100] train_loss: 0.67527 valid_loss: 0.62772\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[71/100] train_loss: 0.67246 valid_loss: 0.63763\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[72/100] train_loss: 0.66143 valid_loss: 0.64879\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[73/100] train_loss: 0.76821 valid_loss: 0.65866\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[74/100] train_loss: 0.86784 valid_loss: 0.65475\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[75/100] train_loss: 0.69603 valid_loss: 0.65044\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[76/100] train_loss: 0.85633 valid_loss: 0.63435\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[77/100] train_loss: 0.76526 valid_loss: 0.61874\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[78/100] train_loss: 0.79684 valid_loss: 0.59589\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[79/100] train_loss: 0.75563 valid_loss: 0.57367\n",
      "Validation loss decreased (0.575543 --> 0.573673).  Saving model ...\n",
      "[80/100] train_loss: 0.71214 valid_loss: 0.56560\n",
      "Validation loss decreased (0.573673 --> 0.565601).  Saving model ...\n",
      "[81/100] train_loss: 0.67745 valid_loss: 0.58023\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[82/100] train_loss: 0.65248 valid_loss: 0.61686\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[83/100] train_loss: 0.75818 valid_loss: 0.64374\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[84/100] train_loss: 0.75030 valid_loss: 0.67410\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[85/100] train_loss: 0.80619 valid_loss: 0.67476\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[86/100] train_loss: 0.78472 valid_loss: 0.65099\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[87/100] train_loss: 0.65548 valid_loss: 0.62795\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[88/100] train_loss: 0.75200 valid_loss: 0.61015\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[89/100] train_loss: 0.69193 valid_loss: 0.59578\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[90/100] train_loss: 0.64275 valid_loss: 0.58143\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[91/100] train_loss: 0.64281 valid_loss: 0.57194\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[92/100] train_loss: 0.62608 valid_loss: 0.56235\n",
      "Validation loss decreased (0.565601 --> 0.562346).  Saving model ...\n",
      "[93/100] train_loss: 0.63974 valid_loss: 0.55796\n",
      "Validation loss decreased (0.562346 --> 0.557958).  Saving model ...\n",
      "[94/100] train_loss: 0.63695 valid_loss: 0.55710\n",
      "Validation loss decreased (0.557958 --> 0.557100).  Saving model ...\n",
      "[95/100] train_loss: 0.60897 valid_loss: 0.55590\n",
      "Validation loss decreased (0.557100 --> 0.555898).  Saving model ...\n",
      "[96/100] train_loss: 0.79898 valid_loss: 0.55471\n",
      "Validation loss decreased (0.555898 --> 0.554715).  Saving model ...\n",
      "[97/100] train_loss: 0.65294 valid_loss: 0.55535\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[98/100] train_loss: 0.64953 valid_loss: 0.55918\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[99/100] train_loss: 0.59999 valid_loss: 0.56439\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[100/100] train_loss: 0.72868 valid_loss: 0.57093\n",
      "EarlyStopping counter: 4 out of 100\n",
      "  Training 4/5 for Fold 2\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] train_loss: 1.02409 valid_loss: 0.91471\n",
      "Validation loss decreased (inf --> 0.914714).  Saving model ...\n",
      "[2/100] train_loss: 0.71465 valid_loss: 0.91550\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[3/100] train_loss: 2.22675 valid_loss: 0.91167\n",
      "Validation loss decreased (0.914714 --> 0.911670).  Saving model ...\n",
      "[4/100] train_loss: 0.80021 valid_loss: 0.90853\n",
      "Validation loss decreased (0.911670 --> 0.908527).  Saving model ...\n",
      "[5/100] train_loss: 0.79960 valid_loss: 0.90586\n",
      "Validation loss decreased (0.908527 --> 0.905858).  Saving model ...\n",
      "[6/100] train_loss: 0.76703 valid_loss: 0.90311\n",
      "Validation loss decreased (0.905858 --> 0.903107).  Saving model ...\n",
      "[7/100] train_loss: 2.14988 valid_loss: 0.89846\n",
      "Validation loss decreased (0.903107 --> 0.898458).  Saving model ...\n",
      "[8/100] train_loss: 0.79783 valid_loss: 0.89433\n",
      "Validation loss decreased (0.898458 --> 0.894330).  Saving model ...\n",
      "[9/100] train_loss: 0.68824 valid_loss: 0.89024\n",
      "Validation loss decreased (0.894330 --> 0.890242).  Saving model ...\n",
      "[10/100] train_loss: 2.08683 valid_loss: 0.88473\n",
      "Validation loss decreased (0.890242 --> 0.884726).  Saving model ...\n",
      "[11/100] train_loss: 0.79624 valid_loss: 0.87970\n",
      "Validation loss decreased (0.884726 --> 0.879703).  Saving model ...\n",
      "[12/100] train_loss: 2.03777 valid_loss: 0.87342\n",
      "Validation loss decreased (0.879703 --> 0.873423).  Saving model ...\n",
      "[13/100] train_loss: 0.99877 valid_loss: 0.86865\n",
      "Validation loss decreased (0.873423 --> 0.868649).  Saving model ...\n",
      "[14/100] train_loss: 0.75787 valid_loss: 0.86399\n",
      "Validation loss decreased (0.868649 --> 0.863986).  Saving model ...\n",
      "[15/100] train_loss: 1.95981 valid_loss: 0.85780\n",
      "Validation loss decreased (0.863986 --> 0.857800).  Saving model ...\n",
      "[16/100] train_loss: 0.82155 valid_loss: 0.85200\n",
      "Validation loss decreased (0.857800 --> 0.852002).  Saving model ...\n",
      "[17/100] train_loss: 0.65510 valid_loss: 0.84618\n",
      "Validation loss decreased (0.852002 --> 0.846179).  Saving model ...\n",
      "[18/100] train_loss: 0.99745 valid_loss: 0.84164\n",
      "Validation loss decreased (0.846179 --> 0.841637).  Saving model ...\n",
      "[19/100] train_loss: 0.99597 valid_loss: 0.83824\n",
      "Validation loss decreased (0.841637 --> 0.838240).  Saving model ...\n",
      "[20/100] train_loss: 0.99302 valid_loss: 0.83587\n",
      "Validation loss decreased (0.838240 --> 0.835871).  Saving model ...\n",
      "[21/100] train_loss: 1.79949 valid_loss: 0.83079\n",
      "Validation loss decreased (0.835871 --> 0.830795).  Saving model ...\n",
      "[22/100] train_loss: 0.78922 valid_loss: 0.82587\n",
      "Validation loss decreased (0.830795 --> 0.825866).  Saving model ...\n",
      "[23/100] train_loss: 0.98259 valid_loss: 0.82193\n",
      "Validation loss decreased (0.825866 --> 0.821934).  Saving model ...\n",
      "[24/100] train_loss: 0.78729 valid_loss: 0.81807\n",
      "Validation loss decreased (0.821934 --> 0.818074).  Saving model ...\n",
      "[25/100] train_loss: 0.74555 valid_loss: 0.81391\n",
      "Validation loss decreased (0.818074 --> 0.813908).  Saving model ...\n",
      "[26/100] train_loss: 0.74441 valid_loss: 0.80939\n",
      "Validation loss decreased (0.813908 --> 0.809395).  Saving model ...\n",
      "[27/100] train_loss: 0.74318 valid_loss: 0.80449\n",
      "Validation loss decreased (0.809395 --> 0.804495).  Saving model ...\n",
      "[28/100] train_loss: 0.75786 valid_loss: 0.79931\n",
      "Validation loss decreased (0.804495 --> 0.799306).  Saving model ...\n",
      "[29/100] train_loss: 0.75049 valid_loss: 0.79371\n",
      "Validation loss decreased (0.799306 --> 0.793705).  Saving model ...\n",
      "[30/100] train_loss: 0.78090 valid_loss: 0.78805\n",
      "Validation loss decreased (0.793705 --> 0.788055).  Saving model ...\n",
      "[31/100] train_loss: 0.73762 valid_loss: 0.78176\n",
      "Validation loss decreased (0.788055 --> 0.781762).  Saving model ...\n",
      "[32/100] train_loss: 1.47295 valid_loss: 0.77009\n",
      "Validation loss decreased (0.781762 --> 0.770089).  Saving model ...\n",
      "[33/100] train_loss: 1.41935 valid_loss: 0.75327\n",
      "Validation loss decreased (0.770089 --> 0.753272).  Saving model ...\n",
      "[34/100] train_loss: 1.34800 valid_loss: 0.73076\n",
      "Validation loss decreased (0.753272 --> 0.730763).  Saving model ...\n",
      "[35/100] train_loss: 0.72699 valid_loss: 0.70606\n",
      "Validation loss decreased (0.730763 --> 0.706064).  Saving model ...\n",
      "[36/100] train_loss: 1.18257 valid_loss: 0.67424\n",
      "Validation loss decreased (0.706064 --> 0.674243).  Saving model ...\n",
      "[37/100] train_loss: 0.71886 valid_loss: 0.64034\n",
      "Validation loss decreased (0.674243 --> 0.640342).  Saving model ...\n",
      "[38/100] train_loss: 0.76857 valid_loss: 0.60878\n",
      "Validation loss decreased (0.640342 --> 0.608782).  Saving model ...\n",
      "[39/100] train_loss: 0.60523 valid_loss: 0.58569\n",
      "Validation loss decreased (0.608782 --> 0.585690).  Saving model ...\n",
      "[40/100] train_loss: 0.76673 valid_loss: 0.57690\n",
      "Validation loss decreased (0.585690 --> 0.576900).  Saving model ...\n",
      "[41/100] train_loss: 0.70132 valid_loss: 0.58445\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[42/100] train_loss: 0.76846 valid_loss: 0.60418\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[43/100] train_loss: 0.77248 valid_loss: 0.62755\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[44/100] train_loss: 0.94564 valid_loss: 0.65267\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[45/100] train_loss: 1.15229 valid_loss: 0.64299\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[46/100] train_loss: 0.93345 valid_loss: 0.63356\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[47/100] train_loss: 0.73032 valid_loss: 0.61527\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[48/100] train_loss: 0.68652 valid_loss: 0.60075\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[49/100] train_loss: 0.68536 valid_loss: 0.59017\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[50/100] train_loss: 0.62716 valid_loss: 0.57940\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[51/100] train_loss: 0.84887 valid_loss: 0.57327\n",
      "Validation loss decreased (0.576900 --> 0.573272).  Saving model ...\n",
      "[52/100] train_loss: 0.87479 valid_loss: 0.56799\n",
      "Validation loss decreased (0.573272 --> 0.567987).  Saving model ...\n",
      "[53/100] train_loss: 0.69103 valid_loss: 0.56845\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[54/100] train_loss: 0.75776 valid_loss: 0.57191\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[55/100] train_loss: 0.69553 valid_loss: 0.57633\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[56/100] train_loss: 0.76013 valid_loss: 0.58103\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[57/100] train_loss: 0.69544 valid_loss: 0.59008\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[58/100] train_loss: 0.69940 valid_loss: 0.59824\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[59/100] train_loss: 0.67994 valid_loss: 0.60418\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[60/100] train_loss: 0.92155 valid_loss: 0.60464\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[61/100] train_loss: 0.91983 valid_loss: 0.60040\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[62/100] train_loss: 0.88055 valid_loss: 0.59679\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[63/100] train_loss: 0.69804 valid_loss: 0.59258\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[64/100] train_loss: 0.69252 valid_loss: 0.58792\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[65/100] train_loss: 0.69398 valid_loss: 0.58347\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[66/100] train_loss: 0.66990 valid_loss: 0.58233\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[67/100] train_loss: 0.67916 valid_loss: 0.58039\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[68/100] train_loss: 0.68782 valid_loss: 0.57827\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[69/100] train_loss: 0.86669 valid_loss: 0.57652\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[70/100] train_loss: 0.68281 valid_loss: 0.57490\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[71/100] train_loss: 0.82030 valid_loss: 0.57427\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[72/100] train_loss: 0.67596 valid_loss: 0.57522\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[73/100] train_loss: 0.75250 valid_loss: 0.57781\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[74/100] train_loss: 0.75036 valid_loss: 0.58182\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[75/100] train_loss: 0.74795 valid_loss: 0.58709\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[76/100] train_loss: 0.76013 valid_loss: 0.59647\n",
      "EarlyStopping counter: 24 out of 100\n",
      "[77/100] train_loss: 0.81339 valid_loss: 0.59896\n",
      "EarlyStopping counter: 25 out of 100\n",
      "[78/100] train_loss: 0.74303 valid_loss: 0.60489\n",
      "EarlyStopping counter: 26 out of 100\n",
      "[79/100] train_loss: 0.68420 valid_loss: 0.60456\n",
      "EarlyStopping counter: 27 out of 100\n",
      "[80/100] train_loss: 0.59412 valid_loss: 0.60584\n",
      "EarlyStopping counter: 28 out of 100\n",
      "[81/100] train_loss: 0.73919 valid_loss: 0.60783\n",
      "EarlyStopping counter: 29 out of 100\n",
      "[82/100] train_loss: 0.73798 valid_loss: 0.61059\n",
      "EarlyStopping counter: 30 out of 100\n",
      "[83/100] train_loss: 0.58147 valid_loss: 0.61450\n",
      "EarlyStopping counter: 31 out of 100\n",
      "[84/100] train_loss: 0.70893 valid_loss: 0.62240\n",
      "EarlyStopping counter: 32 out of 100\n",
      "[85/100] train_loss: 0.89962 valid_loss: 0.61735\n",
      "EarlyStopping counter: 33 out of 100\n",
      "[86/100] train_loss: 0.66797 valid_loss: 0.60669\n",
      "EarlyStopping counter: 34 out of 100\n",
      "[87/100] train_loss: 0.87359 valid_loss: 0.58963\n",
      "EarlyStopping counter: 35 out of 100\n",
      "[88/100] train_loss: 0.71525 valid_loss: 0.58015\n",
      "EarlyStopping counter: 36 out of 100\n",
      "[89/100] train_loss: 0.72200 valid_loss: 0.57559\n",
      "EarlyStopping counter: 37 out of 100\n",
      "[90/100] train_loss: 0.72327 valid_loss: 0.57418\n",
      "EarlyStopping counter: 38 out of 100\n",
      "[91/100] train_loss: 0.74229 valid_loss: 0.57344\n",
      "EarlyStopping counter: 39 out of 100\n",
      "[92/100] train_loss: 0.71463 valid_loss: 0.57475\n",
      "EarlyStopping counter: 40 out of 100\n",
      "[93/100] train_loss: 0.70500 valid_loss: 0.57822\n",
      "EarlyStopping counter: 41 out of 100\n",
      "[94/100] train_loss: 0.81388 valid_loss: 0.57637\n",
      "EarlyStopping counter: 42 out of 100\n",
      "[95/100] train_loss: 0.81250 valid_loss: 0.57472\n",
      "EarlyStopping counter: 43 out of 100\n",
      "[96/100] train_loss: 0.81005 valid_loss: 0.57326\n",
      "EarlyStopping counter: 44 out of 100\n",
      "[97/100] train_loss: 0.80647 valid_loss: 0.57196\n",
      "EarlyStopping counter: 45 out of 100\n",
      "[98/100] train_loss: 0.68068 valid_loss: 0.57176\n",
      "EarlyStopping counter: 46 out of 100\n",
      "[99/100] train_loss: 0.78274 valid_loss: 0.57057\n",
      "EarlyStopping counter: 47 out of 100\n",
      "[100/100] train_loss: 0.75353 valid_loss: 0.57156\n",
      "EarlyStopping counter: 48 out of 100\n",
      "  Training 5/5 for Fold 2\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] train_loss: 2.21712 valid_loss: 0.95275\n",
      "Validation loss decreased (inf --> 0.952754).  Saving model ...\n",
      "[2/100] train_loss: 0.89183 valid_loss: 0.94740\n",
      "Validation loss decreased (0.952754 --> 0.947402).  Saving model ...\n",
      "[3/100] train_loss: 0.76980 valid_loss: 0.94176\n",
      "Validation loss decreased (0.947402 --> 0.941757).  Saving model ...\n",
      "[4/100] train_loss: 2.13966 valid_loss: 0.93526\n",
      "Validation loss decreased (0.941757 --> 0.935264).  Saving model ...\n",
      "[5/100] train_loss: 0.79667 valid_loss: 0.92953\n",
      "Validation loss decreased (0.935264 --> 0.929525).  Saving model ...\n",
      "[6/100] train_loss: 0.76567 valid_loss: 0.92371\n",
      "Validation loss decreased (0.929525 --> 0.923712).  Saving model ...\n",
      "[7/100] train_loss: 2.07500 valid_loss: 0.91709\n",
      "Validation loss decreased (0.923712 --> 0.917093).  Saving model ...\n",
      "[8/100] train_loss: 0.76270 valid_loss: 0.91052\n",
      "Validation loss decreased (0.917093 --> 0.910517).  Saving model ...\n",
      "[9/100] train_loss: 0.79449 valid_loss: 0.90447\n",
      "Validation loss decreased (0.910517 --> 0.904471).  Saving model ...\n",
      "[10/100] train_loss: 0.69521 valid_loss: 0.89856\n",
      "Validation loss decreased (0.904471 --> 0.898564).  Saving model ...\n",
      "[11/100] train_loss: 0.84342 valid_loss: 0.89309\n",
      "Validation loss decreased (0.898564 --> 0.893090).  Saving model ...\n",
      "[12/100] train_loss: 1.97236 valid_loss: 0.88636\n",
      "Validation loss decreased (0.893090 --> 0.886355).  Saving model ...\n",
      "[13/100] train_loss: 0.75537 valid_loss: 0.87958\n",
      "Validation loss decreased (0.886355 --> 0.879582).  Saving model ...\n",
      "[14/100] train_loss: 0.79163 valid_loss: 0.87320\n",
      "Validation loss decreased (0.879582 --> 0.873199).  Saving model ...\n",
      "[15/100] train_loss: 0.79105 valid_loss: 0.86717\n",
      "Validation loss decreased (0.873199 --> 0.867170).  Saving model ...\n",
      "[16/100] train_loss: 0.75086 valid_loss: 0.86099\n",
      "Validation loss decreased (0.867170 --> 0.860990).  Saving model ...\n",
      "[17/100] train_loss: 0.66657 valid_loss: 0.85465\n",
      "Validation loss decreased (0.860990 --> 0.854649).  Saving model ...\n",
      "[18/100] train_loss: 0.74770 valid_loss: 0.84812\n",
      "Validation loss decreased (0.854649 --> 0.848120).  Saving model ...\n",
      "[19/100] train_loss: 0.78839 valid_loss: 0.84190\n",
      "Validation loss decreased (0.848120 --> 0.841896).  Saving model ...\n",
      "[20/100] train_loss: 0.78763 valid_loss: 0.83595\n",
      "Validation loss decreased (0.841896 --> 0.835946).  Saving model ...\n",
      "[21/100] train_loss: 0.79361 valid_loss: 0.82989\n",
      "Validation loss decreased (0.835946 --> 0.829889).  Saving model ...\n",
      "[22/100] train_loss: 1.76725 valid_loss: 0.82100\n",
      "Validation loss decreased (0.829889 --> 0.821000).  Saving model ...\n",
      "[23/100] train_loss: 1.73606 valid_loss: 0.80959\n",
      "Validation loss decreased (0.821000 --> 0.809586).  Saving model ...\n",
      "[24/100] train_loss: 0.77254 valid_loss: 0.79799\n",
      "Validation loss decreased (0.809586 --> 0.797990).  Saving model ...\n",
      "[25/100] train_loss: 0.73438 valid_loss: 0.78612\n",
      "Validation loss decreased (0.797990 --> 0.786120).  Saving model ...\n",
      "[26/100] train_loss: 0.73197 valid_loss: 0.77393\n",
      "Validation loss decreased (0.786120 --> 0.773934).  Saving model ...\n",
      "[27/100] train_loss: 1.01195 valid_loss: 0.76456\n",
      "Validation loss decreased (0.773934 --> 0.764558).  Saving model ...\n",
      "[28/100] train_loss: 0.78134 valid_loss: 0.75534\n",
      "Validation loss decreased (0.764558 --> 0.755340).  Saving model ...\n",
      "[29/100] train_loss: 0.72844 valid_loss: 0.74519\n",
      "Validation loss decreased (0.755340 --> 0.745195).  Saving model ...\n",
      "[30/100] train_loss: 0.60946 valid_loss: 0.73437\n",
      "Validation loss decreased (0.745195 --> 0.734366).  Saving model ...\n",
      "[31/100] train_loss: 0.60608 valid_loss: 0.72289\n",
      "Validation loss decreased (0.734366 --> 0.722890).  Saving model ...\n",
      "[32/100] train_loss: 0.77690 valid_loss: 0.71147\n",
      "Validation loss decreased (0.722890 --> 0.711474).  Saving model ...\n",
      "[33/100] train_loss: 0.68792 valid_loss: 0.69799\n",
      "Validation loss decreased (0.711474 --> 0.697994).  Saving model ...\n",
      "[34/100] train_loss: 1.27839 valid_loss: 0.67707\n",
      "Validation loss decreased (0.697994 --> 0.677066).  Saving model ...\n",
      "[35/100] train_loss: 0.60543 valid_loss: 0.65749\n",
      "Validation loss decreased (0.677066 --> 0.657486).  Saving model ...\n",
      "[36/100] train_loss: 0.61381 valid_loss: 0.64129\n",
      "Validation loss decreased (0.657486 --> 0.641293).  Saving model ...\n",
      "[37/100] train_loss: 0.62437 valid_loss: 0.63048\n",
      "Validation loss decreased (0.641293 --> 0.630477).  Saving model ...\n",
      "[38/100] train_loss: 1.08097 valid_loss: 0.61168\n",
      "Validation loss decreased (0.630477 --> 0.611678).  Saving model ...\n",
      "[39/100] train_loss: 1.03208 valid_loss: 0.58921\n",
      "Validation loss decreased (0.611678 --> 0.589210).  Saving model ...\n",
      "[40/100] train_loss: 0.77517 valid_loss: 0.57300\n",
      "Validation loss decreased (0.589210 --> 0.573001).  Saving model ...\n",
      "[41/100] train_loss: 0.59836 valid_loss: 0.56374\n",
      "Validation loss decreased (0.573001 --> 0.563737).  Saving model ...\n",
      "[42/100] train_loss: 0.89816 valid_loss: 0.56393\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[43/100] train_loss: 0.85848 valid_loss: 0.56458\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[44/100] train_loss: 0.60356 valid_loss: 0.56474\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[45/100] train_loss: 0.85214 valid_loss: 0.56336\n",
      "Validation loss decreased (0.563737 --> 0.563362).  Saving model ...\n",
      "[46/100] train_loss: 0.59002 valid_loss: 0.56540\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[47/100] train_loss: 0.82150 valid_loss: 0.56886\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[48/100] train_loss: 1.01019 valid_loss: 0.57332\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[49/100] train_loss: 0.76803 valid_loss: 0.57871\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[50/100] train_loss: 0.71790 valid_loss: 0.58997\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[51/100] train_loss: 0.69082 valid_loss: 0.60778\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[52/100] train_loss: 0.66159 valid_loss: 0.63049\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[53/100] train_loss: 0.89229 valid_loss: 0.64214\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[54/100] train_loss: 0.76342 valid_loss: 0.65254\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[55/100] train_loss: 0.68651 valid_loss: 0.66008\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[56/100] train_loss: 0.95247 valid_loss: 0.66821\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[57/100] train_loss: 0.69959 valid_loss: 0.67387\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[58/100] train_loss: 0.94218 valid_loss: 0.68025\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[59/100] train_loss: 0.61463 valid_loss: 0.68678\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[60/100] train_loss: 0.93037 valid_loss: 0.69395\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[61/100] train_loss: 0.97033 valid_loss: 0.68799\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[62/100] train_loss: 0.76145 valid_loss: 0.68165\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[63/100] train_loss: 0.61275 valid_loss: 0.67657\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[64/100] train_loss: 0.90696 valid_loss: 0.67277\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[65/100] train_loss: 0.75851 valid_loss: 0.66843\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[66/100] train_loss: 0.70519 valid_loss: 0.66177\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[67/100] train_loss: 0.61475 valid_loss: 0.65824\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[68/100] train_loss: 0.70416 valid_loss: 0.65263\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[69/100] train_loss: 0.82048 valid_loss: 0.63561\n",
      "EarlyStopping counter: 24 out of 100\n",
      "[70/100] train_loss: 0.62454 valid_loss: 0.62482\n",
      "EarlyStopping counter: 25 out of 100\n",
      "[71/100] train_loss: 0.63034 valid_loss: 0.62131\n",
      "EarlyStopping counter: 26 out of 100\n",
      "[72/100] train_loss: 0.69244 valid_loss: 0.61523\n",
      "EarlyStopping counter: 27 out of 100\n",
      "[73/100] train_loss: 0.63385 valid_loss: 0.61769\n",
      "EarlyStopping counter: 28 out of 100\n",
      "[74/100] train_loss: 0.75285 valid_loss: 0.61126\n",
      "EarlyStopping counter: 29 out of 100\n",
      "[75/100] train_loss: 0.86302 valid_loss: 0.60613\n",
      "EarlyStopping counter: 30 out of 100\n",
      "[76/100] train_loss: 0.85920 valid_loss: 0.60222\n",
      "EarlyStopping counter: 31 out of 100\n",
      "[77/100] train_loss: 0.71804 valid_loss: 0.59200\n",
      "EarlyStopping counter: 32 out of 100\n",
      "[78/100] train_loss: 0.65774 valid_loss: 0.59702\n",
      "EarlyStopping counter: 33 out of 100\n",
      "[79/100] train_loss: 0.84565 valid_loss: 0.60300\n",
      "EarlyStopping counter: 34 out of 100\n",
      "[80/100] train_loss: 0.75021 valid_loss: 0.60758\n",
      "EarlyStopping counter: 35 out of 100\n",
      "[81/100] train_loss: 0.69890 valid_loss: 0.60883\n",
      "EarlyStopping counter: 36 out of 100\n",
      "[82/100] train_loss: 0.69664 valid_loss: 0.60667\n",
      "EarlyStopping counter: 37 out of 100\n",
      "[83/100] train_loss: 0.75008 valid_loss: 0.60314\n",
      "EarlyStopping counter: 38 out of 100\n",
      "[84/100] train_loss: 0.66863 valid_loss: 0.59792\n",
      "EarlyStopping counter: 39 out of 100\n",
      "[85/100] train_loss: 0.66035 valid_loss: 0.59253\n",
      "EarlyStopping counter: 40 out of 100\n",
      "[86/100] train_loss: 0.82272 valid_loss: 0.58867\n",
      "EarlyStopping counter: 41 out of 100\n",
      "[87/100] train_loss: 0.74088 valid_loss: 0.61781\n",
      "EarlyStopping counter: 42 out of 100\n",
      "[88/100] train_loss: 0.66663 valid_loss: 0.64022\n",
      "EarlyStopping counter: 43 out of 100\n",
      "[89/100] train_loss: 0.81485 valid_loss: 0.66148\n",
      "EarlyStopping counter: 44 out of 100\n",
      "[90/100] train_loss: 0.67283 valid_loss: 0.69905\n",
      "EarlyStopping counter: 45 out of 100\n",
      "[91/100] train_loss: 0.63566 valid_loss: 0.73981\n",
      "EarlyStopping counter: 46 out of 100\n",
      "[92/100] train_loss: 0.74055 valid_loss: 0.76636\n",
      "EarlyStopping counter: 47 out of 100\n",
      "[93/100] train_loss: 0.80637 valid_loss: 0.78844\n",
      "EarlyStopping counter: 48 out of 100\n",
      "[94/100] train_loss: 0.58145 valid_loss: 0.80704\n",
      "EarlyStopping counter: 49 out of 100\n",
      "[95/100] train_loss: 0.75060 valid_loss: 0.81876\n",
      "EarlyStopping counter: 50 out of 100\n",
      "[96/100] train_loss: 0.76028 valid_loss: 0.82758\n",
      "EarlyStopping counter: 51 out of 100\n",
      "[97/100] train_loss: 0.89779 valid_loss: 0.81884\n",
      "EarlyStopping counter: 52 out of 100\n",
      "[98/100] train_loss: 0.76016 valid_loss: 0.80954\n",
      "EarlyStopping counter: 53 out of 100\n",
      "[99/100] train_loss: 0.74822 valid_loss: 0.79738\n",
      "EarlyStopping counter: 54 out of 100\n",
      "[100/100] train_loss: 0.75814 valid_loss: 0.78484\n",
      "EarlyStopping counter: 55 out of 100\n",
      "  Fold 3/7\n",
      "  Training 1/5 for Fold 3\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n",
      "[1/100] train_loss: 1.05416 valid_loss: 0.72713\n",
      "Validation loss decreased (inf --> 0.727125).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/100] train_loss: 1.01417 valid_loss: 0.72676\n",
      "Validation loss decreased (0.727125 --> 0.726757).  Saving model ...\n",
      "[3/100] train_loss: 0.80491 valid_loss: 0.72651\n",
      "Validation loss decreased (0.726757 --> 0.726510).  Saving model ...\n",
      "[4/100] train_loss: 1.03014 valid_loss: 0.72540\n",
      "Validation loss decreased (0.726510 --> 0.725396).  Saving model ...\n",
      "[5/100] train_loss: 1.02287 valid_loss: 0.72387\n",
      "Validation loss decreased (0.725396 --> 0.723868).  Saving model ...\n",
      "[6/100] train_loss: 1.01378 valid_loss: 0.72214\n",
      "Validation loss decreased (0.723868 --> 0.722137).  Saving model ...\n",
      "[7/100] train_loss: 0.70774 valid_loss: 0.72076\n",
      "Validation loss decreased (0.722137 --> 0.720760).  Saving model ...\n",
      "[8/100] train_loss: 2.27920 valid_loss: 0.71939\n",
      "Validation loss decreased (0.720760 --> 0.719393).  Saving model ...\n",
      "[9/100] train_loss: 1.01296 valid_loss: 0.71857\n",
      "Validation loss decreased (0.719393 --> 0.718566).  Saving model ...\n",
      "[10/100] train_loss: 0.97767 valid_loss: 0.71753\n",
      "Validation loss decreased (0.718566 --> 0.717525).  Saving model ...\n",
      "[11/100] train_loss: 0.96961 valid_loss: 0.71633\n",
      "Validation loss decreased (0.717525 --> 0.716327).  Saving model ...\n",
      "[12/100] train_loss: 0.79872 valid_loss: 0.71525\n",
      "Validation loss decreased (0.716327 --> 0.715250).  Saving model ...\n",
      "[13/100] train_loss: 2.16335 valid_loss: 0.71403\n",
      "Validation loss decreased (0.715250 --> 0.714034).  Saving model ...\n",
      "[14/100] train_loss: 0.67729 valid_loss: 0.71294\n",
      "Validation loss decreased (0.714034 --> 0.712944).  Saving model ...\n",
      "[15/100] train_loss: 1.02051 valid_loss: 0.71219\n",
      "Validation loss decreased (0.712944 --> 0.712188).  Saving model ...\n",
      "[16/100] train_loss: 0.66832 valid_loss: 0.71149\n",
      "Validation loss decreased (0.712188 --> 0.711486).  Saving model ...\n",
      "[17/100] train_loss: 1.01982 valid_loss: 0.71104\n",
      "Validation loss decreased (0.711486 --> 0.711044).  Saving model ...\n",
      "[18/100] train_loss: 2.03722 valid_loss: 0.71023\n",
      "Validation loss decreased (0.711044 --> 0.710233).  Saving model ...\n",
      "[19/100] train_loss: 0.79427 valid_loss: 0.70944\n",
      "Validation loss decreased (0.710233 --> 0.709440).  Saving model ...\n",
      "[20/100] train_loss: 0.79341 valid_loss: 0.70866\n",
      "Validation loss decreased (0.709440 --> 0.708660).  Saving model ...\n",
      "[21/100] train_loss: 0.89246 valid_loss: 0.70759\n",
      "Validation loss decreased (0.708660 --> 0.707594).  Saving model ...\n",
      "[22/100] train_loss: 1.92214 valid_loss: 0.70621\n",
      "Validation loss decreased (0.707594 --> 0.706207).  Saving model ...\n",
      "[23/100] train_loss: 0.79068 valid_loss: 0.70485\n",
      "Validation loss decreased (0.706207 --> 0.704852).  Saving model ...\n",
      "[24/100] train_loss: 1.01443 valid_loss: 0.70374\n",
      "Validation loss decreased (0.704852 --> 0.703738).  Saving model ...\n",
      "[25/100] train_loss: 0.78857 valid_loss: 0.70262\n",
      "Validation loss decreased (0.703738 --> 0.702624).  Saving model ...\n",
      "[26/100] train_loss: 0.78738 valid_loss: 0.70150\n",
      "Validation loss decreased (0.702624 --> 0.701505).  Saving model ...\n",
      "[27/100] train_loss: 0.78613 valid_loss: 0.70038\n",
      "Validation loss decreased (0.701505 --> 0.700377).  Saving model ...\n",
      "[28/100] train_loss: 0.61271 valid_loss: 0.69922\n",
      "Validation loss decreased (0.700377 --> 0.699216).  Saving model ...\n",
      "[29/100] train_loss: 0.74306 valid_loss: 0.69812\n",
      "Validation loss decreased (0.699216 --> 0.698124).  Saving model ...\n",
      "[30/100] train_loss: 1.63534 valid_loss: 0.69630\n",
      "Validation loss decreased (0.698124 --> 0.696303).  Saving model ...\n",
      "[31/100] train_loss: 0.72434 valid_loss: 0.69453\n",
      "Validation loss decreased (0.696303 --> 0.694530).  Saving model ...\n",
      "[32/100] train_loss: 0.59439 valid_loss: 0.69273\n",
      "Validation loss decreased (0.694530 --> 0.692733).  Saving model ...\n",
      "[33/100] train_loss: 1.46185 valid_loss: 0.69019\n",
      "Validation loss decreased (0.692733 --> 0.690193).  Saving model ...\n",
      "[34/100] train_loss: 0.59316 valid_loss: 0.68774\n",
      "Validation loss decreased (0.690193 --> 0.687740).  Saving model ...\n",
      "[35/100] train_loss: 1.31847 valid_loss: 0.68462\n",
      "Validation loss decreased (0.687740 --> 0.684620).  Saving model ...\n",
      "[36/100] train_loss: 1.23897 valid_loss: 0.68106\n",
      "Validation loss decreased (0.684620 --> 0.681056).  Saving model ...\n",
      "[37/100] train_loss: 1.00930 valid_loss: 0.67771\n",
      "Validation loss decreased (0.681056 --> 0.677713).  Saving model ...\n",
      "[38/100] train_loss: 0.77340 valid_loss: 0.67463\n",
      "Validation loss decreased (0.677713 --> 0.674634).  Saving model ...\n",
      "[39/100] train_loss: 0.72308 valid_loss: 0.67269\n",
      "Validation loss decreased (0.674634 --> 0.672693).  Saving model ...\n",
      "[40/100] train_loss: 0.58703 valid_loss: 0.67088\n",
      "Validation loss decreased (0.672693 --> 0.670880).  Saving model ...\n",
      "[41/100] train_loss: 1.00184 valid_loss: 0.66865\n",
      "Validation loss decreased (0.670880 --> 0.668647).  Saving model ...\n",
      "[42/100] train_loss: 0.57881 valid_loss: 0.66626\n",
      "Validation loss decreased (0.668647 --> 0.666260).  Saving model ...\n",
      "[43/100] train_loss: 0.57778 valid_loss: 0.66356\n",
      "Validation loss decreased (0.666260 --> 0.663558).  Saving model ...\n",
      "[44/100] train_loss: 0.81986 valid_loss: 0.66149\n",
      "Validation loss decreased (0.663558 --> 0.661491).  Saving model ...\n",
      "[45/100] train_loss: 0.97499 valid_loss: 0.65998\n",
      "Validation loss decreased (0.661491 --> 0.659984).  Saving model ...\n",
      "[46/100] train_loss: 0.86859 valid_loss: 0.65915\n",
      "Validation loss decreased (0.659984 --> 0.659150).  Saving model ...\n",
      "[47/100] train_loss: 0.77401 valid_loss: 0.66060\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[48/100] train_loss: 0.95157 valid_loss: 0.66294\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[49/100] train_loss: 0.72336 valid_loss: 0.66708\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[50/100] train_loss: 0.69219 valid_loss: 0.67214\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[51/100] train_loss: 0.61612 valid_loss: 0.67433\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[52/100] train_loss: 0.92641 valid_loss: 0.67675\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[53/100] train_loss: 0.91252 valid_loss: 0.67739\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[54/100] train_loss: 0.64818 valid_loss: 0.67558\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[55/100] train_loss: 0.91119 valid_loss: 0.67424\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[56/100] train_loss: 0.65972 valid_loss: 0.67294\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[57/100] train_loss: 0.65903 valid_loss: 0.67164\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[58/100] train_loss: 0.76367 valid_loss: 0.67011\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[59/100] train_loss: 0.76270 valid_loss: 0.66830\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[60/100] train_loss: 0.60528 valid_loss: 0.66451\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[61/100] train_loss: 0.88431 valid_loss: 0.66135\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[62/100] train_loss: 0.79818 valid_loss: 0.65635\n",
      "Validation loss decreased (0.659150 --> 0.656349).  Saving model ...\n",
      "[63/100] train_loss: 0.75662 valid_loss: 0.65057\n",
      "Validation loss decreased (0.656349 --> 0.650570).  Saving model ...\n",
      "[64/100] train_loss: 0.75451 valid_loss: 0.64400\n",
      "Validation loss decreased (0.650570 --> 0.643998).  Saving model ...\n",
      "[65/100] train_loss: 0.75210 valid_loss: 0.63686\n",
      "Validation loss decreased (0.643998 --> 0.636860).  Saving model ...\n",
      "[66/100] train_loss: 0.59923 valid_loss: 0.63026\n",
      "Validation loss decreased (0.636860 --> 0.630257).  Saving model ...\n",
      "[67/100] train_loss: 0.74593 valid_loss: 0.62511\n",
      "Validation loss decreased (0.630257 --> 0.625113).  Saving model ...\n",
      "[68/100] train_loss: 0.61379 valid_loss: 0.62305\n",
      "Validation loss decreased (0.625113 --> 0.623048).  Saving model ...\n",
      "[69/100] train_loss: 0.58370 valid_loss: 0.62119\n",
      "Validation loss decreased (0.623048 --> 0.621193).  Saving model ...\n",
      "[70/100] train_loss: 0.69647 valid_loss: 0.61977\n",
      "Validation loss decreased (0.621193 --> 0.619773).  Saving model ...\n",
      "[71/100] train_loss: 0.88398 valid_loss: 0.61917\n",
      "Validation loss decreased (0.619773 --> 0.619175).  Saving model ...\n",
      "[72/100] train_loss: 0.62522 valid_loss: 0.62328\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[73/100] train_loss: 0.84466 valid_loss: 0.63178\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[74/100] train_loss: 0.58250 valid_loss: 0.64093\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[75/100] train_loss: 0.79757 valid_loss: 0.65296\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[76/100] train_loss: 0.75937 valid_loss: 0.66524\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[77/100] train_loss: 0.83474 valid_loss: 0.67598\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[78/100] train_loss: 0.77391 valid_loss: 0.68321\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[79/100] train_loss: 0.57192 valid_loss: 0.68803\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[80/100] train_loss: 0.57652 valid_loss: 0.69028\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[81/100] train_loss: 0.82443 valid_loss: 0.69361\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[82/100] train_loss: 0.63087 valid_loss: 0.69731\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[83/100] train_loss: 0.81796 valid_loss: 0.70190\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[84/100] train_loss: 0.81406 valid_loss: 0.70740\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[85/100] train_loss: 0.60444 valid_loss: 0.71281\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[86/100] train_loss: 0.86623 valid_loss: 0.71646\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[87/100] train_loss: 0.80105 valid_loss: 0.72134\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[88/100] train_loss: 0.59113 valid_loss: 0.72622\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[89/100] train_loss: 0.79177 valid_loss: 0.73231\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[90/100] train_loss: 0.67547 valid_loss: 0.73929\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[91/100] train_loss: 0.77916 valid_loss: 0.74422\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[92/100] train_loss: 0.60973 valid_loss: 0.74193\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[93/100] train_loss: 0.58650 valid_loss: 0.73960\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[94/100] train_loss: 0.77361 valid_loss: 0.73892\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[95/100] train_loss: 0.66347 valid_loss: 0.73967\n",
      "EarlyStopping counter: 24 out of 100\n",
      "[96/100] train_loss: 0.76751 valid_loss: 0.74227\n",
      "EarlyStopping counter: 25 out of 100\n",
      "[97/100] train_loss: 0.64628 valid_loss: 0.74638\n",
      "EarlyStopping counter: 26 out of 100\n",
      "[98/100] train_loss: 0.77760 valid_loss: 0.74998\n",
      "EarlyStopping counter: 27 out of 100\n",
      "[99/100] train_loss: 0.75935 valid_loss: 0.75324\n",
      "EarlyStopping counter: 28 out of 100\n",
      "[100/100] train_loss: 0.75406 valid_loss: 0.75891\n",
      "EarlyStopping counter: 29 out of 100\n",
      "  Training 2/5 for Fold 3\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] train_loss: 0.95926 valid_loss: 0.72133\n",
      "Validation loss decreased (inf --> 0.721334).  Saving model ...\n",
      "[2/100] train_loss: 0.85910 valid_loss: 0.72103\n",
      "Validation loss decreased (0.721334 --> 0.721029).  Saving model ...\n",
      "[3/100] train_loss: 0.71154 valid_loss: 0.72092\n",
      "Validation loss decreased (0.721029 --> 0.720915).  Saving model ...\n",
      "[4/100] train_loss: 1.10259 valid_loss: 0.72070\n",
      "Validation loss decreased (0.720915 --> 0.720701).  Saving model ...\n",
      "[5/100] train_loss: 0.70030 valid_loss: 0.72056\n",
      "Validation loss decreased (0.720701 --> 0.720561).  Saving model ...\n",
      "[6/100] train_loss: 1.09347 valid_loss: 0.72046\n",
      "Validation loss decreased (0.720561 --> 0.720463).  Saving model ...\n",
      "[7/100] train_loss: 0.81181 valid_loss: 0.72036\n",
      "Validation loss decreased (0.720463 --> 0.720357).  Saving model ...\n",
      "[8/100] train_loss: 1.07941 valid_loss: 0.72037\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[9/100] train_loss: 0.81643 valid_loss: 0.72050\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[10/100] train_loss: 0.92622 valid_loss: 0.72038\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[11/100] train_loss: 0.67580 valid_loss: 0.72028\n",
      "Validation loss decreased (0.720357 --> 0.720282).  Saving model ...\n",
      "[12/100] train_loss: 1.05338 valid_loss: 0.72033\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[13/100] train_loss: 0.91938 valid_loss: 0.72011\n",
      "Validation loss decreased (0.720282 --> 0.720112).  Saving model ...\n",
      "[14/100] train_loss: 0.91581 valid_loss: 0.71966\n",
      "Validation loss decreased (0.720112 --> 0.719657).  Saving model ...\n",
      "[15/100] train_loss: 0.78673 valid_loss: 0.71931\n",
      "Validation loss decreased (0.719657 --> 0.719311).  Saving model ...\n",
      "[16/100] train_loss: 0.90549 valid_loss: 0.71874\n",
      "Validation loss decreased (0.719311 --> 0.718737).  Saving model ...\n",
      "[17/100] train_loss: 0.77453 valid_loss: 0.71827\n",
      "Validation loss decreased (0.718737 --> 0.718268).  Saving model ...\n",
      "[18/100] train_loss: 0.79663 valid_loss: 0.71779\n",
      "Validation loss decreased (0.718268 --> 0.717789).  Saving model ...\n",
      "[19/100] train_loss: 1.02945 valid_loss: 0.71749\n",
      "Validation loss decreased (0.717789 --> 0.717487).  Saving model ...\n",
      "[20/100] train_loss: 1.02531 valid_loss: 0.71737\n",
      "Validation loss decreased (0.717487 --> 0.717367).  Saving model ...\n",
      "[21/100] train_loss: 0.74694 valid_loss: 0.71732\n",
      "Validation loss decreased (0.717367 --> 0.717324).  Saving model ...\n",
      "[22/100] train_loss: 0.62500 valid_loss: 0.71728\n",
      "Validation loss decreased (0.717324 --> 0.717281).  Saving model ...\n",
      "[23/100] train_loss: 0.73019 valid_loss: 0.71730\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[24/100] train_loss: 1.00383 valid_loss: 0.71759\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[25/100] train_loss: 0.99713 valid_loss: 0.71818\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[26/100] train_loss: 1.67736 valid_loss: 0.71839\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[27/100] train_loss: 0.78150 valid_loss: 0.71858\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[28/100] train_loss: 0.59981 valid_loss: 0.71877\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[29/100] train_loss: 0.83651 valid_loss: 0.71828\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[30/100] train_loss: 1.52242 valid_loss: 0.71755\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[31/100] train_loss: 0.81358 valid_loss: 0.71613\n",
      "Validation loss decreased (0.717281 --> 0.716129).  Saving model ...\n",
      "[32/100] train_loss: 0.77315 valid_loss: 0.71461\n",
      "Validation loss decreased (0.716129 --> 0.714612).  Saving model ...\n",
      "[33/100] train_loss: 1.36247 valid_loss: 0.71290\n",
      "Validation loss decreased (0.714612 --> 0.712896).  Saving model ...\n",
      "[34/100] train_loss: 0.65031 valid_loss: 0.71129\n",
      "Validation loss decreased (0.712896 --> 0.711289).  Saving model ...\n",
      "[35/100] train_loss: 0.74421 valid_loss: 0.70878\n",
      "Validation loss decreased (0.711289 --> 0.708779).  Saving model ...\n",
      "[36/100] train_loss: 0.72385 valid_loss: 0.70537\n",
      "Validation loss decreased (0.708779 --> 0.705369).  Saving model ...\n",
      "[37/100] train_loss: 1.18642 valid_loss: 0.70191\n",
      "Validation loss decreased (0.705369 --> 0.701907).  Saving model ...\n",
      "[38/100] train_loss: 1.14370 valid_loss: 0.69842\n",
      "Validation loss decreased (0.701907 --> 0.698424).  Saving model ...\n",
      "[39/100] train_loss: 0.63795 valid_loss: 0.69516\n",
      "Validation loss decreased (0.698424 --> 0.695160).  Saving model ...\n",
      "[40/100] train_loss: 0.64055 valid_loss: 0.69237\n",
      "Validation loss decreased (0.695160 --> 0.692374).  Saving model ...\n",
      "[41/100] train_loss: 0.77134 valid_loss: 0.68991\n",
      "Validation loss decreased (0.692374 --> 0.689910).  Saving model ...\n",
      "[42/100] train_loss: 0.62784 valid_loss: 0.68802\n",
      "Validation loss decreased (0.689910 --> 0.688015).  Saving model ...\n",
      "[43/100] train_loss: 0.60239 valid_loss: 0.68554\n",
      "Validation loss decreased (0.688015 --> 0.685542).  Saving model ...\n",
      "[44/100] train_loss: 0.61189 valid_loss: 0.68361\n",
      "Validation loss decreased (0.685542 --> 0.683609).  Saving model ...\n",
      "[45/100] train_loss: 0.77293 valid_loss: 0.68197\n",
      "Validation loss decreased (0.683609 --> 0.681974).  Saving model ...\n",
      "[46/100] train_loss: 0.96211 valid_loss: 0.68056\n",
      "Validation loss decreased (0.681974 --> 0.680559).  Saving model ...\n",
      "[47/100] train_loss: 0.89221 valid_loss: 0.67913\n",
      "Validation loss decreased (0.680559 --> 0.679128).  Saving model ...\n",
      "[48/100] train_loss: 0.77129 valid_loss: 0.67771\n",
      "Validation loss decreased (0.679128 --> 0.677709).  Saving model ...\n",
      "[49/100] train_loss: 0.94990 valid_loss: 0.67629\n",
      "Validation loss decreased (0.677709 --> 0.676285).  Saving model ...\n",
      "[50/100] train_loss: 0.60347 valid_loss: 0.67471\n",
      "Validation loss decreased (0.676285 --> 0.674708).  Saving model ...\n",
      "[51/100] train_loss: 0.58719 valid_loss: 0.67331\n",
      "Validation loss decreased (0.674708 --> 0.673308).  Saving model ...\n",
      "[52/100] train_loss: 0.85678 valid_loss: 0.67407\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[53/100] train_loss: 0.58672 valid_loss: 0.67477\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[54/100] train_loss: 0.79930 valid_loss: 0.67521\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[55/100] train_loss: 0.76608 valid_loss: 0.67554\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[56/100] train_loss: 0.91008 valid_loss: 0.67615\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[57/100] train_loss: 0.64400 valid_loss: 0.67665\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[58/100] train_loss: 0.75317 valid_loss: 0.67848\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[59/100] train_loss: 0.65419 valid_loss: 0.68008\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[60/100] train_loss: 0.72006 valid_loss: 0.68242\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[61/100] train_loss: 0.69702 valid_loss: 0.68508\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[62/100] train_loss: 0.67113 valid_loss: 0.68772\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[63/100] train_loss: 0.64921 valid_loss: 0.69016\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[64/100] train_loss: 0.90973 valid_loss: 0.69136\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[65/100] train_loss: 0.62817 valid_loss: 0.69252\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[66/100] train_loss: 0.77150 valid_loss: 0.69340\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[67/100] train_loss: 0.96727 valid_loss: 0.69331\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[68/100] train_loss: 0.77171 valid_loss: 0.69306\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[69/100] train_loss: 0.70797 valid_loss: 0.69110\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[70/100] train_loss: 0.73772 valid_loss: 0.68933\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[71/100] train_loss: 0.86377 valid_loss: 0.68809\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[72/100] train_loss: 0.86022 valid_loss: 0.68738\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[73/100] train_loss: 0.61633 valid_loss: 0.68689\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[74/100] train_loss: 0.61606 valid_loss: 0.68665\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[75/100] train_loss: 0.84611 valid_loss: 0.68707\n",
      "EarlyStopping counter: 24 out of 100\n",
      "[76/100] train_loss: 0.61353 valid_loss: 0.68779\n",
      "EarlyStopping counter: 25 out of 100\n",
      "[77/100] train_loss: 0.83525 valid_loss: 0.68929\n",
      "EarlyStopping counter: 26 out of 100\n",
      "[78/100] train_loss: 0.84124 valid_loss: 0.69007\n",
      "EarlyStopping counter: 27 out of 100\n",
      "[79/100] train_loss: 0.62761 valid_loss: 0.68759\n",
      "EarlyStopping counter: 28 out of 100\n",
      "[80/100] train_loss: 0.76658 valid_loss: 0.68433\n",
      "EarlyStopping counter: 29 out of 100\n",
      "[81/100] train_loss: 0.72732 valid_loss: 0.68128\n",
      "EarlyStopping counter: 30 out of 100\n",
      "[82/100] train_loss: 0.64080 valid_loss: 0.67922\n",
      "EarlyStopping counter: 31 out of 100\n",
      "[83/100] train_loss: 0.56225 valid_loss: 0.67582\n",
      "EarlyStopping counter: 32 out of 100\n",
      "[84/100] train_loss: 0.76686 valid_loss: 0.67224\n",
      "Validation loss decreased (0.673308 --> 0.672237).  Saving model ...\n",
      "[85/100] train_loss: 0.79755 valid_loss: 0.66979\n",
      "Validation loss decreased (0.672237 --> 0.669787).  Saving model ...\n",
      "[86/100] train_loss: 0.69321 valid_loss: 0.66987\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[87/100] train_loss: 0.76345 valid_loss: 0.66829\n",
      "Validation loss decreased (0.669787 --> 0.668290).  Saving model ...\n",
      "[88/100] train_loss: 0.78653 valid_loss: 0.66804\n",
      "Validation loss decreased (0.668290 --> 0.668040).  Saving model ...\n",
      "[89/100] train_loss: 0.67157 valid_loss: 0.67014\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[90/100] train_loss: 0.64708 valid_loss: 0.67379\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[91/100] train_loss: 0.76852 valid_loss: 0.67516\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[92/100] train_loss: 0.59976 valid_loss: 0.67714\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[93/100] train_loss: 0.56614 valid_loss: 0.67512\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[94/100] train_loss: 0.77161 valid_loss: 0.67440\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[95/100] train_loss: 0.79646 valid_loss: 0.67229\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[96/100] train_loss: 0.79897 valid_loss: 0.67064\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[97/100] train_loss: 0.57196 valid_loss: 0.66356\n",
      "Validation loss decreased (0.668040 --> 0.663565).  Saving model ...\n",
      "[98/100] train_loss: 0.57753 valid_loss: 0.65653\n",
      "Validation loss decreased (0.663565 --> 0.656527).  Saving model ...\n",
      "[99/100] train_loss: 0.80177 valid_loss: 0.64989\n",
      "Validation loss decreased (0.656527 --> 0.649886).  Saving model ...\n",
      "[100/100] train_loss: 0.77187 valid_loss: 0.64085\n",
      "Validation loss decreased (0.649886 --> 0.640851).  Saving model ...\n",
      "  Training 3/5 for Fold 3\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n",
      "[1/100] train_loss: 0.81566 valid_loss: 0.72081\n",
      "Validation loss decreased (inf --> 0.720815).  Saving model ...\n",
      "[2/100] train_loss: 1.06383 valid_loss: 0.72116\n",
      "EarlyStopping counter: 1 out of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/100] train_loss: 1.05189 valid_loss: 0.72191\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[4/100] train_loss: 0.83578 valid_loss: 0.72290\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[5/100] train_loss: 1.02978 valid_loss: 0.72413\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[6/100] train_loss: 0.98540 valid_loss: 0.72405\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[7/100] train_loss: 2.11501 valid_loss: 0.72359\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[8/100] train_loss: 0.98027 valid_loss: 0.72259\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[9/100] train_loss: 0.97461 valid_loss: 0.72122\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[10/100] train_loss: 0.81479 valid_loss: 0.72016\n",
      "Validation loss decreased (0.720815 --> 0.720158).  Saving model ...\n",
      "[11/100] train_loss: 0.81073 valid_loss: 0.71934\n",
      "Validation loss decreased (0.720158 --> 0.719335).  Saving model ...\n",
      "[12/100] train_loss: 0.79923 valid_loss: 0.71855\n",
      "Validation loss decreased (0.719335 --> 0.718550).  Saving model ...\n",
      "[13/100] train_loss: 0.79838 valid_loss: 0.71780\n",
      "Validation loss decreased (0.718550 --> 0.717795).  Saving model ...\n",
      "[14/100] train_loss: 1.99395 valid_loss: 0.71687\n",
      "Validation loss decreased (0.717795 --> 0.716872).  Saving model ...\n",
      "[15/100] train_loss: 0.79682 valid_loss: 0.71599\n",
      "Validation loss decreased (0.716872 --> 0.715989).  Saving model ...\n",
      "[16/100] train_loss: 0.79610 valid_loss: 0.71514\n",
      "Validation loss decreased (0.715989 --> 0.715138).  Saving model ...\n",
      "[17/100] train_loss: 0.92817 valid_loss: 0.71395\n",
      "Validation loss decreased (0.715138 --> 0.713951).  Saving model ...\n",
      "[18/100] train_loss: 1.91701 valid_loss: 0.71267\n",
      "Validation loss decreased (0.713951 --> 0.712669).  Saving model ...\n",
      "[19/100] train_loss: 0.65912 valid_loss: 0.71149\n",
      "Validation loss decreased (0.712669 --> 0.711492).  Saving model ...\n",
      "[20/100] train_loss: 0.79337 valid_loss: 0.71037\n",
      "Validation loss decreased (0.711492 --> 0.710374).  Saving model ...\n",
      "[21/100] train_loss: 1.84451 valid_loss: 0.70913\n",
      "Validation loss decreased (0.710374 --> 0.709130).  Saving model ...\n",
      "[22/100] train_loss: 0.79211 valid_loss: 0.70794\n",
      "Validation loss decreased (0.709130 --> 0.707944).  Saving model ...\n",
      "[23/100] train_loss: 1.78723 valid_loss: 0.70663\n",
      "Validation loss decreased (0.707944 --> 0.706630).  Saving model ...\n",
      "[24/100] train_loss: 1.75263 valid_loss: 0.70521\n",
      "Validation loss decreased (0.706630 --> 0.705209).  Saving model ...\n",
      "[25/100] train_loss: 1.71156 valid_loss: 0.70371\n",
      "Validation loss decreased (0.705209 --> 0.703705).  Saving model ...\n",
      "[26/100] train_loss: 0.84307 valid_loss: 0.70204\n",
      "Validation loss decreased (0.703705 --> 0.702042).  Saving model ...\n",
      "[27/100] train_loss: 1.61462 valid_loss: 0.70039\n",
      "Validation loss decreased (0.702042 --> 0.700392).  Saving model ...\n",
      "[28/100] train_loss: 0.78979 valid_loss: 0.69892\n",
      "Validation loss decreased (0.700392 --> 0.698918).  Saving model ...\n",
      "[29/100] train_loss: 0.78971 valid_loss: 0.69761\n",
      "Validation loss decreased (0.698918 --> 0.697612).  Saving model ...\n",
      "[30/100] train_loss: 0.70711 valid_loss: 0.69654\n",
      "Validation loss decreased (0.697612 --> 0.696539).  Saving model ...\n",
      "[31/100] train_loss: 0.69860 valid_loss: 0.69567\n",
      "Validation loss decreased (0.696539 --> 0.695669).  Saving model ...\n",
      "[32/100] train_loss: 0.79000 valid_loss: 0.69491\n",
      "Validation loss decreased (0.695669 --> 0.694914).  Saving model ...\n",
      "[33/100] train_loss: 0.68010 valid_loss: 0.69431\n",
      "Validation loss decreased (0.694914 --> 0.694313).  Saving model ...\n",
      "[34/100] train_loss: 0.62099 valid_loss: 0.69388\n",
      "Validation loss decreased (0.694313 --> 0.693878).  Saving model ...\n",
      "[35/100] train_loss: 1.05243 valid_loss: 0.69328\n",
      "Validation loss decreased (0.693878 --> 0.693285).  Saving model ...\n",
      "[36/100] train_loss: 0.69080 valid_loss: 0.69266\n",
      "Validation loss decreased (0.693285 --> 0.692657).  Saving model ...\n",
      "[37/100] train_loss: 0.64676 valid_loss: 0.69216\n",
      "Validation loss decreased (0.692657 --> 0.692158).  Saving model ...\n",
      "[38/100] train_loss: 0.79311 valid_loss: 0.69163\n",
      "Validation loss decreased (0.692158 --> 0.691627).  Saving model ...\n",
      "[39/100] train_loss: 1.01642 valid_loss: 0.69133\n",
      "Validation loss decreased (0.691627 --> 0.691333).  Saving model ...\n",
      "[40/100] train_loss: 0.72377 valid_loss: 0.69114\n",
      "Validation loss decreased (0.691333 --> 0.691142).  Saving model ...\n",
      "[41/100] train_loss: 0.73823 valid_loss: 0.69069\n",
      "Validation loss decreased (0.691142 --> 0.690695).  Saving model ...\n",
      "[42/100] train_loss: 0.79581 valid_loss: 0.68997\n",
      "Validation loss decreased (0.690695 --> 0.689970).  Saving model ...\n",
      "[43/100] train_loss: 0.79403 valid_loss: 0.68906\n",
      "Validation loss decreased (0.689970 --> 0.689057).  Saving model ...\n",
      "[44/100] train_loss: 0.79198 valid_loss: 0.68804\n",
      "Validation loss decreased (0.689057 --> 0.688042).  Saving model ...\n",
      "[45/100] train_loss: 1.03508 valid_loss: 0.68664\n",
      "Validation loss decreased (0.688042 --> 0.686637).  Saving model ...\n",
      "[46/100] train_loss: 1.02591 valid_loss: 0.68521\n",
      "Validation loss decreased (0.686637 --> 0.685215).  Saving model ...\n",
      "[47/100] train_loss: 0.78369 valid_loss: 0.68420\n",
      "Validation loss decreased (0.685215 --> 0.684197).  Saving model ...\n",
      "[48/100] train_loss: 0.64698 valid_loss: 0.68309\n",
      "Validation loss decreased (0.684197 --> 0.683094).  Saving model ...\n",
      "[49/100] train_loss: 0.77863 valid_loss: 0.68208\n",
      "Validation loss decreased (0.683094 --> 0.682080).  Saving model ...\n",
      "[50/100] train_loss: 0.77650 valid_loss: 0.68116\n",
      "Validation loss decreased (0.682080 --> 0.681159).  Saving model ...\n",
      "[51/100] train_loss: 0.97865 valid_loss: 0.68040\n",
      "Validation loss decreased (0.681159 --> 0.680403).  Saving model ...\n",
      "[52/100] train_loss: 0.67130 valid_loss: 0.68035\n",
      "Validation loss decreased (0.680403 --> 0.680346).  Saving model ...\n",
      "[53/100] train_loss: 0.95979 valid_loss: 0.68064\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[54/100] train_loss: 0.65933 valid_loss: 0.68002\n",
      "Validation loss decreased (0.680346 --> 0.680019).  Saving model ...\n",
      "[55/100] train_loss: 0.92198 valid_loss: 0.67855\n",
      "Validation loss decreased (0.680019 --> 0.678554).  Saving model ...\n",
      "[56/100] train_loss: 0.76533 valid_loss: 0.67707\n",
      "Validation loss decreased (0.678554 --> 0.677067).  Saving model ...\n",
      "[57/100] train_loss: 0.86689 valid_loss: 0.67477\n",
      "Validation loss decreased (0.677067 --> 0.674767).  Saving model ...\n",
      "[58/100] train_loss: 0.82604 valid_loss: 0.67173\n",
      "Validation loss decreased (0.674767 --> 0.671731).  Saving model ...\n",
      "[59/100] train_loss: 0.63643 valid_loss: 0.66847\n",
      "Validation loss decreased (0.671731 --> 0.668466).  Saving model ...\n",
      "[60/100] train_loss: 0.90968 valid_loss: 0.66536\n",
      "Validation loss decreased (0.668466 --> 0.665364).  Saving model ...\n",
      "[61/100] train_loss: 0.72659 valid_loss: 0.66245\n",
      "Validation loss decreased (0.665364 --> 0.662455).  Saving model ...\n",
      "[62/100] train_loss: 0.61626 valid_loss: 0.65925\n",
      "Validation loss decreased (0.662455 --> 0.659252).  Saving model ...\n",
      "[63/100] train_loss: 0.98853 valid_loss: 0.66113\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[64/100] train_loss: 0.88587 valid_loss: 0.66342\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[65/100] train_loss: 0.75600 valid_loss: 0.66546\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[66/100] train_loss: 0.62157 valid_loss: 0.66736\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[67/100] train_loss: 0.58450 valid_loss: 0.66975\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[68/100] train_loss: 0.62370 valid_loss: 0.67204\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[69/100] train_loss: 0.86154 valid_loss: 0.67500\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[70/100] train_loss: 0.62024 valid_loss: 0.67795\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[71/100] train_loss: 0.61636 valid_loss: 0.68092\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[72/100] train_loss: 0.75432 valid_loss: 0.68344\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[73/100] train_loss: 0.75344 valid_loss: 0.68546\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[74/100] train_loss: 0.91720 valid_loss: 0.68956\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[75/100] train_loss: 0.58551 valid_loss: 0.69165\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[76/100] train_loss: 0.59083 valid_loss: 0.69146\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[77/100] train_loss: 0.83036 valid_loss: 0.69222\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[78/100] train_loss: 0.59021 valid_loss: 0.69059\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[79/100] train_loss: 0.75059 valid_loss: 0.68841\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[80/100] train_loss: 0.66095 valid_loss: 0.68623\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[81/100] train_loss: 0.60370 valid_loss: 0.68418\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[82/100] train_loss: 0.80832 valid_loss: 0.68421\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[83/100] train_loss: 0.78062 valid_loss: 0.68591\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[84/100] train_loss: 0.74761 valid_loss: 0.68664\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[85/100] train_loss: 0.61999 valid_loss: 0.68741\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[86/100] train_loss: 0.67658 valid_loss: 0.68892\n",
      "EarlyStopping counter: 24 out of 100\n",
      "[87/100] train_loss: 0.63276 valid_loss: 0.69038\n",
      "EarlyStopping counter: 25 out of 100\n",
      "[88/100] train_loss: 0.74956 valid_loss: 0.69096\n",
      "EarlyStopping counter: 26 out of 100\n",
      "[89/100] train_loss: 0.74943 valid_loss: 0.69079\n",
      "EarlyStopping counter: 27 out of 100\n",
      "[90/100] train_loss: 0.64870 valid_loss: 0.68629\n",
      "EarlyStopping counter: 28 out of 100\n",
      "[91/100] train_loss: 0.61396 valid_loss: 0.68253\n",
      "EarlyStopping counter: 29 out of 100\n",
      "[92/100] train_loss: 0.74594 valid_loss: 0.67841\n",
      "EarlyStopping counter: 30 out of 100\n",
      "[93/100] train_loss: 0.84662 valid_loss: 0.67264\n",
      "EarlyStopping counter: 31 out of 100\n",
      "[94/100] train_loss: 0.80914 valid_loss: 0.66803\n",
      "EarlyStopping counter: 32 out of 100\n",
      "[95/100] train_loss: 0.61442 valid_loss: 0.65960\n",
      "EarlyStopping counter: 33 out of 100\n",
      "[96/100] train_loss: 0.80228 valid_loss: 0.64908\n",
      "Validation loss decreased (0.659252 --> 0.649080).  Saving model ...\n",
      "[97/100] train_loss: 0.57650 valid_loss: 0.63590\n",
      "Validation loss decreased (0.649080 --> 0.635896).  Saving model ...\n",
      "[98/100] train_loss: 0.80385 valid_loss: 0.62411\n",
      "Validation loss decreased (0.635896 --> 0.624106).  Saving model ...\n",
      "[99/100] train_loss: 0.62749 valid_loss: 0.61356\n",
      "Validation loss decreased (0.624106 --> 0.613555).  Saving model ...\n",
      "[100/100] train_loss: 0.72191 valid_loss: 0.60593\n",
      "Validation loss decreased (0.613555 --> 0.605929).  Saving model ...\n",
      "  Training 4/5 for Fold 3\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] train_loss: 0.80794 valid_loss: 0.71462\n",
      "Validation loss decreased (inf --> 0.714624).  Saving model ...\n",
      "[2/100] train_loss: 0.86453 valid_loss: 0.71466\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[3/100] train_loss: 0.72158 valid_loss: 0.71463\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[4/100] train_loss: 0.80371 valid_loss: 0.71450\n",
      "Validation loss decreased (0.714624 --> 0.714498).  Saving model ...\n",
      "[5/100] train_loss: 2.21476 valid_loss: 0.71418\n",
      "Validation loss decreased (0.714498 --> 0.714176).  Saving model ...\n",
      "[6/100] train_loss: 0.82650 valid_loss: 0.71402\n",
      "Validation loss decreased (0.714176 --> 0.714022).  Saving model ...\n",
      "[7/100] train_loss: 0.69519 valid_loss: 0.71388\n",
      "Validation loss decreased (0.714022 --> 0.713876).  Saving model ...\n",
      "[8/100] train_loss: 0.80123 valid_loss: 0.71371\n",
      "Validation loss decreased (0.713876 --> 0.713708).  Saving model ...\n",
      "[9/100] train_loss: 0.80234 valid_loss: 0.71364\n",
      "Validation loss decreased (0.713708 --> 0.713637).  Saving model ...\n",
      "[10/100] train_loss: 2.09510 valid_loss: 0.71332\n",
      "Validation loss decreased (0.713637 --> 0.713316).  Saving model ...\n",
      "[11/100] train_loss: 1.05994 valid_loss: 0.71336\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[12/100] train_loss: 0.66606 valid_loss: 0.71337\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[13/100] train_loss: 2.01653 valid_loss: 0.71310\n",
      "Validation loss decreased (0.713316 --> 0.713103).  Saving model ...\n",
      "[14/100] train_loss: 1.98490 valid_loss: 0.71263\n",
      "Validation loss decreased (0.713103 --> 0.712627).  Saving model ...\n",
      "[15/100] train_loss: 0.75724 valid_loss: 0.71222\n",
      "Validation loss decreased (0.712627 --> 0.712221).  Saving model ...\n",
      "[16/100] train_loss: 1.91093 valid_loss: 0.71161\n",
      "Validation loss decreased (0.712221 --> 0.711612).  Saving model ...\n",
      "[17/100] train_loss: 1.05429 valid_loss: 0.71127\n",
      "Validation loss decreased (0.711612 --> 0.711274).  Saving model ...\n",
      "[18/100] train_loss: 0.89631 valid_loss: 0.71055\n",
      "Validation loss decreased (0.711274 --> 0.710553).  Saving model ...\n",
      "[19/100] train_loss: 0.62689 valid_loss: 0.70984\n",
      "Validation loss decreased (0.710553 --> 0.709839).  Saving model ...\n",
      "[20/100] train_loss: 1.74852 valid_loss: 0.70889\n",
      "Validation loss decreased (0.709839 --> 0.708894).  Saving model ...\n",
      "[21/100] train_loss: 1.05097 valid_loss: 0.70821\n",
      "Validation loss decreased (0.708894 --> 0.708210).  Saving model ...\n",
      "[22/100] train_loss: 0.85494 valid_loss: 0.70714\n",
      "Validation loss decreased (0.708210 --> 0.707138).  Saving model ...\n",
      "[23/100] train_loss: 0.61090 valid_loss: 0.70607\n",
      "Validation loss decreased (0.707138 --> 0.706071).  Saving model ...\n",
      "[24/100] train_loss: 0.79270 valid_loss: 0.70502\n",
      "Validation loss decreased (0.706071 --> 0.705025).  Saving model ...\n",
      "[25/100] train_loss: 1.04578 valid_loss: 0.70427\n",
      "Validation loss decreased (0.705025 --> 0.704271).  Saving model ...\n",
      "[26/100] train_loss: 0.80968 valid_loss: 0.70299\n",
      "Validation loss decreased (0.704271 --> 0.702988).  Saving model ...\n",
      "[27/100] train_loss: 0.60685 valid_loss: 0.70173\n",
      "Validation loss decreased (0.702988 --> 0.701730).  Saving model ...\n",
      "[28/100] train_loss: 1.38142 valid_loss: 0.69999\n",
      "Validation loss decreased (0.701730 --> 0.699992).  Saving model ...\n",
      "[29/100] train_loss: 0.61242 valid_loss: 0.69832\n",
      "Validation loss decreased (0.699992 --> 0.698320).  Saving model ...\n",
      "[30/100] train_loss: 0.75119 valid_loss: 0.69603\n",
      "Validation loss decreased (0.698320 --> 0.696032).  Saving model ...\n",
      "[31/100] train_loss: 1.21126 valid_loss: 0.69325\n",
      "Validation loss decreased (0.696032 --> 0.693250).  Saving model ...\n",
      "[32/100] train_loss: 0.70412 valid_loss: 0.68985\n",
      "Validation loss decreased (0.693250 --> 0.689850).  Saving model ...\n",
      "[33/100] train_loss: 1.04222 valid_loss: 0.68674\n",
      "Validation loss decreased (0.689850 --> 0.686739).  Saving model ...\n",
      "[34/100] train_loss: 0.79370 valid_loss: 0.68372\n",
      "Validation loss decreased (0.686739 --> 0.683723).  Saving model ...\n",
      "[35/100] train_loss: 0.61977 valid_loss: 0.68012\n",
      "Validation loss decreased (0.683723 --> 0.680119).  Saving model ...\n",
      "[36/100] train_loss: 0.64592 valid_loss: 0.67733\n",
      "Validation loss decreased (0.680119 --> 0.677326).  Saving model ...\n",
      "[37/100] train_loss: 0.58832 valid_loss: 0.67547\n",
      "Validation loss decreased (0.677326 --> 0.675471).  Saving model ...\n",
      "[38/100] train_loss: 0.90795 valid_loss: 0.67536\n",
      "Validation loss decreased (0.675471 --> 0.675357).  Saving model ...\n",
      "[39/100] train_loss: 0.90486 valid_loss: 0.67558\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[40/100] train_loss: 1.03868 valid_loss: 0.67462\n",
      "Validation loss decreased (0.675357 --> 0.674623).  Saving model ...\n",
      "[41/100] train_loss: 0.81085 valid_loss: 0.67283\n",
      "Validation loss decreased (0.674623 --> 0.672826).  Saving model ...\n",
      "[42/100] train_loss: 0.59681 valid_loss: 0.67063\n",
      "Validation loss decreased (0.672826 --> 0.670632).  Saving model ...\n",
      "[43/100] train_loss: 1.01518 valid_loss: 0.66859\n",
      "Validation loss decreased (0.670632 --> 0.668588).  Saving model ...\n",
      "[44/100] train_loss: 0.62929 valid_loss: 0.66776\n",
      "Validation loss decreased (0.668588 --> 0.667758).  Saving model ...\n",
      "[45/100] train_loss: 0.84594 valid_loss: 0.66904\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[46/100] train_loss: 0.84403 valid_loss: 0.67042\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[47/100] train_loss: 0.61938 valid_loss: 0.67189\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[48/100] train_loss: 0.97199 valid_loss: 0.67364\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[49/100] train_loss: 0.59154 valid_loss: 0.67451\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[50/100] train_loss: 0.59418 valid_loss: 0.67434\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[51/100] train_loss: 0.95190 valid_loss: 0.67458\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[52/100] train_loss: 0.71597 valid_loss: 0.67612\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[53/100] train_loss: 0.93862 valid_loss: 0.67800\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[54/100] train_loss: 0.68666 valid_loss: 0.68074\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[55/100] train_loss: 0.64283 valid_loss: 0.68318\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[56/100] train_loss: 0.85450 valid_loss: 0.68429\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[57/100] train_loss: 0.62783 valid_loss: 0.68311\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[58/100] train_loss: 0.62011 valid_loss: 0.67975\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[59/100] train_loss: 0.76734 valid_loss: 0.67612\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[60/100] train_loss: 0.79638 valid_loss: 0.67115\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[61/100] train_loss: 0.76956 valid_loss: 0.66468\n",
      "Validation loss decreased (0.667758 --> 0.664679).  Saving model ...\n",
      "[62/100] train_loss: 0.89680 valid_loss: 0.65826\n",
      "Validation loss decreased (0.664679 --> 0.658257).  Saving model ...\n",
      "[63/100] train_loss: 0.89208 valid_loss: 0.65203\n",
      "Validation loss decreased (0.658257 --> 0.652032).  Saving model ...\n",
      "[64/100] train_loss: 0.76091 valid_loss: 0.64519\n",
      "Validation loss decreased (0.652032 --> 0.645186).  Saving model ...\n",
      "[65/100] train_loss: 0.63035 valid_loss: 0.63830\n",
      "Validation loss decreased (0.645186 --> 0.638304).  Saving model ...\n",
      "[66/100] train_loss: 0.87241 valid_loss: 0.63751\n",
      "Validation loss decreased (0.638304 --> 0.637510).  Saving model ...\n",
      "[67/100] train_loss: 0.62499 valid_loss: 0.63642\n",
      "Validation loss decreased (0.637510 --> 0.636420).  Saving model ...\n",
      "[68/100] train_loss: 0.62384 valid_loss: 0.63506\n",
      "Validation loss decreased (0.636420 --> 0.635060).  Saving model ...\n",
      "[69/100] train_loss: 0.61972 valid_loss: 0.63344\n",
      "Validation loss decreased (0.635060 --> 0.633444).  Saving model ...\n",
      "[70/100] train_loss: 0.86292 valid_loss: 0.63258\n",
      "Validation loss decreased (0.633444 --> 0.632584).  Saving model ...\n",
      "[71/100] train_loss: 0.66546 valid_loss: 0.63214\n",
      "Validation loss decreased (0.632584 --> 0.632141).  Saving model ...\n",
      "[72/100] train_loss: 0.66189 valid_loss: 0.63218\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[73/100] train_loss: 0.94757 valid_loss: 0.63945\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[74/100] train_loss: 0.90945 valid_loss: 0.65212\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[75/100] train_loss: 0.83725 valid_loss: 0.66610\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[76/100] train_loss: 0.59405 valid_loss: 0.67976\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[77/100] train_loss: 0.69580 valid_loss: 0.69066\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[78/100] train_loss: 0.64976 valid_loss: 0.69908\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[79/100] train_loss: 0.80622 valid_loss: 0.70420\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[80/100] train_loss: 0.68211 valid_loss: 0.70858\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[81/100] train_loss: 0.68934 valid_loss: 0.71248\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[82/100] train_loss: 0.93167 valid_loss: 0.71458\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[83/100] train_loss: 0.69449 valid_loss: 0.71675\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[84/100] train_loss: 0.84355 valid_loss: 0.71937\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[85/100] train_loss: 0.69234 valid_loss: 0.72209\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[86/100] train_loss: 0.95880 valid_loss: 0.72357\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[87/100] train_loss: 0.59467 valid_loss: 0.72507\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[88/100] train_loss: 0.91904 valid_loss: 0.72558\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[89/100] train_loss: 0.83246 valid_loss: 0.72690\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[90/100] train_loss: 0.60277 valid_loss: 0.72831\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[91/100] train_loss: 0.82604 valid_loss: 0.73058\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[92/100] train_loss: 0.82230 valid_loss: 0.73375\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[93/100] train_loss: 0.81794 valid_loss: 0.73787\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[94/100] train_loss: 0.64994 valid_loss: 0.74245\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[95/100] train_loss: 0.62839 valid_loss: 0.74696\n",
      "EarlyStopping counter: 24 out of 100\n",
      "[96/100] train_loss: 0.77392 valid_loss: 0.75030\n",
      "EarlyStopping counter: 25 out of 100\n",
      "[97/100] train_loss: 0.73029 valid_loss: 0.75320\n",
      "EarlyStopping counter: 26 out of 100\n",
      "[98/100] train_loss: 0.64594 valid_loss: 0.75595\n",
      "EarlyStopping counter: 27 out of 100\n",
      "[99/100] train_loss: 0.70439 valid_loss: 0.75836\n",
      "EarlyStopping counter: 28 out of 100\n",
      "[100/100] train_loss: 0.77607 valid_loss: 0.75933\n",
      "EarlyStopping counter: 29 out of 100\n",
      "  Training 5/5 for Fold 3\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n",
      "[1/100] train_loss: 2.18128 valid_loss: 0.72324\n",
      "Validation loss decreased (inf --> 0.723238).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/100] train_loss: 0.98503 valid_loss: 0.72215\n",
      "Validation loss decreased (0.723238 --> 0.722151).  Saving model ...\n",
      "[3/100] train_loss: 0.72368 valid_loss: 0.72149\n",
      "Validation loss decreased (0.722151 --> 0.721494).  Saving model ...\n",
      "[4/100] train_loss: 1.07218 valid_loss: 0.72094\n",
      "Validation loss decreased (0.721494 --> 0.720937).  Saving model ...\n",
      "[5/100] train_loss: 0.81471 valid_loss: 0.72037\n",
      "Validation loss decreased (0.720937 --> 0.720369).  Saving model ...\n",
      "[6/100] train_loss: 1.06704 valid_loss: 0.71989\n",
      "Validation loss decreased (0.720369 --> 0.719893).  Saving model ...\n",
      "[7/100] train_loss: 2.04372 valid_loss: 0.71951\n",
      "Validation loss decreased (0.719893 --> 0.719506).  Saving model ...\n",
      "[8/100] train_loss: 0.95195 valid_loss: 0.71883\n",
      "Validation loss decreased (0.719506 --> 0.718833).  Saving model ...\n",
      "[9/100] train_loss: 0.84551 valid_loss: 0.71836\n",
      "Validation loss decreased (0.718833 --> 0.718364).  Saving model ...\n",
      "[10/100] train_loss: 1.05486 valid_loss: 0.71795\n",
      "Validation loss decreased (0.718364 --> 0.717950).  Saving model ...\n",
      "[11/100] train_loss: 1.96980 valid_loss: 0.71758\n",
      "Validation loss decreased (0.717950 --> 0.717578).  Saving model ...\n",
      "[12/100] train_loss: 0.83372 valid_loss: 0.71733\n",
      "Validation loss decreased (0.717578 --> 0.717329).  Saving model ...\n",
      "[13/100] train_loss: 0.92951 valid_loss: 0.71684\n",
      "Validation loss decreased (0.717329 --> 0.716842).  Saving model ...\n",
      "[14/100] train_loss: 0.92426 valid_loss: 0.71617\n",
      "Validation loss decreased (0.716842 --> 0.716175).  Saving model ...\n",
      "[15/100] train_loss: 0.82029 valid_loss: 0.71566\n",
      "Validation loss decreased (0.716175 --> 0.715656).  Saving model ...\n",
      "[16/100] train_loss: 1.04368 valid_loss: 0.71519\n",
      "Validation loss decreased (0.715656 --> 0.715191).  Saving model ...\n",
      "[17/100] train_loss: 0.81095 valid_loss: 0.71484\n",
      "Validation loss decreased (0.715191 --> 0.714836).  Saving model ...\n",
      "[18/100] train_loss: 0.80572 valid_loss: 0.71458\n",
      "Validation loss decreased (0.714836 --> 0.714575).  Saving model ...\n",
      "[19/100] train_loss: 0.89966 valid_loss: 0.71410\n",
      "Validation loss decreased (0.714575 --> 0.714100).  Saving model ...\n",
      "[20/100] train_loss: 1.79155 valid_loss: 0.71363\n",
      "Validation loss decreased (0.714100 --> 0.713632).  Saving model ...\n",
      "[21/100] train_loss: 0.80125 valid_loss: 0.71316\n",
      "Validation loss decreased (0.713632 --> 0.713158).  Saving model ...\n",
      "[22/100] train_loss: 0.88166 valid_loss: 0.71250\n",
      "Validation loss decreased (0.713158 --> 0.712502).  Saving model ...\n",
      "[23/100] train_loss: 1.03467 valid_loss: 0.71191\n",
      "Validation loss decreased (0.712502 --> 0.711909).  Saving model ...\n",
      "[24/100] train_loss: 0.77252 valid_loss: 0.71141\n",
      "Validation loss decreased (0.711909 --> 0.711411).  Saving model ...\n",
      "[25/100] train_loss: 0.76665 valid_loss: 0.71099\n",
      "Validation loss decreased (0.711411 --> 0.710994).  Saving model ...\n",
      "[26/100] train_loss: 1.63961 valid_loss: 0.71051\n",
      "Validation loss decreased (0.710994 --> 0.710510).  Saving model ...\n",
      "[27/100] train_loss: 1.60462 valid_loss: 0.70996\n",
      "Validation loss decreased (0.710510 --> 0.709957).  Saving model ...\n",
      "[28/100] train_loss: 1.02693 valid_loss: 0.70944\n",
      "Validation loss decreased (0.709957 --> 0.709436).  Saving model ...\n",
      "[29/100] train_loss: 0.82961 valid_loss: 0.70867\n",
      "Validation loss decreased (0.709436 --> 0.708668).  Saving model ...\n",
      "[30/100] train_loss: 1.02236 valid_loss: 0.70794\n",
      "Validation loss decreased (0.708668 --> 0.707945).  Saving model ...\n",
      "[31/100] train_loss: 0.61848 valid_loss: 0.70722\n",
      "Validation loss decreased (0.707945 --> 0.707216).  Saving model ...\n",
      "[32/100] train_loss: 0.80032 valid_loss: 0.70619\n",
      "Validation loss decreased (0.707216 --> 0.706187).  Saving model ...\n",
      "[33/100] train_loss: 0.79019 valid_loss: 0.70514\n",
      "Validation loss decreased (0.706187 --> 0.705143).  Saving model ...\n",
      "[34/100] train_loss: 1.30318 valid_loss: 0.70393\n",
      "Validation loss decreased (0.705143 --> 0.703934).  Saving model ...\n",
      "[35/100] train_loss: 0.78799 valid_loss: 0.70270\n",
      "Validation loss decreased (0.703934 --> 0.702696).  Saving model ...\n",
      "[36/100] train_loss: 1.19236 valid_loss: 0.70125\n",
      "Validation loss decreased (0.702696 --> 0.701250).  Saving model ...\n",
      "[37/100] train_loss: 0.78598 valid_loss: 0.69976\n",
      "Validation loss decreased (0.701250 --> 0.699765).  Saving model ...\n",
      "[38/100] train_loss: 0.63253 valid_loss: 0.69840\n",
      "Validation loss decreased (0.699765 --> 0.698405).  Saving model ...\n",
      "[39/100] train_loss: 0.78433 valid_loss: 0.69702\n",
      "Validation loss decreased (0.698405 --> 0.697020).  Saving model ...\n",
      "[40/100] train_loss: 0.98822 valid_loss: 0.69548\n",
      "Validation loss decreased (0.697020 --> 0.695475).  Saving model ...\n",
      "[41/100] train_loss: 0.69264 valid_loss: 0.69447\n",
      "Validation loss decreased (0.695475 --> 0.694466).  Saving model ...\n",
      "[42/100] train_loss: 0.78282 valid_loss: 0.69344\n",
      "Validation loss decreased (0.694466 --> 0.693444).  Saving model ...\n",
      "[43/100] train_loss: 0.89721 valid_loss: 0.69245\n",
      "Validation loss decreased (0.693444 --> 0.692446).  Saving model ...\n",
      "[44/100] train_loss: 0.78238 valid_loss: 0.69143\n",
      "Validation loss decreased (0.692446 --> 0.691426).  Saving model ...\n",
      "[45/100] train_loss: 0.84528 valid_loss: 0.69056\n",
      "Validation loss decreased (0.691426 --> 0.690563).  Saving model ...\n",
      "[46/100] train_loss: 0.98662 valid_loss: 0.68941\n",
      "Validation loss decreased (0.690563 --> 0.689412).  Saving model ...\n",
      "[47/100] train_loss: 0.60348 valid_loss: 0.68797\n",
      "Validation loss decreased (0.689412 --> 0.687972).  Saving model ...\n",
      "[48/100] train_loss: 0.78105 valid_loss: 0.68639\n",
      "Validation loss decreased (0.687972 --> 0.686395).  Saving model ...\n",
      "[49/100] train_loss: 0.95341 valid_loss: 0.68621\n",
      "Validation loss decreased (0.686395 --> 0.686207).  Saving model ...\n",
      "[50/100] train_loss: 0.77941 valid_loss: 0.68598\n",
      "Validation loss decreased (0.686207 --> 0.685980).  Saving model ...\n",
      "[51/100] train_loss: 0.60994 valid_loss: 0.68569\n",
      "Validation loss decreased (0.685980 --> 0.685685).  Saving model ...\n",
      "[52/100] train_loss: 0.95928 valid_loss: 0.68527\n",
      "Validation loss decreased (0.685685 --> 0.685274).  Saving model ...\n",
      "[53/100] train_loss: 0.73787 valid_loss: 0.68514\n",
      "Validation loss decreased (0.685274 --> 0.685138).  Saving model ...\n",
      "[54/100] train_loss: 0.77634 valid_loss: 0.68500\n",
      "Validation loss decreased (0.685138 --> 0.685004).  Saving model ...\n",
      "[55/100] train_loss: 0.94241 valid_loss: 0.68495\n",
      "Validation loss decreased (0.685004 --> 0.684952).  Saving model ...\n",
      "[56/100] train_loss: 0.60737 valid_loss: 0.68453\n",
      "Validation loss decreased (0.684952 --> 0.684531).  Saving model ...\n",
      "[57/100] train_loss: 0.77386 valid_loss: 0.68417\n",
      "Validation loss decreased (0.684531 --> 0.684170).  Saving model ...\n",
      "[58/100] train_loss: 0.77292 valid_loss: 0.68384\n",
      "Validation loss decreased (0.684170 --> 0.683839).  Saving model ...\n",
      "[59/100] train_loss: 0.91560 valid_loss: 0.68386\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[60/100] train_loss: 0.69528 valid_loss: 0.68412\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[61/100] train_loss: 0.84550 valid_loss: 0.68588\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[62/100] train_loss: 0.80874 valid_loss: 0.68844\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[63/100] train_loss: 0.89102 valid_loss: 0.69099\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[64/100] train_loss: 0.71172 valid_loss: 0.69296\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[65/100] train_loss: 0.77191 valid_loss: 0.69464\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[66/100] train_loss: 0.67347 valid_loss: 0.69646\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[67/100] train_loss: 0.69454 valid_loss: 0.69828\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[68/100] train_loss: 0.77305 valid_loss: 0.69977\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[69/100] train_loss: 0.78514 valid_loss: 0.70050\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[70/100] train_loss: 0.63786 valid_loss: 0.70130\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[71/100] train_loss: 0.77304 valid_loss: 0.70187\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[72/100] train_loss: 0.63227 valid_loss: 0.70250\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[73/100] train_loss: 0.78092 valid_loss: 0.70242\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[74/100] train_loss: 0.84703 valid_loss: 0.70302\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[75/100] train_loss: 0.84180 valid_loss: 0.70440\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[76/100] train_loss: 0.83503 valid_loss: 0.70668\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[77/100] train_loss: 0.71310 valid_loss: 0.70596\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[78/100] train_loss: 0.77188 valid_loss: 0.70486\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[79/100] train_loss: 0.77143 valid_loss: 0.70329\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[80/100] train_loss: 0.80889 valid_loss: 0.70286\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[81/100] train_loss: 0.72058 valid_loss: 0.70289\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[82/100] train_loss: 0.65875 valid_loss: 0.70353\n",
      "EarlyStopping counter: 24 out of 100\n",
      "[83/100] train_loss: 0.64206 valid_loss: 0.70420\n",
      "EarlyStopping counter: 25 out of 100\n",
      "[84/100] train_loss: 0.66188 valid_loss: 0.70552\n",
      "EarlyStopping counter: 26 out of 100\n",
      "[85/100] train_loss: 0.65271 valid_loss: 0.70736\n",
      "EarlyStopping counter: 27 out of 100\n",
      "[86/100] train_loss: 0.72951 valid_loss: 0.70953\n",
      "EarlyStopping counter: 28 out of 100\n",
      "[87/100] train_loss: 0.62692 valid_loss: 0.71193\n",
      "EarlyStopping counter: 29 out of 100\n",
      "[88/100] train_loss: 0.77261 valid_loss: 0.71595\n",
      "EarlyStopping counter: 30 out of 100\n",
      "[89/100] train_loss: 0.60858 valid_loss: 0.72006\n",
      "EarlyStopping counter: 31 out of 100\n",
      "[90/100] train_loss: 0.67401 valid_loss: 0.71695\n",
      "EarlyStopping counter: 32 out of 100\n",
      "[91/100] train_loss: 0.75203 valid_loss: 0.71419\n",
      "EarlyStopping counter: 33 out of 100\n",
      "[92/100] train_loss: 0.75882 valid_loss: 0.71339\n",
      "EarlyStopping counter: 34 out of 100\n",
      "[93/100] train_loss: 0.77492 valid_loss: 0.71075\n",
      "EarlyStopping counter: 35 out of 100\n",
      "[94/100] train_loss: 0.77444 valid_loss: 0.70618\n",
      "EarlyStopping counter: 36 out of 100\n",
      "[95/100] train_loss: 0.77322 valid_loss: 0.69974\n",
      "EarlyStopping counter: 37 out of 100\n",
      "[96/100] train_loss: 0.61341 valid_loss: 0.68602\n",
      "EarlyStopping counter: 38 out of 100\n",
      "[97/100] train_loss: 0.75122 valid_loss: 0.67237\n",
      "Validation loss decreased (0.683839 --> 0.672368).  Saving model ...\n",
      "[98/100] train_loss: 0.65185 valid_loss: 0.65817\n",
      "Validation loss decreased (0.672368 --> 0.658168).  Saving model ...\n",
      "[99/100] train_loss: 0.59854 valid_loss: 0.64512\n",
      "Validation loss decreased (0.658168 --> 0.645115).  Saving model ...\n",
      "[100/100] train_loss: 0.74101 valid_loss: 0.63305\n",
      "Validation loss decreased (0.645115 --> 0.633048).  Saving model ...\n",
      "  Fold 4/7\n",
      "  Training 1/5 for Fold 4\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n",
      "[1/100] train_loss: 0.85942 valid_loss: 0.66791\n",
      "Validation loss decreased (inf --> 0.667912).  Saving model ...\n",
      "[2/100] train_loss: 0.78637 valid_loss: 0.66070\n",
      "Validation loss decreased (0.667912 --> 0.660696).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/100] train_loss: 0.89565 valid_loss: 0.65598\n",
      "Validation loss decreased (0.660696 --> 0.655981).  Saving model ...\n",
      "[4/100] train_loss: 2.21567 valid_loss: 0.65042\n",
      "Validation loss decreased (0.655981 --> 0.650423).  Saving model ...\n",
      "[5/100] train_loss: 2.18604 valid_loss: 0.64427\n",
      "Validation loss decreased (0.650423 --> 0.644271).  Saving model ...\n",
      "[6/100] train_loss: 1.04102 valid_loss: 0.63857\n",
      "Validation loss decreased (0.644271 --> 0.638572).  Saving model ...\n",
      "[7/100] train_loss: 0.77470 valid_loss: 0.63361\n",
      "Validation loss decreased (0.638572 --> 0.633609).  Saving model ...\n",
      "[8/100] train_loss: 1.01745 valid_loss: 0.62886\n",
      "Validation loss decreased (0.633609 --> 0.628858).  Saving model ...\n",
      "[9/100] train_loss: 0.78806 valid_loss: 0.62376\n",
      "Validation loss decreased (0.628858 --> 0.623759).  Saving model ...\n",
      "[10/100] train_loss: 0.78064 valid_loss: 0.61844\n",
      "Validation loss decreased (0.623759 --> 0.618443).  Saving model ...\n",
      "[11/100] train_loss: 0.89818 valid_loss: 0.61382\n",
      "Validation loss decreased (0.618443 --> 0.613817).  Saving model ...\n",
      "[12/100] train_loss: 0.77082 valid_loss: 0.60957\n",
      "Validation loss decreased (0.613817 --> 0.609574).  Saving model ...\n",
      "[13/100] train_loss: 0.75576 valid_loss: 0.60572\n",
      "Validation loss decreased (0.609574 --> 0.605720).  Saving model ...\n",
      "[14/100] train_loss: 0.89884 valid_loss: 0.60233\n",
      "Validation loss decreased (0.605720 --> 0.602329).  Saving model ...\n",
      "[15/100] train_loss: 1.87456 valid_loss: 0.59821\n",
      "Validation loss decreased (0.602329 --> 0.598208).  Saving model ...\n",
      "[16/100] train_loss: 0.76517 valid_loss: 0.59450\n",
      "Validation loss decreased (0.598208 --> 0.594499).  Saving model ...\n",
      "[17/100] train_loss: 0.93140 valid_loss: 0.59093\n",
      "Validation loss decreased (0.594499 --> 0.590929).  Saving model ...\n",
      "[18/100] train_loss: 0.89676 valid_loss: 0.58791\n",
      "Validation loss decreased (0.590929 --> 0.587914).  Saving model ...\n",
      "[19/100] train_loss: 0.71346 valid_loss: 0.58474\n",
      "Validation loss decreased (0.587914 --> 0.584743).  Saving model ...\n",
      "[20/100] train_loss: 0.70475 valid_loss: 0.58165\n",
      "Validation loss decreased (0.584743 --> 0.581652).  Saving model ...\n",
      "[21/100] train_loss: 1.66378 valid_loss: 0.57906\n",
      "Validation loss decreased (0.581652 --> 0.579057).  Saving model ...\n",
      "[22/100] train_loss: 1.61284 valid_loss: 0.57789\n",
      "Validation loss decreased (0.579057 --> 0.577885).  Saving model ...\n",
      "[23/100] train_loss: 0.75266 valid_loss: 0.57894\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[24/100] train_loss: 0.65746 valid_loss: 0.58260\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[25/100] train_loss: 0.64549 valid_loss: 0.58977\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[26/100] train_loss: 0.71774 valid_loss: 0.60131\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[27/100] train_loss: 0.74440 valid_loss: 0.61740\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[28/100] train_loss: 0.76693 valid_loss: 0.64156\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[29/100] train_loss: 0.74213 valid_loss: 0.67661\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[30/100] train_loss: 0.69757 valid_loss: 0.71997\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[31/100] train_loss: 0.74160 valid_loss: 0.76852\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[32/100] train_loss: 0.74381 valid_loss: 0.81868\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[33/100] train_loss: 1.03005 valid_loss: 0.87819\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[34/100] train_loss: 0.99337 valid_loss: 0.94456\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[35/100] train_loss: 0.74960 valid_loss: 0.95269\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[36/100] train_loss: 0.76880 valid_loss: 0.94917\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[37/100] train_loss: 0.76742 valid_loss: 0.93584\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[38/100] train_loss: 0.87299 valid_loss: 0.93318\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[39/100] train_loss: 0.65932 valid_loss: 0.93510\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[40/100] train_loss: 0.69702 valid_loss: 0.90523\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[41/100] train_loss: 0.65893 valid_loss: 0.88260\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[42/100] train_loss: 0.74803 valid_loss: 0.85914\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[43/100] train_loss: 0.57772 valid_loss: 0.84583\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[44/100] train_loss: 0.89965 valid_loss: 0.83367\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[45/100] train_loss: 0.57847 valid_loss: 0.83063\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[46/100] train_loss: 0.73769 valid_loss: 0.82693\n",
      "EarlyStopping counter: 24 out of 100\n",
      "[47/100] train_loss: 0.57593 valid_loss: 0.83141\n",
      "EarlyStopping counter: 25 out of 100\n",
      "[48/100] train_loss: 0.87606 valid_loss: 0.83557\n",
      "EarlyStopping counter: 26 out of 100\n",
      "[49/100] train_loss: 0.73847 valid_loss: 0.85750\n",
      "EarlyStopping counter: 27 out of 100\n",
      "[50/100] train_loss: 0.72235 valid_loss: 0.89527\n",
      "EarlyStopping counter: 28 out of 100\n",
      "[51/100] train_loss: 0.65204 valid_loss: 0.93869\n",
      "EarlyStopping counter: 29 out of 100\n",
      "[52/100] train_loss: 0.64815 valid_loss: 0.98780\n",
      "EarlyStopping counter: 30 out of 100\n",
      "[53/100] train_loss: 0.67254 valid_loss: 1.04393\n",
      "EarlyStopping counter: 31 out of 100\n",
      "[54/100] train_loss: 0.63854 valid_loss: 1.10504\n",
      "EarlyStopping counter: 32 out of 100\n",
      "[55/100] train_loss: 0.64415 valid_loss: 1.11479\n",
      "EarlyStopping counter: 33 out of 100\n",
      "[56/100] train_loss: 0.63315 valid_loss: 1.12642\n",
      "EarlyStopping counter: 34 out of 100\n",
      "[57/100] train_loss: 0.83219 valid_loss: 1.13807\n",
      "EarlyStopping counter: 35 out of 100\n",
      "[58/100] train_loss: 0.82679 valid_loss: 1.14979\n",
      "EarlyStopping counter: 36 out of 100\n",
      "[59/100] train_loss: 0.65397 valid_loss: 1.10532\n",
      "EarlyStopping counter: 37 out of 100\n",
      "[60/100] train_loss: 0.63017 valid_loss: 1.02622\n",
      "EarlyStopping counter: 38 out of 100\n",
      "[61/100] train_loss: 0.59316 valid_loss: 0.93437\n",
      "EarlyStopping counter: 39 out of 100\n",
      "[62/100] train_loss: 0.58424 valid_loss: 0.86136\n",
      "EarlyStopping counter: 40 out of 100\n",
      "[63/100] train_loss: 0.63664 valid_loss: 0.81072\n",
      "EarlyStopping counter: 41 out of 100\n",
      "[64/100] train_loss: 0.57100 valid_loss: 0.78151\n",
      "EarlyStopping counter: 42 out of 100\n",
      "[65/100] train_loss: 0.59951 valid_loss: 0.76646\n",
      "EarlyStopping counter: 43 out of 100\n",
      "[66/100] train_loss: 0.59202 valid_loss: 0.77104\n",
      "EarlyStopping counter: 44 out of 100\n",
      "[67/100] train_loss: 0.73583 valid_loss: 0.77727\n",
      "EarlyStopping counter: 45 out of 100\n",
      "[68/100] train_loss: 0.70036 valid_loss: 0.78563\n",
      "EarlyStopping counter: 46 out of 100\n",
      "[69/100] train_loss: 0.64854 valid_loss: 0.80735\n",
      "EarlyStopping counter: 47 out of 100\n",
      "[70/100] train_loss: 0.69549 valid_loss: 0.83157\n",
      "EarlyStopping counter: 48 out of 100\n",
      "[71/100] train_loss: 0.77304 valid_loss: 0.85597\n",
      "EarlyStopping counter: 49 out of 100\n",
      "[72/100] train_loss: 0.58219 valid_loss: 0.88955\n",
      "EarlyStopping counter: 50 out of 100\n",
      "[73/100] train_loss: 0.63236 valid_loss: 0.92730\n",
      "EarlyStopping counter: 51 out of 100\n",
      "[74/100] train_loss: 0.67335 valid_loss: 0.96914\n",
      "EarlyStopping counter: 52 out of 100\n",
      "[75/100] train_loss: 0.76858 valid_loss: 1.01016\n",
      "EarlyStopping counter: 53 out of 100\n",
      "[76/100] train_loss: 0.76731 valid_loss: 1.05012\n",
      "EarlyStopping counter: 54 out of 100\n",
      "[77/100] train_loss: 0.55679 valid_loss: 1.06339\n",
      "EarlyStopping counter: 55 out of 100\n",
      "[78/100] train_loss: 0.57241 valid_loss: 1.06634\n",
      "EarlyStopping counter: 56 out of 100\n",
      "[79/100] train_loss: 0.64275 valid_loss: 1.07832\n",
      "EarlyStopping counter: 57 out of 100\n",
      "[80/100] train_loss: 0.63572 valid_loss: 1.07561\n",
      "EarlyStopping counter: 58 out of 100\n",
      "[81/100] train_loss: 0.56724 valid_loss: 1.04125\n",
      "EarlyStopping counter: 59 out of 100\n",
      "[82/100] train_loss: 0.55823 valid_loss: 0.98641\n",
      "EarlyStopping counter: 60 out of 100\n",
      "[83/100] train_loss: 0.62527 valid_loss: 0.93444\n",
      "EarlyStopping counter: 61 out of 100\n",
      "[84/100] train_loss: 0.57060 valid_loss: 0.89867\n",
      "EarlyStopping counter: 62 out of 100\n",
      "[85/100] train_loss: 0.65018 valid_loss: 0.87478\n",
      "EarlyStopping counter: 63 out of 100\n",
      "[86/100] train_loss: 0.71776 valid_loss: 0.85767\n",
      "EarlyStopping counter: 64 out of 100\n",
      "[87/100] train_loss: 0.64593 valid_loss: 0.84954\n",
      "EarlyStopping counter: 65 out of 100\n",
      "[88/100] train_loss: 0.53865 valid_loss: 0.84727\n",
      "EarlyStopping counter: 66 out of 100\n",
      "[89/100] train_loss: 0.62939 valid_loss: 0.85270\n",
      "EarlyStopping counter: 67 out of 100\n",
      "[90/100] train_loss: 0.62313 valid_loss: 0.86709\n",
      "EarlyStopping counter: 68 out of 100\n",
      "[91/100] train_loss: 0.54037 valid_loss: 0.87580\n",
      "EarlyStopping counter: 69 out of 100\n",
      "[92/100] train_loss: 0.69840 valid_loss: 0.88892\n",
      "EarlyStopping counter: 70 out of 100\n",
      "[93/100] train_loss: 0.59954 valid_loss: 0.90578\n",
      "EarlyStopping counter: 71 out of 100\n",
      "[94/100] train_loss: 0.59745 valid_loss: 0.92352\n",
      "EarlyStopping counter: 72 out of 100\n",
      "[95/100] train_loss: 0.55622 valid_loss: 0.91981\n",
      "EarlyStopping counter: 73 out of 100\n",
      "[96/100] train_loss: 0.56460 valid_loss: 0.92575\n",
      "EarlyStopping counter: 74 out of 100\n",
      "[97/100] train_loss: 0.61875 valid_loss: 0.93455\n",
      "EarlyStopping counter: 75 out of 100\n",
      "[98/100] train_loss: 0.67883 valid_loss: 0.94782\n",
      "EarlyStopping counter: 76 out of 100\n",
      "[99/100] train_loss: 0.67617 valid_loss: 0.96485\n",
      "EarlyStopping counter: 77 out of 100\n",
      "[100/100] train_loss: 0.55913 valid_loss: 0.98015\n",
      "EarlyStopping counter: 78 out of 100\n",
      "  Training 2/5 for Fold 4\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n",
      "[1/100] train_loss: 0.87548 valid_loss: 0.67493\n",
      "Validation loss decreased (inf --> 0.674926).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/100] train_loss: 0.80717 valid_loss: 0.66938\n",
      "Validation loss decreased (0.674926 --> 0.669376).  Saving model ...\n",
      "[3/100] train_loss: 0.85015 valid_loss: 0.66320\n",
      "Validation loss decreased (0.669376 --> 0.663202).  Saving model ...\n",
      "[4/100] train_loss: 0.97948 valid_loss: 0.65889\n",
      "Validation loss decreased (0.663202 --> 0.658888).  Saving model ...\n",
      "[5/100] train_loss: 0.78417 valid_loss: 0.65507\n",
      "Validation loss decreased (0.658888 --> 0.655065).  Saving model ...\n",
      "[6/100] train_loss: 1.02960 valid_loss: 0.65132\n",
      "Validation loss decreased (0.655065 --> 0.651317).  Saving model ...\n",
      "[7/100] train_loss: 2.14328 valid_loss: 0.64757\n",
      "Validation loss decreased (0.651317 --> 0.647572).  Saving model ...\n",
      "[8/100] train_loss: 0.79988 valid_loss: 0.64416\n",
      "Validation loss decreased (0.647572 --> 0.644159).  Saving model ...\n",
      "[9/100] train_loss: 0.79909 valid_loss: 0.64100\n",
      "Validation loss decreased (0.644159 --> 0.641001).  Saving model ...\n",
      "[10/100] train_loss: 0.97024 valid_loss: 0.63827\n",
      "Validation loss decreased (0.641001 --> 0.638269).  Saving model ...\n",
      "[11/100] train_loss: 0.77719 valid_loss: 0.63577\n",
      "Validation loss decreased (0.638269 --> 0.635769).  Saving model ...\n",
      "[12/100] train_loss: 0.77611 valid_loss: 0.63346\n",
      "Validation loss decreased (0.635769 --> 0.633463).  Saving model ...\n",
      "[13/100] train_loss: 0.77477 valid_loss: 0.63132\n",
      "Validation loss decreased (0.633463 --> 0.631316).  Saving model ...\n",
      "[14/100] train_loss: 0.79488 valid_loss: 0.62919\n",
      "Validation loss decreased (0.631316 --> 0.629192).  Saving model ...\n",
      "[15/100] train_loss: 0.78863 valid_loss: 0.62631\n",
      "Validation loss decreased (0.629192 --> 0.626310).  Saving model ...\n",
      "[16/100] train_loss: 0.98065 valid_loss: 0.62332\n",
      "Validation loss decreased (0.626310 --> 0.623318).  Saving model ...\n",
      "[17/100] train_loss: 0.97468 valid_loss: 0.62024\n",
      "Validation loss decreased (0.623318 --> 0.620240).  Saving model ...\n",
      "[18/100] train_loss: 0.79130 valid_loss: 0.61727\n",
      "Validation loss decreased (0.620240 --> 0.617267).  Saving model ...\n",
      "[19/100] train_loss: 0.77145 valid_loss: 0.61367\n",
      "Validation loss decreased (0.617267 --> 0.613666).  Saving model ...\n",
      "[20/100] train_loss: 0.76552 valid_loss: 0.60956\n",
      "Validation loss decreased (0.613666 --> 0.609555).  Saving model ...\n",
      "[21/100] train_loss: 0.96971 valid_loss: 0.60580\n",
      "Validation loss decreased (0.609555 --> 0.605797).  Saving model ...\n",
      "[22/100] train_loss: 1.89986 valid_loss: 0.60151\n",
      "Validation loss decreased (0.605797 --> 0.601510).  Saving model ...\n",
      "[23/100] train_loss: 0.74317 valid_loss: 0.59688\n",
      "Validation loss decreased (0.601510 --> 0.596883).  Saving model ...\n",
      "[24/100] train_loss: 0.92767 valid_loss: 0.59233\n",
      "Validation loss decreased (0.596883 --> 0.592325).  Saving model ...\n",
      "[25/100] train_loss: 1.81195 valid_loss: 0.58751\n",
      "Validation loss decreased (0.592325 --> 0.587508).  Saving model ...\n",
      "[26/100] train_loss: 0.78263 valid_loss: 0.58322\n",
      "Validation loss decreased (0.587508 --> 0.583221).  Saving model ...\n",
      "[27/100] train_loss: 0.97215 valid_loss: 0.57960\n",
      "Validation loss decreased (0.583221 --> 0.579604).  Saving model ...\n",
      "[28/100] train_loss: 0.97124 valid_loss: 0.57660\n",
      "Validation loss decreased (0.579604 --> 0.576602).  Saving model ...\n",
      "[29/100] train_loss: 1.65563 valid_loss: 0.57377\n",
      "Validation loss decreased (0.576602 --> 0.573770).  Saving model ...\n",
      "[30/100] train_loss: 0.86706 valid_loss: 0.57196\n",
      "Validation loss decreased (0.573770 --> 0.571958).  Saving model ...\n",
      "[31/100] train_loss: 0.77574 valid_loss: 0.57157\n",
      "Validation loss decreased (0.571958 --> 0.571570).  Saving model ...\n",
      "[32/100] train_loss: 0.96504 valid_loss: 0.57271\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[33/100] train_loss: 0.77257 valid_loss: 0.57554\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[34/100] train_loss: 0.81271 valid_loss: 0.58138\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[35/100] train_loss: 0.76918 valid_loss: 0.59028\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[36/100] train_loss: 0.72621 valid_loss: 0.60285\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[37/100] train_loss: 0.62054 valid_loss: 0.62021\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[38/100] train_loss: 0.95457 valid_loss: 0.64102\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[39/100] train_loss: 0.71973 valid_loss: 0.67488\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[40/100] train_loss: 1.09095 valid_loss: 0.72815\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[41/100] train_loss: 1.02893 valid_loss: 0.80208\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[42/100] train_loss: 0.69905 valid_loss: 0.88670\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[43/100] train_loss: 0.69124 valid_loss: 0.97851\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[44/100] train_loss: 0.68191 valid_loss: 1.07480\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[45/100] train_loss: 0.82912 valid_loss: 1.11871\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[46/100] train_loss: 0.85044 valid_loss: 1.15115\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[47/100] train_loss: 0.95208 valid_loss: 1.18203\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[48/100] train_loss: 0.60403 valid_loss: 1.18024\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[49/100] train_loss: 0.85106 valid_loss: 1.12182\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[50/100] train_loss: 0.66775 valid_loss: 1.07512\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[51/100] train_loss: 0.67031 valid_loss: 1.03846\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[52/100] train_loss: 0.57064 valid_loss: 1.00082\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[53/100] train_loss: 0.91074 valid_loss: 0.96850\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[54/100] train_loss: 0.71606 valid_loss: 0.95168\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[55/100] train_loss: 0.67855 valid_loss: 0.94049\n",
      "EarlyStopping counter: 24 out of 100\n",
      "[56/100] train_loss: 0.57540 valid_loss: 0.93605\n",
      "EarlyStopping counter: 25 out of 100\n",
      "[57/100] train_loss: 0.69344 valid_loss: 0.94655\n",
      "EarlyStopping counter: 26 out of 100\n",
      "[58/100] train_loss: 0.57863 valid_loss: 0.96168\n",
      "EarlyStopping counter: 27 out of 100\n",
      "[59/100] train_loss: 0.74799 valid_loss: 0.97650\n",
      "EarlyStopping counter: 28 out of 100\n",
      "[60/100] train_loss: 0.67826 valid_loss: 0.99449\n",
      "EarlyStopping counter: 29 out of 100\n",
      "[61/100] train_loss: 0.67583 valid_loss: 1.01571\n",
      "EarlyStopping counter: 30 out of 100\n",
      "[62/100] train_loss: 0.86945 valid_loss: 1.03684\n",
      "EarlyStopping counter: 31 out of 100\n",
      "[63/100] train_loss: 0.58769 valid_loss: 1.04544\n",
      "EarlyStopping counter: 32 out of 100\n",
      "[64/100] train_loss: 0.64300 valid_loss: 1.06249\n",
      "EarlyStopping counter: 33 out of 100\n",
      "[65/100] train_loss: 0.63840 valid_loss: 1.08640\n",
      "EarlyStopping counter: 34 out of 100\n",
      "[66/100] train_loss: 0.73887 valid_loss: 1.11060\n",
      "EarlyStopping counter: 35 out of 100\n",
      "[67/100] train_loss: 0.73753 valid_loss: 1.13516\n",
      "EarlyStopping counter: 36 out of 100\n",
      "[68/100] train_loss: 0.73599 valid_loss: 1.16017\n",
      "EarlyStopping counter: 37 out of 100\n",
      "[69/100] train_loss: 0.73423 valid_loss: 1.18569\n",
      "EarlyStopping counter: 38 out of 100\n",
      "[70/100] train_loss: 0.61568 valid_loss: 1.16791\n",
      "EarlyStopping counter: 39 out of 100\n",
      "[71/100] train_loss: 0.73139 valid_loss: 1.15408\n",
      "EarlyStopping counter: 40 out of 100\n",
      "[72/100] train_loss: 0.82620 valid_loss: 1.14303\n",
      "EarlyStopping counter: 41 out of 100\n",
      "[73/100] train_loss: 0.82038 valid_loss: 1.13454\n",
      "EarlyStopping counter: 42 out of 100\n",
      "[74/100] train_loss: 0.81337 valid_loss: 1.12844\n",
      "EarlyStopping counter: 43 out of 100\n",
      "[75/100] train_loss: 0.68646 valid_loss: 1.12739\n",
      "EarlyStopping counter: 44 out of 100\n",
      "[76/100] train_loss: 0.79978 valid_loss: 1.12819\n",
      "EarlyStopping counter: 45 out of 100\n",
      "[77/100] train_loss: 0.61727 valid_loss: 1.12781\n",
      "EarlyStopping counter: 46 out of 100\n",
      "[78/100] train_loss: 0.61603 valid_loss: 1.12604\n",
      "EarlyStopping counter: 47 out of 100\n",
      "[79/100] train_loss: 0.65358 valid_loss: 1.07378\n",
      "EarlyStopping counter: 48 out of 100\n",
      "[80/100] train_loss: 0.77813 valid_loss: 1.02790\n",
      "EarlyStopping counter: 49 out of 100\n",
      "[81/100] train_loss: 0.70337 valid_loss: 0.99015\n",
      "EarlyStopping counter: 50 out of 100\n",
      "[82/100] train_loss: 0.69971 valid_loss: 0.96017\n",
      "EarlyStopping counter: 51 out of 100\n",
      "[83/100] train_loss: 0.59567 valid_loss: 0.92921\n",
      "EarlyStopping counter: 52 out of 100\n",
      "[84/100] train_loss: 0.73142 valid_loss: 0.90519\n",
      "EarlyStopping counter: 53 out of 100\n",
      "[85/100] train_loss: 0.61386 valid_loss: 0.89622\n",
      "EarlyStopping counter: 54 out of 100\n",
      "[86/100] train_loss: 0.59538 valid_loss: 0.89927\n",
      "EarlyStopping counter: 55 out of 100\n",
      "[87/100] train_loss: 0.64900 valid_loss: 0.91056\n",
      "EarlyStopping counter: 56 out of 100\n",
      "[88/100] train_loss: 0.76337 valid_loss: 0.92294\n",
      "EarlyStopping counter: 57 out of 100\n",
      "[89/100] train_loss: 0.60802 valid_loss: 0.94173\n",
      "EarlyStopping counter: 58 out of 100\n",
      "[90/100] train_loss: 0.71101 valid_loss: 0.96590\n",
      "EarlyStopping counter: 59 out of 100\n",
      "[91/100] train_loss: 0.70545 valid_loss: 0.99577\n",
      "EarlyStopping counter: 60 out of 100\n",
      "[92/100] train_loss: 0.69859 valid_loss: 1.03138\n",
      "EarlyStopping counter: 61 out of 100\n",
      "[93/100] train_loss: 0.69105 valid_loss: 1.07190\n",
      "EarlyStopping counter: 62 out of 100\n",
      "[94/100] train_loss: 0.61028 valid_loss: 1.09451\n",
      "EarlyStopping counter: 63 out of 100\n",
      "[95/100] train_loss: 0.61101 valid_loss: 1.09766\n",
      "EarlyStopping counter: 64 out of 100\n",
      "[96/100] train_loss: 0.60866 valid_loss: 1.08347\n",
      "EarlyStopping counter: 65 out of 100\n",
      "[97/100] train_loss: 0.57267 valid_loss: 1.07439\n",
      "EarlyStopping counter: 66 out of 100\n",
      "[98/100] train_loss: 0.60105 valid_loss: 1.05369\n",
      "EarlyStopping counter: 67 out of 100\n",
      "[99/100] train_loss: 0.69713 valid_loss: 1.01445\n",
      "EarlyStopping counter: 68 out of 100\n",
      "[100/100] train_loss: 0.70280 valid_loss: 0.93798\n",
      "EarlyStopping counter: 69 out of 100\n",
      "  Training 3/5 for Fold 4\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n",
      "[1/100] train_loss: 1.05438 valid_loss: 0.69044\n",
      "Validation loss decreased (inf --> 0.690441).  Saving model ...\n",
      "[2/100] train_loss: 0.89467 valid_loss: 0.68468\n",
      "Validation loss decreased (0.690441 --> 0.684682).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/100] train_loss: 2.27892 valid_loss: 0.67944\n",
      "Validation loss decreased (0.684682 --> 0.679444).  Saving model ...\n",
      "[4/100] train_loss: 1.02161 valid_loss: 0.67474\n",
      "Validation loss decreased (0.679444 --> 0.674739).  Saving model ...\n",
      "[5/100] train_loss: 2.22754 valid_loss: 0.66997\n",
      "Validation loss decreased (0.674739 --> 0.669971).  Saving model ...\n",
      "[6/100] train_loss: 0.86908 valid_loss: 0.66509\n",
      "Validation loss decreased (0.669971 --> 0.665088).  Saving model ...\n",
      "[7/100] train_loss: 0.86258 valid_loss: 0.66017\n",
      "Validation loss decreased (0.665088 --> 0.660173).  Saving model ...\n",
      "[8/100] train_loss: 0.78394 valid_loss: 0.65578\n",
      "Validation loss decreased (0.660173 --> 0.655778).  Saving model ...\n",
      "[9/100] train_loss: 0.84870 valid_loss: 0.65128\n",
      "Validation loss decreased (0.655778 --> 0.651277).  Saving model ...\n",
      "[10/100] train_loss: 0.97361 valid_loss: 0.64694\n",
      "Validation loss decreased (0.651277 --> 0.646935).  Saving model ...\n",
      "[11/100] train_loss: 0.95078 valid_loss: 0.64317\n",
      "Validation loss decreased (0.646935 --> 0.643166).  Saving model ...\n",
      "[12/100] train_loss: 0.96067 valid_loss: 0.63941\n",
      "Validation loss decreased (0.643166 --> 0.639407).  Saving model ...\n",
      "[13/100] train_loss: 0.82394 valid_loss: 0.63540\n",
      "Validation loss decreased (0.639407 --> 0.635403).  Saving model ...\n",
      "[14/100] train_loss: 0.95282 valid_loss: 0.63186\n",
      "Validation loss decreased (0.635403 --> 0.631856).  Saving model ...\n",
      "[15/100] train_loss: 0.81234 valid_loss: 0.62802\n",
      "Validation loss decreased (0.631856 --> 0.628021).  Saving model ...\n",
      "[16/100] train_loss: 0.77744 valid_loss: 0.62443\n",
      "Validation loss decreased (0.628021 --> 0.624429).  Saving model ...\n",
      "[17/100] train_loss: 0.74441 valid_loss: 0.62105\n",
      "Validation loss decreased (0.624429 --> 0.621054).  Saving model ...\n",
      "[18/100] train_loss: 0.95036 valid_loss: 0.61802\n",
      "Validation loss decreased (0.621054 --> 0.618023).  Saving model ...\n",
      "[19/100] train_loss: 0.94830 valid_loss: 0.61529\n",
      "Validation loss decreased (0.618023 --> 0.615287).  Saving model ...\n",
      "[20/100] train_loss: 0.78499 valid_loss: 0.61205\n",
      "Validation loss decreased (0.615287 --> 0.612052).  Saving model ...\n",
      "[21/100] train_loss: 0.77284 valid_loss: 0.60895\n",
      "Validation loss decreased (0.612052 --> 0.608952).  Saving model ...\n",
      "[22/100] train_loss: 0.93885 valid_loss: 0.60611\n",
      "Validation loss decreased (0.608952 --> 0.606111).  Saving model ...\n",
      "[23/100] train_loss: 0.74032 valid_loss: 0.60336\n",
      "Validation loss decreased (0.606111 --> 0.603363).  Saving model ...\n",
      "[24/100] train_loss: 0.76379 valid_loss: 0.60001\n",
      "Validation loss decreased (0.603363 --> 0.600006).  Saving model ...\n",
      "[25/100] train_loss: 0.76855 valid_loss: 0.59676\n",
      "Validation loss decreased (0.600006 --> 0.596761).  Saving model ...\n",
      "[26/100] train_loss: 0.90459 valid_loss: 0.59313\n",
      "Validation loss decreased (0.596761 --> 0.593129).  Saving model ...\n",
      "[27/100] train_loss: 1.83409 valid_loss: 0.58856\n",
      "Validation loss decreased (0.593129 --> 0.588558).  Saving model ...\n",
      "[28/100] train_loss: 0.73577 valid_loss: 0.58368\n",
      "Validation loss decreased (0.588558 --> 0.583678).  Saving model ...\n",
      "[29/100] train_loss: 0.76293 valid_loss: 0.57920\n",
      "Validation loss decreased (0.583678 --> 0.579204).  Saving model ...\n",
      "[30/100] train_loss: 0.76131 valid_loss: 0.57518\n",
      "Validation loss decreased (0.579204 --> 0.575177).  Saving model ...\n",
      "[31/100] train_loss: 0.70587 valid_loss: 0.57106\n",
      "Validation loss decreased (0.575177 --> 0.571063).  Saving model ...\n",
      "[32/100] train_loss: 1.65553 valid_loss: 0.56702\n",
      "Validation loss decreased (0.571063 --> 0.567024).  Saving model ...\n",
      "[33/100] train_loss: 0.75584 valid_loss: 0.56467\n",
      "Validation loss decreased (0.567024 --> 0.564670).  Saving model ...\n",
      "[34/100] train_loss: 0.91670 valid_loss: 0.56442\n",
      "Validation loss decreased (0.564670 --> 0.564418).  Saving model ...\n",
      "[35/100] train_loss: 0.65418 valid_loss: 0.56708\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[36/100] train_loss: 0.78497 valid_loss: 0.57549\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[37/100] train_loss: 0.74747 valid_loss: 0.59122\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[38/100] train_loss: 0.70476 valid_loss: 0.61603\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[39/100] train_loss: 0.74332 valid_loss: 0.65037\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[40/100] train_loss: 0.62615 valid_loss: 0.67631\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[41/100] train_loss: 0.91420 valid_loss: 0.70306\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[42/100] train_loss: 0.63783 valid_loss: 0.70559\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[43/100] train_loss: 0.68290 valid_loss: 0.71158\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[44/100] train_loss: 0.67890 valid_loss: 0.72116\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[45/100] train_loss: 0.67346 valid_loss: 0.73465\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[46/100] train_loss: 0.90769 valid_loss: 0.74679\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[47/100] train_loss: 0.66158 valid_loss: 0.76359\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[48/100] train_loss: 0.62679 valid_loss: 0.75351\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[49/100] train_loss: 0.73365 valid_loss: 0.74327\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[50/100] train_loss: 0.89616 valid_loss: 0.73398\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[51/100] train_loss: 0.59986 valid_loss: 0.71605\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[52/100] train_loss: 0.59223 valid_loss: 0.69658\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[53/100] train_loss: 0.72528 valid_loss: 0.68142\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[54/100] train_loss: 0.87122 valid_loss: 0.66864\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[55/100] train_loss: 0.56234 valid_loss: 0.66208\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[56/100] train_loss: 0.56022 valid_loss: 0.66046\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[57/100] train_loss: 0.59011 valid_loss: 0.66903\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[58/100] train_loss: 0.63443 valid_loss: 0.68046\n",
      "EarlyStopping counter: 24 out of 100\n",
      "[59/100] train_loss: 0.83819 valid_loss: 0.69240\n",
      "EarlyStopping counter: 25 out of 100\n",
      "[60/100] train_loss: 0.71727 valid_loss: 0.70882\n",
      "EarlyStopping counter: 26 out of 100\n",
      "[61/100] train_loss: 0.62409 valid_loss: 0.72412\n",
      "EarlyStopping counter: 27 out of 100\n",
      "[62/100] train_loss: 0.91040 valid_loss: 0.74842\n",
      "EarlyStopping counter: 28 out of 100\n",
      "[63/100] train_loss: 0.55755 valid_loss: 0.75456\n",
      "EarlyStopping counter: 29 out of 100\n",
      "[64/100] train_loss: 0.71507 valid_loss: 0.76709\n",
      "EarlyStopping counter: 30 out of 100\n",
      "[65/100] train_loss: 0.61093 valid_loss: 0.78418\n",
      "EarlyStopping counter: 31 out of 100\n",
      "[66/100] train_loss: 0.79861 valid_loss: 0.80158\n",
      "EarlyStopping counter: 32 out of 100\n",
      "[67/100] train_loss: 0.71441 valid_loss: 0.82498\n",
      "EarlyStopping counter: 33 out of 100\n",
      "[68/100] train_loss: 0.60376 valid_loss: 0.85075\n",
      "EarlyStopping counter: 34 out of 100\n",
      "[69/100] train_loss: 0.78534 valid_loss: 0.87592\n",
      "EarlyStopping counter: 35 out of 100\n",
      "[70/100] train_loss: 0.78040 valid_loss: 0.90047\n",
      "EarlyStopping counter: 36 out of 100\n",
      "[71/100] train_loss: 0.59953 valid_loss: 0.88358\n",
      "EarlyStopping counter: 37 out of 100\n",
      "[72/100] train_loss: 0.74109 valid_loss: 0.88141\n",
      "EarlyStopping counter: 38 out of 100\n",
      "[73/100] train_loss: 0.60515 valid_loss: 0.89130\n",
      "EarlyStopping counter: 39 out of 100\n",
      "[74/100] train_loss: 0.58782 valid_loss: 0.87580\n",
      "EarlyStopping counter: 40 out of 100\n",
      "[75/100] train_loss: 0.58763 valid_loss: 0.83736\n",
      "EarlyStopping counter: 41 out of 100\n",
      "[76/100] train_loss: 0.71473 valid_loss: 0.81060\n",
      "EarlyStopping counter: 42 out of 100\n",
      "[77/100] train_loss: 0.59748 valid_loss: 0.79284\n",
      "EarlyStopping counter: 43 out of 100\n",
      "[78/100] train_loss: 0.72107 valid_loss: 0.79710\n",
      "EarlyStopping counter: 44 out of 100\n",
      "[79/100] train_loss: 0.70891 valid_loss: 0.80761\n",
      "EarlyStopping counter: 45 out of 100\n",
      "[80/100] train_loss: 0.57952 valid_loss: 0.80002\n",
      "EarlyStopping counter: 46 out of 100\n",
      "[81/100] train_loss: 0.70476 valid_loss: 0.81240\n",
      "EarlyStopping counter: 47 out of 100\n",
      "[82/100] train_loss: 0.57164 valid_loss: 0.82595\n",
      "EarlyStopping counter: 48 out of 100\n",
      "[83/100] train_loss: 0.58957 valid_loss: 0.81803\n",
      "EarlyStopping counter: 49 out of 100\n",
      "[84/100] train_loss: 0.58417 valid_loss: 0.79242\n",
      "EarlyStopping counter: 50 out of 100\n",
      "[85/100] train_loss: 0.69365 valid_loss: 0.77667\n",
      "EarlyStopping counter: 51 out of 100\n",
      "[86/100] train_loss: 0.57130 valid_loss: 0.76974\n",
      "EarlyStopping counter: 52 out of 100\n",
      "[87/100] train_loss: 0.59766 valid_loss: 0.75702\n",
      "EarlyStopping counter: 53 out of 100\n",
      "[88/100] train_loss: 0.74877 valid_loss: 0.74653\n",
      "EarlyStopping counter: 54 out of 100\n",
      "[89/100] train_loss: 0.69365 valid_loss: 0.74396\n",
      "EarlyStopping counter: 55 out of 100\n",
      "[90/100] train_loss: 0.58715 valid_loss: 0.74490\n",
      "EarlyStopping counter: 56 out of 100\n",
      "[91/100] train_loss: 0.72326 valid_loss: 0.76918\n",
      "EarlyStopping counter: 57 out of 100\n",
      "[92/100] train_loss: 0.53509 valid_loss: 0.78694\n",
      "EarlyStopping counter: 58 out of 100\n",
      "[93/100] train_loss: 0.58234 valid_loss: 0.80797\n",
      "EarlyStopping counter: 59 out of 100\n",
      "[94/100] train_loss: 0.73553 valid_loss: 0.82921\n",
      "EarlyStopping counter: 60 out of 100\n",
      "[95/100] train_loss: 0.57836 valid_loss: 0.85276\n",
      "EarlyStopping counter: 61 out of 100\n",
      "[96/100] train_loss: 0.72989 valid_loss: 0.87621\n",
      "EarlyStopping counter: 62 out of 100\n",
      "[97/100] train_loss: 0.57599 valid_loss: 0.86939\n",
      "EarlyStopping counter: 63 out of 100\n",
      "[98/100] train_loss: 0.72357 valid_loss: 0.86366\n",
      "EarlyStopping counter: 64 out of 100\n",
      "[99/100] train_loss: 0.53311 valid_loss: 0.83830\n",
      "EarlyStopping counter: 65 out of 100\n",
      "[100/100] train_loss: 0.57345 valid_loss: 0.82110\n",
      "EarlyStopping counter: 66 out of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training 4/5 for Fold 4\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n",
      "[1/100] train_loss: 0.86910 valid_loss: 0.66182\n",
      "Validation loss decreased (inf --> 0.661823).  Saving model ...\n",
      "[2/100] train_loss: 0.77972 valid_loss: 0.65707\n",
      "Validation loss decreased (0.661823 --> 0.657070).  Saving model ...\n",
      "[3/100] train_loss: 1.04028 valid_loss: 0.65440\n",
      "Validation loss decreased (0.657070 --> 0.654401).  Saving model ...\n",
      "[4/100] train_loss: 1.03375 valid_loss: 0.65255\n",
      "Validation loss decreased (0.654401 --> 0.652547).  Saving model ...\n",
      "[5/100] train_loss: 0.77801 valid_loss: 0.65071\n",
      "Validation loss decreased (0.652547 --> 0.650707).  Saving model ...\n",
      "[6/100] train_loss: 2.13890 valid_loss: 0.64769\n",
      "Validation loss decreased (0.650707 --> 0.647693).  Saving model ...\n",
      "[7/100] train_loss: 0.82986 valid_loss: 0.64428\n",
      "Validation loss decreased (0.647693 --> 0.644278).  Saving model ...\n",
      "[8/100] train_loss: 0.96727 valid_loss: 0.64093\n",
      "Validation loss decreased (0.644278 --> 0.640927).  Saving model ...\n",
      "[9/100] train_loss: 0.96244 valid_loss: 0.63766\n",
      "Validation loss decreased (0.640927 --> 0.637660).  Saving model ...\n",
      "[10/100] train_loss: 1.00879 valid_loss: 0.63488\n",
      "Validation loss decreased (0.637660 --> 0.634878).  Saving model ...\n",
      "[11/100] train_loss: 0.80564 valid_loss: 0.63234\n",
      "Validation loss decreased (0.634878 --> 0.632339).  Saving model ...\n",
      "[12/100] train_loss: 1.00387 valid_loss: 0.63013\n",
      "Validation loss decreased (0.632339 --> 0.630128).  Saving model ...\n",
      "[13/100] train_loss: 0.77070 valid_loss: 0.62806\n",
      "Validation loss decreased (0.630128 --> 0.628064).  Saving model ...\n",
      "[14/100] train_loss: 1.99537 valid_loss: 0.62524\n",
      "Validation loss decreased (0.628064 --> 0.625240).  Saving model ...\n",
      "[15/100] train_loss: 0.80235 valid_loss: 0.62262\n",
      "Validation loss decreased (0.625240 --> 0.622624).  Saving model ...\n",
      "[16/100] train_loss: 0.76757 valid_loss: 0.62019\n",
      "Validation loss decreased (0.622624 --> 0.620190).  Saving model ...\n",
      "[17/100] train_loss: 0.98872 valid_loss: 0.61800\n",
      "Validation loss decreased (0.620190 --> 0.618002).  Saving model ...\n",
      "[18/100] train_loss: 0.79026 valid_loss: 0.61541\n",
      "Validation loss decreased (0.618002 --> 0.615407).  Saving model ...\n",
      "[19/100] train_loss: 1.89590 valid_loss: 0.61213\n",
      "Validation loss decreased (0.615407 --> 0.612129).  Saving model ...\n",
      "[20/100] train_loss: 0.78044 valid_loss: 0.60865\n",
      "Validation loss decreased (0.612129 --> 0.608655).  Saving model ...\n",
      "[21/100] train_loss: 1.84118 valid_loss: 0.60471\n",
      "Validation loss decreased (0.608655 --> 0.604709).  Saving model ...\n",
      "[22/100] train_loss: 1.80574 valid_loss: 0.60044\n",
      "Validation loss decreased (0.604709 --> 0.600445).  Saving model ...\n",
      "[23/100] train_loss: 0.97365 valid_loss: 0.59667\n",
      "Validation loss decreased (0.600445 --> 0.596673).  Saving model ...\n",
      "[24/100] train_loss: 0.75701 valid_loss: 0.59333\n",
      "Validation loss decreased (0.596673 --> 0.593326).  Saving model ...\n",
      "[25/100] train_loss: 0.96820 valid_loss: 0.59041\n",
      "Validation loss decreased (0.593326 --> 0.590412).  Saving model ...\n",
      "[26/100] train_loss: 1.64328 valid_loss: 0.58725\n",
      "Validation loss decreased (0.590412 --> 0.587251).  Saving model ...\n",
      "[27/100] train_loss: 0.75191 valid_loss: 0.58476\n",
      "Validation loss decreased (0.587251 --> 0.584759).  Saving model ...\n",
      "[28/100] train_loss: 1.54418 valid_loss: 0.58264\n",
      "Validation loss decreased (0.584759 --> 0.582641).  Saving model ...\n",
      "[29/100] train_loss: 0.74733 valid_loss: 0.58185\n",
      "Validation loss decreased (0.582641 --> 0.581846).  Saving model ...\n",
      "[30/100] train_loss: 1.42020 valid_loss: 0.58305\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[31/100] train_loss: 1.34399 valid_loss: 0.58866\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[32/100] train_loss: 1.25436 valid_loss: 0.60308\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[33/100] train_loss: 1.15461 valid_loss: 0.63384\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[34/100] train_loss: 0.72853 valid_loss: 0.68334\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[35/100] train_loss: 0.77960 valid_loss: 0.75136\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[36/100] train_loss: 0.61868 valid_loss: 0.83307\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[37/100] train_loss: 0.94342 valid_loss: 0.92354\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[38/100] train_loss: 0.77875 valid_loss: 1.01763\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[39/100] train_loss: 0.67866 valid_loss: 1.06734\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[40/100] train_loss: 0.93278 valid_loss: 1.11475\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[41/100] train_loss: 0.69688 valid_loss: 1.16234\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[42/100] train_loss: 0.72189 valid_loss: 1.15740\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[43/100] train_loss: 0.69230 valid_loss: 1.15531\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[44/100] train_loss: 0.91207 valid_loss: 1.15399\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[45/100] train_loss: 0.81279 valid_loss: 1.14409\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[46/100] train_loss: 0.90004 valid_loss: 1.13619\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[47/100] train_loss: 0.78885 valid_loss: 1.12370\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[48/100] train_loss: 0.76552 valid_loss: 1.11329\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[49/100] train_loss: 0.64533 valid_loss: 1.07937\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[50/100] train_loss: 0.87460 valid_loss: 1.05097\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[51/100] train_loss: 0.73500 valid_loss: 1.02765\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[52/100] train_loss: 0.69174 valid_loss: 1.01092\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[53/100] train_loss: 0.69364 valid_loss: 0.99978\n",
      "EarlyStopping counter: 24 out of 100\n",
      "[54/100] train_loss: 0.69421 valid_loss: 0.99344\n",
      "EarlyStopping counter: 25 out of 100\n",
      "[55/100] train_loss: 0.69339 valid_loss: 0.99131\n",
      "EarlyStopping counter: 26 out of 100\n",
      "[56/100] train_loss: 0.84598 valid_loss: 0.99077\n",
      "EarlyStopping counter: 27 out of 100\n",
      "[57/100] train_loss: 0.69206 valid_loss: 0.99720\n",
      "EarlyStopping counter: 28 out of 100\n",
      "[58/100] train_loss: 0.68787 valid_loss: 1.00716\n",
      "EarlyStopping counter: 29 out of 100\n",
      "[59/100] train_loss: 0.76290 valid_loss: 1.01820\n",
      "EarlyStopping counter: 30 out of 100\n",
      "[60/100] train_loss: 0.76212 valid_loss: 1.03026\n",
      "EarlyStopping counter: 31 out of 100\n",
      "[61/100] train_loss: 0.67787 valid_loss: 1.04562\n",
      "EarlyStopping counter: 32 out of 100\n",
      "[62/100] train_loss: 0.75965 valid_loss: 1.06178\n",
      "EarlyStopping counter: 33 out of 100\n",
      "[63/100] train_loss: 0.66738 valid_loss: 1.05058\n",
      "EarlyStopping counter: 34 out of 100\n",
      "[64/100] train_loss: 0.66909 valid_loss: 1.04365\n",
      "EarlyStopping counter: 35 out of 100\n",
      "[65/100] train_loss: 0.75659 valid_loss: 1.03949\n",
      "EarlyStopping counter: 36 out of 100\n",
      "[66/100] train_loss: 0.66883 valid_loss: 1.04185\n",
      "EarlyStopping counter: 37 out of 100\n",
      "[67/100] train_loss: 0.81685 valid_loss: 1.04529\n",
      "EarlyStopping counter: 38 out of 100\n",
      "[68/100] train_loss: 0.66302 valid_loss: 1.05069\n",
      "EarlyStopping counter: 39 out of 100\n",
      "[69/100] train_loss: 0.75254 valid_loss: 1.05805\n",
      "EarlyStopping counter: 40 out of 100\n",
      "[70/100] train_loss: 0.65910 valid_loss: 1.06645\n",
      "EarlyStopping counter: 41 out of 100\n",
      "[71/100] train_loss: 0.74966 valid_loss: 1.07680\n",
      "EarlyStopping counter: 42 out of 100\n",
      "[72/100] train_loss: 0.60507 valid_loss: 1.08218\n",
      "EarlyStopping counter: 43 out of 100\n",
      "[73/100] train_loss: 0.79810 valid_loss: 1.08841\n",
      "EarlyStopping counter: 44 out of 100\n",
      "[74/100] train_loss: 0.68164 valid_loss: 1.06411\n",
      "EarlyStopping counter: 45 out of 100\n",
      "[75/100] train_loss: 0.74565 valid_loss: 1.04565\n",
      "EarlyStopping counter: 46 out of 100\n",
      "[76/100] train_loss: 0.65546 valid_loss: 1.00730\n",
      "EarlyStopping counter: 47 out of 100\n",
      "[77/100] train_loss: 0.78494 valid_loss: 0.97528\n",
      "EarlyStopping counter: 48 out of 100\n",
      "[78/100] train_loss: 0.78120 valid_loss: 0.94860\n",
      "EarlyStopping counter: 49 out of 100\n",
      "[79/100] train_loss: 0.75180 valid_loss: 0.92777\n",
      "EarlyStopping counter: 50 out of 100\n",
      "[80/100] train_loss: 0.75288 valid_loss: 0.91186\n",
      "EarlyStopping counter: 51 out of 100\n",
      "[81/100] train_loss: 0.68943 valid_loss: 0.90864\n",
      "EarlyStopping counter: 52 out of 100\n",
      "[82/100] train_loss: 0.75240 valid_loss: 0.90799\n",
      "EarlyStopping counter: 53 out of 100\n",
      "[83/100] train_loss: 0.76597 valid_loss: 0.90838\n",
      "EarlyStopping counter: 54 out of 100\n",
      "[84/100] train_loss: 0.76325 valid_loss: 0.90969\n",
      "EarlyStopping counter: 55 out of 100\n",
      "[85/100] train_loss: 0.69124 valid_loss: 0.92195\n",
      "EarlyStopping counter: 56 out of 100\n",
      "[86/100] train_loss: 0.68723 valid_loss: 0.94414\n",
      "EarlyStopping counter: 57 out of 100\n",
      "[87/100] train_loss: 0.58606 valid_loss: 0.95963\n",
      "EarlyStopping counter: 58 out of 100\n",
      "[88/100] train_loss: 0.58465 valid_loss: 0.96802\n",
      "EarlyStopping counter: 59 out of 100\n",
      "[89/100] train_loss: 0.59512 valid_loss: 0.97354\n",
      "EarlyStopping counter: 60 out of 100\n",
      "[90/100] train_loss: 0.69423 valid_loss: 0.98297\n",
      "EarlyStopping counter: 61 out of 100\n",
      "[91/100] train_loss: 0.59349 valid_loss: 0.98901\n",
      "EarlyStopping counter: 62 out of 100\n",
      "[92/100] train_loss: 0.57836 valid_loss: 0.98689\n",
      "EarlyStopping counter: 63 out of 100\n",
      "[93/100] train_loss: 0.74244 valid_loss: 0.98594\n",
      "EarlyStopping counter: 64 out of 100\n",
      "[94/100] train_loss: 0.74725 valid_loss: 0.98826\n",
      "EarlyStopping counter: 65 out of 100\n",
      "[95/100] train_loss: 0.73990 valid_loss: 0.99141\n",
      "EarlyStopping counter: 66 out of 100\n",
      "[96/100] train_loss: 0.74245 valid_loss: 0.99784\n",
      "EarlyStopping counter: 67 out of 100\n",
      "[97/100] train_loss: 0.57318 valid_loss: 0.99441\n",
      "EarlyStopping counter: 68 out of 100\n",
      "[98/100] train_loss: 0.58635 valid_loss: 0.99198\n",
      "EarlyStopping counter: 69 out of 100\n",
      "[99/100] train_loss: 0.58557 valid_loss: 0.99081\n",
      "EarlyStopping counter: 70 out of 100\n",
      "[100/100] train_loss: 0.73108 valid_loss: 0.99404\n",
      "EarlyStopping counter: 71 out of 100\n",
      "  Training 5/5 for Fold 4\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n",
      "[1/100] train_loss: 1.01193 valid_loss: 0.67013\n",
      "Validation loss decreased (inf --> 0.670125).  Saving model ...\n",
      "[2/100] train_loss: 0.99783 valid_loss: 0.66701\n",
      "Validation loss decreased (0.670125 --> 0.667008).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/100] train_loss: 0.98394 valid_loss: 0.66389\n",
      "Validation loss decreased (0.667008 --> 0.663885).  Saving model ...\n",
      "[4/100] train_loss: 0.97014 valid_loss: 0.66075\n",
      "Validation loss decreased (0.663885 --> 0.660747).  Saving model ...\n",
      "[5/100] train_loss: 0.79867 valid_loss: 0.65727\n",
      "Validation loss decreased (0.660747 --> 0.657270).  Saving model ...\n",
      "[6/100] train_loss: 0.75186 valid_loss: 0.65405\n",
      "Validation loss decreased (0.657270 --> 0.654047).  Saving model ...\n",
      "[7/100] train_loss: 0.93364 valid_loss: 0.65075\n",
      "Validation loss decreased (0.654047 --> 0.650745).  Saving model ...\n",
      "[8/100] train_loss: 0.74704 valid_loss: 0.64754\n",
      "Validation loss decreased (0.650745 --> 0.647538).  Saving model ...\n",
      "[9/100] train_loss: 2.04459 valid_loss: 0.64362\n",
      "Validation loss decreased (0.647538 --> 0.643618).  Saving model ...\n",
      "[10/100] train_loss: 0.89934 valid_loss: 0.63972\n",
      "Validation loss decreased (0.643618 --> 0.639723).  Saving model ...\n",
      "[11/100] train_loss: 0.79400 valid_loss: 0.63596\n",
      "Validation loss decreased (0.639723 --> 0.635960).  Saving model ...\n",
      "[12/100] train_loss: 1.06577 valid_loss: 0.63261\n",
      "Validation loss decreased (0.635960 --> 0.632613).  Saving model ...\n",
      "[13/100] train_loss: 0.73767 valid_loss: 0.62939\n",
      "Validation loss decreased (0.632613 --> 0.629387).  Saving model ...\n",
      "[14/100] train_loss: 0.73605 valid_loss: 0.62625\n",
      "Validation loss decreased (0.629387 --> 0.626249).  Saving model ...\n",
      "[15/100] train_loss: 0.73438 valid_loss: 0.62317\n",
      "Validation loss decreased (0.626249 --> 0.623171).  Saving model ...\n",
      "[16/100] train_loss: 0.78897 valid_loss: 0.62009\n",
      "Validation loss decreased (0.623171 --> 0.620088).  Saving model ...\n",
      "[17/100] train_loss: 1.85107 valid_loss: 0.61586\n",
      "Validation loss decreased (0.620088 --> 0.615859).  Saving model ...\n",
      "[18/100] train_loss: 0.82402 valid_loss: 0.61143\n",
      "Validation loss decreased (0.615859 --> 0.611433).  Saving model ...\n",
      "[19/100] train_loss: 0.78543 valid_loss: 0.60710\n",
      "Validation loss decreased (0.611433 --> 0.607103).  Saving model ...\n",
      "[20/100] train_loss: 0.79896 valid_loss: 0.60244\n",
      "Validation loss decreased (0.607103 --> 0.602443).  Saving model ...\n",
      "[21/100] train_loss: 0.78295 valid_loss: 0.59786\n",
      "Validation loss decreased (0.602443 --> 0.597863).  Saving model ...\n",
      "[22/100] train_loss: 0.81051 valid_loss: 0.59249\n",
      "Validation loss decreased (0.597863 --> 0.592492).  Saving model ...\n",
      "[23/100] train_loss: 0.80340 valid_loss: 0.58671\n",
      "Validation loss decreased (0.592492 --> 0.586709).  Saving model ...\n",
      "[24/100] train_loss: 1.08098 valid_loss: 0.58188\n",
      "Validation loss decreased (0.586709 --> 0.581880).  Saving model ...\n",
      "[25/100] train_loss: 0.77796 valid_loss: 0.57749\n",
      "Validation loss decreased (0.581880 --> 0.577490).  Saving model ...\n",
      "[26/100] train_loss: 1.07851 valid_loss: 0.57397\n",
      "Validation loss decreased (0.577490 --> 0.573966).  Saving model ...\n",
      "[27/100] train_loss: 0.71803 valid_loss: 0.57004\n",
      "Validation loss decreased (0.573966 --> 0.570043).  Saving model ...\n",
      "[28/100] train_loss: 0.71556 valid_loss: 0.56674\n",
      "Validation loss decreased (0.570043 --> 0.566743).  Saving model ...\n",
      "[29/100] train_loss: 1.06776 valid_loss: 0.56433\n",
      "Validation loss decreased (0.566743 --> 0.564327).  Saving model ...\n",
      "[30/100] train_loss: 0.76952 valid_loss: 0.56244\n",
      "Validation loss decreased (0.564327 --> 0.562441).  Saving model ...\n",
      "[31/100] train_loss: 1.39670 valid_loss: 0.56065\n",
      "Validation loss decreased (0.562441 --> 0.560647).  Saving model ...\n",
      "[32/100] train_loss: 0.76589 valid_loss: 0.56046\n",
      "Validation loss decreased (0.560647 --> 0.560464).  Saving model ...\n",
      "[33/100] train_loss: 0.65364 valid_loss: 0.56282\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[34/100] train_loss: 0.63817 valid_loss: 0.57000\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[35/100] train_loss: 0.62316 valid_loss: 0.58500\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[36/100] train_loss: 1.04956 valid_loss: 0.60616\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[37/100] train_loss: 0.60936 valid_loss: 0.63179\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[38/100] train_loss: 0.75714 valid_loss: 0.66162\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[39/100] train_loss: 1.03777 valid_loss: 0.69057\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[40/100] train_loss: 0.62013 valid_loss: 0.70146\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[41/100] train_loss: 1.01626 valid_loss: 0.70897\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[42/100] train_loss: 1.00200 valid_loss: 0.71385\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[43/100] train_loss: 0.60293 valid_loss: 0.70377\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[44/100] train_loss: 0.74263 valid_loss: 0.69666\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[45/100] train_loss: 0.95922 valid_loss: 0.68974\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[46/100] train_loss: 0.65200 valid_loss: 0.69888\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[47/100] train_loss: 0.74099 valid_loss: 0.70958\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[48/100] train_loss: 0.74028 valid_loss: 0.72184\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[49/100] train_loss: 1.02448 valid_loss: 0.73500\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[50/100] train_loss: 0.66082 valid_loss: 0.75251\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[51/100] train_loss: 0.90440 valid_loss: 0.76946\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[52/100] train_loss: 0.66063 valid_loss: 0.79118\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[53/100] train_loss: 0.89091 valid_loss: 0.81202\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[54/100] train_loss: 0.58317 valid_loss: 0.84231\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[55/100] train_loss: 0.73335 valid_loss: 0.87446\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[56/100] train_loss: 0.73090 valid_loss: 0.90841\n",
      "EarlyStopping counter: 24 out of 100\n",
      "[57/100] train_loss: 0.72757 valid_loss: 0.94420\n",
      "EarlyStopping counter: 25 out of 100\n",
      "[58/100] train_loss: 0.59533 valid_loss: 0.94407\n",
      "EarlyStopping counter: 26 out of 100\n",
      "[59/100] train_loss: 0.56236 valid_loss: 0.92272\n",
      "EarlyStopping counter: 27 out of 100\n",
      "[60/100] train_loss: 0.72245 valid_loss: 0.90862\n",
      "EarlyStopping counter: 28 out of 100\n",
      "[61/100] train_loss: 0.84902 valid_loss: 0.89683\n",
      "EarlyStopping counter: 29 out of 100\n",
      "[62/100] train_loss: 0.72174 valid_loss: 0.89111\n",
      "EarlyStopping counter: 30 out of 100\n",
      "[63/100] train_loss: 0.57893 valid_loss: 0.86994\n",
      "EarlyStopping counter: 31 out of 100\n",
      "[64/100] train_loss: 0.83601 valid_loss: 0.85200\n",
      "EarlyStopping counter: 32 out of 100\n",
      "[65/100] train_loss: 0.63622 valid_loss: 0.84491\n",
      "EarlyStopping counter: 33 out of 100\n",
      "[66/100] train_loss: 0.62768 valid_loss: 0.84698\n",
      "EarlyStopping counter: 34 out of 100\n",
      "[67/100] train_loss: 0.55012 valid_loss: 0.83732\n",
      "EarlyStopping counter: 35 out of 100\n",
      "[68/100] train_loss: 0.61067 valid_loss: 0.83259\n",
      "EarlyStopping counter: 36 out of 100\n",
      "[69/100] train_loss: 0.70705 valid_loss: 0.83384\n",
      "EarlyStopping counter: 37 out of 100\n",
      "[70/100] train_loss: 0.70138 valid_loss: 0.84052\n",
      "EarlyStopping counter: 38 out of 100\n",
      "[71/100] train_loss: 0.69419 valid_loss: 0.85176\n",
      "EarlyStopping counter: 39 out of 100\n",
      "[72/100] train_loss: 0.81271 valid_loss: 0.86222\n",
      "EarlyStopping counter: 40 out of 100\n",
      "[73/100] train_loss: 0.68333 valid_loss: 0.87203\n",
      "EarlyStopping counter: 41 out of 100\n",
      "[74/100] train_loss: 0.80570 valid_loss: 0.88115\n",
      "EarlyStopping counter: 42 out of 100\n",
      "[75/100] train_loss: 0.80157 valid_loss: 0.90038\n",
      "EarlyStopping counter: 43 out of 100\n",
      "[76/100] train_loss: 0.79518 valid_loss: 0.91916\n",
      "EarlyStopping counter: 44 out of 100\n",
      "[77/100] train_loss: 0.72408 valid_loss: 0.90079\n",
      "EarlyStopping counter: 45 out of 100\n",
      "[78/100] train_loss: 0.77968 valid_loss: 0.88529\n",
      "EarlyStopping counter: 46 out of 100\n",
      "[79/100] train_loss: 0.57848 valid_loss: 0.85410\n",
      "EarlyStopping counter: 47 out of 100\n",
      "[80/100] train_loss: 0.62368 valid_loss: 0.81409\n",
      "EarlyStopping counter: 48 out of 100\n",
      "[81/100] train_loss: 0.54551 valid_loss: 0.77409\n",
      "EarlyStopping counter: 49 out of 100\n",
      "[82/100] train_loss: 0.68691 valid_loss: 0.74643\n",
      "EarlyStopping counter: 50 out of 100\n",
      "[83/100] train_loss: 0.74151 valid_loss: 0.72353\n",
      "EarlyStopping counter: 51 out of 100\n",
      "[84/100] train_loss: 0.70441 valid_loss: 0.70905\n",
      "EarlyStopping counter: 52 out of 100\n",
      "[85/100] train_loss: 0.56465 valid_loss: 0.69908\n",
      "EarlyStopping counter: 53 out of 100\n",
      "[86/100] train_loss: 0.55837 valid_loss: 0.70073\n",
      "EarlyStopping counter: 54 out of 100\n",
      "[87/100] train_loss: 0.56005 valid_loss: 0.71312\n",
      "EarlyStopping counter: 55 out of 100\n",
      "[88/100] train_loss: 0.81996 valid_loss: 0.74855\n",
      "EarlyStopping counter: 56 out of 100\n",
      "[89/100] train_loss: 0.54426 valid_loss: 0.79404\n",
      "EarlyStopping counter: 57 out of 100\n",
      "[90/100] train_loss: 0.71177 valid_loss: 0.84045\n",
      "EarlyStopping counter: 58 out of 100\n",
      "[91/100] train_loss: 0.52697 valid_loss: 0.89063\n",
      "EarlyStopping counter: 59 out of 100\n",
      "[92/100] train_loss: 0.62501 valid_loss: 0.94900\n",
      "EarlyStopping counter: 60 out of 100\n",
      "[93/100] train_loss: 0.70359 valid_loss: 1.02010\n",
      "EarlyStopping counter: 61 out of 100\n",
      "[94/100] train_loss: 0.56694 valid_loss: 1.09004\n",
      "EarlyStopping counter: 62 out of 100\n",
      "[95/100] train_loss: 0.65812 valid_loss: 1.14194\n",
      "EarlyStopping counter: 63 out of 100\n",
      "[96/100] train_loss: 0.69414 valid_loss: 1.19143\n",
      "EarlyStopping counter: 64 out of 100\n",
      "[97/100] train_loss: 0.61013 valid_loss: 1.21204\n",
      "EarlyStopping counter: 65 out of 100\n",
      "[98/100] train_loss: 0.67635 valid_loss: 1.20458\n",
      "EarlyStopping counter: 66 out of 100\n",
      "[99/100] train_loss: 0.66250 valid_loss: 1.19066\n",
      "EarlyStopping counter: 67 out of 100\n",
      "[100/100] train_loss: 0.64165 valid_loss: 1.17939\n",
      "EarlyStopping counter: 68 out of 100\n",
      "  Fold 5/7\n",
      "  Training 1/5 for Fold 5\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] train_loss: 2.45973 valid_loss: 0.74264\n",
      "Validation loss decreased (inf --> 0.742642).  Saving model ...\n",
      "[2/100] train_loss: 0.89637 valid_loss: 0.74192\n",
      "Validation loss decreased (0.742642 --> 0.741915).  Saving model ...\n",
      "[3/100] train_loss: 0.78611 valid_loss: 0.74114\n",
      "Validation loss decreased (0.741915 --> 0.741142).  Saving model ...\n",
      "[4/100] train_loss: 0.78349 valid_loss: 0.74038\n",
      "Validation loss decreased (0.741142 --> 0.740383).  Saving model ...\n",
      "[5/100] train_loss: 0.87368 valid_loss: 0.73972\n",
      "Validation loss decreased (0.740383 --> 0.739718).  Saving model ...\n",
      "[6/100] train_loss: 0.77822 valid_loss: 0.73907\n",
      "Validation loss decreased (0.739718 --> 0.739065).  Saving model ...\n",
      "[7/100] train_loss: 0.86073 valid_loss: 0.73848\n",
      "Validation loss decreased (0.739065 --> 0.738482).  Saving model ...\n",
      "[8/100] train_loss: 0.91288 valid_loss: 0.73807\n",
      "Validation loss decreased (0.738482 --> 0.738073).  Saving model ...\n",
      "[9/100] train_loss: 0.84758 valid_loss: 0.73766\n",
      "Validation loss decreased (0.738073 --> 0.737662).  Saving model ...\n",
      "[10/100] train_loss: 2.25966 valid_loss: 0.73725\n",
      "Validation loss decreased (0.737662 --> 0.737251).  Saving model ...\n",
      "[11/100] train_loss: 1.02857 valid_loss: 0.73678\n",
      "Validation loss decreased (0.737251 --> 0.736782).  Saving model ...\n",
      "[12/100] train_loss: 0.68718 valid_loss: 0.73633\n",
      "Validation loss decreased (0.736782 --> 0.736328).  Saving model ...\n",
      "[13/100] train_loss: 1.01438 valid_loss: 0.73584\n",
      "Validation loss decreased (0.736328 --> 0.735839).  Saving model ...\n",
      "[14/100] train_loss: 0.91892 valid_loss: 0.73544\n",
      "Validation loss decreased (0.735839 --> 0.735439).  Saving model ...\n",
      "[15/100] train_loss: 0.76222 valid_loss: 0.73502\n",
      "Validation loss decreased (0.735439 --> 0.735022).  Saving model ...\n",
      "[16/100] train_loss: 0.80426 valid_loss: 0.73459\n",
      "Validation loss decreased (0.735022 --> 0.734590).  Saving model ...\n",
      "[17/100] train_loss: 2.11223 valid_loss: 0.73414\n",
      "Validation loss decreased (0.734590 --> 0.734141).  Saving model ...\n",
      "[18/100] train_loss: 0.97730 valid_loss: 0.73365\n",
      "Validation loss decreased (0.734141 --> 0.733654).  Saving model ...\n",
      "[19/100] train_loss: 0.92457 valid_loss: 0.73322\n",
      "Validation loss decreased (0.733654 --> 0.733222).  Saving model ...\n",
      "[20/100] train_loss: 0.75091 valid_loss: 0.73277\n",
      "Validation loss decreased (0.733222 --> 0.732767).  Saving model ...\n",
      "[21/100] train_loss: 0.92591 valid_loss: 0.73235\n",
      "Validation loss decreased (0.732767 --> 0.732353).  Saving model ...\n",
      "[22/100] train_loss: 0.94379 valid_loss: 0.73186\n",
      "Validation loss decreased (0.732353 --> 0.731857).  Saving model ...\n",
      "[23/100] train_loss: 0.93474 valid_loss: 0.73130\n",
      "Validation loss decreased (0.731857 --> 0.731296).  Saving model ...\n",
      "[24/100] train_loss: 1.93118 valid_loss: 0.73068\n",
      "Validation loss decreased (0.731296 --> 0.730678).  Saving model ...\n",
      "[25/100] train_loss: 0.62510 valid_loss: 0.73004\n",
      "Validation loss decreased (0.730678 --> 0.730039).  Saving model ...\n",
      "[26/100] train_loss: 1.85506 valid_loss: 0.72935\n",
      "Validation loss decreased (0.730039 --> 0.729347).  Saving model ...\n",
      "[27/100] train_loss: 0.93288 valid_loss: 0.72868\n",
      "Validation loss decreased (0.729347 --> 0.728678).  Saving model ...\n",
      "[28/100] train_loss: 0.86600 valid_loss: 0.72794\n",
      "Validation loss decreased (0.728678 --> 0.727938).  Saving model ...\n",
      "[29/100] train_loss: 0.71787 valid_loss: 0.72717\n",
      "Validation loss decreased (0.727938 --> 0.727167).  Saving model ...\n",
      "[30/100] train_loss: 0.83085 valid_loss: 0.72637\n",
      "Validation loss decreased (0.727167 --> 0.726370).  Saving model ...\n",
      "[31/100] train_loss: 1.60077 valid_loss: 0.72564\n",
      "Validation loss decreased (0.726370 --> 0.725641).  Saving model ...\n",
      "[32/100] train_loss: 0.68313 valid_loss: 0.72508\n",
      "Validation loss decreased (0.725641 --> 0.725080).  Saving model ...\n",
      "[33/100] train_loss: 0.75684 valid_loss: 0.72492\n",
      "Validation loss decreased (0.725080 --> 0.724917).  Saving model ...\n",
      "[34/100] train_loss: 0.72562 valid_loss: 0.72568\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[35/100] train_loss: 0.59350 valid_loss: 0.72765\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[36/100] train_loss: 0.66044 valid_loss: 0.73232\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[37/100] train_loss: 0.62999 valid_loss: 0.74245\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[38/100] train_loss: 0.66155 valid_loss: 0.75409\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[39/100] train_loss: 0.59184 valid_loss: 0.77138\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[40/100] train_loss: 0.68584 valid_loss: 0.78780\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[41/100] train_loss: 0.73681 valid_loss: 0.79259\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[42/100] train_loss: 0.58325 valid_loss: 0.79630\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[43/100] train_loss: 0.61800 valid_loss: 0.79642\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[44/100] train_loss: 1.01255 valid_loss: 0.80209\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[45/100] train_loss: 0.73755 valid_loss: 0.79682\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[46/100] train_loss: 0.71909 valid_loss: 0.78494\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[47/100] train_loss: 0.71060 valid_loss: 0.77020\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[48/100] train_loss: 1.05093 valid_loss: 0.75348\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[49/100] train_loss: 0.58320 valid_loss: 0.74220\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[50/100] train_loss: 0.58594 valid_loss: 0.73466\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[51/100] train_loss: 0.66046 valid_loss: 0.72780\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[52/100] train_loss: 0.66269 valid_loss: 0.72300\n",
      "Validation loss decreased (0.724917 --> 0.723000).  Saving model ...\n",
      "[53/100] train_loss: 1.00950 valid_loss: 0.72063\n",
      "Validation loss decreased (0.723000 --> 0.720626).  Saving model ...\n",
      "[54/100] train_loss: 0.65962 valid_loss: 0.71866\n",
      "Validation loss decreased (0.720626 --> 0.718663).  Saving model ...\n",
      "[55/100] train_loss: 0.61394 valid_loss: 0.71712\n",
      "Validation loss decreased (0.718663 --> 0.717123).  Saving model ...\n",
      "[56/100] train_loss: 0.97315 valid_loss: 0.71622\n",
      "Validation loss decreased (0.717123 --> 0.716218).  Saving model ...\n",
      "[57/100] train_loss: 0.59862 valid_loss: 0.71547\n",
      "Validation loss decreased (0.716218 --> 0.715472).  Saving model ...\n",
      "[58/100] train_loss: 0.59047 valid_loss: 0.71496\n",
      "Validation loss decreased (0.715472 --> 0.714958).  Saving model ...\n",
      "[59/100] train_loss: 0.59819 valid_loss: 0.71478\n",
      "Validation loss decreased (0.714958 --> 0.714784).  Saving model ...\n",
      "[60/100] train_loss: 0.71714 valid_loss: 0.71358\n",
      "Validation loss decreased (0.714784 --> 0.713579).  Saving model ...\n",
      "[61/100] train_loss: 0.82337 valid_loss: 0.71331\n",
      "Validation loss decreased (0.713579 --> 0.713308).  Saving model ...\n",
      "[62/100] train_loss: 0.59042 valid_loss: 0.71313\n",
      "Validation loss decreased (0.713308 --> 0.713127).  Saving model ...\n",
      "[63/100] train_loss: 0.58915 valid_loss: 0.71292\n",
      "Validation loss decreased (0.713127 --> 0.712918).  Saving model ...\n",
      "[64/100] train_loss: 0.75680 valid_loss: 0.71411\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[65/100] train_loss: 0.83410 valid_loss: 0.71169\n",
      "Validation loss decreased (0.712918 --> 0.711687).  Saving model ...\n",
      "[66/100] train_loss: 0.83443 valid_loss: 0.70762\n",
      "Validation loss decreased (0.711687 --> 0.707618).  Saving model ...\n",
      "[67/100] train_loss: 0.57103 valid_loss: 0.70508\n",
      "Validation loss decreased (0.707618 --> 0.705084).  Saving model ...\n",
      "[68/100] train_loss: 0.77366 valid_loss: 0.70422\n",
      "Validation loss decreased (0.705084 --> 0.704224).  Saving model ...\n",
      "[69/100] train_loss: 0.76184 valid_loss: 0.70459\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[70/100] train_loss: 0.87996 valid_loss: 0.70521\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[71/100] train_loss: 0.57605 valid_loss: 0.70567\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[72/100] train_loss: 0.87194 valid_loss: 0.70624\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[73/100] train_loss: 0.62608 valid_loss: 0.70636\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[74/100] train_loss: 0.86195 valid_loss: 0.70662\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[75/100] train_loss: 0.85605 valid_loss: 0.70707\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[76/100] train_loss: 0.63194 valid_loss: 0.70702\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[77/100] train_loss: 0.59153 valid_loss: 0.70606\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[78/100] train_loss: 0.83787 valid_loss: 0.70535\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[79/100] train_loss: 0.67828 valid_loss: 0.70392\n",
      "Validation loss decreased (0.704224 --> 0.703922).  Saving model ...\n",
      "[80/100] train_loss: 0.78039 valid_loss: 0.70195\n",
      "Validation loss decreased (0.703922 --> 0.701955).  Saving model ...\n",
      "[81/100] train_loss: 0.67219 valid_loss: 0.69893\n",
      "Validation loss decreased (0.701955 --> 0.698925).  Saving model ...\n",
      "[82/100] train_loss: 0.54955 valid_loss: 0.69549\n",
      "Validation loss decreased (0.698925 --> 0.695493).  Saving model ...\n",
      "[83/100] train_loss: 0.54499 valid_loss: 0.69212\n",
      "Validation loss decreased (0.695493 --> 0.692118).  Saving model ...\n",
      "[84/100] train_loss: 0.58651 valid_loss: 0.68791\n",
      "Validation loss decreased (0.692118 --> 0.687907).  Saving model ...\n",
      "[85/100] train_loss: 0.70195 valid_loss: 0.68360\n",
      "Validation loss decreased (0.687907 --> 0.683601).  Saving model ...\n",
      "[86/100] train_loss: 0.80976 valid_loss: 0.67964\n",
      "Validation loss decreased (0.683601 --> 0.679640).  Saving model ...\n",
      "[87/100] train_loss: 0.68187 valid_loss: 0.67605\n",
      "Validation loss decreased (0.679640 --> 0.676055).  Saving model ...\n",
      "[88/100] train_loss: 0.60661 valid_loss: 0.67215\n",
      "Validation loss decreased (0.676055 --> 0.672151).  Saving model ...\n",
      "[89/100] train_loss: 0.97463 valid_loss: 0.67160\n",
      "Validation loss decreased (0.672151 --> 0.671605).  Saving model ...\n",
      "[90/100] train_loss: 0.66068 valid_loss: 0.67136\n",
      "Validation loss decreased (0.671605 --> 0.671356).  Saving model ...\n",
      "[91/100] train_loss: 0.79714 valid_loss: 0.67119\n",
      "Validation loss decreased (0.671356 --> 0.671187).  Saving model ...\n",
      "[92/100] train_loss: 0.92668 valid_loss: 0.67439\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[93/100] train_loss: 0.79339 valid_loss: 0.67808\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[94/100] train_loss: 0.81705 valid_loss: 0.68466\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[95/100] train_loss: 0.56715 valid_loss: 0.69148\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[96/100] train_loss: 0.69539 valid_loss: 0.69656\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[97/100] train_loss: 0.55165 valid_loss: 0.70092\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[98/100] train_loss: 0.78483 valid_loss: 0.70493\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[99/100] train_loss: 0.60832 valid_loss: 0.70919\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[100/100] train_loss: 0.79447 valid_loss: 0.71209\n",
      "EarlyStopping counter: 9 out of 100\n",
      "  Training 2/5 for Fold 5\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n",
      "[1/100] train_loss: 0.77331 valid_loss: 0.77093\n",
      "Validation loss decreased (inf --> 0.770934).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/100] train_loss: 0.77075 valid_loss: 0.77065\n",
      "Validation loss decreased (0.770934 --> 0.770647).  Saving model ...\n",
      "[3/100] train_loss: 0.92781 valid_loss: 0.77112\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[4/100] train_loss: 0.91900 valid_loss: 0.77185\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[5/100] train_loss: 1.07710 valid_loss: 0.77163\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[6/100] train_loss: 1.07421 valid_loss: 0.77104\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[7/100] train_loss: 0.83249 valid_loss: 0.77072\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[8/100] train_loss: 0.89876 valid_loss: 0.77062\n",
      "Validation loss decreased (0.770647 --> 0.770622).  Saving model ...\n",
      "[9/100] train_loss: 1.93412 valid_loss: 0.77086\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[10/100] train_loss: 0.67656 valid_loss: 0.77111\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[11/100] train_loss: 0.75933 valid_loss: 0.77132\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[12/100] train_loss: 0.75838 valid_loss: 0.77147\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[13/100] train_loss: 1.05382 valid_loss: 0.77131\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[14/100] train_loss: 0.75640 valid_loss: 0.77113\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[15/100] train_loss: 1.04640 valid_loss: 0.77071\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[16/100] train_loss: 0.79955 valid_loss: 0.77043\n",
      "Validation loss decreased (0.770622 --> 0.770426).  Saving model ...\n",
      "[17/100] train_loss: 1.03598 valid_loss: 0.76993\n",
      "Validation loss decreased (0.770426 --> 0.769932).  Saving model ...\n",
      "[18/100] train_loss: 0.75253 valid_loss: 0.76946\n",
      "Validation loss decreased (0.769932 --> 0.769456).  Saving model ...\n",
      "[19/100] train_loss: 0.65239 valid_loss: 0.76903\n",
      "Validation loss decreased (0.769456 --> 0.769030).  Saving model ...\n",
      "[20/100] train_loss: 1.75758 valid_loss: 0.76887\n",
      "Validation loss decreased (0.769030 --> 0.768872).  Saving model ...\n",
      "[21/100] train_loss: 0.85534 valid_loss: 0.76880\n",
      "Validation loss decreased (0.768872 --> 0.768805).  Saving model ...\n",
      "[22/100] train_loss: 0.74813 valid_loss: 0.76871\n",
      "Validation loss decreased (0.768805 --> 0.768710).  Saving model ...\n",
      "[23/100] train_loss: 0.77098 valid_loss: 0.76868\n",
      "Validation loss decreased (0.768710 --> 0.768679).  Saving model ...\n",
      "[24/100] train_loss: 1.00383 valid_loss: 0.76842\n",
      "Validation loss decreased (0.768679 --> 0.768419).  Saving model ...\n",
      "[25/100] train_loss: 0.76042 valid_loss: 0.76823\n",
      "Validation loss decreased (0.768419 --> 0.768227).  Saving model ...\n",
      "[26/100] train_loss: 0.99450 valid_loss: 0.76782\n",
      "Validation loss decreased (0.768227 --> 0.767825).  Saving model ...\n",
      "[27/100] train_loss: 1.58439 valid_loss: 0.76762\n",
      "Validation loss decreased (0.767825 --> 0.767617).  Saving model ...\n",
      "[28/100] train_loss: 0.81705 valid_loss: 0.76747\n",
      "Validation loss decreased (0.767617 --> 0.767474).  Saving model ...\n",
      "[29/100] train_loss: 0.73489 valid_loss: 0.76737\n",
      "Validation loss decreased (0.767474 --> 0.767367).  Saving model ...\n",
      "[30/100] train_loss: 0.79813 valid_loss: 0.76732\n",
      "Validation loss decreased (0.767367 --> 0.767318).  Saving model ...\n",
      "[31/100] train_loss: 0.71959 valid_loss: 0.76730\n",
      "Validation loss decreased (0.767318 --> 0.767298).  Saving model ...\n",
      "[32/100] train_loss: 0.96808 valid_loss: 0.76700\n",
      "Validation loss decreased (0.767298 --> 0.767004).  Saving model ...\n",
      "[33/100] train_loss: 0.70258 valid_loss: 0.76673\n",
      "Validation loss decreased (0.767004 --> 0.766728).  Saving model ...\n",
      "[34/100] train_loss: 0.75184 valid_loss: 0.76650\n",
      "Validation loss decreased (0.766728 --> 0.766497).  Saving model ...\n",
      "[35/100] train_loss: 0.68397 valid_loss: 0.76627\n",
      "Validation loss decreased (0.766497 --> 0.766269).  Saving model ...\n",
      "[36/100] train_loss: 0.67389 valid_loss: 0.76604\n",
      "Validation loss decreased (0.766269 --> 0.766038).  Saving model ...\n",
      "[37/100] train_loss: 0.65939 valid_loss: 0.76570\n",
      "Validation loss decreased (0.766038 --> 0.765703).  Saving model ...\n",
      "[38/100] train_loss: 1.12784 valid_loss: 0.76542\n",
      "Validation loss decreased (0.765703 --> 0.765420).  Saving model ...\n",
      "[39/100] train_loss: 0.67608 valid_loss: 0.76519\n",
      "Validation loss decreased (0.765420 --> 0.765188).  Saving model ...\n",
      "[40/100] train_loss: 0.65435 valid_loss: 0.76507\n",
      "Validation loss decreased (0.765188 --> 0.765070).  Saving model ...\n",
      "[41/100] train_loss: 0.93662 valid_loss: 0.76443\n",
      "Validation loss decreased (0.765070 --> 0.764434).  Saving model ...\n",
      "[42/100] train_loss: 0.70291 valid_loss: 0.76386\n",
      "Validation loss decreased (0.764434 --> 0.763862).  Saving model ...\n",
      "[43/100] train_loss: 0.92652 valid_loss: 0.76264\n",
      "Validation loss decreased (0.763862 --> 0.762644).  Saving model ...\n",
      "[44/100] train_loss: 0.91814 valid_loss: 0.76066\n",
      "Validation loss decreased (0.762644 --> 0.760655).  Saving model ...\n",
      "[45/100] train_loss: 0.90676 valid_loss: 0.75779\n",
      "Validation loss decreased (0.760655 --> 0.757787).  Saving model ...\n",
      "[46/100] train_loss: 0.71903 valid_loss: 0.75412\n",
      "Validation loss decreased (0.757787 --> 0.754124).  Saving model ...\n",
      "[47/100] train_loss: 0.88227 valid_loss: 0.75052\n",
      "Validation loss decreased (0.754124 --> 0.750523).  Saving model ...\n",
      "[48/100] train_loss: 0.67652 valid_loss: 0.74759\n",
      "Validation loss decreased (0.750523 --> 0.747587).  Saving model ...\n",
      "[49/100] train_loss: 0.68082 valid_loss: 0.74631\n",
      "Validation loss decreased (0.747587 --> 0.746312).  Saving model ...\n",
      "[50/100] train_loss: 0.84847 valid_loss: 0.74605\n",
      "Validation loss decreased (0.746312 --> 0.746050).  Saving model ...\n",
      "[51/100] train_loss: 0.66845 valid_loss: 0.74636\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[52/100] train_loss: 0.63390 valid_loss: 0.74846\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[53/100] train_loss: 0.66880 valid_loss: 0.74999\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[54/100] train_loss: 0.87433 valid_loss: 0.75176\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[55/100] train_loss: 0.67111 valid_loss: 0.75247\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[56/100] train_loss: 0.80057 valid_loss: 0.75370\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[57/100] train_loss: 0.88239 valid_loss: 0.75580\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[58/100] train_loss: 0.66570 valid_loss: 0.75668\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[59/100] train_loss: 0.64488 valid_loss: 0.75719\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[60/100] train_loss: 0.65981 valid_loss: 0.75696\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[61/100] train_loss: 0.58304 valid_loss: 0.75699\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[62/100] train_loss: 0.58355 valid_loss: 0.75728\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[63/100] train_loss: 0.66882 valid_loss: 0.75718\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[64/100] train_loss: 0.58380 valid_loss: 0.75733\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[65/100] train_loss: 0.58347 valid_loss: 0.75773\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[66/100] train_loss: 0.64401 valid_loss: 0.75831\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[67/100] train_loss: 0.76761 valid_loss: 0.75956\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[68/100] train_loss: 0.58062 valid_loss: 0.76113\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[69/100] train_loss: 0.57912 valid_loss: 0.76302\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[70/100] train_loss: 0.67554 valid_loss: 0.76442\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[71/100] train_loss: 0.68193 valid_loss: 0.76628\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[72/100] train_loss: 0.86042 valid_loss: 0.76809\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[73/100] train_loss: 0.75233 valid_loss: 0.77037\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[74/100] train_loss: 0.57108 valid_loss: 0.77306\n",
      "EarlyStopping counter: 24 out of 100\n",
      "[75/100] train_loss: 0.82956 valid_loss: 0.77579\n",
      "EarlyStopping counter: 25 out of 100\n",
      "[76/100] train_loss: 0.74532 valid_loss: 0.77882\n",
      "EarlyStopping counter: 26 out of 100\n",
      "[77/100] train_loss: 0.70143 valid_loss: 0.78201\n",
      "EarlyStopping counter: 27 out of 100\n",
      "[78/100] train_loss: 0.69675 valid_loss: 0.78514\n",
      "EarlyStopping counter: 28 out of 100\n",
      "[79/100] train_loss: 0.56701 valid_loss: 0.78848\n",
      "EarlyStopping counter: 29 out of 100\n",
      "[80/100] train_loss: 0.62281 valid_loss: 0.78878\n",
      "EarlyStopping counter: 30 out of 100\n",
      "[81/100] train_loss: 0.68891 valid_loss: 0.78858\n",
      "EarlyStopping counter: 31 out of 100\n",
      "[82/100] train_loss: 0.64507 valid_loss: 0.78863\n",
      "EarlyStopping counter: 32 out of 100\n",
      "[83/100] train_loss: 0.61433 valid_loss: 0.78786\n",
      "EarlyStopping counter: 33 out of 100\n",
      "[84/100] train_loss: 0.56026 valid_loss: 0.78762\n",
      "EarlyStopping counter: 34 out of 100\n",
      "[85/100] train_loss: 0.61042 valid_loss: 0.78800\n",
      "EarlyStopping counter: 35 out of 100\n",
      "[86/100] train_loss: 0.61542 valid_loss: 0.78864\n",
      "EarlyStopping counter: 36 out of 100\n",
      "[87/100] train_loss: 0.55601 valid_loss: 0.78967\n",
      "EarlyStopping counter: 37 out of 100\n",
      "[88/100] train_loss: 0.60757 valid_loss: 0.79178\n",
      "EarlyStopping counter: 38 out of 100\n",
      "[89/100] train_loss: 0.60525 valid_loss: 0.79456\n",
      "EarlyStopping counter: 39 out of 100\n",
      "[90/100] train_loss: 0.83758 valid_loss: 0.79755\n",
      "EarlyStopping counter: 40 out of 100\n",
      "[91/100] train_loss: 0.60106 valid_loss: 0.80088\n",
      "EarlyStopping counter: 41 out of 100\n",
      "[92/100] train_loss: 0.59630 valid_loss: 0.80430\n",
      "EarlyStopping counter: 42 out of 100\n",
      "[93/100] train_loss: 0.72608 valid_loss: 0.80673\n",
      "EarlyStopping counter: 43 out of 100\n",
      "[94/100] train_loss: 0.72124 valid_loss: 0.80831\n",
      "EarlyStopping counter: 44 out of 100\n",
      "[95/100] train_loss: 0.71887 valid_loss: 0.80915\n",
      "EarlyStopping counter: 45 out of 100\n",
      "[96/100] train_loss: 0.59426 valid_loss: 0.81002\n",
      "EarlyStopping counter: 46 out of 100\n",
      "[97/100] train_loss: 0.72137 valid_loss: 0.80994\n",
      "EarlyStopping counter: 47 out of 100\n",
      "[98/100] train_loss: 0.54564 valid_loss: 0.81047\n",
      "EarlyStopping counter: 48 out of 100\n",
      "[99/100] train_loss: 0.60132 valid_loss: 0.80612\n",
      "EarlyStopping counter: 49 out of 100\n",
      "[100/100] train_loss: 0.54496 valid_loss: 0.80277\n",
      "EarlyStopping counter: 50 out of 100\n",
      "  Training 3/5 for Fold 5\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] train_loss: 1.05883 valid_loss: 0.76628\n",
      "Validation loss decreased (inf --> 0.766278).  Saving model ...\n",
      "[2/100] train_loss: 2.17458 valid_loss: 0.76607\n",
      "Validation loss decreased (0.766278 --> 0.766072).  Saving model ...\n",
      "[3/100] train_loss: 0.72795 valid_loss: 0.76576\n",
      "Validation loss decreased (0.766072 --> 0.765762).  Saving model ...\n",
      "[4/100] train_loss: 0.78108 valid_loss: 0.76535\n",
      "Validation loss decreased (0.765762 --> 0.765354).  Saving model ...\n",
      "[5/100] train_loss: 2.11208 valid_loss: 0.76524\n",
      "Validation loss decreased (0.765354 --> 0.765240).  Saving model ...\n",
      "[6/100] train_loss: 1.03254 valid_loss: 0.76493\n",
      "Validation loss decreased (0.765240 --> 0.764928).  Saving model ...\n",
      "[7/100] train_loss: 0.99300 valid_loss: 0.76460\n",
      "Validation loss decreased (0.764928 --> 0.764604).  Saving model ...\n",
      "[8/100] train_loss: 0.82861 valid_loss: 0.76433\n",
      "Validation loss decreased (0.764604 --> 0.764331).  Saving model ...\n",
      "[9/100] train_loss: 0.82461 valid_loss: 0.76411\n",
      "Validation loss decreased (0.764331 --> 0.764112).  Saving model ...\n",
      "[10/100] train_loss: 2.02022 valid_loss: 0.76408\n",
      "Validation loss decreased (0.764112 --> 0.764080).  Saving model ...\n",
      "[11/100] train_loss: 0.81498 valid_loss: 0.76408\n",
      "Validation loss decreased (0.764080 --> 0.764078).  Saving model ...\n",
      "[12/100] train_loss: 0.96810 valid_loss: 0.76408\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[13/100] train_loss: 0.80490 valid_loss: 0.76413\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[14/100] train_loss: 0.79970 valid_loss: 0.76421\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[15/100] train_loss: 1.02508 valid_loss: 0.76410\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[16/100] train_loss: 0.78936 valid_loss: 0.76402\n",
      "Validation loss decreased (0.764078 --> 0.764024).  Saving model ...\n",
      "[17/100] train_loss: 1.02240 valid_loss: 0.76377\n",
      "Validation loss decreased (0.764024 --> 0.763774).  Saving model ...\n",
      "[18/100] train_loss: 0.77961 valid_loss: 0.76357\n",
      "Validation loss decreased (0.763774 --> 0.763570).  Saving model ...\n",
      "[19/100] train_loss: 0.94150 valid_loss: 0.76340\n",
      "Validation loss decreased (0.763570 --> 0.763404).  Saving model ...\n",
      "[20/100] train_loss: 0.76998 valid_loss: 0.76328\n",
      "Validation loss decreased (0.763404 --> 0.763278).  Saving model ...\n",
      "[21/100] train_loss: 0.76487 valid_loss: 0.76319\n",
      "Validation loss decreased (0.763278 --> 0.763189).  Saving model ...\n",
      "[22/100] train_loss: 0.75932 valid_loss: 0.76313\n",
      "Validation loss decreased (0.763189 --> 0.763132).  Saving model ...\n",
      "[23/100] train_loss: 1.82205 valid_loss: 0.76322\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[24/100] train_loss: 0.65309 valid_loss: 0.76329\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[25/100] train_loss: 0.74125 valid_loss: 0.76337\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[26/100] train_loss: 0.73486 valid_loss: 0.76347\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[27/100] train_loss: 1.73904 valid_loss: 0.76369\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[28/100] train_loss: 0.75510 valid_loss: 0.76388\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[29/100] train_loss: 1.68227 valid_loss: 0.76420\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[30/100] train_loss: 0.89153 valid_loss: 0.76456\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[31/100] train_loss: 0.75030 valid_loss: 0.76493\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[32/100] train_loss: 1.57275 valid_loss: 0.76544\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[33/100] train_loss: 0.68863 valid_loss: 0.76596\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[34/100] train_loss: 0.74371 valid_loss: 0.76651\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[35/100] train_loss: 1.00962 valid_loss: 0.76670\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[36/100] train_loss: 0.63070 valid_loss: 0.76682\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[37/100] train_loss: 0.63306 valid_loss: 0.76684\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[38/100] train_loss: 1.31822 valid_loss: 0.76706\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[39/100] train_loss: 0.73400 valid_loss: 0.76730\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[40/100] train_loss: 0.78206 valid_loss: 0.76778\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[41/100] train_loss: 0.72876 valid_loss: 0.76837\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[42/100] train_loss: 1.00105 valid_loss: 0.76839\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[43/100] train_loss: 0.99801 valid_loss: 0.76778\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[44/100] train_loss: 0.65233 valid_loss: 0.76709\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[45/100] train_loss: 0.65287 valid_loss: 0.76629\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[46/100] train_loss: 0.99436 valid_loss: 0.76579\n",
      "EarlyStopping counter: 24 out of 100\n",
      "[47/100] train_loss: 0.97531 valid_loss: 0.76456\n",
      "EarlyStopping counter: 25 out of 100\n",
      "[48/100] train_loss: 0.79840 valid_loss: 0.76313\n",
      "EarlyStopping counter: 26 out of 100\n",
      "[49/100] train_loss: 0.79651 valid_loss: 0.76174\n",
      "Validation loss decreased (0.763132 --> 0.761744).  Saving model ...\n",
      "[50/100] train_loss: 0.65332 valid_loss: 0.76067\n",
      "Validation loss decreased (0.761744 --> 0.760671).  Saving model ...\n",
      "[51/100] train_loss: 0.89805 valid_loss: 0.75983\n",
      "Validation loss decreased (0.760671 --> 0.759828).  Saving model ...\n",
      "[52/100] train_loss: 0.94649 valid_loss: 0.75863\n",
      "Validation loss decreased (0.759828 --> 0.758632).  Saving model ...\n",
      "[53/100] train_loss: 0.93987 valid_loss: 0.75723\n",
      "Validation loss decreased (0.758632 --> 0.757226).  Saving model ...\n",
      "[54/100] train_loss: 0.93122 valid_loss: 0.75577\n",
      "Validation loss decreased (0.757226 --> 0.755773).  Saving model ...\n",
      "[55/100] train_loss: 0.92094 valid_loss: 0.75444\n",
      "Validation loss decreased (0.755773 --> 0.754439).  Saving model ...\n",
      "[56/100] train_loss: 0.77243 valid_loss: 0.75381\n",
      "Validation loss decreased (0.754439 --> 0.753812).  Saving model ...\n",
      "[57/100] train_loss: 0.71508 valid_loss: 0.75341\n",
      "Validation loss decreased (0.753812 --> 0.753411).  Saving model ...\n",
      "[58/100] train_loss: 0.62934 valid_loss: 0.75318\n",
      "Validation loss decreased (0.753411 --> 0.753183).  Saving model ...\n",
      "[59/100] train_loss: 0.73454 valid_loss: 0.75340\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[60/100] train_loss: 0.63295 valid_loss: 0.75363\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[61/100] train_loss: 0.87402 valid_loss: 0.75403\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[62/100] train_loss: 0.68899 valid_loss: 0.75473\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[63/100] train_loss: 0.64458 valid_loss: 0.75534\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[64/100] train_loss: 0.86965 valid_loss: 0.75590\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[65/100] train_loss: 0.67995 valid_loss: 0.75603\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[66/100] train_loss: 0.66383 valid_loss: 0.75638\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[67/100] train_loss: 0.66180 valid_loss: 0.75694\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[68/100] train_loss: 0.84021 valid_loss: 0.75779\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[69/100] train_loss: 0.83564 valid_loss: 0.75899\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[70/100] train_loss: 0.82882 valid_loss: 0.76026\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[71/100] train_loss: 0.80684 valid_loss: 0.76165\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[72/100] train_loss: 0.81841 valid_loss: 0.76354\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[73/100] train_loss: 0.66494 valid_loss: 0.76574\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[74/100] train_loss: 0.72672 valid_loss: 0.76805\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[75/100] train_loss: 0.80102 valid_loss: 0.77092\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[76/100] train_loss: 0.68757 valid_loss: 0.77386\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[77/100] train_loss: 0.73032 valid_loss: 0.77511\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[78/100] train_loss: 0.78604 valid_loss: 0.77696\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[79/100] train_loss: 0.78171 valid_loss: 0.77944\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[80/100] train_loss: 0.66144 valid_loss: 0.78227\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[81/100] train_loss: 0.71889 valid_loss: 0.78273\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[82/100] train_loss: 0.71294 valid_loss: 0.78122\n",
      "EarlyStopping counter: 24 out of 100\n",
      "[83/100] train_loss: 0.76872 valid_loss: 0.78038\n",
      "EarlyStopping counter: 25 out of 100\n",
      "[84/100] train_loss: 0.64923 valid_loss: 0.77938\n",
      "EarlyStopping counter: 26 out of 100\n",
      "[85/100] train_loss: 0.76534 valid_loss: 0.77909\n",
      "EarlyStopping counter: 27 out of 100\n",
      "[86/100] train_loss: 0.65006 valid_loss: 0.77775\n",
      "EarlyStopping counter: 28 out of 100\n",
      "[87/100] train_loss: 0.74587 valid_loss: 0.77693\n",
      "EarlyStopping counter: 29 out of 100\n",
      "[88/100] train_loss: 0.73219 valid_loss: 0.77520\n",
      "EarlyStopping counter: 30 out of 100\n",
      "[89/100] train_loss: 0.75863 valid_loss: 0.77427\n",
      "EarlyStopping counter: 31 out of 100\n",
      "[90/100] train_loss: 0.75656 valid_loss: 0.77410\n",
      "EarlyStopping counter: 32 out of 100\n",
      "[91/100] train_loss: 0.75368 valid_loss: 0.77463\n",
      "EarlyStopping counter: 33 out of 100\n",
      "[92/100] train_loss: 0.69315 valid_loss: 0.77548\n",
      "EarlyStopping counter: 34 out of 100\n",
      "[93/100] train_loss: 0.63745 valid_loss: 0.77683\n",
      "EarlyStopping counter: 35 out of 100\n",
      "[94/100] train_loss: 0.73272 valid_loss: 0.77716\n",
      "EarlyStopping counter: 36 out of 100\n",
      "[95/100] train_loss: 0.66339 valid_loss: 0.77630\n",
      "EarlyStopping counter: 37 out of 100\n",
      "[96/100] train_loss: 0.62397 valid_loss: 0.77580\n",
      "EarlyStopping counter: 38 out of 100\n",
      "[97/100] train_loss: 0.61680 valid_loss: 0.77560\n",
      "EarlyStopping counter: 39 out of 100\n",
      "[98/100] train_loss: 0.59594 valid_loss: 0.77564\n",
      "EarlyStopping counter: 40 out of 100\n",
      "[99/100] train_loss: 0.60623 valid_loss: 0.77590\n",
      "EarlyStopping counter: 41 out of 100\n",
      "[100/100] train_loss: 0.72629 valid_loss: 0.77652\n",
      "EarlyStopping counter: 42 out of 100\n",
      "  Training 4/5 for Fold 5\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] train_loss: 0.78233 valid_loss: 0.77138\n",
      "Validation loss decreased (inf --> 0.771380).  Saving model ...\n",
      "[2/100] train_loss: 0.77751 valid_loss: 0.77008\n",
      "Validation loss decreased (0.771380 --> 0.770075).  Saving model ...\n",
      "[3/100] train_loss: 0.77315 valid_loss: 0.76888\n",
      "Validation loss decreased (0.770075 --> 0.768878).  Saving model ...\n",
      "[4/100] train_loss: 0.76919 valid_loss: 0.76777\n",
      "Validation loss decreased (0.768878 --> 0.767771).  Saving model ...\n",
      "[5/100] train_loss: 0.96305 valid_loss: 0.76728\n",
      "Validation loss decreased (0.767771 --> 0.767280).  Saving model ...\n",
      "[6/100] train_loss: 2.36909 valid_loss: 0.76711\n",
      "Validation loss decreased (0.767280 --> 0.767115).  Saving model ...\n",
      "[7/100] train_loss: 0.94692 valid_loss: 0.76708\n",
      "Validation loss decreased (0.767115 --> 0.767082).  Saving model ...\n",
      "[8/100] train_loss: 0.73176 valid_loss: 0.76708\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[9/100] train_loss: 1.04306 valid_loss: 0.76691\n",
      "Validation loss decreased (0.767082 --> 0.766908).  Saving model ...\n",
      "[10/100] train_loss: 0.93242 valid_loss: 0.76678\n",
      "Validation loss decreased (0.766908 --> 0.766777).  Saving model ...\n",
      "[11/100] train_loss: 1.04254 valid_loss: 0.76652\n",
      "Validation loss decreased (0.766777 --> 0.766520).  Saving model ...\n",
      "[12/100] train_loss: 1.03988 valid_loss: 0.76617\n",
      "Validation loss decreased (0.766520 --> 0.766172).  Saving model ...\n",
      "[13/100] train_loss: 0.75653 valid_loss: 0.76582\n",
      "Validation loss decreased (0.766172 --> 0.765823).  Saving model ...\n",
      "[14/100] train_loss: 2.20533 valid_loss: 0.76557\n",
      "Validation loss decreased (0.765823 --> 0.765575).  Saving model ...\n",
      "[15/100] train_loss: 0.90733 valid_loss: 0.76537\n",
      "Validation loss decreased (0.765575 --> 0.765365).  Saving model ...\n",
      "[16/100] train_loss: 0.70133 valid_loss: 0.76518\n",
      "Validation loss decreased (0.765365 --> 0.765181).  Saving model ...\n",
      "[17/100] train_loss: 1.02418 valid_loss: 0.76490\n",
      "Validation loss decreased (0.765181 --> 0.764895).  Saving model ...\n",
      "[18/100] train_loss: 0.91067 valid_loss: 0.76470\n",
      "Validation loss decreased (0.764895 --> 0.764701).  Saving model ...\n",
      "[19/100] train_loss: 0.75348 valid_loss: 0.76450\n",
      "Validation loss decreased (0.764701 --> 0.764499).  Saving model ...\n",
      "[20/100] train_loss: 0.68697 valid_loss: 0.76431\n",
      "Validation loss decreased (0.764499 --> 0.764313).  Saving model ...\n",
      "[21/100] train_loss: 0.87542 valid_loss: 0.76416\n",
      "Validation loss decreased (0.764313 --> 0.764160).  Saving model ...\n",
      "[22/100] train_loss: 0.68010 valid_loss: 0.76402\n",
      "Validation loss decreased (0.764160 --> 0.764019).  Saving model ...\n",
      "[23/100] train_loss: 0.89679 valid_loss: 0.76396\n",
      "Validation loss decreased (0.764019 --> 0.763959).  Saving model ...\n",
      "[24/100] train_loss: 1.00961 valid_loss: 0.76376\n",
      "Validation loss decreased (0.763959 --> 0.763765).  Saving model ...\n",
      "[25/100] train_loss: 0.66955 valid_loss: 0.76358\n",
      "Validation loss decreased (0.763765 --> 0.763578).  Saving model ...\n",
      "[26/100] train_loss: 0.84805 valid_loss: 0.76342\n",
      "Validation loss decreased (0.763578 --> 0.763421).  Saving model ...\n",
      "[27/100] train_loss: 0.66235 valid_loss: 0.76327\n",
      "Validation loss decreased (0.763421 --> 0.763266).  Saving model ...\n",
      "[28/100] train_loss: 0.87936 valid_loss: 0.76319\n",
      "Validation loss decreased (0.763266 --> 0.763188).  Saving model ...\n",
      "[29/100] train_loss: 0.65451 valid_loss: 0.76310\n",
      "Validation loss decreased (0.763188 --> 0.763101).  Saving model ...\n",
      "[30/100] train_loss: 0.82246 valid_loss: 0.76304\n",
      "Validation loss decreased (0.763101 --> 0.763037).  Saving model ...\n",
      "[31/100] train_loss: 0.99792 valid_loss: 0.76281\n",
      "Validation loss decreased (0.763037 --> 0.762807).  Saving model ...\n",
      "[32/100] train_loss: 1.82860 valid_loss: 0.76267\n",
      "Validation loss decreased (0.762807 --> 0.762668).  Saving model ...\n",
      "[33/100] train_loss: 0.79939 valid_loss: 0.76255\n",
      "Validation loss decreased (0.762668 --> 0.762551).  Saving model ...\n",
      "[34/100] train_loss: 1.74859 valid_loss: 0.76251\n",
      "Validation loss decreased (0.762551 --> 0.762506).  Saving model ...\n",
      "[35/100] train_loss: 0.62622 valid_loss: 0.76243\n",
      "Validation loss decreased (0.762506 --> 0.762435).  Saving model ...\n",
      "[36/100] train_loss: 0.82273 valid_loss: 0.76244\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[37/100] train_loss: 0.75866 valid_loss: 0.76246\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[38/100] train_loss: 0.61281 valid_loss: 0.76243\n",
      "Validation loss decreased (0.762435 --> 0.762433).  Saving model ...\n",
      "[39/100] train_loss: 1.45517 valid_loss: 0.76247\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[40/100] train_loss: 0.98621 valid_loss: 0.76226\n",
      "Validation loss decreased (0.762433 --> 0.762262).  Saving model ...\n",
      "[41/100] train_loss: 0.72670 valid_loss: 0.76202\n",
      "Validation loss decreased (0.762262 --> 0.762025).  Saving model ...\n",
      "[42/100] train_loss: 0.72753 valid_loss: 0.76188\n",
      "Validation loss decreased (0.762025 --> 0.761881).  Saving model ...\n",
      "[43/100] train_loss: 0.98083 valid_loss: 0.76141\n",
      "Validation loss decreased (0.761881 --> 0.761406).  Saving model ...\n",
      "[44/100] train_loss: 1.10889 valid_loss: 0.76091\n",
      "Validation loss decreased (0.761406 --> 0.760912).  Saving model ...\n",
      "[45/100] train_loss: 0.65390 valid_loss: 0.76037\n",
      "Validation loss decreased (0.760912 --> 0.760369).  Saving model ...\n",
      "[46/100] train_loss: 0.74413 valid_loss: 0.75971\n",
      "Validation loss decreased (0.760369 --> 0.759706).  Saving model ...\n",
      "[47/100] train_loss: 0.63759 valid_loss: 0.75896\n",
      "Validation loss decreased (0.759706 --> 0.758964).  Saving model ...\n",
      "[48/100] train_loss: 0.70874 valid_loss: 0.75819\n",
      "Validation loss decreased (0.758964 --> 0.758188).  Saving model ...\n",
      "[49/100] train_loss: 0.96521 valid_loss: 0.75689\n",
      "Validation loss decreased (0.758188 --> 0.756892).  Saving model ...\n",
      "[50/100] train_loss: 0.96018 valid_loss: 0.75510\n",
      "Validation loss decreased (0.756892 --> 0.755100).  Saving model ...\n",
      "[51/100] train_loss: 0.95270 valid_loss: 0.75291\n",
      "Validation loss decreased (0.755100 --> 0.752910).  Saving model ...\n",
      "[52/100] train_loss: 0.62616 valid_loss: 0.75086\n",
      "Validation loss decreased (0.752910 --> 0.750859).  Saving model ...\n",
      "[53/100] train_loss: 0.93456 valid_loss: 0.74873\n",
      "Validation loss decreased (0.750859 --> 0.748729).  Saving model ...\n",
      "[54/100] train_loss: 0.92436 valid_loss: 0.74672\n",
      "Validation loss decreased (0.748729 --> 0.746722).  Saving model ...\n",
      "[55/100] train_loss: 0.59299 valid_loss: 0.74546\n",
      "Validation loss decreased (0.746722 --> 0.745456).  Saving model ...\n",
      "[56/100] train_loss: 0.81361 valid_loss: 0.74470\n",
      "Validation loss decreased (0.745456 --> 0.744701).  Saving model ...\n",
      "[57/100] train_loss: 0.79514 valid_loss: 0.74432\n",
      "Validation loss decreased (0.744701 --> 0.744321).  Saving model ...\n",
      "[58/100] train_loss: 0.61165 valid_loss: 0.74453\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[59/100] train_loss: 0.93602 valid_loss: 0.74576\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[60/100] train_loss: 0.87241 valid_loss: 0.74691\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[61/100] train_loss: 0.84687 valid_loss: 0.74843\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[62/100] train_loss: 0.60648 valid_loss: 0.74942\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[63/100] train_loss: 0.63415 valid_loss: 0.74999\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[64/100] train_loss: 0.64448 valid_loss: 0.75024\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[65/100] train_loss: 0.69983 valid_loss: 0.75074\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[66/100] train_loss: 0.82329 valid_loss: 0.75107\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[67/100] train_loss: 0.82813 valid_loss: 0.75129\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[68/100] train_loss: 0.81503 valid_loss: 0.75142\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[69/100] train_loss: 0.78825 valid_loss: 0.75151\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[70/100] train_loss: 0.71378 valid_loss: 0.75190\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[71/100] train_loss: 0.72404 valid_loss: 0.75253\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[72/100] train_loss: 0.66362 valid_loss: 0.75280\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[73/100] train_loss: 0.71519 valid_loss: 0.75327\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[74/100] train_loss: 0.82806 valid_loss: 0.75388\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[75/100] train_loss: 0.68205 valid_loss: 0.75416\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[76/100] train_loss: 0.73158 valid_loss: 0.75444\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[77/100] train_loss: 0.74339 valid_loss: 0.75442\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[78/100] train_loss: 0.74329 valid_loss: 0.75411\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[79/100] train_loss: 0.67904 valid_loss: 0.75354\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[80/100] train_loss: 0.67209 valid_loss: 0.75272\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[81/100] train_loss: 0.73976 valid_loss: 0.75160\n",
      "EarlyStopping counter: 24 out of 100\n",
      "[82/100] train_loss: 0.67520 valid_loss: 0.75054\n",
      "EarlyStopping counter: 25 out of 100\n",
      "[83/100] train_loss: 0.73474 valid_loss: 0.74915\n",
      "EarlyStopping counter: 26 out of 100\n",
      "[84/100] train_loss: 0.73020 valid_loss: 0.74744\n",
      "EarlyStopping counter: 27 out of 100\n",
      "[85/100] train_loss: 0.61883 valid_loss: 0.74547\n",
      "EarlyStopping counter: 28 out of 100\n",
      "[86/100] train_loss: 0.64507 valid_loss: 0.74357\n",
      "Validation loss decreased (0.744321 --> 0.743570).  Saving model ...\n",
      "[87/100] train_loss: 0.59760 valid_loss: 0.74145\n",
      "Validation loss decreased (0.743570 --> 0.741446).  Saving model ...\n",
      "[88/100] train_loss: 0.70552 valid_loss: 0.73875\n",
      "Validation loss decreased (0.741446 --> 0.738753).  Saving model ...\n",
      "[89/100] train_loss: 1.03140 valid_loss: 0.73738\n",
      "Validation loss decreased (0.738753 --> 0.737376).  Saving model ...\n",
      "[90/100] train_loss: 1.00108 valid_loss: 0.73721\n",
      "Validation loss decreased (0.737376 --> 0.737215).  Saving model ...\n",
      "[91/100] train_loss: 0.69216 valid_loss: 0.73662\n",
      "Validation loss decreased (0.737215 --> 0.736623).  Saving model ...\n",
      "[92/100] train_loss: 0.82587 valid_loss: 0.73628\n",
      "Validation loss decreased (0.736623 --> 0.736282).  Saving model ...\n",
      "[93/100] train_loss: 0.65709 valid_loss: 0.73596\n",
      "Validation loss decreased (0.736282 --> 0.735962).  Saving model ...\n",
      "[94/100] train_loss: 0.82855 valid_loss: 0.73583\n",
      "Validation loss decreased (0.735962 --> 0.735827).  Saving model ...\n",
      "[95/100] train_loss: 0.74308 valid_loss: 0.73632\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[96/100] train_loss: 0.60254 valid_loss: 0.73677\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[97/100] train_loss: 0.82827 valid_loss: 0.73731\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[98/100] train_loss: 0.65310 valid_loss: 0.73741\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[99/100] train_loss: 0.65712 valid_loss: 0.73713\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[100/100] train_loss: 0.61310 valid_loss: 0.73663\n",
      "EarlyStopping counter: 6 out of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training 5/5 for Fold 5\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n",
      "[1/100] train_loss: 1.02174 valid_loss: 0.74316\n",
      "Validation loss decreased (inf --> 0.743159).  Saving model ...\n",
      "[2/100] train_loss: 0.76753 valid_loss: 0.74301\n",
      "Validation loss decreased (0.743159 --> 0.743010).  Saving model ...\n",
      "[3/100] train_loss: 0.89697 valid_loss: 0.74289\n",
      "Validation loss decreased (0.743010 --> 0.742887).  Saving model ...\n",
      "[4/100] train_loss: 0.72881 valid_loss: 0.74281\n",
      "Validation loss decreased (0.742887 --> 0.742812).  Saving model ...\n",
      "[5/100] train_loss: 0.97983 valid_loss: 0.74282\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[6/100] train_loss: 0.97024 valid_loss: 0.74291\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[7/100] train_loss: 2.11777 valid_loss: 0.74311\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[8/100] train_loss: 0.94958 valid_loss: 0.74337\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[9/100] train_loss: 0.75291 valid_loss: 0.74364\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[10/100] train_loss: 0.75124 valid_loss: 0.74391\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[11/100] train_loss: 2.00166 valid_loss: 0.74430\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[12/100] train_loss: 1.01160 valid_loss: 0.74450\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[13/100] train_loss: 0.74696 valid_loss: 0.74468\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[14/100] train_loss: 0.82618 valid_loss: 0.74490\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[15/100] train_loss: 0.82008 valid_loss: 0.74514\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[16/100] train_loss: 1.01553 valid_loss: 0.74519\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[17/100] train_loss: 0.65823 valid_loss: 0.74523\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[18/100] train_loss: 0.74183 valid_loss: 0.74524\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[19/100] train_loss: 0.79376 valid_loss: 0.74531\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[20/100] train_loss: 0.64495 valid_loss: 0.74535\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[21/100] train_loss: 0.85480 valid_loss: 0.74546\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[22/100] train_loss: 1.71512 valid_loss: 0.74579\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[23/100] train_loss: 0.62977 valid_loss: 0.74612\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[24/100] train_loss: 0.73420 valid_loss: 0.74644\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[25/100] train_loss: 1.01612 valid_loss: 0.74648\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[26/100] train_loss: 0.80774 valid_loss: 0.74662\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[27/100] train_loss: 1.52206 valid_loss: 0.74706\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[28/100] train_loss: 0.72724 valid_loss: 0.74753\n",
      "EarlyStopping counter: 24 out of 100\n",
      "[29/100] train_loss: 0.72517 valid_loss: 0.74801\n",
      "EarlyStopping counter: 25 out of 100\n",
      "[30/100] train_loss: 1.01820 valid_loss: 0.74809\n",
      "EarlyStopping counter: 26 out of 100\n",
      "[31/100] train_loss: 0.72119 valid_loss: 0.74815\n",
      "EarlyStopping counter: 27 out of 100\n",
      "[32/100] train_loss: 1.01408 valid_loss: 0.74774\n",
      "EarlyStopping counter: 28 out of 100\n",
      "[33/100] train_loss: 0.71729 valid_loss: 0.74730\n",
      "EarlyStopping counter: 29 out of 100\n",
      "[34/100] train_loss: 0.60369 valid_loss: 0.74671\n",
      "EarlyStopping counter: 30 out of 100\n",
      "[35/100] train_loss: 1.16152 valid_loss: 0.74667\n",
      "EarlyStopping counter: 31 out of 100\n",
      "[36/100] train_loss: 0.61396 valid_loss: 0.74643\n",
      "EarlyStopping counter: 32 out of 100\n",
      "[37/100] train_loss: 0.62273 valid_loss: 0.74592\n",
      "EarlyStopping counter: 33 out of 100\n",
      "[38/100] train_loss: 0.66084 valid_loss: 0.74569\n",
      "EarlyStopping counter: 34 out of 100\n",
      "[39/100] train_loss: 0.62870 valid_loss: 0.74573\n",
      "EarlyStopping counter: 35 out of 100\n",
      "[40/100] train_loss: 0.70325 valid_loss: 0.74577\n",
      "EarlyStopping counter: 36 out of 100\n",
      "[41/100] train_loss: 0.61155 valid_loss: 0.74626\n",
      "EarlyStopping counter: 37 out of 100\n",
      "[42/100] train_loss: 0.60433 valid_loss: 0.74754\n",
      "EarlyStopping counter: 38 out of 100\n",
      "[43/100] train_loss: 0.59515 valid_loss: 0.74988\n",
      "EarlyStopping counter: 39 out of 100\n",
      "[44/100] train_loss: 0.98284 valid_loss: 0.75121\n",
      "EarlyStopping counter: 40 out of 100\n",
      "[45/100] train_loss: 0.59186 valid_loss: 0.75166\n",
      "EarlyStopping counter: 41 out of 100\n",
      "[46/100] train_loss: 0.69689 valid_loss: 0.75052\n",
      "EarlyStopping counter: 42 out of 100\n",
      "[47/100] train_loss: 0.96138 valid_loss: 0.74699\n",
      "EarlyStopping counter: 43 out of 100\n",
      "[48/100] train_loss: 0.60277 valid_loss: 0.74037\n",
      "Validation loss decreased (0.742812 --> 0.740375).  Saving model ...\n",
      "[49/100] train_loss: 0.62768 valid_loss: 0.73349\n",
      "Validation loss decreased (0.740375 --> 0.733490).  Saving model ...\n",
      "[50/100] train_loss: 0.83501 valid_loss: 0.72972\n",
      "Validation loss decreased (0.733490 --> 0.729719).  Saving model ...\n",
      "[51/100] train_loss: 0.91588 valid_loss: 0.72698\n",
      "Validation loss decreased (0.729719 --> 0.726978).  Saving model ...\n",
      "[52/100] train_loss: 0.67936 valid_loss: 0.72533\n",
      "Validation loss decreased (0.726978 --> 0.725328).  Saving model ...\n",
      "[53/100] train_loss: 0.58713 valid_loss: 0.72444\n",
      "Validation loss decreased (0.725328 --> 0.724443).  Saving model ...\n",
      "[54/100] train_loss: 0.58264 valid_loss: 0.72411\n",
      "Validation loss decreased (0.724443 --> 0.724109).  Saving model ...\n",
      "[55/100] train_loss: 0.83375 valid_loss: 0.72498\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[56/100] train_loss: 0.78935 valid_loss: 0.72587\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[57/100] train_loss: 0.87282 valid_loss: 0.72676\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[58/100] train_loss: 0.69964 valid_loss: 0.72745\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[59/100] train_loss: 0.86282 valid_loss: 0.72815\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[60/100] train_loss: 0.85731 valid_loss: 0.72892\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[61/100] train_loss: 0.85088 valid_loss: 0.72978\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[62/100] train_loss: 0.66719 valid_loss: 0.72998\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[63/100] train_loss: 0.80350 valid_loss: 0.72997\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[64/100] train_loss: 0.83173 valid_loss: 0.73017\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[65/100] train_loss: 0.71078 valid_loss: 0.73014\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[66/100] train_loss: 0.81926 valid_loss: 0.73037\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[67/100] train_loss: 0.70802 valid_loss: 0.73026\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[68/100] train_loss: 0.73176 valid_loss: 0.73101\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[69/100] train_loss: 0.71784 valid_loss: 0.73237\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[70/100] train_loss: 0.68034 valid_loss: 0.73296\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[71/100] train_loss: 0.79908 valid_loss: 0.73373\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[72/100] train_loss: 0.69740 valid_loss: 0.73390\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[73/100] train_loss: 0.63937 valid_loss: 0.73443\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[74/100] train_loss: 0.71353 valid_loss: 0.73450\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[75/100] train_loss: 0.71392 valid_loss: 0.73416\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[76/100] train_loss: 0.78856 valid_loss: 0.73411\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[77/100] train_loss: 0.60578 valid_loss: 0.73430\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[78/100] train_loss: 0.66622 valid_loss: 0.73382\n",
      "EarlyStopping counter: 24 out of 100\n",
      "[79/100] train_loss: 0.59698 valid_loss: 0.73356\n",
      "EarlyStopping counter: 25 out of 100\n",
      "[80/100] train_loss: 0.65446 valid_loss: 0.73268\n",
      "EarlyStopping counter: 26 out of 100\n",
      "[81/100] train_loss: 0.73064 valid_loss: 0.73124\n",
      "EarlyStopping counter: 27 out of 100\n",
      "[82/100] train_loss: 0.72690 valid_loss: 0.72922\n",
      "EarlyStopping counter: 28 out of 100\n",
      "[83/100] train_loss: 0.71779 valid_loss: 0.72662\n",
      "EarlyStopping counter: 29 out of 100\n",
      "[84/100] train_loss: 0.70371 valid_loss: 0.72340\n",
      "Validation loss decreased (0.724109 --> 0.723395).  Saving model ...\n",
      "[85/100] train_loss: 0.79708 valid_loss: 0.71987\n",
      "Validation loss decreased (0.723395 --> 0.719871).  Saving model ...\n",
      "[86/100] train_loss: 0.63979 valid_loss: 0.71715\n",
      "Validation loss decreased (0.719871 --> 0.717154).  Saving model ...\n",
      "[87/100] train_loss: 0.65191 valid_loss: 0.71367\n",
      "Validation loss decreased (0.717154 --> 0.713673).  Saving model ...\n",
      "[88/100] train_loss: 0.67677 valid_loss: 0.71147\n",
      "Validation loss decreased (0.713673 --> 0.711467).  Saving model ...\n",
      "[89/100] train_loss: 0.55683 valid_loss: 0.70943\n",
      "Validation loss decreased (0.711467 --> 0.709432).  Saving model ...\n",
      "[90/100] train_loss: 0.64757 valid_loss: 0.70669\n",
      "Validation loss decreased (0.709432 --> 0.706693).  Saving model ...\n",
      "[91/100] train_loss: 0.55548 valid_loss: 0.70431\n",
      "Validation loss decreased (0.706693 --> 0.704315).  Saving model ...\n",
      "[92/100] train_loss: 0.60625 valid_loss: 0.70117\n",
      "Validation loss decreased (0.704315 --> 0.701166).  Saving model ...\n",
      "[93/100] train_loss: 0.77819 valid_loss: 0.69839\n",
      "Validation loss decreased (0.701166 --> 0.698388).  Saving model ...\n",
      "[94/100] train_loss: 0.55759 valid_loss: 0.69638\n",
      "Validation loss decreased (0.698388 --> 0.696382).  Saving model ...\n",
      "[95/100] train_loss: 0.77486 valid_loss: 0.69470\n",
      "Validation loss decreased (0.696382 --> 0.694704).  Saving model ...\n",
      "[96/100] train_loss: 0.62725 valid_loss: 0.69226\n",
      "Validation loss decreased (0.694704 --> 0.692261).  Saving model ...\n",
      "[97/100] train_loss: 0.76928 valid_loss: 0.69015\n",
      "Validation loss decreased (0.692261 --> 0.690153).  Saving model ...\n",
      "[98/100] train_loss: 0.57197 valid_loss: 0.68753\n",
      "Validation loss decreased (0.690153 --> 0.687531).  Saving model ...\n",
      "[99/100] train_loss: 0.56332 valid_loss: 0.68643\n",
      "Validation loss decreased (0.687531 --> 0.686431).  Saving model ...\n",
      "[100/100] train_loss: 0.79398 valid_loss: 0.68820\n",
      "EarlyStopping counter: 1 out of 100\n",
      "  Fold 6/7\n",
      "  Training 1/5 for Fold 6\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n",
      "[1/100] train_loss: 0.79606 valid_loss: 0.92080\n",
      "Validation loss decreased (inf --> 0.920797).  Saving model ...\n",
      "[2/100] train_loss: 0.75205 valid_loss: 0.92546\n",
      "EarlyStopping counter: 1 out of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/100] train_loss: 0.78480 valid_loss: 0.93069\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[4/100] train_loss: 0.80401 valid_loss: 0.93356\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[5/100] train_loss: 2.29160 valid_loss: 0.93659\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[6/100] train_loss: 1.03563 valid_loss: 0.94063\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[7/100] train_loss: 0.84954 valid_loss: 0.94421\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[8/100] train_loss: 0.76865 valid_loss: 0.94781\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[9/100] train_loss: 2.20360 valid_loss: 0.95154\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[10/100] train_loss: 0.76402 valid_loss: 0.95525\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[11/100] train_loss: 0.76180 valid_loss: 0.95894\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[12/100] train_loss: 2.13679 valid_loss: 0.96285\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[13/100] train_loss: 0.75749 valid_loss: 0.96673\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[14/100] train_loss: 0.96671 valid_loss: 0.97137\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[15/100] train_loss: 0.75315 valid_loss: 0.97594\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[16/100] train_loss: 0.79403 valid_loss: 0.97993\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[17/100] train_loss: 2.02628 valid_loss: 0.98432\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[18/100] train_loss: 2.00128 valid_loss: 0.98912\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[19/100] train_loss: 0.74495 valid_loss: 0.99387\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[20/100] train_loss: 1.94318 valid_loss: 0.99911\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[21/100] train_loss: 0.74098 valid_loss: 1.00431\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[22/100] train_loss: 0.77164 valid_loss: 1.00937\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[23/100] train_loss: 0.73720 valid_loss: 1.01439\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[24/100] train_loss: 0.64619 valid_loss: 1.01932\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[25/100] train_loss: 0.64179 valid_loss: 1.02417\n",
      "EarlyStopping counter: 24 out of 100\n",
      "[26/100] train_loss: 0.79201 valid_loss: 1.02839\n",
      "EarlyStopping counter: 25 out of 100\n",
      "[27/100] train_loss: 0.73828 valid_loss: 1.03268\n",
      "EarlyStopping counter: 26 out of 100\n",
      "[28/100] train_loss: 0.62867 valid_loss: 1.03694\n",
      "EarlyStopping counter: 27 out of 100\n",
      "[29/100] train_loss: 1.65824 valid_loss: 1.04279\n",
      "EarlyStopping counter: 28 out of 100\n",
      "[30/100] train_loss: 0.61962 valid_loss: 1.04860\n",
      "EarlyStopping counter: 29 out of 100\n",
      "[31/100] train_loss: 0.79759 valid_loss: 1.05632\n",
      "EarlyStopping counter: 30 out of 100\n",
      "[32/100] train_loss: 0.72119 valid_loss: 1.06399\n",
      "EarlyStopping counter: 31 out of 100\n",
      "[33/100] train_loss: 1.46781 valid_loss: 1.07387\n",
      "EarlyStopping counter: 32 out of 100\n",
      "[34/100] train_loss: 0.79348 valid_loss: 1.08291\n",
      "EarlyStopping counter: 33 out of 100\n",
      "[35/100] train_loss: 0.66338 valid_loss: 1.09259\n",
      "EarlyStopping counter: 34 out of 100\n",
      "[36/100] train_loss: 0.65248 valid_loss: 1.10307\n",
      "EarlyStopping counter: 35 out of 100\n",
      "[37/100] train_loss: 0.61773 valid_loss: 1.11258\n",
      "EarlyStopping counter: 36 out of 100\n",
      "[38/100] train_loss: 0.67528 valid_loss: 1.12604\n",
      "EarlyStopping counter: 37 out of 100\n",
      "[39/100] train_loss: 0.65528 valid_loss: 1.14407\n",
      "EarlyStopping counter: 38 out of 100\n",
      "[40/100] train_loss: 1.02517 valid_loss: 1.16855\n",
      "EarlyStopping counter: 39 out of 100\n",
      "[41/100] train_loss: 0.61820 valid_loss: 1.19560\n",
      "EarlyStopping counter: 40 out of 100\n",
      "[42/100] train_loss: 0.77151 valid_loss: 1.21181\n",
      "EarlyStopping counter: 41 out of 100\n",
      "[43/100] train_loss: 0.88218 valid_loss: 1.23404\n",
      "EarlyStopping counter: 42 out of 100\n",
      "[44/100] train_loss: 0.76731 valid_loss: 1.23766\n",
      "EarlyStopping counter: 43 out of 100\n",
      "[45/100] train_loss: 0.77349 valid_loss: 1.22403\n",
      "EarlyStopping counter: 44 out of 100\n",
      "[46/100] train_loss: 0.64468 valid_loss: 1.20772\n",
      "EarlyStopping counter: 45 out of 100\n",
      "[47/100] train_loss: 0.64102 valid_loss: 1.19024\n",
      "EarlyStopping counter: 46 out of 100\n",
      "[48/100] train_loss: 0.86765 valid_loss: 1.16610\n",
      "EarlyStopping counter: 47 out of 100\n",
      "[49/100] train_loss: 0.82259 valid_loss: 1.14167\n",
      "EarlyStopping counter: 48 out of 100\n",
      "[50/100] train_loss: 0.61345 valid_loss: 1.12206\n",
      "EarlyStopping counter: 49 out of 100\n",
      "[51/100] train_loss: 0.60794 valid_loss: 1.10725\n",
      "EarlyStopping counter: 50 out of 100\n",
      "[52/100] train_loss: 0.70581 valid_loss: 1.09273\n",
      "EarlyStopping counter: 51 out of 100\n",
      "[53/100] train_loss: 0.61829 valid_loss: 1.08115\n",
      "EarlyStopping counter: 52 out of 100\n",
      "[54/100] train_loss: 0.94199 valid_loss: 1.07429\n",
      "EarlyStopping counter: 53 out of 100\n",
      "[55/100] train_loss: 0.64952 valid_loss: 1.06709\n",
      "EarlyStopping counter: 54 out of 100\n",
      "[56/100] train_loss: 0.70751 valid_loss: 1.06004\n",
      "EarlyStopping counter: 55 out of 100\n",
      "[57/100] train_loss: 0.65661 valid_loss: 1.05576\n",
      "EarlyStopping counter: 56 out of 100\n",
      "[58/100] train_loss: 0.78731 valid_loss: 1.05097\n",
      "EarlyStopping counter: 57 out of 100\n",
      "[59/100] train_loss: 0.70577 valid_loss: 1.04607\n",
      "EarlyStopping counter: 58 out of 100\n",
      "[60/100] train_loss: 0.66194 valid_loss: 1.04355\n",
      "EarlyStopping counter: 59 out of 100\n",
      "[61/100] train_loss: 0.65925 valid_loss: 1.04311\n",
      "EarlyStopping counter: 60 out of 100\n",
      "[62/100] train_loss: 0.70327 valid_loss: 1.04204\n",
      "EarlyStopping counter: 61 out of 100\n",
      "[63/100] train_loss: 0.78104 valid_loss: 1.04018\n",
      "EarlyStopping counter: 62 out of 100\n",
      "[64/100] train_loss: 0.64091 valid_loss: 1.04028\n",
      "EarlyStopping counter: 63 out of 100\n",
      "[65/100] train_loss: 0.63181 valid_loss: 1.04215\n",
      "EarlyStopping counter: 64 out of 100\n",
      "[66/100] train_loss: 0.69989 valid_loss: 1.04277\n",
      "EarlyStopping counter: 65 out of 100\n",
      "[67/100] train_loss: 0.63356 valid_loss: 1.04216\n",
      "EarlyStopping counter: 66 out of 100\n",
      "[68/100] train_loss: 0.69927 valid_loss: 1.03989\n",
      "EarlyStopping counter: 67 out of 100\n",
      "[69/100] train_loss: 0.88193 valid_loss: 1.04006\n",
      "EarlyStopping counter: 68 out of 100\n",
      "[70/100] train_loss: 0.64372 valid_loss: 1.03866\n",
      "EarlyStopping counter: 69 out of 100\n",
      "[71/100] train_loss: 0.58732 valid_loss: 1.03763\n",
      "EarlyStopping counter: 70 out of 100\n",
      "[72/100] train_loss: 0.70127 valid_loss: 1.03356\n",
      "EarlyStopping counter: 71 out of 100\n",
      "[73/100] train_loss: 0.65535 valid_loss: 1.02798\n",
      "EarlyStopping counter: 72 out of 100\n",
      "[74/100] train_loss: 0.69811 valid_loss: 1.01994\n",
      "EarlyStopping counter: 73 out of 100\n",
      "[75/100] train_loss: 0.76536 valid_loss: 1.01177\n",
      "EarlyStopping counter: 74 out of 100\n",
      "[76/100] train_loss: 0.63452 valid_loss: 1.00333\n",
      "EarlyStopping counter: 75 out of 100\n",
      "[77/100] train_loss: 0.62182 valid_loss: 0.99499\n",
      "EarlyStopping counter: 76 out of 100\n",
      "[78/100] train_loss: 0.75888 valid_loss: 0.98724\n",
      "EarlyStopping counter: 77 out of 100\n",
      "[79/100] train_loss: 0.67939 valid_loss: 0.98096\n",
      "EarlyStopping counter: 78 out of 100\n",
      "[80/100] train_loss: 0.59133 valid_loss: 0.97498\n",
      "EarlyStopping counter: 79 out of 100\n",
      "[81/100] train_loss: 0.92072 valid_loss: 0.97124\n",
      "EarlyStopping counter: 80 out of 100\n",
      "[82/100] train_loss: 0.67491 valid_loss: 0.96737\n",
      "EarlyStopping counter: 81 out of 100\n",
      "[83/100] train_loss: 0.89408 valid_loss: 0.96517\n",
      "EarlyStopping counter: 82 out of 100\n",
      "[84/100] train_loss: 0.58793 valid_loss: 0.96266\n",
      "EarlyStopping counter: 83 out of 100\n",
      "[85/100] train_loss: 0.75144 valid_loss: 0.96008\n",
      "EarlyStopping counter: 84 out of 100\n",
      "[86/100] train_loss: 0.56699 valid_loss: 0.95831\n",
      "EarlyStopping counter: 85 out of 100\n",
      "[87/100] train_loss: 0.60173 valid_loss: 0.95588\n",
      "EarlyStopping counter: 86 out of 100\n",
      "[88/100] train_loss: 0.68950 valid_loss: 0.95407\n",
      "EarlyStopping counter: 87 out of 100\n",
      "[89/100] train_loss: 0.73966 valid_loss: 0.95302\n",
      "EarlyStopping counter: 88 out of 100\n",
      "[90/100] train_loss: 0.66550 valid_loss: 0.94977\n",
      "EarlyStopping counter: 89 out of 100\n",
      "[91/100] train_loss: 0.69754 valid_loss: 0.94714\n",
      "EarlyStopping counter: 90 out of 100\n",
      "[92/100] train_loss: 0.67626 valid_loss: 0.94495\n",
      "EarlyStopping counter: 91 out of 100\n",
      "[93/100] train_loss: 0.74227 valid_loss: 0.94268\n",
      "EarlyStopping counter: 92 out of 100\n",
      "[94/100] train_loss: 0.62527 valid_loss: 0.93670\n",
      "EarlyStopping counter: 93 out of 100\n",
      "[95/100] train_loss: 0.63190 valid_loss: 0.93142\n",
      "EarlyStopping counter: 94 out of 100\n",
      "[96/100] train_loss: 0.77538 valid_loss: 0.92566\n",
      "EarlyStopping counter: 95 out of 100\n",
      "[97/100] train_loss: 0.70832 valid_loss: 0.91987\n",
      "Validation loss decreased (0.920797 --> 0.919867).  Saving model ...\n",
      "[98/100] train_loss: 0.65555 valid_loss: 0.91497\n",
      "Validation loss decreased (0.919867 --> 0.914973).  Saving model ...\n",
      "[99/100] train_loss: 0.71223 valid_loss: 0.91102\n",
      "Validation loss decreased (0.914973 --> 0.911016).  Saving model ...\n",
      "[100/100] train_loss: 0.75183 valid_loss: 0.90758\n",
      "Validation loss decreased (0.911016 --> 0.907585).  Saving model ...\n",
      "  Training 2/5 for Fold 6\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n",
      "[1/100] train_loss: 0.77386 valid_loss: 0.86049\n",
      "Validation loss decreased (inf --> 0.860488).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/100] train_loss: 0.94083 valid_loss: 0.86213\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[3/100] train_loss: 1.07245 valid_loss: 0.86722\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[4/100] train_loss: 0.77581 valid_loss: 0.87277\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[5/100] train_loss: 0.77175 valid_loss: 0.87869\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[6/100] train_loss: 0.90174 valid_loss: 0.88381\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[7/100] train_loss: 2.32421 valid_loss: 0.88880\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[8/100] train_loss: 2.29647 valid_loss: 0.89410\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[9/100] train_loss: 1.00494 valid_loss: 0.90034\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[10/100] train_loss: 0.99144 valid_loss: 0.90742\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[11/100] train_loss: 0.97680 valid_loss: 0.91530\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[12/100] train_loss: 0.69526 valid_loss: 0.92285\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[13/100] train_loss: 2.13490 valid_loss: 0.93071\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[14/100] train_loss: 2.09738 valid_loss: 0.93898\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[15/100] train_loss: 0.73335 valid_loss: 0.94724\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[16/100] train_loss: 0.89675 valid_loss: 0.95665\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[17/100] train_loss: 0.82737 valid_loss: 0.96586\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[18/100] train_loss: 1.92907 valid_loss: 0.97600\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[19/100] train_loss: 0.81062 valid_loss: 0.98610\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[20/100] train_loss: 0.71682 valid_loss: 0.99621\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[21/100] train_loss: 1.77911 valid_loss: 1.00798\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[22/100] train_loss: 0.76733 valid_loss: 1.01946\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[23/100] train_loss: 1.65951 valid_loss: 1.03335\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[24/100] train_loss: 0.60470 valid_loss: 1.04798\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[25/100] train_loss: 0.71799 valid_loss: 1.06610\n",
      "EarlyStopping counter: 24 out of 100\n",
      "[26/100] train_loss: 0.58866 valid_loss: 1.08570\n",
      "EarlyStopping counter: 25 out of 100\n",
      "[27/100] train_loss: 0.66741 valid_loss: 1.11044\n",
      "EarlyStopping counter: 26 out of 100\n",
      "[28/100] train_loss: 0.64214 valid_loss: 1.14181\n",
      "EarlyStopping counter: 27 out of 100\n",
      "[29/100] train_loss: 1.17859 valid_loss: 1.18353\n",
      "EarlyStopping counter: 28 out of 100\n",
      "[30/100] train_loss: 0.58086 valid_loss: 1.23074\n",
      "EarlyStopping counter: 29 out of 100\n",
      "[31/100] train_loss: 0.64749 valid_loss: 1.29059\n",
      "EarlyStopping counter: 30 out of 100\n",
      "[32/100] train_loss: 0.62054 valid_loss: 1.34734\n",
      "EarlyStopping counter: 31 out of 100\n",
      "[33/100] train_loss: 0.87150 valid_loss: 1.36988\n",
      "EarlyStopping counter: 32 out of 100\n",
      "[34/100] train_loss: 0.63253 valid_loss: 1.37348\n",
      "EarlyStopping counter: 33 out of 100\n",
      "[35/100] train_loss: 0.60258 valid_loss: 1.38346\n",
      "EarlyStopping counter: 34 out of 100\n",
      "[36/100] train_loss: 0.69561 valid_loss: 1.37035\n",
      "EarlyStopping counter: 35 out of 100\n",
      "[37/100] train_loss: 0.94174 valid_loss: 1.32146\n",
      "EarlyStopping counter: 36 out of 100\n",
      "[38/100] train_loss: 0.60061 valid_loss: 1.28664\n",
      "EarlyStopping counter: 37 out of 100\n",
      "[39/100] train_loss: 0.87856 valid_loss: 1.26770\n",
      "EarlyStopping counter: 38 out of 100\n",
      "[40/100] train_loss: 0.85327 valid_loss: 1.23662\n",
      "EarlyStopping counter: 39 out of 100\n",
      "[41/100] train_loss: 0.84018 valid_loss: 1.19998\n",
      "EarlyStopping counter: 40 out of 100\n",
      "[42/100] train_loss: 0.60256 valid_loss: 1.16765\n",
      "EarlyStopping counter: 41 out of 100\n",
      "[43/100] train_loss: 0.60798 valid_loss: 1.14331\n",
      "EarlyStopping counter: 42 out of 100\n",
      "[44/100] train_loss: 0.59666 valid_loss: 1.12208\n",
      "EarlyStopping counter: 43 out of 100\n",
      "[45/100] train_loss: 0.60978 valid_loss: 1.10556\n",
      "EarlyStopping counter: 44 out of 100\n",
      "[46/100] train_loss: 0.63186 valid_loss: 1.08906\n",
      "EarlyStopping counter: 45 out of 100\n",
      "[47/100] train_loss: 0.60979 valid_loss: 1.07612\n",
      "EarlyStopping counter: 46 out of 100\n",
      "[48/100] train_loss: 0.71320 valid_loss: 1.06114\n",
      "EarlyStopping counter: 47 out of 100\n",
      "[49/100] train_loss: 0.62095 valid_loss: 1.04687\n",
      "EarlyStopping counter: 48 out of 100\n",
      "[50/100] train_loss: 0.60750 valid_loss: 1.03619\n",
      "EarlyStopping counter: 49 out of 100\n",
      "[51/100] train_loss: 0.96499 valid_loss: 1.03041\n",
      "EarlyStopping counter: 50 out of 100\n",
      "[52/100] train_loss: 0.95020 valid_loss: 1.02830\n",
      "EarlyStopping counter: 51 out of 100\n",
      "[53/100] train_loss: 0.60328 valid_loss: 1.02767\n",
      "EarlyStopping counter: 52 out of 100\n",
      "[54/100] train_loss: 0.76642 valid_loss: 1.02490\n",
      "EarlyStopping counter: 53 out of 100\n",
      "[55/100] train_loss: 0.85027 valid_loss: 1.02476\n",
      "EarlyStopping counter: 54 out of 100\n",
      "[56/100] train_loss: 0.58175 valid_loss: 1.02489\n",
      "EarlyStopping counter: 55 out of 100\n",
      "[57/100] train_loss: 0.58120 valid_loss: 1.02412\n",
      "EarlyStopping counter: 56 out of 100\n",
      "[58/100] train_loss: 0.57539 valid_loss: 1.02322\n",
      "EarlyStopping counter: 57 out of 100\n",
      "[59/100] train_loss: 0.72248 valid_loss: 1.02351\n",
      "EarlyStopping counter: 58 out of 100\n",
      "[60/100] train_loss: 0.58213 valid_loss: 1.02300\n",
      "EarlyStopping counter: 59 out of 100\n",
      "[61/100] train_loss: 0.58840 valid_loss: 1.02141\n",
      "EarlyStopping counter: 60 out of 100\n",
      "[62/100] train_loss: 0.62153 valid_loss: 1.01380\n",
      "EarlyStopping counter: 61 out of 100\n",
      "[63/100] train_loss: 0.58955 valid_loss: 1.00609\n",
      "EarlyStopping counter: 62 out of 100\n",
      "[64/100] train_loss: 0.79461 valid_loss: 0.99290\n",
      "EarlyStopping counter: 63 out of 100\n",
      "[65/100] train_loss: 0.77859 valid_loss: 0.97748\n",
      "EarlyStopping counter: 64 out of 100\n",
      "[66/100] train_loss: 0.68385 valid_loss: 0.96136\n",
      "EarlyStopping counter: 65 out of 100\n",
      "[67/100] train_loss: 0.58141 valid_loss: 0.94631\n",
      "EarlyStopping counter: 66 out of 100\n",
      "[68/100] train_loss: 0.81107 valid_loss: 0.93351\n",
      "EarlyStopping counter: 67 out of 100\n",
      "[69/100] train_loss: 0.67244 valid_loss: 0.92318\n",
      "EarlyStopping counter: 68 out of 100\n",
      "[70/100] train_loss: 0.59433 valid_loss: 0.91474\n",
      "EarlyStopping counter: 69 out of 100\n",
      "[71/100] train_loss: 0.74025 valid_loss: 0.90737\n",
      "EarlyStopping counter: 70 out of 100\n",
      "[72/100] train_loss: 0.68252 valid_loss: 0.90154\n",
      "EarlyStopping counter: 71 out of 100\n",
      "[73/100] train_loss: 0.61019 valid_loss: 0.89623\n",
      "EarlyStopping counter: 72 out of 100\n",
      "[74/100] train_loss: 0.68801 valid_loss: 0.89215\n",
      "EarlyStopping counter: 73 out of 100\n",
      "[75/100] train_loss: 0.74195 valid_loss: 0.88851\n",
      "EarlyStopping counter: 74 out of 100\n",
      "[76/100] train_loss: 0.68854 valid_loss: 0.88712\n",
      "EarlyStopping counter: 75 out of 100\n",
      "[77/100] train_loss: 0.66455 valid_loss: 0.88588\n",
      "EarlyStopping counter: 76 out of 100\n",
      "[78/100] train_loss: 0.91399 valid_loss: 0.88535\n",
      "EarlyStopping counter: 77 out of 100\n",
      "[79/100] train_loss: 0.66052 valid_loss: 0.88491\n",
      "EarlyStopping counter: 78 out of 100\n",
      "[80/100] train_loss: 0.66050 valid_loss: 0.88625\n",
      "EarlyStopping counter: 79 out of 100\n",
      "[81/100] train_loss: 0.64034 valid_loss: 0.88758\n",
      "EarlyStopping counter: 80 out of 100\n",
      "[82/100] train_loss: 0.62552 valid_loss: 0.88894\n",
      "EarlyStopping counter: 81 out of 100\n",
      "[83/100] train_loss: 0.75526 valid_loss: 0.89051\n",
      "EarlyStopping counter: 82 out of 100\n",
      "[84/100] train_loss: 0.58820 valid_loss: 0.89209\n",
      "EarlyStopping counter: 83 out of 100\n",
      "[85/100] train_loss: 0.65907 valid_loss: 0.89405\n",
      "EarlyStopping counter: 84 out of 100\n",
      "[86/100] train_loss: 0.55927 valid_loss: 0.89598\n",
      "EarlyStopping counter: 85 out of 100\n",
      "[87/100] train_loss: 0.87331 valid_loss: 0.89716\n",
      "EarlyStopping counter: 86 out of 100\n",
      "[88/100] train_loss: 0.72206 valid_loss: 0.89734\n",
      "EarlyStopping counter: 87 out of 100\n",
      "[89/100] train_loss: 0.64628 valid_loss: 0.89695\n",
      "EarlyStopping counter: 88 out of 100\n",
      "[90/100] train_loss: 0.56301 valid_loss: 0.89456\n",
      "EarlyStopping counter: 89 out of 100\n",
      "[91/100] train_loss: 0.72056 valid_loss: 0.89127\n",
      "EarlyStopping counter: 90 out of 100\n",
      "[92/100] train_loss: 0.87299 valid_loss: 0.88772\n",
      "EarlyStopping counter: 91 out of 100\n",
      "[93/100] train_loss: 0.54696 valid_loss: 0.88346\n",
      "EarlyStopping counter: 92 out of 100\n",
      "[94/100] train_loss: 0.76803 valid_loss: 0.87928\n",
      "EarlyStopping counter: 93 out of 100\n",
      "[95/100] train_loss: 0.65034 valid_loss: 0.87616\n",
      "EarlyStopping counter: 94 out of 100\n",
      "[96/100] train_loss: 0.65818 valid_loss: 0.87304\n",
      "EarlyStopping counter: 95 out of 100\n",
      "[97/100] train_loss: 0.57613 valid_loss: 0.87126\n",
      "EarlyStopping counter: 96 out of 100\n",
      "[98/100] train_loss: 0.59149 valid_loss: 0.86936\n",
      "EarlyStopping counter: 97 out of 100\n",
      "[99/100] train_loss: 0.60825 valid_loss: 0.86894\n",
      "EarlyStopping counter: 98 out of 100\n",
      "[100/100] train_loss: 0.56212 valid_loss: 0.86831\n",
      "EarlyStopping counter: 99 out of 100\n",
      "  Training 3/5 for Fold 6\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n",
      "[1/100] train_loss: 0.71463 valid_loss: 0.90120\n",
      "Validation loss decreased (inf --> 0.901197).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/100] train_loss: 1.05048 valid_loss: 0.90599\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[3/100] train_loss: 1.03923 valid_loss: 0.91182\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[4/100] train_loss: 0.69752 valid_loss: 0.91639\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[5/100] train_loss: 0.69260 valid_loss: 0.92018\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[6/100] train_loss: 0.68745 valid_loss: 0.92344\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[7/100] train_loss: 0.79042 valid_loss: 0.92672\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[8/100] train_loss: 2.08105 valid_loss: 0.92957\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[9/100] train_loss: 0.98316 valid_loss: 0.93319\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[10/100] train_loss: 2.02906 valid_loss: 0.93670\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[11/100] train_loss: 1.99792 valid_loss: 0.94024\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[12/100] train_loss: 0.79051 valid_loss: 0.94330\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[13/100] train_loss: 0.79030 valid_loss: 0.94593\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[14/100] train_loss: 0.65227 valid_loss: 0.94845\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[15/100] train_loss: 0.64868 valid_loss: 0.95088\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[16/100] train_loss: 0.74988 valid_loss: 0.95357\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[17/100] train_loss: 0.91350 valid_loss: 0.95715\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[18/100] train_loss: 1.78983 valid_loss: 0.96117\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[19/100] train_loss: 1.75352 valid_loss: 0.96567\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[20/100] train_loss: 0.88096 valid_loss: 0.97096\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[21/100] train_loss: 0.86742 valid_loss: 0.97707\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[22/100] train_loss: 0.85268 valid_loss: 0.98406\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[23/100] train_loss: 0.70301 valid_loss: 0.99119\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[24/100] train_loss: 0.78889 valid_loss: 0.99774\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[25/100] train_loss: 0.72465 valid_loss: 1.00447\n",
      "EarlyStopping counter: 24 out of 100\n",
      "[26/100] train_loss: 0.72180 valid_loss: 1.01139\n",
      "EarlyStopping counter: 25 out of 100\n",
      "[27/100] train_loss: 0.71902 valid_loss: 1.01851\n",
      "EarlyStopping counter: 26 out of 100\n",
      "[28/100] train_loss: 0.79112 valid_loss: 1.02468\n",
      "EarlyStopping counter: 27 out of 100\n",
      "[29/100] train_loss: 0.74264 valid_loss: 1.03296\n",
      "EarlyStopping counter: 28 out of 100\n",
      "[30/100] train_loss: 0.62663 valid_loss: 1.04032\n",
      "EarlyStopping counter: 29 out of 100\n",
      "[31/100] train_loss: 0.63219 valid_loss: 1.04631\n",
      "EarlyStopping counter: 30 out of 100\n",
      "[32/100] train_loss: 0.70827 valid_loss: 1.05203\n",
      "EarlyStopping counter: 31 out of 100\n",
      "[33/100] train_loss: 0.79681 valid_loss: 1.05579\n",
      "EarlyStopping counter: 32 out of 100\n",
      "[34/100] train_loss: 0.79751 valid_loss: 1.05745\n",
      "EarlyStopping counter: 33 out of 100\n",
      "[35/100] train_loss: 0.79767 valid_loss: 1.05696\n",
      "EarlyStopping counter: 34 out of 100\n",
      "[36/100] train_loss: 0.65567 valid_loss: 1.05402\n",
      "EarlyStopping counter: 35 out of 100\n",
      "[37/100] train_loss: 0.64651 valid_loss: 1.05205\n",
      "EarlyStopping counter: 36 out of 100\n",
      "[38/100] train_loss: 0.64675 valid_loss: 1.05098\n",
      "EarlyStopping counter: 37 out of 100\n",
      "[39/100] train_loss: 0.79393 valid_loss: 1.04805\n",
      "EarlyStopping counter: 38 out of 100\n",
      "[40/100] train_loss: 0.65117 valid_loss: 1.04901\n",
      "EarlyStopping counter: 39 out of 100\n",
      "[41/100] train_loss: 1.06237 valid_loss: 1.05353\n",
      "EarlyStopping counter: 40 out of 100\n",
      "[42/100] train_loss: 0.62652 valid_loss: 1.06090\n",
      "EarlyStopping counter: 41 out of 100\n",
      "[43/100] train_loss: 0.79714 valid_loss: 1.06540\n",
      "EarlyStopping counter: 42 out of 100\n",
      "[44/100] train_loss: 0.62791 valid_loss: 1.07025\n",
      "EarlyStopping counter: 43 out of 100\n",
      "[45/100] train_loss: 0.62473 valid_loss: 1.07515\n",
      "EarlyStopping counter: 44 out of 100\n",
      "[46/100] train_loss: 0.62271 valid_loss: 1.07954\n",
      "EarlyStopping counter: 45 out of 100\n",
      "[47/100] train_loss: 0.59776 valid_loss: 1.07814\n",
      "EarlyStopping counter: 46 out of 100\n",
      "[48/100] train_loss: 0.73087 valid_loss: 1.06589\n",
      "EarlyStopping counter: 47 out of 100\n",
      "[49/100] train_loss: 0.87182 valid_loss: 1.04973\n",
      "EarlyStopping counter: 48 out of 100\n",
      "[50/100] train_loss: 0.70517 valid_loss: 1.03263\n",
      "EarlyStopping counter: 49 out of 100\n",
      "[51/100] train_loss: 0.76710 valid_loss: 1.01623\n",
      "EarlyStopping counter: 50 out of 100\n",
      "[52/100] train_loss: 0.78003 valid_loss: 1.00188\n",
      "EarlyStopping counter: 51 out of 100\n",
      "[53/100] train_loss: 0.68806 valid_loss: 0.98984\n",
      "EarlyStopping counter: 52 out of 100\n",
      "[54/100] train_loss: 0.63871 valid_loss: 0.98038\n",
      "EarlyStopping counter: 53 out of 100\n",
      "[55/100] train_loss: 0.69054 valid_loss: 0.97240\n",
      "EarlyStopping counter: 54 out of 100\n",
      "[56/100] train_loss: 1.02530 valid_loss: 0.96733\n",
      "EarlyStopping counter: 55 out of 100\n",
      "[57/100] train_loss: 0.69261 valid_loss: 0.96297\n",
      "EarlyStopping counter: 56 out of 100\n",
      "[58/100] train_loss: 0.69276 valid_loss: 0.95926\n",
      "EarlyStopping counter: 57 out of 100\n",
      "[59/100] train_loss: 1.01827 valid_loss: 0.95743\n",
      "EarlyStopping counter: 58 out of 100\n",
      "[60/100] train_loss: 0.62180 valid_loss: 0.95517\n",
      "EarlyStopping counter: 59 out of 100\n",
      "[61/100] train_loss: 0.76711 valid_loss: 0.95267\n",
      "EarlyStopping counter: 60 out of 100\n",
      "[62/100] train_loss: 0.68874 valid_loss: 0.95064\n",
      "EarlyStopping counter: 61 out of 100\n",
      "[63/100] train_loss: 0.65545 valid_loss: 0.95066\n",
      "EarlyStopping counter: 62 out of 100\n",
      "[64/100] train_loss: 0.89612 valid_loss: 0.95187\n",
      "EarlyStopping counter: 63 out of 100\n",
      "[65/100] train_loss: 0.61973 valid_loss: 0.95470\n",
      "EarlyStopping counter: 64 out of 100\n",
      "[66/100] train_loss: 0.68177 valid_loss: 0.95605\n",
      "EarlyStopping counter: 65 out of 100\n",
      "[67/100] train_loss: 0.58493 valid_loss: 0.95798\n",
      "EarlyStopping counter: 66 out of 100\n",
      "[68/100] train_loss: 0.57654 valid_loss: 0.95974\n",
      "EarlyStopping counter: 67 out of 100\n",
      "[69/100] train_loss: 0.67115 valid_loss: 0.95987\n",
      "EarlyStopping counter: 68 out of 100\n",
      "[70/100] train_loss: 0.75123 valid_loss: 0.96056\n",
      "EarlyStopping counter: 69 out of 100\n",
      "[71/100] train_loss: 0.76107 valid_loss: 0.95976\n",
      "EarlyStopping counter: 70 out of 100\n",
      "[72/100] train_loss: 0.84046 valid_loss: 0.95605\n",
      "EarlyStopping counter: 71 out of 100\n",
      "[73/100] train_loss: 0.68826 valid_loss: 0.94772\n",
      "EarlyStopping counter: 72 out of 100\n",
      "[74/100] train_loss: 0.71975 valid_loss: 0.94079\n",
      "EarlyStopping counter: 73 out of 100\n",
      "[75/100] train_loss: 0.75486 valid_loss: 0.93388\n",
      "EarlyStopping counter: 74 out of 100\n",
      "[76/100] train_loss: 0.77764 valid_loss: 0.92621\n",
      "EarlyStopping counter: 75 out of 100\n",
      "[77/100] train_loss: 0.57507 valid_loss: 0.91852\n",
      "EarlyStopping counter: 76 out of 100\n",
      "[78/100] train_loss: 0.57034 valid_loss: 0.91141\n",
      "EarlyStopping counter: 77 out of 100\n",
      "[79/100] train_loss: 0.67136 valid_loss: 0.90448\n",
      "EarlyStopping counter: 78 out of 100\n",
      "[80/100] train_loss: 0.66529 valid_loss: 0.89889\n",
      "Validation loss decreased (0.901197 --> 0.898892).  Saving model ...\n",
      "[81/100] train_loss: 0.59801 valid_loss: 0.89515\n",
      "Validation loss decreased (0.898892 --> 0.895148).  Saving model ...\n",
      "[82/100] train_loss: 0.75463 valid_loss: 0.89176\n",
      "Validation loss decreased (0.895148 --> 0.891757).  Saving model ...\n",
      "[83/100] train_loss: 0.80509 valid_loss: 0.88921\n",
      "Validation loss decreased (0.891757 --> 0.889211).  Saving model ...\n",
      "[84/100] train_loss: 0.70072 valid_loss: 0.88736\n",
      "Validation loss decreased (0.889211 --> 0.887363).  Saving model ...\n",
      "[85/100] train_loss: 0.78798 valid_loss: 0.88610\n",
      "Validation loss decreased (0.887363 --> 0.886098).  Saving model ...\n",
      "[86/100] train_loss: 0.58857 valid_loss: 0.88599\n",
      "Validation loss decreased (0.886098 --> 0.885987).  Saving model ...\n",
      "[87/100] train_loss: 0.73168 valid_loss: 0.88619\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[88/100] train_loss: 0.68832 valid_loss: 0.88692\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[89/100] train_loss: 0.67901 valid_loss: 0.88815\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[90/100] train_loss: 0.74391 valid_loss: 0.88933\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[91/100] train_loss: 0.75671 valid_loss: 0.88896\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[92/100] train_loss: 0.74048 valid_loss: 0.88854\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[93/100] train_loss: 0.65491 valid_loss: 0.88811\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[94/100] train_loss: 0.65966 valid_loss: 0.88343\n",
      "Validation loss decreased (0.885987 --> 0.883428).  Saving model ...\n",
      "[95/100] train_loss: 0.61501 valid_loss: 0.87722\n",
      "Validation loss decreased (0.883428 --> 0.877225).  Saving model ...\n",
      "[96/100] train_loss: 0.63546 valid_loss: 0.87108\n",
      "Validation loss decreased (0.877225 --> 0.871083).  Saving model ...\n",
      "[97/100] train_loss: 0.63707 valid_loss: 0.86605\n",
      "Validation loss decreased (0.871083 --> 0.866047).  Saving model ...\n",
      "[98/100] train_loss: 0.64054 valid_loss: 0.86162\n",
      "Validation loss decreased (0.866047 --> 0.861623).  Saving model ...\n",
      "[99/100] train_loss: 0.64834 valid_loss: 0.85864\n",
      "Validation loss decreased (0.861623 --> 0.858640).  Saving model ...\n",
      "[100/100] train_loss: 0.54970 valid_loss: 0.85546\n",
      "Validation loss decreased (0.858640 --> 0.855457).  Saving model ...\n",
      "  Training 4/5 for Fold 6\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] train_loss: 1.00932 valid_loss: 0.94777\n",
      "Validation loss decreased (inf --> 0.947766).  Saving model ...\n",
      "[2/100] train_loss: 0.99812 valid_loss: 0.95641\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[3/100] train_loss: 0.77961 valid_loss: 0.96370\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[4/100] train_loss: 2.23480 valid_loss: 0.96862\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[5/100] train_loss: 0.70453 valid_loss: 0.97303\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[6/100] train_loss: 0.96261 valid_loss: 0.97829\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[7/100] train_loss: 0.95476 valid_loss: 0.98427\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[8/100] train_loss: 0.69516 valid_loss: 0.98983\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[9/100] train_loss: 0.85058 valid_loss: 0.99509\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[10/100] train_loss: 0.84591 valid_loss: 1.00009\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[11/100] train_loss: 0.92496 valid_loss: 1.00605\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[12/100] train_loss: 0.76384 valid_loss: 1.01157\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[13/100] train_loss: 0.81154 valid_loss: 1.01613\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[14/100] train_loss: 0.67431 valid_loss: 1.02058\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[15/100] train_loss: 0.82075 valid_loss: 1.02503\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[16/100] train_loss: 0.81052 valid_loss: 1.02858\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[17/100] train_loss: 0.88529 valid_loss: 1.03376\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[18/100] train_loss: 0.80965 valid_loss: 1.03807\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[19/100] train_loss: 0.75359 valid_loss: 1.04223\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[20/100] train_loss: 1.95012 valid_loss: 1.04773\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[21/100] train_loss: 0.85406 valid_loss: 1.05503\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[22/100] train_loss: 0.84273 valid_loss: 1.06427\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[23/100] train_loss: 1.86045 valid_loss: 1.07516\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[24/100] train_loss: 0.80881 valid_loss: 1.08525\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[25/100] train_loss: 0.74269 valid_loss: 1.09512\n",
      "EarlyStopping counter: 24 out of 100\n",
      "[26/100] train_loss: 0.80957 valid_loss: 1.10389\n",
      "EarlyStopping counter: 25 out of 100\n",
      "[27/100] train_loss: 0.62167 valid_loss: 1.11329\n",
      "EarlyStopping counter: 26 out of 100\n",
      "[28/100] train_loss: 0.75386 valid_loss: 1.12702\n",
      "EarlyStopping counter: 27 out of 100\n",
      "[29/100] train_loss: 1.59442 valid_loss: 1.14560\n",
      "EarlyStopping counter: 28 out of 100\n",
      "[30/100] train_loss: 0.71950 valid_loss: 1.16721\n",
      "EarlyStopping counter: 29 out of 100\n",
      "[31/100] train_loss: 1.45063 valid_loss: 1.19716\n",
      "EarlyStopping counter: 30 out of 100\n",
      "[32/100] train_loss: 0.66269 valid_loss: 1.23742\n",
      "EarlyStopping counter: 31 out of 100\n",
      "[33/100] train_loss: 0.63992 valid_loss: 1.29169\n",
      "EarlyStopping counter: 32 out of 100\n",
      "[34/100] train_loss: 0.62706 valid_loss: 1.36059\n",
      "EarlyStopping counter: 33 out of 100\n",
      "[35/100] train_loss: 0.64433 valid_loss: 1.45360\n",
      "EarlyStopping counter: 34 out of 100\n",
      "[36/100] train_loss: 0.96880 valid_loss: 1.46132\n",
      "EarlyStopping counter: 35 out of 100\n",
      "[37/100] train_loss: 0.63913 valid_loss: 1.46356\n",
      "EarlyStopping counter: 36 out of 100\n",
      "[38/100] train_loss: 0.66409 valid_loss: 1.43647\n",
      "EarlyStopping counter: 37 out of 100\n",
      "[39/100] train_loss: 0.65532 valid_loss: 1.39221\n",
      "EarlyStopping counter: 38 out of 100\n",
      "[40/100] train_loss: 0.62731 valid_loss: 1.35569\n",
      "EarlyStopping counter: 39 out of 100\n",
      "[41/100] train_loss: 0.85045 valid_loss: 1.30020\n",
      "EarlyStopping counter: 40 out of 100\n",
      "[42/100] train_loss: 0.61833 valid_loss: 1.25523\n",
      "EarlyStopping counter: 41 out of 100\n",
      "[43/100] train_loss: 0.61459 valid_loss: 1.22036\n",
      "EarlyStopping counter: 42 out of 100\n",
      "[44/100] train_loss: 0.99052 valid_loss: 1.20170\n",
      "EarlyStopping counter: 43 out of 100\n",
      "[45/100] train_loss: 0.61913 valid_loss: 1.18730\n",
      "EarlyStopping counter: 44 out of 100\n",
      "[46/100] train_loss: 0.83519 valid_loss: 1.16899\n",
      "EarlyStopping counter: 45 out of 100\n",
      "[47/100] train_loss: 0.68076 valid_loss: 1.14926\n",
      "EarlyStopping counter: 46 out of 100\n",
      "[48/100] train_loss: 0.96616 valid_loss: 1.13926\n",
      "EarlyStopping counter: 47 out of 100\n",
      "[49/100] train_loss: 0.67166 valid_loss: 1.12710\n",
      "EarlyStopping counter: 48 out of 100\n",
      "[50/100] train_loss: 0.94462 valid_loss: 1.12206\n",
      "EarlyStopping counter: 49 out of 100\n",
      "[51/100] train_loss: 0.72921 valid_loss: 1.11500\n",
      "EarlyStopping counter: 50 out of 100\n",
      "[52/100] train_loss: 0.64082 valid_loss: 1.11068\n",
      "EarlyStopping counter: 51 out of 100\n",
      "[53/100] train_loss: 0.69452 valid_loss: 1.10296\n",
      "EarlyStopping counter: 52 out of 100\n",
      "[54/100] train_loss: 0.63766 valid_loss: 1.09783\n",
      "EarlyStopping counter: 53 out of 100\n",
      "[55/100] train_loss: 0.63443 valid_loss: 1.09478\n",
      "EarlyStopping counter: 54 out of 100\n",
      "[56/100] train_loss: 0.62802 valid_loss: 1.09329\n",
      "EarlyStopping counter: 55 out of 100\n",
      "[57/100] train_loss: 0.80592 valid_loss: 1.08900\n",
      "EarlyStopping counter: 56 out of 100\n",
      "[58/100] train_loss: 0.72291 valid_loss: 1.08181\n",
      "EarlyStopping counter: 57 out of 100\n",
      "[59/100] train_loss: 0.78276 valid_loss: 1.07791\n",
      "EarlyStopping counter: 58 out of 100\n",
      "[60/100] train_loss: 0.75772 valid_loss: 1.06944\n",
      "EarlyStopping counter: 59 out of 100\n",
      "[61/100] train_loss: 0.71653 valid_loss: 1.05900\n",
      "EarlyStopping counter: 60 out of 100\n",
      "[62/100] train_loss: 0.73583 valid_loss: 1.04652\n",
      "EarlyStopping counter: 61 out of 100\n",
      "[63/100] train_loss: 0.78712 valid_loss: 1.03489\n",
      "EarlyStopping counter: 62 out of 100\n",
      "[64/100] train_loss: 0.66874 valid_loss: 1.02318\n",
      "EarlyStopping counter: 63 out of 100\n",
      "[65/100] train_loss: 0.78116 valid_loss: 1.01286\n",
      "EarlyStopping counter: 64 out of 100\n",
      "[66/100] train_loss: 0.61436 valid_loss: 1.00340\n",
      "EarlyStopping counter: 65 out of 100\n",
      "[67/100] train_loss: 0.70173 valid_loss: 0.99598\n",
      "EarlyStopping counter: 66 out of 100\n",
      "[68/100] train_loss: 0.77780 valid_loss: 0.98931\n",
      "EarlyStopping counter: 67 out of 100\n",
      "[69/100] train_loss: 0.71725 valid_loss: 0.98396\n",
      "EarlyStopping counter: 68 out of 100\n",
      "[70/100] train_loss: 0.72081 valid_loss: 0.97967\n",
      "EarlyStopping counter: 69 out of 100\n",
      "[71/100] train_loss: 1.07660 valid_loss: 0.97813\n",
      "EarlyStopping counter: 70 out of 100\n",
      "[72/100] train_loss: 0.71741 valid_loss: 0.97709\n",
      "EarlyStopping counter: 71 out of 100\n",
      "[73/100] train_loss: 0.77384 valid_loss: 0.97587\n",
      "EarlyStopping counter: 72 out of 100\n",
      "[74/100] train_loss: 0.98225 valid_loss: 0.97667\n",
      "EarlyStopping counter: 73 out of 100\n",
      "[75/100] train_loss: 0.91650 valid_loss: 0.97914\n",
      "EarlyStopping counter: 74 out of 100\n",
      "[76/100] train_loss: 0.60871 valid_loss: 0.98074\n",
      "EarlyStopping counter: 75 out of 100\n",
      "[77/100] train_loss: 0.79086 valid_loss: 0.98334\n",
      "EarlyStopping counter: 76 out of 100\n",
      "[78/100] train_loss: 0.76685 valid_loss: 0.98546\n",
      "EarlyStopping counter: 77 out of 100\n",
      "[79/100] train_loss: 0.68333 valid_loss: 0.98681\n",
      "EarlyStopping counter: 78 out of 100\n",
      "[80/100] train_loss: 0.82894 valid_loss: 0.98492\n",
      "EarlyStopping counter: 79 out of 100\n",
      "[81/100] train_loss: 0.84129 valid_loss: 0.98033\n",
      "EarlyStopping counter: 80 out of 100\n",
      "[82/100] train_loss: 0.68237 valid_loss: 0.97503\n",
      "EarlyStopping counter: 81 out of 100\n",
      "[83/100] train_loss: 0.75737 valid_loss: 0.96837\n",
      "EarlyStopping counter: 82 out of 100\n",
      "[84/100] train_loss: 0.70459 valid_loss: 0.96313\n",
      "EarlyStopping counter: 83 out of 100\n",
      "[85/100] train_loss: 0.65057 valid_loss: 0.95743\n",
      "EarlyStopping counter: 84 out of 100\n",
      "[86/100] train_loss: 0.76534 valid_loss: 0.95239\n",
      "EarlyStopping counter: 85 out of 100\n",
      "[87/100] train_loss: 0.71275 valid_loss: 0.94837\n",
      "EarlyStopping counter: 86 out of 100\n",
      "[88/100] train_loss: 0.58833 valid_loss: 0.94461\n",
      "Validation loss decreased (0.947766 --> 0.944613).  Saving model ...\n",
      "[89/100] train_loss: 0.72855 valid_loss: 0.94160\n",
      "Validation loss decreased (0.944613 --> 0.941602).  Saving model ...\n",
      "[90/100] train_loss: 0.70152 valid_loss: 0.93917\n",
      "Validation loss decreased (0.941602 --> 0.939165).  Saving model ...\n",
      "[91/100] train_loss: 0.73651 valid_loss: 0.93725\n",
      "Validation loss decreased (0.939165 --> 0.937247).  Saving model ...\n",
      "[92/100] train_loss: 0.91504 valid_loss: 0.93689\n",
      "Validation loss decreased (0.937247 --> 0.936890).  Saving model ...\n",
      "[93/100] train_loss: 0.70292 valid_loss: 0.93828\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[94/100] train_loss: 0.69959 valid_loss: 0.93983\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[95/100] train_loss: 0.73024 valid_loss: 0.94159\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[96/100] train_loss: 0.69195 valid_loss: 0.94345\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[97/100] train_loss: 0.58395 valid_loss: 0.94498\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[98/100] train_loss: 0.61169 valid_loss: 0.94779\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[99/100] train_loss: 0.59242 valid_loss: 0.95147\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[100/100] train_loss: 0.57657 valid_loss: 0.95533\n",
      "EarlyStopping counter: 8 out of 100\n",
      "  Training 5/5 for Fold 6\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n",
      "[1/100] train_loss: 2.05520 valid_loss: 1.05231\n",
      "Validation loss decreased (inf --> 1.052312).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/100] train_loss: 0.80983 valid_loss: 1.05507\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[3/100] train_loss: 0.80387 valid_loss: 1.05763\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[4/100] train_loss: 0.92518 valid_loss: 1.06168\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[5/100] train_loss: 0.77902 valid_loss: 1.06529\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[6/100] train_loss: 0.68748 valid_loss: 1.06848\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[7/100] train_loss: 0.82909 valid_loss: 1.07042\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[8/100] train_loss: 0.68194 valid_loss: 1.07221\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[9/100] train_loss: 0.77669 valid_loss: 1.07409\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[10/100] train_loss: 1.89199 valid_loss: 1.07638\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[11/100] train_loss: 0.82952 valid_loss: 1.07781\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[12/100] train_loss: 0.77383 valid_loss: 1.07917\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[13/100] train_loss: 1.83819 valid_loss: 1.08110\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[14/100] train_loss: 0.83004 valid_loss: 1.08227\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[15/100] train_loss: 0.77130 valid_loss: 1.08339\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[16/100] train_loss: 1.77329 valid_loss: 1.08522\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[17/100] train_loss: 0.86808 valid_loss: 1.08809\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[18/100] train_loss: 0.65684 valid_loss: 1.09082\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[19/100] train_loss: 0.65450 valid_loss: 1.09340\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[20/100] train_loss: 0.76621 valid_loss: 1.09581\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[21/100] train_loss: 0.76507 valid_loss: 1.09805\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[22/100] train_loss: 0.72003 valid_loss: 1.10047\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[23/100] train_loss: 0.83227 valid_loss: 1.10187\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[24/100] train_loss: 0.64390 valid_loss: 1.10312\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[25/100] train_loss: 0.83205 valid_loss: 1.10331\n",
      "EarlyStopping counter: 24 out of 100\n",
      "[26/100] train_loss: 0.83162 valid_loss: 1.10248\n",
      "EarlyStopping counter: 25 out of 100\n",
      "[27/100] train_loss: 1.48884 valid_loss: 1.10352\n",
      "EarlyStopping counter: 26 out of 100\n",
      "[28/100] train_loss: 0.75582 valid_loss: 1.10444\n",
      "EarlyStopping counter: 27 out of 100\n",
      "[29/100] train_loss: 0.63950 valid_loss: 1.10505\n",
      "EarlyStopping counter: 28 out of 100\n",
      "[30/100] train_loss: 0.67911 valid_loss: 1.10592\n",
      "EarlyStopping counter: 29 out of 100\n",
      "[31/100] train_loss: 0.75100 valid_loss: 1.10667\n",
      "EarlyStopping counter: 30 out of 100\n",
      "[32/100] train_loss: 1.29274 valid_loss: 1.10911\n",
      "EarlyStopping counter: 31 out of 100\n",
      "[33/100] train_loss: 0.74423 valid_loss: 1.11352\n",
      "EarlyStopping counter: 32 out of 100\n",
      "[34/100] train_loss: 0.83476 valid_loss: 1.11627\n",
      "EarlyStopping counter: 33 out of 100\n",
      "[35/100] train_loss: 0.83702 valid_loss: 1.11706\n",
      "EarlyStopping counter: 34 out of 100\n",
      "[36/100] train_loss: 1.07026 valid_loss: 1.11931\n",
      "EarlyStopping counter: 35 out of 100\n",
      "[37/100] train_loss: 0.76864 valid_loss: 1.11907\n",
      "EarlyStopping counter: 36 out of 100\n",
      "[38/100] train_loss: 0.66397 valid_loss: 1.11792\n",
      "EarlyStopping counter: 37 out of 100\n",
      "[39/100] train_loss: 0.79487 valid_loss: 1.11468\n",
      "EarlyStopping counter: 38 out of 100\n",
      "[40/100] train_loss: 0.73829 valid_loss: 1.11125\n",
      "EarlyStopping counter: 39 out of 100\n",
      "[41/100] train_loss: 0.64829 valid_loss: 1.10769\n",
      "EarlyStopping counter: 40 out of 100\n",
      "[42/100] train_loss: 0.83708 valid_loss: 1.10266\n",
      "EarlyStopping counter: 41 out of 100\n",
      "[43/100] train_loss: 0.64238 valid_loss: 1.09799\n",
      "EarlyStopping counter: 42 out of 100\n",
      "[44/100] train_loss: 0.72684 valid_loss: 1.09259\n",
      "EarlyStopping counter: 43 out of 100\n",
      "[45/100] train_loss: 0.67043 valid_loss: 1.08956\n",
      "EarlyStopping counter: 44 out of 100\n",
      "[46/100] train_loss: 0.64621 valid_loss: 1.08694\n",
      "EarlyStopping counter: 45 out of 100\n",
      "[47/100] train_loss: 0.73867 valid_loss: 1.08408\n",
      "EarlyStopping counter: 46 out of 100\n",
      "[48/100] train_loss: 0.67346 valid_loss: 1.08305\n",
      "EarlyStopping counter: 47 out of 100\n",
      "[49/100] train_loss: 0.66879 valid_loss: 1.08357\n",
      "EarlyStopping counter: 48 out of 100\n",
      "[50/100] train_loss: 0.65987 valid_loss: 1.08548\n",
      "EarlyStopping counter: 49 out of 100\n",
      "[51/100] train_loss: 0.64933 valid_loss: 1.08768\n",
      "EarlyStopping counter: 50 out of 100\n",
      "[52/100] train_loss: 0.64598 valid_loss: 1.09021\n",
      "EarlyStopping counter: 51 out of 100\n",
      "[53/100] train_loss: 0.62668 valid_loss: 1.09336\n",
      "EarlyStopping counter: 52 out of 100\n",
      "[54/100] train_loss: 0.82593 valid_loss: 1.09435\n",
      "EarlyStopping counter: 53 out of 100\n",
      "[55/100] train_loss: 0.61438 valid_loss: 1.09475\n",
      "EarlyStopping counter: 54 out of 100\n",
      "[56/100] train_loss: 0.76377 valid_loss: 1.09278\n",
      "EarlyStopping counter: 55 out of 100\n",
      "[57/100] train_loss: 0.62745 valid_loss: 1.09125\n",
      "EarlyStopping counter: 56 out of 100\n",
      "[58/100] train_loss: 0.82546 valid_loss: 1.08706\n",
      "EarlyStopping counter: 57 out of 100\n",
      "[59/100] train_loss: 0.74919 valid_loss: 1.08128\n",
      "EarlyStopping counter: 58 out of 100\n",
      "[60/100] train_loss: 0.90142 valid_loss: 1.07710\n",
      "EarlyStopping counter: 59 out of 100\n",
      "[61/100] train_loss: 0.89700 valid_loss: 1.07414\n",
      "EarlyStopping counter: 60 out of 100\n",
      "[62/100] train_loss: 0.72111 valid_loss: 1.06979\n",
      "EarlyStopping counter: 61 out of 100\n",
      "[63/100] train_loss: 0.73978 valid_loss: 1.06261\n",
      "EarlyStopping counter: 62 out of 100\n",
      "[64/100] train_loss: 0.60805 valid_loss: 1.05562\n",
      "EarlyStopping counter: 63 out of 100\n",
      "[65/100] train_loss: 0.73027 valid_loss: 1.04730\n",
      "Validation loss decreased (1.052312 --> 1.047300).  Saving model ...\n",
      "[66/100] train_loss: 0.80388 valid_loss: 1.03906\n",
      "Validation loss decreased (1.047300 --> 1.039058).  Saving model ...\n",
      "[67/100] train_loss: 0.80166 valid_loss: 1.03100\n",
      "Validation loss decreased (1.039058 --> 1.031004).  Saving model ...\n",
      "[68/100] train_loss: 0.66243 valid_loss: 1.02337\n",
      "Validation loss decreased (1.031004 --> 1.023370).  Saving model ...\n",
      "[69/100] train_loss: 0.64982 valid_loss: 1.01626\n",
      "Validation loss decreased (1.023370 --> 1.016258).  Saving model ...\n",
      "[70/100] train_loss: 0.79669 valid_loss: 1.00960\n",
      "Validation loss decreased (1.016258 --> 1.009605).  Saving model ...\n",
      "[71/100] train_loss: 0.79563 valid_loss: 1.00337\n",
      "Validation loss decreased (1.009605 --> 1.003371).  Saving model ...\n",
      "[72/100] train_loss: 0.94064 valid_loss: 0.99819\n",
      "Validation loss decreased (1.003371 --> 0.998194).  Saving model ...\n",
      "[73/100] train_loss: 0.61902 valid_loss: 0.99325\n",
      "Validation loss decreased (0.998194 --> 0.993247).  Saving model ...\n",
      "[74/100] train_loss: 0.79275 valid_loss: 0.98846\n",
      "Validation loss decreased (0.993247 --> 0.988465).  Saving model ...\n",
      "[75/100] train_loss: 0.71209 valid_loss: 0.98458\n",
      "Validation loss decreased (0.988465 --> 0.984585).  Saving model ...\n",
      "[76/100] train_loss: 0.79082 valid_loss: 0.98077\n",
      "Validation loss decreased (0.984585 --> 0.980770).  Saving model ...\n",
      "[77/100] train_loss: 0.71613 valid_loss: 0.97743\n",
      "Validation loss decreased (0.980770 --> 0.977425).  Saving model ...\n",
      "[78/100] train_loss: 0.78876 valid_loss: 0.97411\n",
      "Validation loss decreased (0.977425 --> 0.974105).  Saving model ...\n",
      "[79/100] train_loss: 0.63343 valid_loss: 0.97210\n",
      "Validation loss decreased (0.974105 --> 0.972104).  Saving model ...\n",
      "[80/100] train_loss: 0.78620 valid_loss: 0.97001\n",
      "Validation loss decreased (0.972104 --> 0.970015).  Saving model ...\n",
      "[81/100] train_loss: 0.61930 valid_loss: 0.96777\n",
      "Validation loss decreased (0.970015 --> 0.967766).  Saving model ...\n",
      "[82/100] train_loss: 0.61967 valid_loss: 0.96536\n",
      "Validation loss decreased (0.967766 --> 0.965362).  Saving model ...\n",
      "[83/100] train_loss: 0.70773 valid_loss: 0.96359\n",
      "Validation loss decreased (0.965362 --> 0.963594).  Saving model ...\n",
      "[84/100] train_loss: 0.69924 valid_loss: 0.96208\n",
      "Validation loss decreased (0.963594 --> 0.962082).  Saving model ...\n",
      "[85/100] train_loss: 0.70436 valid_loss: 0.96112\n",
      "Validation loss decreased (0.962082 --> 0.961117).  Saving model ...\n",
      "[86/100] train_loss: 0.57996 valid_loss: 0.96009\n",
      "Validation loss decreased (0.961117 --> 0.960086).  Saving model ...\n",
      "[87/100] train_loss: 0.68951 valid_loss: 0.95907\n",
      "Validation loss decreased (0.960086 --> 0.959069).  Saving model ...\n",
      "[88/100] train_loss: 0.63984 valid_loss: 0.95766\n",
      "Validation loss decreased (0.959069 --> 0.957657).  Saving model ...\n",
      "[89/100] train_loss: 0.57311 valid_loss: 0.95566\n",
      "Validation loss decreased (0.957657 --> 0.955658).  Saving model ...\n",
      "[90/100] train_loss: 0.57119 valid_loss: 0.95315\n",
      "Validation loss decreased (0.955658 --> 0.953150).  Saving model ...\n",
      "[91/100] train_loss: 0.68393 valid_loss: 0.95127\n",
      "Validation loss decreased (0.953150 --> 0.951273).  Saving model ...\n",
      "[92/100] train_loss: 0.67837 valid_loss: 0.94994\n",
      "Validation loss decreased (0.951273 --> 0.949936).  Saving model ...\n",
      "[93/100] train_loss: 0.76862 valid_loss: 0.94856\n",
      "Validation loss decreased (0.949936 --> 0.948559).  Saving model ...\n",
      "[94/100] train_loss: 0.56393 valid_loss: 0.94657\n",
      "Validation loss decreased (0.948559 --> 0.946566).  Saving model ...\n",
      "[95/100] train_loss: 0.76524 valid_loss: 0.94459\n",
      "Validation loss decreased (0.946566 --> 0.944586).  Saving model ...\n",
      "[96/100] train_loss: 0.56080 valid_loss: 0.94202\n",
      "Validation loss decreased (0.944586 --> 0.942020).  Saving model ...\n",
      "[97/100] train_loss: 0.79200 valid_loss: 0.93951\n",
      "Validation loss decreased (0.942020 --> 0.939513).  Saving model ...\n",
      "[98/100] train_loss: 0.55842 valid_loss: 0.93637\n",
      "Validation loss decreased (0.939513 --> 0.936365).  Saving model ...\n",
      "[99/100] train_loss: 0.76333 valid_loss: 0.93334\n",
      "Validation loss decreased (0.936365 --> 0.933343).  Saving model ...\n",
      "[100/100] train_loss: 0.72010 valid_loss: 0.93037\n",
      "Validation loss decreased (0.933343 --> 0.930374).  Saving model ...\n",
      "  Fold 7/7\n",
      "  Training 1/5 for Fold 7\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n",
      "[1/100] train_loss: 0.77429 valid_loss: 0.80062\n",
      "Validation loss decreased (inf --> 0.800623).  Saving model ...\n",
      "[2/100] train_loss: 0.81604 valid_loss: 0.79971\n",
      "Validation loss decreased (0.800623 --> 0.799709).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/100] train_loss: 0.81387 valid_loss: 0.79884\n",
      "Validation loss decreased (0.799709 --> 0.798844).  Saving model ...\n",
      "[4/100] train_loss: 0.81161 valid_loss: 0.79804\n",
      "Validation loss decreased (0.798844 --> 0.798043).  Saving model ...\n",
      "[5/100] train_loss: 1.03455 valid_loss: 0.79831\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[6/100] train_loss: 0.70267 valid_loss: 0.79685\n",
      "Validation loss decreased (0.798043 --> 0.796851).  Saving model ...\n",
      "[7/100] train_loss: 0.76381 valid_loss: 0.79572\n",
      "Validation loss decreased (0.796851 --> 0.795715).  Saving model ...\n",
      "[8/100] train_loss: 2.01505 valid_loss: 0.79289\n",
      "Validation loss decreased (0.795715 --> 0.792892).  Saving model ...\n",
      "[9/100] train_loss: 0.80394 valid_loss: 0.79031\n",
      "Validation loss decreased (0.792892 --> 0.790310).  Saving model ...\n",
      "[10/100] train_loss: 0.93097 valid_loss: 0.78794\n",
      "Validation loss decreased (0.790310 --> 0.787943).  Saving model ...\n",
      "[11/100] train_loss: 0.68838 valid_loss: 0.78500\n",
      "Validation loss decreased (0.787943 --> 0.784998).  Saving model ...\n",
      "[12/100] train_loss: 1.01209 valid_loss: 0.78283\n",
      "Validation loss decreased (0.784998 --> 0.782832).  Saving model ...\n",
      "[13/100] train_loss: 0.75742 valid_loss: 0.78086\n",
      "Validation loss decreased (0.782832 --> 0.780860).  Saving model ...\n",
      "[14/100] train_loss: 0.67962 valid_loss: 0.77833\n",
      "Validation loss decreased (0.780860 --> 0.778327).  Saving model ...\n",
      "[15/100] train_loss: 0.67662 valid_loss: 0.77531\n",
      "Validation loss decreased (0.778327 --> 0.775307).  Saving model ...\n",
      "[16/100] train_loss: 1.89960 valid_loss: 0.77151\n",
      "Validation loss decreased (0.775307 --> 0.771511).  Saving model ...\n",
      "[17/100] train_loss: 0.89712 valid_loss: 0.76788\n",
      "Validation loss decreased (0.771511 --> 0.767881).  Saving model ...\n",
      "[18/100] train_loss: 1.85465 valid_loss: 0.76356\n",
      "Validation loss decreased (0.767881 --> 0.763557).  Saving model ...\n",
      "[19/100] train_loss: 1.82531 valid_loss: 0.75863\n",
      "Validation loss decreased (0.763557 --> 0.758625).  Saving model ...\n",
      "[20/100] train_loss: 0.87038 valid_loss: 0.75382\n",
      "Validation loss decreased (0.758625 --> 0.753823).  Saving model ...\n",
      "[21/100] train_loss: 0.65292 valid_loss: 0.74876\n",
      "Validation loss decreased (0.753823 --> 0.748763).  Saving model ...\n",
      "[22/100] train_loss: 0.79416 valid_loss: 0.74391\n",
      "Validation loss decreased (0.748763 --> 0.743912).  Saving model ...\n",
      "[23/100] train_loss: 0.83751 valid_loss: 0.73907\n",
      "Validation loss decreased (0.743912 --> 0.739071).  Saving model ...\n",
      "[24/100] train_loss: 1.01777 valid_loss: 0.73488\n",
      "Validation loss decreased (0.739071 --> 0.734877).  Saving model ...\n",
      "[25/100] train_loss: 0.81547 valid_loss: 0.73052\n",
      "Validation loss decreased (0.734877 --> 0.730518).  Saving model ...\n",
      "[26/100] train_loss: 0.63348 valid_loss: 0.72580\n",
      "Validation loss decreased (0.730518 --> 0.725802).  Saving model ...\n",
      "[27/100] train_loss: 0.79049 valid_loss: 0.72119\n",
      "Validation loss decreased (0.725802 --> 0.721185).  Saving model ...\n",
      "[28/100] train_loss: 0.62670 valid_loss: 0.71623\n",
      "Validation loss decreased (0.721185 --> 0.716226).  Saving model ...\n",
      "[29/100] train_loss: 0.73222 valid_loss: 0.71125\n",
      "Validation loss decreased (0.716226 --> 0.711246).  Saving model ...\n",
      "[30/100] train_loss: 1.43548 valid_loss: 0.70445\n",
      "Validation loss decreased (0.711246 --> 0.704447).  Saving model ...\n",
      "[31/100] train_loss: 0.74055 valid_loss: 0.69700\n",
      "Validation loss decreased (0.704447 --> 0.696998).  Saving model ...\n",
      "[32/100] train_loss: 0.72702 valid_loss: 0.68938\n",
      "Validation loss decreased (0.696998 --> 0.689377).  Saving model ...\n",
      "[33/100] train_loss: 0.72562 valid_loss: 0.68158\n",
      "Validation loss decreased (0.689377 --> 0.681579).  Saving model ...\n",
      "[34/100] train_loss: 1.02775 valid_loss: 0.67468\n",
      "Validation loss decreased (0.681579 --> 0.674684).  Saving model ...\n",
      "[35/100] train_loss: 0.62822 valid_loss: 0.66985\n",
      "Validation loss decreased (0.674684 --> 0.669853).  Saving model ...\n",
      "[36/100] train_loss: 0.72183 valid_loss: 0.66491\n",
      "Validation loss decreased (0.669853 --> 0.664914).  Saving model ...\n",
      "[37/100] train_loss: 0.64021 valid_loss: 0.66375\n",
      "Validation loss decreased (0.664914 --> 0.663752).  Saving model ...\n",
      "[38/100] train_loss: 0.64766 valid_loss: 0.66099\n",
      "Validation loss decreased (0.663752 --> 0.660991).  Saving model ...\n",
      "[39/100] train_loss: 0.71843 valid_loss: 0.65815\n",
      "Validation loss decreased (0.660991 --> 0.658149).  Saving model ...\n",
      "[40/100] train_loss: 0.63150 valid_loss: 0.65381\n",
      "Validation loss decreased (0.658149 --> 0.653812).  Saving model ...\n",
      "[41/100] train_loss: 1.06233 valid_loss: 0.64642\n",
      "Validation loss decreased (0.653812 --> 0.646418).  Saving model ...\n",
      "[42/100] train_loss: 0.77357 valid_loss: 0.63910\n",
      "Validation loss decreased (0.646418 --> 0.639101).  Saving model ...\n",
      "[43/100] train_loss: 0.77202 valid_loss: 0.63194\n",
      "Validation loss decreased (0.639101 --> 0.631944).  Saving model ...\n",
      "[44/100] train_loss: 0.74073 valid_loss: 0.63801\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[45/100] train_loss: 0.95568 valid_loss: 0.64201\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[46/100] train_loss: 0.76723 valid_loss: 0.64604\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[47/100] train_loss: 0.71514 valid_loss: 0.65011\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[48/100] train_loss: 0.88930 valid_loss: 0.65223\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[49/100] train_loss: 0.85999 valid_loss: 0.65274\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[50/100] train_loss: 0.59519 valid_loss: 0.65412\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[51/100] train_loss: 0.59439 valid_loss: 0.65641\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[52/100] train_loss: 0.93000 valid_loss: 0.65892\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[53/100] train_loss: 0.68757 valid_loss: 0.66080\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[54/100] train_loss: 0.58689 valid_loss: 0.66310\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[55/100] train_loss: 0.71507 valid_loss: 0.66412\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[56/100] train_loss: 0.68522 valid_loss: 0.66452\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[57/100] train_loss: 0.76531 valid_loss: 0.66407\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[58/100] train_loss: 0.76569 valid_loss: 0.66277\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[59/100] train_loss: 0.76586 valid_loss: 0.66061\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[60/100] train_loss: 0.86447 valid_loss: 0.65859\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[61/100] train_loss: 0.63814 valid_loss: 0.65773\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[62/100] train_loss: 0.69260 valid_loss: 0.65674\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[63/100] train_loss: 0.76642 valid_loss: 0.65466\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[64/100] train_loss: 0.61410 valid_loss: 0.65802\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[65/100] train_loss: 0.62101 valid_loss: 0.66297\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[66/100] train_loss: 0.61405 valid_loss: 0.66876\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[67/100] train_loss: 0.83162 valid_loss: 0.67359\n",
      "EarlyStopping counter: 24 out of 100\n",
      "[68/100] train_loss: 0.77062 valid_loss: 0.67697\n",
      "EarlyStopping counter: 25 out of 100\n",
      "[69/100] train_loss: 0.72065 valid_loss: 0.68022\n",
      "EarlyStopping counter: 26 out of 100\n",
      "[70/100] train_loss: 0.77159 valid_loss: 0.68230\n",
      "EarlyStopping counter: 27 out of 100\n",
      "[71/100] train_loss: 0.62295 valid_loss: 0.68065\n",
      "EarlyStopping counter: 28 out of 100\n",
      "[72/100] train_loss: 0.71559 valid_loss: 0.67934\n",
      "EarlyStopping counter: 29 out of 100\n",
      "[73/100] train_loss: 0.70609 valid_loss: 0.67820\n",
      "EarlyStopping counter: 30 out of 100\n",
      "[74/100] train_loss: 0.76358 valid_loss: 0.67624\n",
      "EarlyStopping counter: 31 out of 100\n",
      "[75/100] train_loss: 0.59610 valid_loss: 0.67560\n",
      "EarlyStopping counter: 32 out of 100\n",
      "[76/100] train_loss: 0.59832 valid_loss: 0.67618\n",
      "EarlyStopping counter: 33 out of 100\n",
      "[77/100] train_loss: 0.91695 valid_loss: 0.69343\n",
      "EarlyStopping counter: 34 out of 100\n",
      "[78/100] train_loss: 0.59808 valid_loss: 0.70670\n",
      "EarlyStopping counter: 35 out of 100\n",
      "[79/100] train_loss: 0.66940 valid_loss: 0.71723\n",
      "EarlyStopping counter: 36 out of 100\n",
      "[80/100] train_loss: 0.75615 valid_loss: 0.72537\n",
      "EarlyStopping counter: 37 out of 100\n",
      "[81/100] train_loss: 0.75584 valid_loss: 0.73170\n",
      "EarlyStopping counter: 38 out of 100\n",
      "[82/100] train_loss: 0.75523 valid_loss: 0.73662\n",
      "EarlyStopping counter: 39 out of 100\n",
      "[83/100] train_loss: 0.61617 valid_loss: 0.74036\n",
      "EarlyStopping counter: 40 out of 100\n",
      "[84/100] train_loss: 0.60821 valid_loss: 0.74496\n",
      "EarlyStopping counter: 41 out of 100\n",
      "[85/100] train_loss: 0.75118 valid_loss: 0.74860\n",
      "EarlyStopping counter: 42 out of 100\n",
      "[86/100] train_loss: 0.60034 valid_loss: 0.75259\n",
      "EarlyStopping counter: 43 out of 100\n",
      "[87/100] train_loss: 0.75400 valid_loss: 0.75460\n",
      "EarlyStopping counter: 44 out of 100\n",
      "[88/100] train_loss: 0.65526 valid_loss: 0.75637\n",
      "EarlyStopping counter: 45 out of 100\n",
      "[89/100] train_loss: 0.74251 valid_loss: 0.75756\n",
      "EarlyStopping counter: 46 out of 100\n",
      "[90/100] train_loss: 0.68153 valid_loss: 0.75776\n",
      "EarlyStopping counter: 47 out of 100\n",
      "[91/100] train_loss: 0.73562 valid_loss: 0.75742\n",
      "EarlyStopping counter: 48 out of 100\n",
      "[92/100] train_loss: 0.62556 valid_loss: 0.75688\n",
      "EarlyStopping counter: 49 out of 100\n",
      "[93/100] train_loss: 0.84547 valid_loss: 0.75734\n",
      "EarlyStopping counter: 50 out of 100\n",
      "[94/100] train_loss: 0.61000 valid_loss: 0.75827\n",
      "EarlyStopping counter: 51 out of 100\n",
      "[95/100] train_loss: 0.61517 valid_loss: 0.75984\n",
      "EarlyStopping counter: 52 out of 100\n",
      "[96/100] train_loss: 0.71825 valid_loss: 0.76054\n",
      "EarlyStopping counter: 53 out of 100\n",
      "[97/100] train_loss: 0.84728 valid_loss: 0.76095\n",
      "EarlyStopping counter: 54 out of 100\n",
      "[98/100] train_loss: 0.70733 valid_loss: 0.76928\n",
      "EarlyStopping counter: 55 out of 100\n",
      "[99/100] train_loss: 0.67842 valid_loss: 0.77578\n",
      "EarlyStopping counter: 56 out of 100\n",
      "[100/100] train_loss: 0.56467 valid_loss: 0.78125\n",
      "EarlyStopping counter: 57 out of 100\n",
      "  Training 2/5 for Fold 7\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n",
      "[1/100] train_loss: 1.02720 valid_loss: 0.84511\n",
      "Validation loss decreased (inf --> 0.845114).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/100] train_loss: 2.26332 valid_loss: 0.84016\n",
      "Validation loss decreased (0.845114 --> 0.840165).  Saving model ...\n",
      "[3/100] train_loss: 1.01160 valid_loss: 0.83659\n",
      "Validation loss decreased (0.840165 --> 0.836594).  Saving model ...\n",
      "[4/100] train_loss: 0.73835 valid_loss: 0.83191\n",
      "Validation loss decreased (0.836594 --> 0.831911).  Saving model ...\n",
      "[5/100] train_loss: 1.00922 valid_loss: 0.82843\n",
      "Validation loss decreased (0.831911 --> 0.828430).  Saving model ...\n",
      "[6/100] train_loss: 0.77777 valid_loss: 0.82557\n",
      "Validation loss decreased (0.828430 --> 0.825573).  Saving model ...\n",
      "[7/100] train_loss: 0.77602 valid_loss: 0.82319\n",
      "Validation loss decreased (0.825573 --> 0.823187).  Saving model ...\n",
      "[8/100] train_loss: 2.14915 valid_loss: 0.81961\n",
      "Validation loss decreased (0.823187 --> 0.819614).  Saving model ...\n",
      "[9/100] train_loss: 0.99756 valid_loss: 0.81660\n",
      "Validation loss decreased (0.819614 --> 0.816602).  Saving model ...\n",
      "[10/100] train_loss: 0.98114 valid_loss: 0.81399\n",
      "Validation loss decreased (0.816602 --> 0.813986).  Saving model ...\n",
      "[11/100] train_loss: 0.70952 valid_loss: 0.81052\n",
      "Validation loss decreased (0.813986 --> 0.810516).  Saving model ...\n",
      "[12/100] train_loss: 0.99391 valid_loss: 0.80752\n",
      "Validation loss decreased (0.810516 --> 0.807519).  Saving model ...\n",
      "[13/100] train_loss: 2.05074 valid_loss: 0.80366\n",
      "Validation loss decreased (0.807519 --> 0.803661).  Saving model ...\n",
      "[14/100] train_loss: 0.99003 valid_loss: 0.80025\n",
      "Validation loss decreased (0.803661 --> 0.800248).  Saving model ...\n",
      "[15/100] train_loss: 0.95242 valid_loss: 0.79711\n",
      "Validation loss decreased (0.800248 --> 0.797110).  Saving model ...\n",
      "[16/100] train_loss: 0.76037 valid_loss: 0.79422\n",
      "Validation loss decreased (0.797110 --> 0.794222).  Saving model ...\n",
      "[17/100] train_loss: 0.75856 valid_loss: 0.79156\n",
      "Validation loss decreased (0.794222 --> 0.791557).  Saving model ...\n",
      "[18/100] train_loss: 0.68062 valid_loss: 0.78810\n",
      "Validation loss decreased (0.791557 --> 0.788096).  Saving model ...\n",
      "[19/100] train_loss: 0.79769 valid_loss: 0.78467\n",
      "Validation loss decreased (0.788096 --> 0.784670).  Saving model ...\n",
      "[20/100] train_loss: 0.92100 valid_loss: 0.78139\n",
      "Validation loss decreased (0.784670 --> 0.781391).  Saving model ...\n",
      "[21/100] train_loss: 0.91345 valid_loss: 0.77820\n",
      "Validation loss decreased (0.781391 --> 0.778196).  Saving model ...\n",
      "[22/100] train_loss: 0.98008 valid_loss: 0.77533\n",
      "Validation loss decreased (0.778196 --> 0.775328).  Saving model ...\n",
      "[23/100] train_loss: 0.89702 valid_loss: 0.77243\n",
      "Validation loss decreased (0.775328 --> 0.772432).  Saving model ...\n",
      "[24/100] train_loss: 0.88792 valid_loss: 0.76946\n",
      "Validation loss decreased (0.772432 --> 0.769458).  Saving model ...\n",
      "[25/100] train_loss: 0.74119 valid_loss: 0.76655\n",
      "Validation loss decreased (0.769458 --> 0.766548).  Saving model ...\n",
      "[26/100] train_loss: 0.73847 valid_loss: 0.76368\n",
      "Validation loss decreased (0.766548 --> 0.763676).  Saving model ...\n",
      "[27/100] train_loss: 0.64044 valid_loss: 0.75967\n",
      "Validation loss decreased (0.763676 --> 0.759669).  Saving model ...\n",
      "[28/100] train_loss: 0.73297 valid_loss: 0.75568\n",
      "Validation loss decreased (0.759669 --> 0.755681).  Saving model ...\n",
      "[29/100] train_loss: 0.78275 valid_loss: 0.75152\n",
      "Validation loss decreased (0.755681 --> 0.751521).  Saving model ...\n",
      "[30/100] train_loss: 0.72745 valid_loss: 0.74731\n",
      "Validation loss decreased (0.751521 --> 0.747311).  Saving model ...\n",
      "[31/100] train_loss: 0.72467 valid_loss: 0.74301\n",
      "Validation loss decreased (0.747311 --> 0.743007).  Saving model ...\n",
      "[32/100] train_loss: 0.61416 valid_loss: 0.73733\n",
      "Validation loss decreased (0.743007 --> 0.737332).  Saving model ...\n",
      "[33/100] train_loss: 0.71892 valid_loss: 0.73146\n",
      "Validation loss decreased (0.737332 --> 0.731463).  Saving model ...\n",
      "[34/100] train_loss: 1.49962 valid_loss: 0.72284\n",
      "Validation loss decreased (0.731463 --> 0.722845).  Saving model ...\n",
      "[35/100] train_loss: 0.71298 valid_loss: 0.71400\n",
      "Validation loss decreased (0.722845 --> 0.713998).  Saving model ...\n",
      "[36/100] train_loss: 0.71030 valid_loss: 0.70489\n",
      "Validation loss decreased (0.713998 --> 0.704895).  Saving model ...\n",
      "[37/100] train_loss: 1.34053 valid_loss: 0.69223\n",
      "Validation loss decreased (0.704895 --> 0.692235).  Saving model ...\n",
      "[38/100] train_loss: 0.58668 valid_loss: 0.67982\n",
      "Validation loss decreased (0.692235 --> 0.679821).  Saving model ...\n",
      "[39/100] train_loss: 0.70547 valid_loss: 0.66698\n",
      "Validation loss decreased (0.679821 --> 0.666978).  Saving model ...\n",
      "[40/100] train_loss: 0.76098 valid_loss: 0.65385\n",
      "Validation loss decreased (0.666978 --> 0.653851).  Saving model ...\n",
      "[41/100] train_loss: 0.61419 valid_loss: 0.64833\n",
      "Validation loss decreased (0.653851 --> 0.648328).  Saving model ...\n",
      "[42/100] train_loss: 1.00170 valid_loss: 0.64433\n",
      "Validation loss decreased (0.648328 --> 0.644327).  Saving model ...\n",
      "[43/100] train_loss: 0.62316 valid_loss: 0.63912\n",
      "Validation loss decreased (0.644327 --> 0.639117).  Saving model ...\n",
      "[44/100] train_loss: 0.61724 valid_loss: 0.63308\n",
      "Validation loss decreased (0.639117 --> 0.633080).  Saving model ...\n",
      "[45/100] train_loss: 1.03775 valid_loss: 0.62593\n",
      "Validation loss decreased (0.633080 --> 0.625934).  Saving model ...\n",
      "[46/100] train_loss: 1.00301 valid_loss: 0.61818\n",
      "Validation loss decreased (0.625934 --> 0.618184).  Saving model ...\n",
      "[47/100] train_loss: 0.75466 valid_loss: 0.61098\n",
      "Validation loss decreased (0.618184 --> 0.610977).  Saving model ...\n",
      "[48/100] train_loss: 0.60815 valid_loss: 0.60650\n",
      "Validation loss decreased (0.610977 --> 0.606496).  Saving model ...\n",
      "[49/100] train_loss: 0.73318 valid_loss: 0.60496\n",
      "Validation loss decreased (0.606496 --> 0.604961).  Saving model ...\n",
      "[50/100] train_loss: 0.75248 valid_loss: 0.60359\n",
      "Validation loss decreased (0.604961 --> 0.603587).  Saving model ...\n",
      "[51/100] train_loss: 0.70961 valid_loss: 0.60379\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[52/100] train_loss: 0.95211 valid_loss: 0.60458\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[53/100] train_loss: 0.75089 valid_loss: 0.60450\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[54/100] train_loss: 0.67969 valid_loss: 0.60393\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[55/100] train_loss: 0.67670 valid_loss: 0.60266\n",
      "Validation loss decreased (0.603587 --> 0.602655).  Saving model ...\n",
      "[56/100] train_loss: 0.90864 valid_loss: 0.60156\n",
      "Validation loss decreased (0.602655 --> 0.601560).  Saving model ...\n",
      "[57/100] train_loss: 0.76735 valid_loss: 0.59930\n",
      "Validation loss decreased (0.601560 --> 0.599305).  Saving model ...\n",
      "[58/100] train_loss: 0.67788 valid_loss: 0.59631\n",
      "Validation loss decreased (0.599305 --> 0.596315).  Saving model ...\n",
      "[59/100] train_loss: 0.67922 valid_loss: 0.59266\n",
      "Validation loss decreased (0.596315 --> 0.592663).  Saving model ...\n",
      "[60/100] train_loss: 0.75338 valid_loss: 0.58800\n",
      "Validation loss decreased (0.592663 --> 0.588002).  Saving model ...\n",
      "[61/100] train_loss: 0.67988 valid_loss: 0.58288\n",
      "Validation loss decreased (0.588002 --> 0.582878).  Saving model ...\n",
      "[62/100] train_loss: 0.67848 valid_loss: 0.57734\n",
      "Validation loss decreased (0.582878 --> 0.577343).  Saving model ...\n",
      "[63/100] train_loss: 0.69632 valid_loss: 0.57340\n",
      "Validation loss decreased (0.577343 --> 0.573396).  Saving model ...\n",
      "[64/100] train_loss: 0.56452 valid_loss: 0.56890\n",
      "Validation loss decreased (0.573396 --> 0.568898).  Saving model ...\n",
      "[65/100] train_loss: 0.67703 valid_loss: 0.56682\n",
      "Validation loss decreased (0.568898 --> 0.566816).  Saving model ...\n",
      "[66/100] train_loss: 0.66551 valid_loss: 0.56706\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[67/100] train_loss: 0.57416 valid_loss: 0.56979\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[68/100] train_loss: 1.01935 valid_loss: 0.59671\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[69/100] train_loss: 0.90304 valid_loss: 0.63583\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[70/100] train_loss: 0.75954 valid_loss: 0.66472\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[71/100] train_loss: 0.65050 valid_loss: 0.68471\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[72/100] train_loss: 0.67581 valid_loss: 0.69927\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[73/100] train_loss: 0.61714 valid_loss: 0.71389\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[74/100] train_loss: 0.76668 valid_loss: 0.72568\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[75/100] train_loss: 0.84029 valid_loss: 0.73578\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[76/100] train_loss: 0.70953 valid_loss: 0.74382\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[77/100] train_loss: 0.69539 valid_loss: 0.75101\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[78/100] train_loss: 0.76756 valid_loss: 0.75697\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[79/100] train_loss: 0.76694 valid_loss: 0.76186\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[80/100] train_loss: 0.59727 valid_loss: 0.76599\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[81/100] train_loss: 0.67894 valid_loss: 0.76980\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[82/100] train_loss: 0.90068 valid_loss: 0.77143\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[83/100] train_loss: 0.64620 valid_loss: 0.77272\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[84/100] train_loss: 0.62185 valid_loss: 0.77374\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[85/100] train_loss: 0.65186 valid_loss: 0.77457\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[86/100] train_loss: 0.75634 valid_loss: 0.77451\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[87/100] train_loss: 0.57864 valid_loss: 0.77436\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[88/100] train_loss: 0.58240 valid_loss: 0.77416\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[89/100] train_loss: 0.83526 valid_loss: 0.77441\n",
      "EarlyStopping counter: 24 out of 100\n",
      "[90/100] train_loss: 0.73710 valid_loss: 0.77376\n",
      "EarlyStopping counter: 25 out of 100\n",
      "[91/100] train_loss: 0.67143 valid_loss: 0.77314\n",
      "EarlyStopping counter: 26 out of 100\n",
      "[92/100] train_loss: 0.70423 valid_loss: 0.77978\n",
      "EarlyStopping counter: 27 out of 100\n",
      "[93/100] train_loss: 0.82469 valid_loss: 0.78615\n",
      "EarlyStopping counter: 28 out of 100\n",
      "[94/100] train_loss: 0.80305 valid_loss: 0.79003\n",
      "EarlyStopping counter: 29 out of 100\n",
      "[95/100] train_loss: 0.73376 valid_loss: 0.79243\n",
      "EarlyStopping counter: 30 out of 100\n",
      "[96/100] train_loss: 0.80832 valid_loss: 0.79494\n",
      "EarlyStopping counter: 31 out of 100\n",
      "[97/100] train_loss: 0.71006 valid_loss: 0.79596\n",
      "EarlyStopping counter: 32 out of 100\n",
      "[98/100] train_loss: 0.60958 valid_loss: 0.80068\n",
      "EarlyStopping counter: 33 out of 100\n",
      "[99/100] train_loss: 0.75068 valid_loss: 0.80387\n",
      "EarlyStopping counter: 34 out of 100\n",
      "[100/100] train_loss: 0.57111 valid_loss: 0.80837\n",
      "EarlyStopping counter: 35 out of 100\n",
      "  Training 3/5 for Fold 7\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n",
      "[1/100] train_loss: 2.25880 valid_loss: 0.79209\n",
      "Validation loss decreased (inf --> 0.792092).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/100] train_loss: 0.77537 valid_loss: 0.78823\n",
      "Validation loss decreased (0.792092 --> 0.788233).  Saving model ...\n",
      "[3/100] train_loss: 2.19001 valid_loss: 0.78379\n",
      "Validation loss decreased (0.788233 --> 0.783786).  Saving model ...\n",
      "[4/100] train_loss: 2.15726 valid_loss: 0.77906\n",
      "Validation loss decreased (0.783786 --> 0.779061).  Saving model ...\n",
      "[5/100] train_loss: 1.04976 valid_loss: 0.77563\n",
      "Validation loss decreased (0.779061 --> 0.775635).  Saving model ...\n",
      "[6/100] train_loss: 0.71131 valid_loss: 0.77160\n",
      "Validation loss decreased (0.775635 --> 0.771598).  Saving model ...\n",
      "[7/100] train_loss: 1.04582 valid_loss: 0.76852\n",
      "Validation loss decreased (0.771598 --> 0.768516).  Saving model ...\n",
      "[8/100] train_loss: 0.80997 valid_loss: 0.76564\n",
      "Validation loss decreased (0.768516 --> 0.765641).  Saving model ...\n",
      "[9/100] train_loss: 0.69998 valid_loss: 0.76225\n",
      "Validation loss decreased (0.765641 --> 0.762251).  Saving model ...\n",
      "[10/100] train_loss: 0.97238 valid_loss: 0.75902\n",
      "Validation loss decreased (0.762251 --> 0.759016).  Saving model ...\n",
      "[11/100] train_loss: 0.96768 valid_loss: 0.75590\n",
      "Validation loss decreased (0.759016 --> 0.755899).  Saving model ...\n",
      "[12/100] train_loss: 1.97441 valid_loss: 0.75205\n",
      "Validation loss decreased (0.755899 --> 0.752052).  Saving model ...\n",
      "[13/100] train_loss: 0.68509 valid_loss: 0.74789\n",
      "Validation loss decreased (0.752052 --> 0.747890).  Saving model ...\n",
      "[14/100] train_loss: 0.80529 valid_loss: 0.74399\n",
      "Validation loss decreased (0.747890 --> 0.743990).  Saving model ...\n",
      "[15/100] train_loss: 0.94369 valid_loss: 0.74019\n",
      "Validation loss decreased (0.743990 --> 0.740191).  Saving model ...\n",
      "[16/100] train_loss: 1.88419 valid_loss: 0.73563\n",
      "Validation loss decreased (0.740191 --> 0.735632).  Saving model ...\n",
      "[17/100] train_loss: 0.80337 valid_loss: 0.73132\n",
      "Validation loss decreased (0.735632 --> 0.731321).  Saving model ...\n",
      "[18/100] train_loss: 0.92262 valid_loss: 0.72707\n",
      "Validation loss decreased (0.731321 --> 0.727065).  Saving model ...\n",
      "[19/100] train_loss: 1.03307 valid_loss: 0.72343\n",
      "Validation loss decreased (0.727065 --> 0.723433).  Saving model ...\n",
      "[20/100] train_loss: 0.80153 valid_loss: 0.71996\n",
      "Validation loss decreased (0.723433 --> 0.719961).  Saving model ...\n",
      "[21/100] train_loss: 0.80078 valid_loss: 0.71663\n",
      "Validation loss decreased (0.719961 --> 0.716633).  Saving model ...\n",
      "[22/100] train_loss: 1.73570 valid_loss: 0.71202\n",
      "Validation loss decreased (0.716633 --> 0.712016).  Saving model ...\n",
      "[23/100] train_loss: 0.74874 valid_loss: 0.70760\n",
      "Validation loss decreased (0.712016 --> 0.707597).  Saving model ...\n",
      "[24/100] train_loss: 0.79862 valid_loss: 0.70334\n",
      "Validation loss decreased (0.707597 --> 0.703337).  Saving model ...\n",
      "[25/100] train_loss: 0.79789 valid_loss: 0.69922\n",
      "Validation loss decreased (0.703337 --> 0.699222).  Saving model ...\n",
      "[26/100] train_loss: 1.02654 valid_loss: 0.69565\n",
      "Validation loss decreased (0.699222 --> 0.695648).  Saving model ...\n",
      "[27/100] train_loss: 0.74309 valid_loss: 0.69218\n",
      "Validation loss decreased (0.695648 --> 0.692180).  Saving model ...\n",
      "[28/100] train_loss: 1.57072 valid_loss: 0.68672\n",
      "Validation loss decreased (0.692180 --> 0.686723).  Saving model ...\n",
      "[29/100] train_loss: 1.53187 valid_loss: 0.67954\n",
      "Validation loss decreased (0.686723 --> 0.679542).  Saving model ...\n",
      "[30/100] train_loss: 1.01858 valid_loss: 0.67286\n",
      "Validation loss decreased (0.679542 --> 0.672864).  Saving model ...\n",
      "[31/100] train_loss: 1.01572 valid_loss: 0.66666\n",
      "Validation loss decreased (0.672864 --> 0.666662).  Saving model ...\n",
      "[32/100] train_loss: 0.79112 valid_loss: 0.66056\n",
      "Validation loss decreased (0.666662 --> 0.660557).  Saving model ...\n",
      "[33/100] train_loss: 1.33625 valid_loss: 0.65199\n",
      "Validation loss decreased (0.660557 --> 0.651993).  Saving model ...\n",
      "[34/100] train_loss: 1.27218 valid_loss: 0.64118\n",
      "Validation loss decreased (0.651993 --> 0.641175).  Saving model ...\n",
      "[35/100] train_loss: 1.19223 valid_loss: 0.62835\n",
      "Validation loss decreased (0.641175 --> 0.628349).  Saving model ...\n",
      "[36/100] train_loss: 0.99793 valid_loss: 0.61654\n",
      "Validation loss decreased (0.628349 --> 0.616543).  Saving model ...\n",
      "[37/100] train_loss: 0.78498 valid_loss: 0.60613\n",
      "Validation loss decreased (0.616543 --> 0.606134).  Saving model ...\n",
      "[38/100] train_loss: 0.78380 valid_loss: 0.59813\n",
      "Validation loss decreased (0.606134 --> 0.598126).  Saving model ...\n",
      "[39/100] train_loss: 0.72670 valid_loss: 0.59506\n",
      "Validation loss decreased (0.598126 --> 0.595059).  Saving model ...\n",
      "[40/100] train_loss: 0.84966 valid_loss: 0.59297\n",
      "Validation loss decreased (0.595059 --> 0.592969).  Saving model ...\n",
      "[41/100] train_loss: 0.70678 valid_loss: 0.59388\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[42/100] train_loss: 0.78067 valid_loss: 0.59806\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[43/100] train_loss: 0.59604 valid_loss: 0.60759\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[44/100] train_loss: 0.58829 valid_loss: 0.62299\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[45/100] train_loss: 0.69044 valid_loss: 0.64519\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[46/100] train_loss: 0.68495 valid_loss: 0.67451\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[47/100] train_loss: 0.78326 valid_loss: 0.70224\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[48/100] train_loss: 0.78580 valid_loss: 0.72238\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[49/100] train_loss: 0.94869 valid_loss: 0.74201\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[50/100] train_loss: 0.66839 valid_loss: 0.76336\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[51/100] train_loss: 1.37341 valid_loss: 0.71507\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[52/100] train_loss: 0.76962 valid_loss: 0.67384\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[53/100] train_loss: 0.75916 valid_loss: 0.63957\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[54/100] train_loss: 0.74600 valid_loss: 0.61387\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[55/100] train_loss: 0.76020 valid_loss: 0.59738\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[56/100] train_loss: 0.72202 valid_loss: 0.58735\n",
      "Validation loss decreased (0.592969 --> 0.587353).  Saving model ...\n",
      "[57/100] train_loss: 0.76136 valid_loss: 0.58212\n",
      "Validation loss decreased (0.587353 --> 0.582120).  Saving model ...\n",
      "[58/100] train_loss: 0.89693 valid_loss: 0.57972\n",
      "Validation loss decreased (0.582120 --> 0.579722).  Saving model ...\n",
      "[59/100] train_loss: 0.89214 valid_loss: 0.57918\n",
      "Validation loss decreased (0.579722 --> 0.579178).  Saving model ...\n",
      "[60/100] train_loss: 0.92568 valid_loss: 0.58241\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[61/100] train_loss: 0.88200 valid_loss: 0.58962\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[62/100] train_loss: 0.76749 valid_loss: 0.59800\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[63/100] train_loss: 0.72822 valid_loss: 0.60505\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[64/100] train_loss: 0.72342 valid_loss: 0.61187\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[65/100] train_loss: 0.72521 valid_loss: 0.61834\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[66/100] train_loss: 0.74812 valid_loss: 0.62987\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[67/100] train_loss: 0.72600 valid_loss: 0.64041\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[68/100] train_loss: 0.65352 valid_loss: 0.64714\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[69/100] train_loss: 0.72199 valid_loss: 0.65331\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[70/100] train_loss: 0.64713 valid_loss: 0.65662\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[71/100] train_loss: 0.69154 valid_loss: 0.66371\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[72/100] train_loss: 0.70545 valid_loss: 0.67010\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[73/100] train_loss: 0.79048 valid_loss: 0.67370\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[74/100] train_loss: 0.78098 valid_loss: 0.67499\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[75/100] train_loss: 0.60464 valid_loss: 0.67515\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[76/100] train_loss: 0.70207 valid_loss: 0.68030\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[77/100] train_loss: 0.73322 valid_loss: 0.68377\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[78/100] train_loss: 0.86097 valid_loss: 0.68730\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[79/100] train_loss: 0.59889 valid_loss: 0.69089\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[80/100] train_loss: 0.65530 valid_loss: 0.69386\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[81/100] train_loss: 0.76008 valid_loss: 0.69584\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[82/100] train_loss: 0.65571 valid_loss: 0.69728\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[83/100] train_loss: 0.61403 valid_loss: 0.69946\n",
      "EarlyStopping counter: 24 out of 100\n",
      "[84/100] train_loss: 0.67905 valid_loss: 0.70109\n",
      "EarlyStopping counter: 25 out of 100\n",
      "[85/100] train_loss: 0.74625 valid_loss: 0.70965\n",
      "EarlyStopping counter: 26 out of 100\n",
      "[86/100] train_loss: 0.64516 valid_loss: 0.71667\n",
      "EarlyStopping counter: 27 out of 100\n",
      "[87/100] train_loss: 0.70235 valid_loss: 0.72800\n",
      "EarlyStopping counter: 28 out of 100\n",
      "[88/100] train_loss: 0.69005 valid_loss: 0.73708\n",
      "EarlyStopping counter: 29 out of 100\n",
      "[89/100] train_loss: 0.83611 valid_loss: 0.74514\n",
      "EarlyStopping counter: 30 out of 100\n",
      "[90/100] train_loss: 0.83309 valid_loss: 0.75243\n",
      "EarlyStopping counter: 31 out of 100\n",
      "[91/100] train_loss: 0.82912 valid_loss: 0.75916\n",
      "EarlyStopping counter: 32 out of 100\n",
      "[92/100] train_loss: 0.57107 valid_loss: 0.76480\n",
      "EarlyStopping counter: 33 out of 100\n",
      "[93/100] train_loss: 0.60840 valid_loss: 0.77168\n",
      "EarlyStopping counter: 34 out of 100\n",
      "[94/100] train_loss: 0.77477 valid_loss: 0.77710\n",
      "EarlyStopping counter: 35 out of 100\n",
      "[95/100] train_loss: 0.57642 valid_loss: 0.78159\n",
      "EarlyStopping counter: 36 out of 100\n",
      "[96/100] train_loss: 0.71315 valid_loss: 0.78511\n",
      "EarlyStopping counter: 37 out of 100\n",
      "[97/100] train_loss: 0.69687 valid_loss: 0.78795\n",
      "EarlyStopping counter: 38 out of 100\n",
      "[98/100] train_loss: 0.66571 valid_loss: 0.79094\n",
      "EarlyStopping counter: 39 out of 100\n",
      "[99/100] train_loss: 0.65765 valid_loss: 0.79368\n",
      "EarlyStopping counter: 40 out of 100\n",
      "[100/100] train_loss: 0.63572 valid_loss: 0.79657\n",
      "EarlyStopping counter: 41 out of 100\n",
      "  Training 4/5 for Fold 7\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n",
      "[1/100] train_loss: 2.26480 valid_loss: 0.81924\n",
      "Validation loss decreased (inf --> 0.819236).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/100] train_loss: 1.01966 valid_loss: 0.81498\n",
      "Validation loss decreased (0.819236 --> 0.814979).  Saving model ...\n",
      "[3/100] train_loss: 0.80783 valid_loss: 0.81141\n",
      "Validation loss decreased (0.814979 --> 0.811411).  Saving model ...\n",
      "[4/100] train_loss: 0.98981 valid_loss: 0.80917\n",
      "Validation loss decreased (0.811411 --> 0.809167).  Saving model ...\n",
      "[5/100] train_loss: 0.99624 valid_loss: 0.80712\n",
      "Validation loss decreased (0.809167 --> 0.807116).  Saving model ...\n",
      "[6/100] train_loss: 0.99027 valid_loss: 0.80516\n",
      "Validation loss decreased (0.807116 --> 0.805164).  Saving model ...\n",
      "[7/100] train_loss: 2.11158 valid_loss: 0.80193\n",
      "Validation loss decreased (0.805164 --> 0.801929).  Saving model ...\n",
      "[8/100] train_loss: 0.97559 valid_loss: 0.79895\n",
      "Validation loss decreased (0.801929 --> 0.798948).  Saving model ...\n",
      "[9/100] train_loss: 0.77169 valid_loss: 0.79628\n",
      "Validation loss decreased (0.798948 --> 0.796283).  Saving model ...\n",
      "[10/100] train_loss: 2.03819 valid_loss: 0.79267\n",
      "Validation loss decreased (0.796283 --> 0.792674).  Saving model ...\n",
      "[11/100] train_loss: 0.99627 valid_loss: 0.78974\n",
      "Validation loss decreased (0.792674 --> 0.789741).  Saving model ...\n",
      "[12/100] train_loss: 0.94496 valid_loss: 0.78696\n",
      "Validation loss decreased (0.789741 --> 0.786959).  Saving model ...\n",
      "[13/100] train_loss: 0.93782 valid_loss: 0.78429\n",
      "Validation loss decreased (0.786959 --> 0.784291).  Saving model ...\n",
      "[14/100] train_loss: 0.68579 valid_loss: 0.78117\n",
      "Validation loss decreased (0.784291 --> 0.781174).  Saving model ...\n",
      "[15/100] train_loss: 0.76301 valid_loss: 0.77830\n",
      "Validation loss decreased (0.781174 --> 0.778303).  Saving model ...\n",
      "[16/100] train_loss: 0.76162 valid_loss: 0.77565\n",
      "Validation loss decreased (0.778303 --> 0.775651).  Saving model ...\n",
      "[17/100] train_loss: 0.90860 valid_loss: 0.77304\n",
      "Validation loss decreased (0.775651 --> 0.773045).  Saving model ...\n",
      "[18/100] train_loss: 1.00322 valid_loss: 0.77095\n",
      "Validation loss decreased (0.773045 --> 0.770945).  Saving model ...\n",
      "[19/100] train_loss: 0.89453 valid_loss: 0.76880\n",
      "Validation loss decreased (0.770945 --> 0.768800).  Saving model ...\n",
      "[20/100] train_loss: 1.00313 valid_loss: 0.76707\n",
      "Validation loss decreased (0.768800 --> 0.767070).  Saving model ...\n",
      "[21/100] train_loss: 0.66336 valid_loss: 0.76479\n",
      "Validation loss decreased (0.767070 --> 0.764794).  Saving model ...\n",
      "[22/100] train_loss: 0.87502 valid_loss: 0.76242\n",
      "Validation loss decreased (0.764794 --> 0.762420).  Saving model ...\n",
      "[23/100] train_loss: 0.86745 valid_loss: 0.75992\n",
      "Validation loss decreased (0.762420 --> 0.759925).  Saving model ...\n",
      "[24/100] train_loss: 0.99872 valid_loss: 0.75782\n",
      "Validation loss decreased (0.759925 --> 0.757817).  Saving model ...\n",
      "[25/100] train_loss: 0.64996 valid_loss: 0.75514\n",
      "Validation loss decreased (0.757817 --> 0.755138).  Saving model ...\n",
      "[26/100] train_loss: 0.74748 valid_loss: 0.75254\n",
      "Validation loss decreased (0.755138 --> 0.752540).  Saving model ...\n",
      "[27/100] train_loss: 1.61205 valid_loss: 0.74819\n",
      "Validation loss decreased (0.752540 --> 0.748193).  Saving model ...\n",
      "[28/100] train_loss: 0.74388 valid_loss: 0.74394\n",
      "Validation loss decreased (0.748193 --> 0.743945).  Saving model ...\n",
      "[29/100] train_loss: 0.79334 valid_loss: 0.73978\n",
      "Validation loss decreased (0.743945 --> 0.739783).  Saving model ...\n",
      "[30/100] train_loss: 0.80108 valid_loss: 0.73533\n",
      "Validation loss decreased (0.739783 --> 0.735328).  Saving model ...\n",
      "[31/100] train_loss: 0.79150 valid_loss: 0.73093\n",
      "Validation loss decreased (0.735328 --> 0.730930).  Saving model ...\n",
      "[32/100] train_loss: 0.98658 valid_loss: 0.72698\n",
      "Validation loss decreased (0.730930 --> 0.726976).  Saving model ...\n",
      "[33/100] train_loss: 1.34943 valid_loss: 0.72047\n",
      "Validation loss decreased (0.726976 --> 0.720472).  Saving model ...\n",
      "[34/100] train_loss: 0.98027 valid_loss: 0.71429\n",
      "Validation loss decreased (0.720472 --> 0.714289).  Saving model ...\n",
      "[35/100] train_loss: 1.22633 valid_loss: 0.70537\n",
      "Validation loss decreased (0.714289 --> 0.705369).  Saving model ...\n",
      "[36/100] train_loss: 0.61934 valid_loss: 0.69667\n",
      "Validation loss decreased (0.705369 --> 0.696671).  Saving model ...\n",
      "[37/100] train_loss: 0.72120 valid_loss: 0.68760\n",
      "Validation loss decreased (0.696671 --> 0.687601).  Saving model ...\n",
      "[38/100] train_loss: 1.02024 valid_loss: 0.67500\n",
      "Validation loss decreased (0.687601 --> 0.675001).  Saving model ...\n",
      "[39/100] train_loss: 0.78033 valid_loss: 0.66157\n",
      "Validation loss decreased (0.675001 --> 0.661572).  Saving model ...\n",
      "[40/100] train_loss: 0.89077 valid_loss: 0.64421\n",
      "Validation loss decreased (0.661572 --> 0.644208).  Saving model ...\n",
      "[41/100] train_loss: 0.94767 valid_loss: 0.62632\n",
      "Validation loss decreased (0.644208 --> 0.626321).  Saving model ...\n",
      "[42/100] train_loss: 0.79281 valid_loss: 0.62106\n",
      "Validation loss decreased (0.626321 --> 0.621059).  Saving model ...\n",
      "[43/100] train_loss: 0.61080 valid_loss: 0.61720\n",
      "Validation loss decreased (0.621059 --> 0.617204).  Saving model ...\n",
      "[44/100] train_loss: 0.77184 valid_loss: 0.61336\n",
      "Validation loss decreased (0.617204 --> 0.613357).  Saving model ...\n",
      "[45/100] train_loss: 0.92101 valid_loss: 0.60983\n",
      "Validation loss decreased (0.613357 --> 0.609834).  Saving model ...\n",
      "[46/100] train_loss: 0.91218 valid_loss: 0.60656\n",
      "Validation loss decreased (0.609834 --> 0.606564).  Saving model ...\n",
      "[47/100] train_loss: 0.90147 valid_loss: 0.60348\n",
      "Validation loss decreased (0.606564 --> 0.603476).  Saving model ...\n",
      "[48/100] train_loss: 0.69919 valid_loss: 0.60096\n",
      "Validation loss decreased (0.603476 --> 0.600964).  Saving model ...\n",
      "[49/100] train_loss: 0.87725 valid_loss: 0.59848\n",
      "Validation loss decreased (0.600964 --> 0.598480).  Saving model ...\n",
      "[50/100] train_loss: 0.63770 valid_loss: 0.60013\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[51/100] train_loss: 0.76668 valid_loss: 0.60082\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[52/100] train_loss: 0.71910 valid_loss: 0.60117\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[53/100] train_loss: 0.69027 valid_loss: 0.60083\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[54/100] train_loss: 0.60463 valid_loss: 0.60365\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[55/100] train_loss: 0.77262 valid_loss: 0.60545\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[56/100] train_loss: 0.95275 valid_loss: 0.62181\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[57/100] train_loss: 0.71554 valid_loss: 0.63626\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[58/100] train_loss: 0.71820 valid_loss: 0.64760\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[59/100] train_loss: 0.80753 valid_loss: 0.66630\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[60/100] train_loss: 0.75465 valid_loss: 0.68769\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[61/100] train_loss: 0.76841 valid_loss: 0.70305\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[62/100] train_loss: 0.66887 valid_loss: 0.71903\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[63/100] train_loss: 0.81023 valid_loss: 0.73215\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[64/100] train_loss: 0.74037 valid_loss: 0.74323\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[65/100] train_loss: 0.88763 valid_loss: 0.75101\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[66/100] train_loss: 0.74206 valid_loss: 0.75802\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[67/100] train_loss: 0.80657 valid_loss: 0.76449\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[68/100] train_loss: 0.90589 valid_loss: 0.76893\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[69/100] train_loss: 0.72009 valid_loss: 0.77269\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[70/100] train_loss: 0.70262 valid_loss: 0.77591\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[71/100] train_loss: 0.72826 valid_loss: 0.77923\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[72/100] train_loss: 0.79706 valid_loss: 0.78277\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[73/100] train_loss: 0.79481 valid_loss: 0.78654\n",
      "EarlyStopping counter: 24 out of 100\n",
      "[74/100] train_loss: 0.70528 valid_loss: 0.79049\n",
      "EarlyStopping counter: 25 out of 100\n",
      "[75/100] train_loss: 0.60176 valid_loss: 0.79433\n",
      "EarlyStopping counter: 26 out of 100\n",
      "[76/100] train_loss: 0.59235 valid_loss: 0.79807\n",
      "EarlyStopping counter: 27 out of 100\n",
      "[77/100] train_loss: 0.65411 valid_loss: 0.80511\n",
      "EarlyStopping counter: 28 out of 100\n",
      "[78/100] train_loss: 0.58937 valid_loss: 0.81156\n",
      "EarlyStopping counter: 29 out of 100\n",
      "[79/100] train_loss: 0.59044 valid_loss: 0.81733\n",
      "EarlyStopping counter: 30 out of 100\n",
      "[80/100] train_loss: 0.69297 valid_loss: 0.82274\n",
      "EarlyStopping counter: 31 out of 100\n",
      "[81/100] train_loss: 0.77588 valid_loss: 0.82829\n",
      "EarlyStopping counter: 32 out of 100\n",
      "[82/100] train_loss: 0.77283 valid_loss: 0.83402\n",
      "EarlyStopping counter: 33 out of 100\n",
      "[83/100] train_loss: 0.67878 valid_loss: 0.83950\n",
      "EarlyStopping counter: 34 out of 100\n",
      "[84/100] train_loss: 0.67618 valid_loss: 0.84859\n",
      "EarlyStopping counter: 35 out of 100\n",
      "[85/100] train_loss: 0.66046 valid_loss: 0.85999\n",
      "EarlyStopping counter: 36 out of 100\n",
      "[86/100] train_loss: 0.59753 valid_loss: 0.86899\n",
      "EarlyStopping counter: 37 out of 100\n",
      "[87/100] train_loss: 0.67475 valid_loss: 0.87692\n",
      "EarlyStopping counter: 38 out of 100\n",
      "[88/100] train_loss: 0.80321 valid_loss: 0.88222\n",
      "EarlyStopping counter: 39 out of 100\n",
      "[89/100] train_loss: 0.80416 valid_loss: 0.88532\n",
      "EarlyStopping counter: 40 out of 100\n",
      "[90/100] train_loss: 0.58516 valid_loss: 0.88860\n",
      "EarlyStopping counter: 41 out of 100\n",
      "[91/100] train_loss: 0.56846 valid_loss: 0.89159\n",
      "EarlyStopping counter: 42 out of 100\n",
      "[92/100] train_loss: 0.68459 valid_loss: 0.89458\n",
      "EarlyStopping counter: 43 out of 100\n",
      "[93/100] train_loss: 0.66780 valid_loss: 0.89800\n",
      "EarlyStopping counter: 44 out of 100\n",
      "[94/100] train_loss: 0.56608 valid_loss: 0.90129\n",
      "EarlyStopping counter: 45 out of 100\n",
      "[95/100] train_loss: 0.75393 valid_loss: 0.90488\n",
      "EarlyStopping counter: 46 out of 100\n",
      "[96/100] train_loss: 0.75242 valid_loss: 0.90877\n",
      "EarlyStopping counter: 47 out of 100\n",
      "[97/100] train_loss: 0.80647 valid_loss: 0.91082\n",
      "EarlyStopping counter: 48 out of 100\n",
      "[98/100] train_loss: 0.74874 valid_loss: 0.91331\n",
      "EarlyStopping counter: 49 out of 100\n",
      "[99/100] train_loss: 0.74658 valid_loss: 0.91619\n",
      "EarlyStopping counter: 50 out of 100\n",
      "[100/100] train_loss: 0.58981 valid_loss: 0.91813\n",
      "EarlyStopping counter: 51 out of 100\n",
      "  Training 5/5 for Fold 7\n",
      "RNN(\n",
      "  (rnn): LSTM(5, 64, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n",
      "[1/100] train_loss: 1.02986 valid_loss: 0.83413\n",
      "Validation loss decreased (inf --> 0.834128).  Saving model ...\n",
      "[2/100] train_loss: 1.01543 valid_loss: 0.83226\n",
      "Validation loss decreased (0.834128 --> 0.832263).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\anaconda3\\envs\\torch_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/100] train_loss: 0.99977 valid_loss: 0.83079\n",
      "Validation loss decreased (0.832263 --> 0.830795).  Saving model ...\n",
      "[4/100] train_loss: 0.99827 valid_loss: 0.82983\n",
      "Validation loss decreased (0.830795 --> 0.829826).  Saving model ...\n",
      "[5/100] train_loss: 0.99121 valid_loss: 0.82854\n",
      "Validation loss decreased (0.829826 --> 0.828543).  Saving model ...\n",
      "[6/100] train_loss: 0.99093 valid_loss: 0.82758\n",
      "Validation loss decreased (0.828543 --> 0.827581).  Saving model ...\n",
      "[7/100] train_loss: 0.79720 valid_loss: 0.82640\n",
      "Validation loss decreased (0.827581 --> 0.826404).  Saving model ...\n",
      "[8/100] train_loss: 0.97842 valid_loss: 0.82504\n",
      "Validation loss decreased (0.826404 --> 0.825045).  Saving model ...\n",
      "[9/100] train_loss: 0.79482 valid_loss: 0.82355\n",
      "Validation loss decreased (0.825045 --> 0.823546).  Saving model ...\n",
      "[10/100] train_loss: 0.70607 valid_loss: 0.82070\n",
      "Validation loss decreased (0.823546 --> 0.820696).  Saving model ...\n",
      "[11/100] train_loss: 0.70174 valid_loss: 0.81680\n",
      "Validation loss decreased (0.820696 --> 0.816804).  Saving model ...\n",
      "[12/100] train_loss: 0.79114 valid_loss: 0.81312\n",
      "Validation loss decreased (0.816804 --> 0.813124).  Saving model ...\n",
      "[13/100] train_loss: 0.78989 valid_loss: 0.80962\n",
      "Validation loss decreased (0.813124 --> 0.809621).  Saving model ...\n",
      "[14/100] train_loss: 0.94510 valid_loss: 0.80624\n",
      "Validation loss decreased (0.809621 --> 0.806238).  Saving model ...\n",
      "[15/100] train_loss: 0.78736 valid_loss: 0.80296\n",
      "Validation loss decreased (0.806238 --> 0.802963).  Saving model ...\n",
      "[16/100] train_loss: 2.08015 valid_loss: 0.79870\n",
      "Validation loss decreased (0.802963 --> 0.798698).  Saving model ...\n",
      "[17/100] train_loss: 0.78498 valid_loss: 0.79464\n",
      "Validation loss decreased (0.798698 --> 0.794637).  Saving model ...\n",
      "[18/100] train_loss: 0.91271 valid_loss: 0.79074\n",
      "Validation loss decreased (0.794637 --> 0.790742).  Saving model ...\n",
      "[19/100] train_loss: 0.90243 valid_loss: 0.78694\n",
      "Validation loss decreased (0.790742 --> 0.786937).  Saving model ...\n",
      "[20/100] train_loss: 0.89052 valid_loss: 0.78316\n",
      "Validation loss decreased (0.786937 --> 0.783161).  Saving model ...\n",
      "[21/100] train_loss: 0.78043 valid_loss: 0.77948\n",
      "Validation loss decreased (0.783161 --> 0.779481).  Saving model ...\n",
      "[22/100] train_loss: 1.91225 valid_loss: 0.77463\n",
      "Validation loss decreased (0.779481 --> 0.774634).  Saving model ...\n",
      "[23/100] train_loss: 0.84889 valid_loss: 0.76981\n",
      "Validation loss decreased (0.774634 --> 0.769809).  Saving model ...\n",
      "[24/100] train_loss: 0.99744 valid_loss: 0.76544\n",
      "Validation loss decreased (0.769809 --> 0.765443).  Saving model ...\n",
      "[25/100] train_loss: 0.73155 valid_loss: 0.76118\n",
      "Validation loss decreased (0.765443 --> 0.761176).  Saving model ...\n",
      "[26/100] train_loss: 0.80337 valid_loss: 0.75673\n",
      "Validation loss decreased (0.761176 --> 0.756733).  Saving model ...\n",
      "[27/100] train_loss: 0.78645 valid_loss: 0.75202\n",
      "Validation loss decreased (0.756733 --> 0.752023).  Saving model ...\n",
      "[28/100] train_loss: 0.77239 valid_loss: 0.74738\n",
      "Validation loss decreased (0.752023 --> 0.747379).  Saving model ...\n",
      "[29/100] train_loss: 0.72439 valid_loss: 0.74265\n",
      "Validation loss decreased (0.747379 --> 0.742654).  Saving model ...\n",
      "[30/100] train_loss: 0.72347 valid_loss: 0.73783\n",
      "Validation loss decreased (0.742654 --> 0.737826).  Saving model ...\n",
      "[31/100] train_loss: 0.76910 valid_loss: 0.73309\n",
      "Validation loss decreased (0.737826 --> 0.733094).  Saving model ...\n",
      "[32/100] train_loss: 0.76804 valid_loss: 0.72847\n",
      "Validation loss decreased (0.733094 --> 0.728466).  Saving model ...\n",
      "[33/100] train_loss: 1.42296 valid_loss: 0.72144\n",
      "Validation loss decreased (0.728466 --> 0.721441).  Saving model ...\n",
      "[34/100] train_loss: 0.58339 valid_loss: 0.71449\n",
      "Validation loss decreased (0.721441 --> 0.714495).  Saving model ...\n",
      "[35/100] train_loss: 1.30584 valid_loss: 0.70529\n",
      "Validation loss decreased (0.714495 --> 0.705292).  Saving model ...\n",
      "[36/100] train_loss: 0.62431 valid_loss: 0.69523\n",
      "Validation loss decreased (0.705292 --> 0.695227).  Saving model ...\n",
      "[37/100] train_loss: 0.75722 valid_loss: 0.68596\n",
      "Validation loss decreased (0.695227 --> 0.685961).  Saving model ...\n",
      "[38/100] train_loss: 0.61144 valid_loss: 0.67720\n",
      "Validation loss decreased (0.685961 --> 0.677197).  Saving model ...\n",
      "[39/100] train_loss: 0.76948 valid_loss: 0.66957\n",
      "Validation loss decreased (0.677197 --> 0.669572).  Saving model ...\n",
      "[40/100] train_loss: 0.76936 valid_loss: 0.66329\n",
      "Validation loss decreased (0.669572 --> 0.663292).  Saving model ...\n",
      "[41/100] train_loss: 0.76841 valid_loss: 0.65848\n",
      "Validation loss decreased (0.663292 --> 0.658479).  Saving model ...\n",
      "[42/100] train_loss: 0.68306 valid_loss: 0.66487\n",
      "EarlyStopping counter: 1 out of 100\n",
      "[43/100] train_loss: 0.66427 valid_loss: 0.67701\n",
      "EarlyStopping counter: 2 out of 100\n",
      "[44/100] train_loss: 0.75980 valid_loss: 0.68751\n",
      "EarlyStopping counter: 3 out of 100\n",
      "[45/100] train_loss: 0.98282 valid_loss: 0.69494\n",
      "EarlyStopping counter: 4 out of 100\n",
      "[46/100] train_loss: 0.59939 valid_loss: 0.70421\n",
      "EarlyStopping counter: 5 out of 100\n",
      "[47/100] train_loss: 0.96012 valid_loss: 0.71043\n",
      "EarlyStopping counter: 6 out of 100\n",
      "[48/100] train_loss: 0.59423 valid_loss: 0.71546\n",
      "EarlyStopping counter: 7 out of 100\n",
      "[49/100] train_loss: 0.59447 valid_loss: 0.71951\n",
      "EarlyStopping counter: 8 out of 100\n",
      "[50/100] train_loss: 0.99916 valid_loss: 0.72336\n",
      "EarlyStopping counter: 9 out of 100\n",
      "[51/100] train_loss: 0.59164 valid_loss: 0.72642\n",
      "EarlyStopping counter: 10 out of 100\n",
      "[52/100] train_loss: 0.84578 valid_loss: 0.72770\n",
      "EarlyStopping counter: 11 out of 100\n",
      "[53/100] train_loss: 0.70647 valid_loss: 0.72836\n",
      "EarlyStopping counter: 12 out of 100\n",
      "[54/100] train_loss: 0.75333 valid_loss: 0.72892\n",
      "EarlyStopping counter: 13 out of 100\n",
      "[55/100] train_loss: 0.58575 valid_loss: 0.72935\n",
      "EarlyStopping counter: 14 out of 100\n",
      "[56/100] train_loss: 0.75141 valid_loss: 0.72965\n",
      "EarlyStopping counter: 15 out of 100\n",
      "[57/100] train_loss: 0.62093 valid_loss: 0.73478\n",
      "EarlyStopping counter: 16 out of 100\n",
      "[58/100] train_loss: 0.72090 valid_loss: 0.73886\n",
      "EarlyStopping counter: 17 out of 100\n",
      "[59/100] train_loss: 0.94622 valid_loss: 0.74262\n",
      "EarlyStopping counter: 18 out of 100\n",
      "[60/100] train_loss: 0.58691 valid_loss: 0.74596\n",
      "EarlyStopping counter: 19 out of 100\n",
      "[61/100] train_loss: 0.93029 valid_loss: 0.74901\n",
      "EarlyStopping counter: 20 out of 100\n",
      "[62/100] train_loss: 0.67797 valid_loss: 0.75129\n",
      "EarlyStopping counter: 21 out of 100\n",
      "[63/100] train_loss: 0.59416 valid_loss: 0.75634\n",
      "EarlyStopping counter: 22 out of 100\n",
      "[64/100] train_loss: 0.57406 valid_loss: 0.76056\n",
      "EarlyStopping counter: 23 out of 100\n",
      "[65/100] train_loss: 0.57370 valid_loss: 0.76408\n",
      "EarlyStopping counter: 24 out of 100\n",
      "[66/100] train_loss: 0.88771 valid_loss: 0.76732\n",
      "EarlyStopping counter: 25 out of 100\n",
      "[67/100] train_loss: 0.67141 valid_loss: 0.76990\n",
      "EarlyStopping counter: 26 out of 100\n",
      "[68/100] train_loss: 0.67113 valid_loss: 0.77253\n",
      "EarlyStopping counter: 27 out of 100\n",
      "[69/100] train_loss: 0.65578 valid_loss: 0.77482\n",
      "EarlyStopping counter: 28 out of 100\n",
      "[70/100] train_loss: 0.66781 valid_loss: 0.77730\n",
      "EarlyStopping counter: 29 out of 100\n",
      "[71/100] train_loss: 0.63829 valid_loss: 0.77975\n",
      "EarlyStopping counter: 30 out of 100\n",
      "[72/100] train_loss: 0.85122 valid_loss: 0.78210\n",
      "EarlyStopping counter: 31 out of 100\n",
      "[73/100] train_loss: 0.57547 valid_loss: 0.78742\n",
      "EarlyStopping counter: 32 out of 100\n",
      "[74/100] train_loss: 0.84045 valid_loss: 0.79232\n",
      "EarlyStopping counter: 33 out of 100\n",
      "[75/100] train_loss: 0.56130 valid_loss: 0.79623\n",
      "EarlyStopping counter: 34 out of 100\n",
      "[76/100] train_loss: 0.75690 valid_loss: 0.79932\n",
      "EarlyStopping counter: 35 out of 100\n",
      "[77/100] train_loss: 0.82249 valid_loss: 0.80219\n",
      "EarlyStopping counter: 36 out of 100\n",
      "[78/100] train_loss: 0.56481 valid_loss: 0.80445\n",
      "EarlyStopping counter: 37 out of 100\n",
      "[79/100] train_loss: 0.55805 valid_loss: 0.80688\n",
      "EarlyStopping counter: 38 out of 100\n",
      "[80/100] train_loss: 0.60417 valid_loss: 0.80948\n",
      "EarlyStopping counter: 39 out of 100\n",
      "[81/100] train_loss: 0.80147 valid_loss: 0.81198\n",
      "EarlyStopping counter: 40 out of 100\n",
      "[82/100] train_loss: 0.54343 valid_loss: 0.81434\n",
      "EarlyStopping counter: 41 out of 100\n",
      "[83/100] train_loss: 0.76502 valid_loss: 0.81595\n",
      "EarlyStopping counter: 42 out of 100\n",
      "[84/100] train_loss: 0.55618 valid_loss: 0.81735\n",
      "EarlyStopping counter: 43 out of 100\n",
      "[85/100] train_loss: 0.78427 valid_loss: 0.81878\n",
      "EarlyStopping counter: 44 out of 100\n",
      "[86/100] train_loss: 0.55174 valid_loss: 0.81932\n",
      "EarlyStopping counter: 45 out of 100\n",
      "[87/100] train_loss: 0.53766 valid_loss: 0.81946\n",
      "EarlyStopping counter: 46 out of 100\n",
      "[88/100] train_loss: 0.55148 valid_loss: 0.81899\n",
      "EarlyStopping counter: 47 out of 100\n",
      "[89/100] train_loss: 0.55444 valid_loss: 0.81932\n",
      "EarlyStopping counter: 48 out of 100\n",
      "[90/100] train_loss: 0.54684 valid_loss: 0.81917\n",
      "EarlyStopping counter: 49 out of 100\n",
      "[91/100] train_loss: 0.70009 valid_loss: 0.82036\n",
      "EarlyStopping counter: 50 out of 100\n",
      "[92/100] train_loss: 0.54292 valid_loss: 0.82372\n",
      "EarlyStopping counter: 51 out of 100\n",
      "[93/100] train_loss: 0.54338 valid_loss: 0.83000\n",
      "EarlyStopping counter: 52 out of 100\n",
      "[94/100] train_loss: 0.67690 valid_loss: 0.83625\n",
      "EarlyStopping counter: 53 out of 100\n",
      "[95/100] train_loss: 0.65760 valid_loss: 0.84311\n",
      "EarlyStopping counter: 54 out of 100\n",
      "[96/100] train_loss: 0.75896 valid_loss: 0.84942\n",
      "EarlyStopping counter: 55 out of 100\n",
      "[97/100] train_loss: 0.76809 valid_loss: 0.85419\n",
      "EarlyStopping counter: 56 out of 100\n",
      "[98/100] train_loss: 0.56769 valid_loss: 0.85747\n",
      "EarlyStopping counter: 57 out of 100\n",
      "[99/100] train_loss: 0.63295 valid_loss: 0.86050\n",
      "EarlyStopping counter: 58 out of 100\n",
      "[100/100] train_loss: 0.62016 valid_loss: 0.86323\n",
      "EarlyStopping counter: 59 out of 100\n"
     ]
    }
   ],
   "source": [
    "y_glob = []  # Will be a list of lists: shape (n_folds, n_repeats_per_fold)\n",
    "sc_y_glob = []\n",
    "\n",
    "all_val_preds = []  # list of length n_folds, each item is (5, n_samples, 36, 3)\n",
    "val_targets = None\n",
    "\n",
    "for fold, (train_idx_A, val_idx_A) in enumerate(cv.split(x_train)):\n",
    "    \n",
    "    print(f\"  Fold {fold + 1}/{k}\")\n",
    "\n",
    "    # Create TensorDatasets and DataLoaders\n",
    "    train_datasetA = TensorDataset(x_train[train_idx_A], y_train[train_idx_A])\n",
    "    val_datasetA = TensorDataset(x_train[val_idx_A], y_train[val_idx_A])\n",
    "    train_loader = DataLoader(train_datasetA, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_datasetA, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Select collocation data for this fold\n",
    "    X_collocation_train_fold = x_collocation_train\n",
    "\n",
    "    fold_errors = []\n",
    "    sc_fold_errors = []\n",
    "\n",
    "    for i in range(5):  # Repeat training to observe variability\n",
    "        model_PINN = RNN(5, 3, 64, 1).to(device)\n",
    "        print(f\"  Training {i+1}/5 for Fold {fold+1}\")\n",
    "        print(model_PINN)\n",
    "\n",
    "        n_epochs = 100\n",
    "        patience = 100\n",
    "\n",
    "        model_PINN, train_loss, valid_loss, test_error, mean_scaled, predictions, targets = train_model(\n",
    "            model_PINN, patience, n_epochs, \n",
    "            X_collocation_train_fold)\n",
    "\n",
    "        fold_errors.append(test_error)\n",
    "        sc_fold_errors.append(mean_scaled)\n",
    "        \n",
    "        if i == 0:\n",
    "            val_preds_fold = [predictions]\n",
    "        else:\n",
    "            val_preds_fold.append(predictions)\n",
    "\n",
    "    y_glob.append(fold_errors)  # Mean Squared Errors\n",
    "    sc_y_glob.append(sc_fold_errors) # Scaled Average Errors\n",
    "    \n",
    "    val_preds_fold = np.stack(val_preds_fold, axis=0)  # shape: (5, n_samples, 36, 3)\n",
    "    all_val_preds.append(val_preds_fold)\n",
    "\n",
    "    if fold == 0:  # Only store ground truth once\n",
    "        val_targets = targets\n",
    "\n",
    "\n",
    "# Convert to NumPy array for easier processing\n",
    "y_glob = np.array(y_glob)  # shape: (n_folds, 5)\n",
    "sc_y_glob = np.array(sc_y_glob)  # shape: (n_folds, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2c8a67-738d-476a-8821-bd11e93e71a2",
   "metadata": {},
   "source": [
    "# VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "271acd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 5)\n",
      "(7, 5, 2)\n"
     ]
    }
   ],
   "source": [
    "print(y_glob.shape)\n",
    "print(sc_y_glob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f3c59b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Summary for Output 1 ===\n",
      "Per-Fold Means: [0.19387229 0.17396378 0.17840112 0.18353649 0.17435881 0.18267033\n",
      " 0.18206093]\n",
      "Per-Fold Std Devs: [0.00683672 0.00522853 0.00742351 0.00801922 0.00588637 0.0031258\n",
      " 0.00676649]\n",
      "Overall Mean: 0.1813, Overall Std: 0.0089\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary Statistics (per training run):\n",
      "          Run_1     Run_2     Run_3     Run_4     Run_5  Fold_Mean  Fold_Std\n",
      "count  7.000000  7.000000  7.000000  7.000000  7.000000   7.000000  7.000000\n",
      "mean   0.181050  0.186316  0.181397  0.175482  0.182086   0.181266  0.006184\n",
      "std    0.009227  0.009885  0.010362  0.007268  0.007325   0.006781  0.001634\n",
      "min    0.173706  0.176254  0.166239  0.163563  0.172446   0.173964  0.003126\n",
      "25%    0.174663  0.178065  0.176009  0.171098  0.177502   0.176380  0.005557\n",
      "50%    0.175582  0.184010  0.181188  0.177914  0.182035   0.182061  0.006766\n",
      "75%    0.185217  0.192662  0.186716  0.179830  0.185652   0.183103  0.007130\n",
      "max    0.198303  0.202494  0.196901  0.185038  0.193815   0.193872  0.008019\n",
      "\n",
      "Per-fold Means and Std Devs:\n",
      "   Fold_Mean  Fold_Std\n",
      "0   0.193872  0.006837\n",
      "1   0.173964  0.005229\n",
      "2   0.178401  0.007424\n",
      "3   0.183536  0.008019\n",
      "4   0.174359  0.005886\n",
      "5   0.182670  0.003126\n",
      "6   0.182061  0.006766\n",
      "\n",
      "Per-fold Summary (across runs):\n",
      "         Fold_1    Fold_2    Fold_3    Fold_4    Fold_5    Fold_6    Fold_7\n",
      "count  5.000000  5.000000  5.000000  5.000000  5.000000  5.000000  5.000000\n",
      "mean   0.193872  0.173964  0.178401  0.183536  0.174359  0.182670  0.182061\n",
      "std    0.007644  0.005846  0.008300  0.008966  0.006581  0.003495  0.007565\n",
      "min    0.185038  0.166239  0.172446  0.175426  0.163563  0.178849  0.170805\n",
      "25%    0.186625  0.171391  0.173706  0.177762  0.174178  0.180622  0.180825\n",
      "50%    0.196901  0.173901  0.174256  0.177914  0.175582  0.181555  0.182787\n",
      "75%    0.198303  0.176254  0.179039  0.192765  0.177282  0.184679  0.184010\n",
      "max    0.202494  0.182035  0.192559  0.193815  0.181188  0.187647  0.191878\n",
      "\n",
      "=== Summary for Output 2 ===\n",
      "Per-Fold Means: [0.21469072 0.23857659 0.22876428 0.28312889 0.23248355 0.27437639\n",
      " 0.25398098]\n",
      "Per-Fold Std Devs: [0.01364637 0.02270032 0.01572569 0.01142573 0.01397966 0.00491754\n",
      " 0.01444341]\n",
      "Overall Mean: 0.2466, Overall Std: 0.0274\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary Statistics (per training run):\n",
      "          Run_1     Run_2     Run_3     Run_4     Run_5  Fold_Mean  Fold_Std\n",
      "count  7.000000  7.000000  7.000000  7.000000  7.000000   7.000000  7.000000\n",
      "mean   0.244209  0.239145  0.247858  0.247176  0.254470   0.246572  0.013834\n",
      "std    0.027819  0.035593  0.021910  0.021525  0.035494   0.025034  0.005290\n",
      "min    0.196853  0.203973  0.218821  0.217346  0.208979   0.214691  0.004918\n",
      "25%    0.229588  0.212968  0.229816  0.235431  0.222925   0.230624  0.012536\n",
      "50%    0.246075  0.232829  0.253004  0.245131  0.273071   0.238577  0.013980\n",
      "75%    0.266099  0.255334  0.263231  0.260018  0.280744   0.264179  0.015085\n",
      "max    0.275162  0.300611  0.277087  0.276855  0.291902   0.283129  0.022700\n",
      "\n",
      "Per-fold Means and Std Devs:\n",
      "   Fold_Mean  Fold_Std\n",
      "0   0.214691  0.013646\n",
      "1   0.238577  0.022700\n",
      "2   0.228764  0.015726\n",
      "3   0.283129  0.011426\n",
      "4   0.232484  0.013980\n",
      "5   0.274376  0.004918\n",
      "6   0.253981  0.014443\n",
      "\n",
      "Per-fold Summary (across runs):\n",
      "         Fold_1    Fold_2    Fold_3    Fold_4    Fold_5    Fold_6    Fold_7\n",
      "count  5.000000  5.000000  5.000000  5.000000  5.000000  5.000000  5.000000\n",
      "mean   0.214691  0.238577  0.228764  0.283129  0.232484  0.274376  0.253981\n",
      "std    0.015257  0.025380  0.017582  0.012774  0.015630  0.005498  0.016148\n",
      "min    0.196853  0.214104  0.209390  0.269190  0.208979  0.266943  0.236982\n",
      "25%    0.203973  0.225450  0.211832  0.276855  0.232829  0.273344  0.237323\n",
      "50%    0.217346  0.228239  0.231393  0.277087  0.233727  0.274064  0.259519\n",
      "75%    0.218821  0.245971  0.245131  0.291902  0.233880  0.275162  0.263009\n",
      "max    0.236461  0.279119  0.246075  0.300611  0.253004  0.282369  0.273071\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Assume sc_y_glob shape is (7, 5, 2) => (folds, runs, outputs)\n",
    "n_outputs = sc_y_glob.shape[2]\n",
    "\n",
    "for i in range(n_outputs):\n",
    "    print(f\"\\n=== Summary for Output {i+1} ===\")\n",
    "    \n",
    "    data_i = sc_y_glob[:, :, i]  # shape: (7, 5)\n",
    "    \n",
    "    fold_means = np.mean(data_i, axis=1)\n",
    "    fold_stds = np.std(data_i, axis=1)\n",
    "\n",
    "    overall_mean = np.mean(data_i)\n",
    "    overall_std = np.std(data_i)\n",
    "\n",
    "    # Print summary\n",
    "    print(\"Per-Fold Means:\", fold_means)\n",
    "    print(\"Per-Fold Std Devs:\", fold_stds)\n",
    "    print(f\"Overall Mean: {overall_mean:.4f}, Overall Std: {overall_std:.4f}\")\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.errorbar(range(1, len(fold_means)+1), fold_means, yerr=fold_stds, fmt='o-', capsize=5, label='Mean ± Std')\n",
    "    plt.title(f'Test Error per Fold (Output {i+1})')\n",
    "    plt.xlabel('Fold')\n",
    "    plt.ylabel('Test Error')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # DataFrame Summary\n",
    "    df_results = pd.DataFrame(data_i, columns=[f\"Run_{j+1}\" for j in range(data_i.shape[1])])\n",
    "    df_results[\"Fold_Mean\"] = df_results.mean(axis=1)\n",
    "    df_results[\"Fold_Std\"] = df_results.std(axis=1)\n",
    "\n",
    "    print(\"\\nSummary Statistics (per training run):\")\n",
    "    print(df_results.describe())\n",
    "\n",
    "    print(\"\\nPer-fold Means and Std Devs:\")\n",
    "    print(df_results[[\"Fold_Mean\", \"Fold_Std\"]])\n",
    "\n",
    "    df_fold_view = df_results.drop(columns=[\"Fold_Mean\", \"Fold_Std\"]).T\n",
    "    df_fold_view.columns = [f\"Fold_{k+1}\" for k in range(df_fold_view.shape[1])]\n",
    "\n",
    "    print(\"\\nPer-fold Summary (across runs):\")\n",
    "    print(df_fold_view.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "727fe7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkeerth\\AppData\\Local\\Temp\\ipykernel_3416\\3604107887.py:16: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  axs[i].legend(loc='best')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fold_idx = 3  # choose fold\n",
    "sample_idx = 0  # choose sample from validation set\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "time = np.arange(36)  # time steps\n",
    "\n",
    "for i, label in enumerate(['CA', 'CC', 'CE']):\n",
    "    for run in range(5):\n",
    "        axs[i].plot(time, all_val_preds[fold_idx][run, sample_idx, :, i], alpha=0.5, label=f'Run {run+1}' if i==0 else None)\n",
    "\n",
    "    axs[i].plot(time, val_targets[sample_idx, :, i], 'k--', label='Actual' if i==0 else None)\n",
    "    axs[i].set_ylabel(label)\n",
    "    axs[i].legend(loc='best')\n",
    "\n",
    "axs[2].set_xlabel(\"Time steps\")\n",
    "plt.suptitle(f\"Validation Prediction Uncertainty for Fold {fold_idx+1}, Sample {sample_idx}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "49a8a5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1200 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fold_idx = 3  # choose fold\n",
    "sample_idx = 0  # choose sample from validation set\n",
    "time = np.arange(36)  # time steps\n",
    "labels = ['CA', 'CC', 'CE']\n",
    "\n",
    "n_runs = len(all_val_preds[fold_idx])\n",
    "\n",
    "# Bigger figure and fonts\n",
    "fig, axs = plt.subplots(3, 1, figsize=(14, 12), sharex=True)\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    runs = np.array([all_val_preds[fold_idx][run, sample_idx, :, i] for run in range(n_runs)])\n",
    "    mean_pred = runs.mean(axis=0)\n",
    "    std_pred = runs.std(axis=0)\n",
    "\n",
    "    # Light individual runs\n",
    "    for run in range(n_runs):\n",
    "        axs[i].plot(time, runs[run], color='gray', alpha=0.3, linewidth=1)\n",
    "\n",
    "    # Mean and uncertainty\n",
    "    axs[i].plot(time, mean_pred, color='blue', linewidth=2.5, label='Mean Prediction')\n",
    "    axs[i].fill_between(time, mean_pred - 3*std_pred, mean_pred + 3*std_pred, \n",
    "                        color='blue', alpha=0.2, label='±3 Std Dev')\n",
    "\n",
    "    # Ground truth\n",
    "    axs[i].plot(time, val_targets[sample_idx, :, i], 'k--', linewidth=2.5, label='Ground Truth')\n",
    "\n",
    "    axs[i].set_ylabel(label, fontsize=14)\n",
    "    axs[i].legend(loc='best', fontsize=12)\n",
    "    axs[i].tick_params(labelsize=12)\n",
    "    axs[i].grid(True, linestyle='--', alpha=0.4)\n",
    "\n",
    "axs[-1].set_xlabel(\"Time Steps\", fontsize=14)\n",
    "plt.suptitle(f\"Validation Prediction Uncertainty\\nFold {fold_idx + 1}, Sample {sample_idx}\", fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e864e073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71da6246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094a45e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548f4660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59233f34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebcd3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
