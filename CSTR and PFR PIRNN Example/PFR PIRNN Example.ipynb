{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbde2abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import math\n",
    "import optuna\n",
    "import time\n",
    "from scipy.integrate import odeint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af28b677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping function\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    \n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57b9590a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'using cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tells whether the model is running on CPU or GPU\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('using GPU:', torch.cuda.get_device_name()) if torch.cuda.is_available() else 'using cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41ba3f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying parameters for PFR and other constants taken Siettos et al.'s work (1998)\n",
    "\n",
    "T0_s = 440 #440 # inlet temperature\n",
    "\n",
    "k_0 = 3.34 * (np.power(10,8)) # pre-exponential constant\n",
    "\n",
    "C_p = 25 # heat capacity of reacting liquid\n",
    "\n",
    "rho_L = 47 # density of reacting liquid\n",
    "\n",
    "T_s = 423 # steady-state reactor temperature                \n",
    "\n",
    "u = 2 # volumetric flow rate  (F/A) Superficial velocity\n",
    "\n",
    "E_by_R = 8600 # activation energy (E/R)\n",
    "\n",
    "delH_term = -44000 # enthalpy of reaction\n",
    "\n",
    "U = 25 #Overall heat transfer coeffecient\n",
    "\n",
    "CA0_s = 1.6 #  steady-state inlet concentration of A\n",
    "\n",
    "CA_s = 0.11 # steady-state reactor concentration of A         \n",
    "\n",
    "Tc_s = 293 # steady state cooling temperature\n",
    "\n",
    "At = 0.01 # Area for heating rate equation\n",
    "\n",
    "A = 0.002  # Area\n",
    "\n",
    "t_final = 0.1 #0.01 # end time for numerical simulation\n",
    "\n",
    "t_step = 0.02 #1e-3 # integration time step h_c\n",
    "\n",
    "P = np.array([[1060, 22], [22, 0.52]]) # a positive definite matrix             \n",
    "\n",
    "length = 1 # total length of reactor\n",
    "\n",
    "N = 10     # number of points to discretize the reactor "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635a540c",
   "metadata": {},
   "source": [
    "# Euler Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfb182bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PFR_simulation_Euler(u, delH_term, k_0, C_p, rho_L, E_by_R, Tc, U, At, A, t_final, t_step, init_C, init_T):\n",
    "\n",
    "    # Method of lines approximates the spatial derivative using finite difference method which reults in a set of coupled ODE\n",
    "    \n",
    "    def method_of_lines_C(C, T):\n",
    "        'coupled ODES at each node point'\n",
    "        D = -u * np.diff(C) / np.diff(z) - k_0 * np.exp(-E_by_R/T[1:]) * C[1:]    # for first order\n",
    "        return np.concatenate([[0], D]) #C0 is constant at entrance\n",
    "\n",
    "\n",
    "    def method_of_lines_T(C, T):\n",
    "        'coupled ODES at each node point'\n",
    "        D = -u * np.diff(T) / np.diff(z) + (-delH_term/(rho_L*C_p)) * k_0 * np.exp(-E_by_R/T[1:])* C[1:] + (U/(rho_L*C_p*A)) * At * (Tc - T[1:]) # for first order\n",
    "        return np.concatenate([[0], D]) #T0 is constant at entrance\n",
    "\n",
    "    N = 10     # number of points to discretize the reactor length\n",
    "    z = np.linspace(0, length, N) # discretized length elements\n",
    "    \n",
    "    #initializing arrays\n",
    "    init_C_A_2_1 = np.zeros(N)\n",
    "    init_T_2_1 = np.zeros(N)  \n",
    "    \n",
    "    init_C_A_2_2 = np.zeros(N)\n",
    "    init_T_2_2 = np.zeros(N)   \n",
    "    \n",
    "    init_C_A_3 = np.zeros(N)\n",
    "    init_T_3 = np.zeros(N)    \n",
    "    \n",
    "    C_A_3 = np.zeros(N)\n",
    "    T_3 = np.zeros(N)    \n",
    "    \n",
    "    \n",
    "    dCAdt1 = method_of_lines_C(init_C, init_T)\n",
    "    dTdt1 = method_of_lines_T(init_C, init_T)\n",
    "    \n",
    "    for i in range(len(init_C)):        \n",
    "        init_C_A_2_1[i] = init_C[i] + dCAdt1[i] * t_step / 2\n",
    "        init_T_2_1[i] = init_T[i] + dTdt1[i] * t_step / 2\n",
    "        \n",
    "    dCAdt2_1 = method_of_lines_C(init_C_A_2_1, init_T_2_1)\n",
    "    dTdt2_1 = method_of_lines_T(init_C_A_2_1, init_T_2_1)        \n",
    "        \n",
    "    for i in range(len(init_C)):\n",
    "        init_C_A_2_2[i] = init_C[i] + dCAdt2_1[i] * t_step / 2\n",
    "        init_T_2_2[i] = init_T[i] + dTdt2_1[i] * t_step / 2\n",
    "        \n",
    "    dCAdt2_2 = method_of_lines_C(init_C_A_2_2, init_T_2_2)\n",
    "    dTdt2_2 = method_of_lines_T(init_C_A_2_2, init_T_2_2)           \n",
    "        \n",
    "    for i in range(len(init_C)):       \n",
    "        init_C_A_3[i] = init_C[i] + dCAdt2_2[i] * t_step / 2\n",
    "        init_T_3[i] = init_T[i] + dTdt2_2[i] * t_step / 2\n",
    "        \n",
    "    dCAdt3 = method_of_lines_C(init_C_A_3, init_T_3)\n",
    "    dTdt3 = method_of_lines_T(init_C_A_3, init_T_3)           \n",
    "        \n",
    "    dCAdt2 = np.add(dCAdt2_1,dCAdt2_2)\n",
    "    dCAdt2 = np.divide(dCAdt2,2)\n",
    "      \n",
    "    dTdt2 = np.add(dTdt2_1,dTdt2_2)\n",
    "    dTdt2 = np.divide(dTdt2,2)        \n",
    "\n",
    "    for i in range(len(init_C)):      \n",
    "        C_A_3[i] = init_C[i] + t_step / 6 * (dCAdt1[i] + 4*dCAdt2[i] + dCAdt3[i])     \n",
    "        T_3[i] = init_T[i] + t_step / 6 * (dTdt1[i] + 4*dTdt2[i] + dTdt3[i])    \n",
    "\n",
    "    return C_A_3 , T_3  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57021e20",
   "metadata": {},
   "source": [
    "# Data generation (PI-RNN) collocation points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afd705be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating inputs and initial states for PFR\n",
    "\n",
    "u2_physics_list = np.linspace(100, 300, 20) # u2 is the cooling temp\n",
    "T_physics_initial = np.linspace(300, 500, 20)  # inlet temperature\n",
    "CA_physics_initial = np.linspace(0.5, 3, 20)  # inlet concentration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ceaacc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of initial conditions: 400\n",
      "shape of x_physics_original is (400, 2)\n"
     ]
    }
   ],
   "source": [
    "# Grouping the initial state vectors\n",
    "\n",
    "T_physics_start = list()\n",
    "CA_physics_start = list()\n",
    "\n",
    "for T in T_physics_initial:\n",
    "    for CA in CA_physics_initial:\n",
    "        CA_physics_start.append(CA)\n",
    "        T_physics_start.append(T)\n",
    "            \n",
    "print(\"number of initial conditions: {}\".format(len(CA_physics_start)))\n",
    "\n",
    "# convert to np.arrays\n",
    "CA_physics_start = np.array([CA_physics_start])\n",
    "T_physics_start = np.array([T_physics_start])\n",
    "x_physics_original = np.concatenate((CA_physics_start.T, T_physics_start.T), axis=1)  # every row is a pair of initial states within stability region\n",
    "print(\"shape of x_physics_original is {}\".format(x_physics_original.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6588c3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 out of 20\n",
      "2 out of 20\n",
      "3 out of 20\n",
      "4 out of 20\n",
      "5 out of 20\n",
      "6 out of 20\n",
      "7 out of 20\n",
      "8 out of 20\n",
      "9 out of 20\n",
      "10 out of 20\n",
      "11 out of 20\n",
      "12 out of 20\n",
      "13 out of 20\n",
      "14 out of 20\n",
      "15 out of 20\n",
      "16 out of 20\n",
      "17 out of 20\n",
      "18 out of 20\n",
      "19 out of 20\n",
      "20 out of 20\n"
     ]
    }
   ],
   "source": [
    "# get X and y data for physics-informed model\n",
    "\n",
    "CA_physics_output = list()\n",
    "T_physics_output = list()\n",
    "CA_physics_input = list()\n",
    "T_physics_input = list()\n",
    "Tc_physics_input = list()\n",
    "\n",
    "\n",
    "for num_id, u2 in enumerate(u2_physics_list):\n",
    "    print(f\"{num_id + 1} out of {u2_physics_list.shape[0]}\")    #just to count and keep track\n",
    "    Tc = u2 + Tc_s\n",
    "        \n",
    "    for C_A_initial, T_initial in x_physics_original:\n",
    "        Tc_physics_input.append(u2)\n",
    "        CA_physics_input.append(C_A_initial)\n",
    "        T_physics_input.append(T_initial)\n",
    "            \n",
    "        N = 10     # number of points to discretize the reactor length\n",
    "        z = np.linspace(0, length, N) # discretized length elements      \n",
    "        init_C = np.zeros(N)    # Concentration in reactor at t = 0\n",
    "        init_C[0] = C_A_initial          # concentration at entrance   \n",
    "        init_T = np.zeros(N)    # T in reactor at t = 0\n",
    "        for i in range(len(init_T)):\n",
    "            if i == 0:\n",
    "                init_T[i] = T_initial \n",
    "            else:\n",
    "                init_T[i] = 293   # at room temperature and scaled with Steady State value\n",
    "            \n",
    "        C_A_list = [init_C] \n",
    "        T_list = [init_T]            \n",
    "                                \n",
    "        for _ in range(int(t_final / t_step)):\n",
    "            \n",
    "            CA_next, T_next = PFR_simulation_Euler(u, delH_term, k_0, C_p, rho_L, E_by_R, Tc, U, At, A, t_final, t_step, init_C, init_T)\n",
    "            C_A_list.append(CA_next)\n",
    "            T_list.append(T_next)\n",
    "            init_C = CA_next\n",
    "            init_T = T_next\n",
    "             \n",
    "        CA_physics_output.append(C_A_list)\n",
    "        T_physics_output.append(T_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa6bcbb",
   "metadata": {},
   "source": [
    "# Collating Input and Output for RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9184f4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN_physics_input_temp shape is (8000, 6, 3)\n"
     ]
    }
   ],
   "source": [
    "# collate input for RNN for physics loss\n",
    "\n",
    "Tc_physics_input = np.array(Tc_physics_input)\n",
    "Tc_physics_input = Tc_physics_input.reshape(-1,1,1)\n",
    "\n",
    "\n",
    "CA_physics_input = np.array(CA_physics_input)\n",
    "CA_physics_input = CA_physics_input.reshape(-1,1,1)\n",
    "\n",
    "\n",
    "T_physics_input = np.array(T_physics_input)\n",
    "T_physics_input = T_physics_input.reshape(-1,1,1)\n",
    "\n",
    "\n",
    "RNN_physics_input_temp = np.concatenate((Tc_physics_input, CA_physics_input, T_physics_input), axis=2)\n",
    "\n",
    "\"\"\"\n",
    "    the input to RNN is in the shape [number of samples x timestep x variables], and the input variables are same for every\n",
    "    time step\n",
    "\"\"\"\n",
    "\n",
    "RNN_physics_input_temp = RNN_physics_input_temp.repeat(6, axis=1)\n",
    "print(\"RNN_physics_input_temp shape is {}\".format(RNN_physics_input_temp.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8deeeaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN_physics_output shape is (8000, 6, 20)\n"
     ]
    }
   ],
   "source": [
    "############################## collate output for RNN ####################################################\n",
    "\n",
    "CA_physics_output = np.array(CA_physics_output)\n",
    "CA_physics_output = CA_physics_output.reshape(-1, 6, 10)\n",
    "\n",
    "T_physics_output = np.array(T_physics_output)\n",
    "T_physics_output = T_physics_output.reshape(-1, 6, 10)\n",
    "\n",
    "RNN_physics_output = np.concatenate((CA_physics_output, T_physics_output), axis=2)\n",
    "print(\"RNN_physics_output shape is {}\".format(RNN_physics_output.shape))  # output shape: number of samples x timestep x variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d32c86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape is (4800, 6, 3), X_val shape is (1600, 6, 3), X_test shape is (1600, 6, 3)\n",
      "y_train shape is (4800, 6, 20), y_val shape is (1600, 6, 20), y_test shape is (1600, 6, 20)\n"
     ]
    }
   ],
   "source": [
    "############################### Split into Training, Test, and Validation Data ################################\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(RNN_physics_input_temp, RNN_physics_output, test_size=0.2, random_state=123)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=123) # 0.25 x 0.8 = 0.2\n",
    "\n",
    "print(f\"X_train shape is {X_train.shape}, X_val shape is {X_val.shape}, X_test shape is {X_test.shape}\")\n",
    "print(f\"y_train shape is {y_train.shape}, y_val shape is {y_val.shape}, y_test shape is {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba755595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract mean and standard deviation dor Standardization\n",
    "\n",
    "mean_Tc = np.mean(X_train[:, 0, 0].reshape(-1))\n",
    "std_Tc = np.std(X_train[:, 0, 0].reshape(-1))\n",
    "\n",
    "# Initializing arrays\n",
    "mean_CA_input=np.zeros(N)\n",
    "std_CA_input=np.zeros(N)\n",
    "\n",
    "mean_T_input=np.zeros(N)\n",
    "std_T_input=np.zeros(N)\n",
    "\n",
    "# Computing mean and standard deviation\n",
    "mean_CA_input = np.mean(X_train[:, 0, -2].reshape(-1))\n",
    "std_CA_input = np.std(X_train[:, 0, -2].reshape(-1))\n",
    "\n",
    "mean_T_input = np.mean(X_train[:, 0, -1].reshape(-1))\n",
    "std_T_input = np.std(X_train[:, 0, -1].reshape(-1))\n",
    "\n",
    "\n",
    "# Extracting mean and standard deviation for concentration and temperature across all samples and time step\n",
    "\n",
    "mean_Cy = np.mean(y_train[:, :, :10])\n",
    "std_Cy = np.std(y_train[:, :, :10])\n",
    "\n",
    "mean_Ty = np.mean(y_train[:, :, 10:])\n",
    "std_Ty = np.std(y_train[:, :, 10:])\n",
    "\n",
    "# Initializing arrays\n",
    "mean_Cy_rep = mean_Cy.repeat(N, axis=0)\n",
    "std_Cy_rep = std_Cy.repeat(N, axis=0)\n",
    "mean_Ty_rep = mean_Ty.repeat(N, axis=0)\n",
    "std_Ty_rep = std_Ty.repeat(N, axis=0)\n",
    "    \n",
    "# Computing mean and standard deviation\n",
    "mean_y = np.concatenate((mean_Cy_rep.reshape(-1), mean_Ty_rep.reshape(-1)))\n",
    "std_y = np.concatenate((std_Cy_rep.reshape(-1), std_Ty_rep.reshape(-1))) \n",
    "\n",
    "mean_y = torch.from_numpy(mean_y).float()\n",
    "std_y = torch.from_numpy(std_y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1394a923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_physics shape is: torch.Size([4800, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "# scaling the input dataset (x_physics)\n",
    "X_physics_train = (X_train - [mean_Tc, mean_CA_input, mean_T_input]) / [std_Tc, std_CA_input, std_T_input]\n",
    "X_physics_train = torch.from_numpy(X_physics_train).float()\n",
    "\n",
    "X_physics_val = (X_val - [mean_Tc, mean_CA_input, mean_T_input]) / [std_Tc, std_CA_input, std_T_input]\n",
    "X_physics_val = torch.from_numpy(X_physics_val).float()\n",
    "\n",
    "X_physics_test = (X_test - [mean_Tc, mean_CA_input, mean_T_input]) / [std_Tc, std_CA_input, std_T_input]\n",
    "X_physics_test = torch.from_numpy(X_physics_test).float()\n",
    "\n",
    "# scaling the output dataset\n",
    "\n",
    "y_train_p = (y_train - mean_y.detach().numpy()) / (std_y.detach().numpy())\n",
    "y_train_p = torch.from_numpy(y_train_p).float()\n",
    "\n",
    "y_test_p = (y_test - mean_y.detach().numpy()) / (std_y.detach().numpy())\n",
    "y_test_p = torch.from_numpy(y_test_p).float()\n",
    "\n",
    "y_val_p = (y_val - mean_y.detach().numpy()) / (std_y.detach().numpy())\n",
    "y_val_p = torch.from_numpy(y_val_p).float()\n",
    "\n",
    "print(f'X_physics shape is: {X_physics_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeb904b",
   "metadata": {},
   "source": [
    "# Preparing dataset for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95530f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_physics_train = TensorDataset(X_physics_train, y_train_p)\n",
    "dataloader_physics_train = DataLoader(dataset_physics_train, batch_size=10800, shuffle=True)\n",
    "\n",
    "dataset_physics_val = TensorDataset(X_physics_val, y_val_p)\n",
    "dataloader_physics_val = DataLoader(dataset_physics_val, batch_size=10800, shuffle=True)\n",
    "\n",
    "dataset_physics_test = TensorDataset(X_physics_test, y_test_p)\n",
    "dataloader_physics_test = DataLoader(dataset_physics_test, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c12de0",
   "metadata": {},
   "source": [
    "# Defining RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afde6620",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \"Defines a RNN network\"\n",
    "    \n",
    "    def __init__(self, N_INPUT, N_OUTPUT, N_HIDDEN, N_LAYERS):\n",
    "        super(RNN, self).__init__()\n",
    "        self.layers = N_LAYERS\n",
    "        \n",
    "        if isinstance(N_HIDDEN, list):\n",
    "            self.rnn = nn.LSTM(N_INPUT, \n",
    "                                N_HIDDEN[0], \n",
    "                                batch_first=True)\n",
    "            \n",
    "            self.rnn1 = nn.ModuleList(\n",
    "                [nn.LSTM(N_HIDDEN[i], \n",
    "                        N_HIDDEN[i+1],\n",
    "                       batch_first=True) for i in range(N_LAYERS - 1)]\n",
    "            )\n",
    "            \n",
    "            self.output_layer = nn.Linear(N_HIDDEN[-1], N_OUTPUT)\n",
    "            \n",
    "            self.list_flag = True\n",
    "            \n",
    "        else:\n",
    "            self.rnn = nn.LSTM(N_INPUT, \n",
    "                                N_HIDDEN,\n",
    "                                N_LAYERS,\n",
    "                                batch_first=True,\n",
    "                                dropout=0.1)\n",
    "            \n",
    "            self.output_layer = nn.Linear(N_HIDDEN, N_OUTPUT)\n",
    "            \n",
    "            self.list_flag = False            \n",
    "          \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, _ = self.rnn(x)\n",
    "        \n",
    "        if self.list_flag:\n",
    "            for i in range(self.layers - 1):\n",
    "                x, _ = self.rnn1[i](x)\n",
    "                \n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a65e386",
   "metadata": {},
   "source": [
    "# Physics-informed RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "180512be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, patience, n_epochs):\n",
    "    \n",
    "    # to track the training loss as the model trains\n",
    "    train_losses = []\n",
    "    # to track the validation loss as the model trains\n",
    "    valid_losses = []\n",
    "    # to track the average training loss per epoch as the model trains\n",
    "    avg_train_losses = []\n",
    "    # to track the average validation loss per epoch as the model trains\n",
    "    avg_valid_losses = [] \n",
    "    \n",
    "    # initialize the early_stopping object\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        \n",
    "        model.train() # prep model for training\n",
    "        for batch, (x_batch, y_train_batch) in enumerate(dataloader_physics_train, 1):\n",
    "            # clear the gradients of all optimized variables\n",
    "            x_batch = x_batch[0].to(device)\n",
    "            y_train_batch = y_train_batch[0].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            NN_output = model_PINN(x_batch)            \n",
    "            \n",
    "            # Data-driven loss\n",
    "            loss1 = torch.mean((NN_output[:, :10] -  y_train_batch[:, :10])**2)  # use mean squared error\n",
    "            loss1_1 = torch.mean((NN_output[:, 10:] - y_train_batch[:, 10:])**2)  # use mean squared error\n",
    "            \n",
    "            # for inital condition\n",
    "            loss2 = torch.mean((NN_output[0, :] - y_train_batch[0, :])**2)\n",
    "            \n",
    "            # collocation point loss\n",
    "            loss21 = torch.mean((NN_output[0, [0,10]] - x_batch[0, 1:])**2)\n",
    "\n",
    "            \n",
    "            # compute the \"physics loss\"\n",
    "            Tc = x_batch[:, 0] * std_Tc + mean_Tc + Tc_s\n",
    "            \n",
    "\n",
    "            # Reversing standardization\n",
    "            NN_output = NN_output * std_y.to(device) + mean_y.to(device)\n",
    "            \n",
    "            \n",
    "            dCA_first = (NN_output[ 1:2, :10] - NN_output[0:1, :10]) / (t_step)\n",
    "            dT_first = (NN_output[ 1:2, 10:] - NN_output[ 0:1, 10:]) / (t_step)\n",
    "            \n",
    "            \n",
    "            dCA_center = (NN_output[ 2:, :10] - NN_output[ :-2, :10]) / (2*t_step)\n",
    "            dT_center = (NN_output[ 2:, 10:] - NN_output[:-2, 10:]) / (2*t_step)\n",
    "            \n",
    "            \n",
    "            dCA_last = (NN_output[ -1:, :10] - NN_output[ -2:-1, :10]) / (t_step)\n",
    "            dT_last = (NN_output[ -1:, 10:] - NN_output[ -2:-1, 10:]) / (t_step)\n",
    "\n",
    "\n",
    "            dCA = torch.cat((dCA_first, dCA_center, dCA_last), 0)\n",
    "            dT = torch.cat((dT_first, dT_center, dT_last), 0)\n",
    "                      \n",
    "            # taking in first point\n",
    "            loss3_1 = dCA[:,1:] - (-u * torch.from_numpy(np.diff(NN_output[ :, :10].detach().numpy(force=True)) / np.diff(z)) - k_0 * torch.exp(-E_by_R/NN_output[ :, 11:]) * NN_output[:, 1:10])            \n",
    "            loss3_2 = dCA[:,0] - 0\n",
    "            loss3_2 = torch.reshape(loss3_2,(6,1))\n",
    "            loss3 = torch.cat((loss3_2, loss3_1),1)\n",
    "            loss3 = torch.mean(loss3**2)            \n",
    "            \n",
    "            \n",
    "            #taking in first point\n",
    "            loss4_1 = dT[:,1:] - (-u * torch.from_numpy(np.diff(NN_output[ :, 10:].detach().numpy(force=True)) / np.diff(z)) + (-delH_term/(rho_L*C_p)) * k_0 * torch.exp(-E_by_R/NN_output[ :, 11:]) * NN_output[ :, 1:10] - (U/(rho_L*C_p*A)) * At * (NN_output[:, 11:]-Tc[0]))            \n",
    "            loss4_2 = dT[:,0] - 0\n",
    "            loss4_2 = torch.reshape(loss4_2,(6,1))\n",
    "            loss4 = torch.cat((loss4_2, loss4_1),1)           \n",
    "            loss4 = torch.mean(loss4**2)\n",
    "            \n",
    "            \n",
    "            # Partial PIRNN (Assuming we only have Temperature data available)\n",
    "            loss =  10e3*(loss1_1) + loss21 + 10e3*loss2 + 10e0*loss3 # add all loss terms together\n",
    "\n",
    "            \n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # record training loss\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval() # prep model for evaluation\n",
    "        for (val_batch, y_val_batch) in dataloader_physics_val:\n",
    "            \n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            val_batch = val_batch[0].to(device)\n",
    "            y_val_batch = y_val_batch[0].to(device)\n",
    "            NN_output = model(val_batch)\n",
    "            \n",
    "            # Data-driven loss\n",
    "            loss1 = torch.mean((NN_output[:, :10] -  y_val_batch[:, :10])**2)  # use mean squared error\n",
    "            loss1_1 = torch.mean((NN_output[:, 10:] - y_val_batch[:, 10:])**2)  # use mean squared error\n",
    "            \n",
    "            \n",
    "            # for inital condition\n",
    "            loss2 = torch.mean((NN_output[0, :] - y_val_batch[0, :])**2)          \n",
    "            \n",
    "            # collocation point loss\n",
    "            loss21 = torch.mean((NN_output[0, [0,10]] - val_batch[0, 1:])**2)\n",
    "            \n",
    "            # compute the \"physics loss\"\n",
    "            Tc = val_batch[:, 0] * std_Tc + mean_Tc + Tc_s\n",
    "            \n",
    "            # Reversing Standardization\n",
    "            NN_output = NN_output * std_y.to(device) + mean_y.to(device)\n",
    "            \n",
    "            \n",
    "            dCA_first = (NN_output[ 1:2, :10] - NN_output[0:1, :10]) / (t_step)\n",
    "            dT_first = (NN_output[ 1:2, 10:] - NN_output[ 0:1, 10:]) / (t_step)\n",
    "            \n",
    "            \n",
    "            dCA_center = (NN_output[ 2:, :10] - NN_output[ :-2, :10]) / (2*t_step)\n",
    "            dT_center = (NN_output[ 2:, 10:] - NN_output[:-2, 10:]) / (2*t_step)\n",
    "            \n",
    "            \n",
    "            dCA_last = (NN_output[ -1:, :10] - NN_output[ -2:-1, :10]) / (t_step)\n",
    "            dT_last = (NN_output[ -1:, 10:] - NN_output[ -2:-1, 10:]) / (t_step)\n",
    "\n",
    "\n",
    "            dCA = torch.cat((dCA_first, dCA_center, dCA_last), 0)\n",
    "            dT = torch.cat((dT_first, dT_center, dT_last), 0)\n",
    "                       \n",
    "            #taking in first point\n",
    "            loss3_1 = dCA[:,1:] - (-u * torch.from_numpy(np.diff(NN_output[ :, :10].detach().numpy(force=True)) / np.diff(z)) - k_0 * torch.exp(-E_by_R/NN_output[ :, 11:]) * NN_output[:, 1:10])            \n",
    "            loss3_2 = dCA[:,0] - 0\n",
    "            loss3_2 = torch.reshape(loss3_2,(6,1))\n",
    "            loss3 = torch.cat((loss3_2, loss3_1),1)\n",
    "            loss3 = torch.mean(loss3_1**2)            \n",
    "             \n",
    "            #taking in first point\n",
    "            loss4_1 = dT[:,1:] - (-u * torch.from_numpy(np.diff(NN_output[ :, 10:].detach().numpy(force=True)) / np.diff(z)) + (-delH_term/(rho_L*C_p)) * k_0 * torch.exp(-E_by_R/NN_output[ :, 11:]) * NN_output[ :, 1:10] - (U/(rho_L*C_p*A)) * At * (NN_output[:, 11:]-Tc[0]))            \n",
    "            loss4_2 = dT[:,0] - 0\n",
    "            loss4_2 = torch.reshape(loss4_2,(6,1))\n",
    "            loss4 = torch.cat((loss4_2, loss4_1),1)           \n",
    "            loss4 = torch.mean(loss4_1**2)  \n",
    "            \n",
    "            # Partial PIRNN (Assuming we only have Temperature data available)\n",
    "            loss =  10e3*(loss1_1) + loss21 + 10e3*loss2 + 10e0*loss3 # add all loss terms together       \n",
    "           \n",
    "            # record validation loss\n",
    "            valid_losses.append(loss.item())\n",
    "\n",
    "        # print training/validation statistics \n",
    "        # calculate average loss over an epoch\n",
    "        train_loss = np.average(train_losses)\n",
    "        valid_loss = np.average(valid_losses)\n",
    "        avg_train_losses.append(train_loss)\n",
    "        avg_valid_losses.append(valid_loss)\n",
    "        \n",
    "        epoch_len = len(str(n_epochs))\n",
    "        \n",
    "        print_msg = (f'[{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +\n",
    "                     f'train_loss: {train_loss:.5f} ' +\n",
    "                     f'valid_loss: {valid_loss:.5f}')\n",
    "        \n",
    "        print(print_msg)\n",
    "        \n",
    "        # clear lists to track next epoch\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        \n",
    "        # early_stopping needs the validation loss to check if it has decresed, \n",
    "        # and if it has, it will make a checkpoint of the current model\n",
    "        early_stopping(valid_loss, model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        \n",
    "    # load the last checkpoint with the best model\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n",
    "    return  model, avg_train_losses, avg_valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e4588bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): LSTM(3, 256, num_layers=3, batch_first=True, dropout=0.1)\n",
      "  (output_layer): Linear(in_features=256, out_features=20, bias=True)\n",
      ")\n",
      "tensor(0.8315, grad_fn=<MeanBackward0>)\n",
      "[   1/1500] train_loss: 12347.53003 valid_loss: 6268.06990\n",
      "Validation loss decreased (inf --> 6268.069895).  Saving model ...\n",
      "tensor(0.4435, grad_fn=<MeanBackward0>)\n",
      "[   2/1500] train_loss: 17383.30709 valid_loss: 5737.37505\n",
      "Validation loss decreased (6268.069895 --> 5737.375046).  Saving model ...\n",
      "tensor(1.4693, grad_fn=<MeanBackward0>)\n",
      "[   3/1500] train_loss: 40376.56317 valid_loss: 10085.53915\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(1.1064, grad_fn=<MeanBackward0>)\n",
      "[   4/1500] train_loss: 9728.23574 valid_loss: 39555.27333\n",
      "EarlyStopping counter: 2 out of 600\n",
      "tensor(0.2865, grad_fn=<MeanBackward0>)\n",
      "[   5/1500] train_loss: 15536.79610 valid_loss: 35906.01249\n",
      "EarlyStopping counter: 3 out of 600\n",
      "tensor(0.2293, grad_fn=<MeanBackward0>)\n",
      "[   6/1500] train_loss: 11385.56421 valid_loss: 34700.99886\n",
      "EarlyStopping counter: 4 out of 600\n",
      "tensor(0.8636, grad_fn=<MeanBackward0>)\n",
      "[   7/1500] train_loss: 4521.94846 valid_loss: 23700.01300\n",
      "EarlyStopping counter: 5 out of 600\n",
      "tensor(0.4410, grad_fn=<MeanBackward0>)\n",
      "[   8/1500] train_loss: 12606.96965 valid_loss: 17101.82520\n",
      "EarlyStopping counter: 6 out of 600\n",
      "tensor(1.3272, grad_fn=<MeanBackward0>)\n",
      "[   9/1500] train_loss: 19811.35912 valid_loss: 25576.11809\n",
      "EarlyStopping counter: 7 out of 600\n",
      "tensor(0.9196, grad_fn=<MeanBackward0>)\n",
      "[  10/1500] train_loss: 6367.39156 valid_loss: 19640.20719\n",
      "EarlyStopping counter: 8 out of 600\n",
      "tensor(1.2661, grad_fn=<MeanBackward0>)\n",
      "[  11/1500] train_loss: 16807.53969 valid_loss: 8473.26110\n",
      "EarlyStopping counter: 9 out of 600\n",
      "tensor(0.7664, grad_fn=<MeanBackward0>)\n",
      "[  12/1500] train_loss: 14296.19493 valid_loss: 6202.16232\n",
      "EarlyStopping counter: 10 out of 600\n",
      "tensor(2.0631, grad_fn=<MeanBackward0>)\n",
      "[  13/1500] train_loss: 11058.57945 valid_loss: 8992.63145\n",
      "EarlyStopping counter: 11 out of 600\n",
      "tensor(1.2508, grad_fn=<MeanBackward0>)\n",
      "[  14/1500] train_loss: 16738.81514 valid_loss: 6086.76330\n",
      "EarlyStopping counter: 12 out of 600\n",
      "tensor(0.1002, grad_fn=<MeanBackward0>)\n",
      "[  15/1500] train_loss: 6846.55577 valid_loss: 3921.16376\n",
      "Validation loss decreased (5737.375046 --> 3921.163757).  Saving model ...\n",
      "tensor(0.9942, grad_fn=<MeanBackward0>)\n",
      "[  16/1500] train_loss: 20560.35842 valid_loss: 22352.73517\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(1.0795, grad_fn=<MeanBackward0>)\n",
      "[  17/1500] train_loss: 26605.43739 valid_loss: 16252.83673\n",
      "EarlyStopping counter: 2 out of 600\n",
      "tensor(1.2700, grad_fn=<MeanBackward0>)\n",
      "[  18/1500] train_loss: 26503.40207 valid_loss: 5178.84736\n",
      "EarlyStopping counter: 3 out of 600\n",
      "tensor(1.1626, grad_fn=<MeanBackward0>)\n",
      "[  19/1500] train_loss: 15475.50430 valid_loss: 5590.16249\n",
      "EarlyStopping counter: 4 out of 600\n",
      "tensor(0.3123, grad_fn=<MeanBackward0>)\n",
      "[  20/1500] train_loss: 13649.84674 valid_loss: 7739.99314\n",
      "EarlyStopping counter: 5 out of 600\n",
      "tensor(0.7765, grad_fn=<MeanBackward0>)\n",
      "[  21/1500] train_loss: 7614.79322 valid_loss: 13169.54621\n",
      "EarlyStopping counter: 6 out of 600\n",
      "tensor(2.3560, grad_fn=<MeanBackward0>)\n",
      "[  22/1500] train_loss: 16307.79564 valid_loss: 12664.31638\n",
      "EarlyStopping counter: 7 out of 600\n",
      "tensor(1.1946, grad_fn=<MeanBackward0>)\n",
      "[  23/1500] train_loss: 5881.58041 valid_loss: 13057.32454\n",
      "EarlyStopping counter: 8 out of 600\n",
      "tensor(1.3769, grad_fn=<MeanBackward0>)\n",
      "[  24/1500] train_loss: 4153.79105 valid_loss: 10701.41460\n",
      "EarlyStopping counter: 9 out of 600\n",
      "tensor(0.9842, grad_fn=<MeanBackward0>)\n",
      "[  25/1500] train_loss: 11225.15796 valid_loss: 6315.87740\n",
      "EarlyStopping counter: 10 out of 600\n",
      "tensor(0.7301, grad_fn=<MeanBackward0>)\n",
      "[  26/1500] train_loss: 4748.34626 valid_loss: 6455.77115\n",
      "EarlyStopping counter: 11 out of 600\n",
      "tensor(0.9167, grad_fn=<MeanBackward0>)\n",
      "[  27/1500] train_loss: 3644.51677 valid_loss: 4891.28713\n",
      "EarlyStopping counter: 12 out of 600\n",
      "tensor(0.6495, grad_fn=<MeanBackward0>)\n",
      "[  28/1500] train_loss: 14776.67720 valid_loss: 12034.82047\n",
      "EarlyStopping counter: 13 out of 600\n",
      "tensor(1.4398, grad_fn=<MeanBackward0>)\n",
      "[  29/1500] train_loss: 3169.84066 valid_loss: 6344.98747\n",
      "EarlyStopping counter: 14 out of 600\n",
      "tensor(1.2438, grad_fn=<MeanBackward0>)\n",
      "[  30/1500] train_loss: 12569.58582 valid_loss: 22623.68567\n",
      "EarlyStopping counter: 15 out of 600\n",
      "tensor(0.7302, grad_fn=<MeanBackward0>)\n",
      "[  31/1500] train_loss: 20663.84761 valid_loss: 2945.49945\n",
      "Validation loss decreased (3921.163757 --> 2945.499451).  Saving model ...\n",
      "tensor(0.7290, grad_fn=<MeanBackward0>)\n",
      "[  32/1500] train_loss: 19257.37085 valid_loss: 7526.07225\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(1.0959, grad_fn=<MeanBackward0>)\n",
      "[  33/1500] train_loss: 8221.66475 valid_loss: 4016.91796\n",
      "EarlyStopping counter: 2 out of 600\n",
      "tensor(0.0950, grad_fn=<MeanBackward0>)\n",
      "[  34/1500] train_loss: 9181.96435 valid_loss: 6880.65890\n",
      "EarlyStopping counter: 3 out of 600\n",
      "tensor(1.6700, grad_fn=<MeanBackward0>)\n",
      "[  35/1500] train_loss: 6720.71380 valid_loss: 8890.40233\n",
      "EarlyStopping counter: 4 out of 600\n",
      "tensor(0.2130, grad_fn=<MeanBackward0>)\n",
      "[  36/1500] train_loss: 5865.72157 valid_loss: 6919.07105\n",
      "EarlyStopping counter: 5 out of 600\n",
      "tensor(1.0649, grad_fn=<MeanBackward0>)\n",
      "[  37/1500] train_loss: 18577.38890 valid_loss: 9354.60428\n",
      "EarlyStopping counter: 6 out of 600\n",
      "tensor(1.1532, grad_fn=<MeanBackward0>)\n",
      "[  38/1500] train_loss: 8893.13467 valid_loss: 10468.07646\n",
      "EarlyStopping counter: 7 out of 600\n",
      "tensor(0.8373, grad_fn=<MeanBackward0>)\n",
      "[  39/1500] train_loss: 7917.06149 valid_loss: 10219.01646\n",
      "EarlyStopping counter: 8 out of 600\n",
      "tensor(1.3925, grad_fn=<MeanBackward0>)\n",
      "[  40/1500] train_loss: 4195.98678 valid_loss: 2051.65286\n",
      "Validation loss decreased (2945.499451 --> 2051.652857).  Saving model ...\n",
      "tensor(2.2381, grad_fn=<MeanBackward0>)\n",
      "[  41/1500] train_loss: 9602.55768 valid_loss: 11196.25419\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(2.7311, grad_fn=<MeanBackward0>)\n",
      "[  42/1500] train_loss: 2154.85836 valid_loss: 8279.85921\n",
      "EarlyStopping counter: 2 out of 600\n",
      "tensor(0.0775, grad_fn=<MeanBackward0>)\n",
      "[  43/1500] train_loss: 5766.67407 valid_loss: 4436.55979\n",
      "EarlyStopping counter: 3 out of 600\n",
      "tensor(1.3934, grad_fn=<MeanBackward0>)\n",
      "[  44/1500] train_loss: 9306.62320 valid_loss: 4027.19640\n",
      "EarlyStopping counter: 4 out of 600\n",
      "tensor(1.8720, grad_fn=<MeanBackward0>)\n",
      "[  45/1500] train_loss: 5846.52865 valid_loss: 3079.35828\n",
      "EarlyStopping counter: 5 out of 600\n",
      "tensor(1.8180, grad_fn=<MeanBackward0>)\n",
      "[  46/1500] train_loss: 3091.29952 valid_loss: 5603.10141\n",
      "EarlyStopping counter: 6 out of 600\n",
      "tensor(1.7943, grad_fn=<MeanBackward0>)\n",
      "[  47/1500] train_loss: 6128.43257 valid_loss: 10331.90089\n",
      "EarlyStopping counter: 7 out of 600\n",
      "tensor(2.7035, grad_fn=<MeanBackward0>)\n",
      "[  48/1500] train_loss: 2202.67712 valid_loss: 10125.42371\n",
      "EarlyStopping counter: 8 out of 600\n",
      "tensor(2.0842, grad_fn=<MeanBackward0>)\n",
      "[  49/1500] train_loss: 1522.38208 valid_loss: 5369.03490\n",
      "EarlyStopping counter: 9 out of 600\n",
      "tensor(2.8905, grad_fn=<MeanBackward0>)\n",
      "[  50/1500] train_loss: 2005.55885 valid_loss: 2809.94239\n",
      "EarlyStopping counter: 10 out of 600\n",
      "tensor(2.2790, grad_fn=<MeanBackward0>)\n",
      "[  51/1500] train_loss: 7965.73655 valid_loss: 9150.77715\n",
      "EarlyStopping counter: 11 out of 600\n",
      "tensor(0.3383, grad_fn=<MeanBackward0>)\n",
      "[  52/1500] train_loss: 3922.14342 valid_loss: 1886.36662\n",
      "Validation loss decreased (2051.652857 --> 1886.366624).  Saving model ...\n",
      "tensor(0.0360, grad_fn=<MeanBackward0>)\n",
      "[  53/1500] train_loss: 8261.73840 valid_loss: 6899.09994\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(2.2899, grad_fn=<MeanBackward0>)\n",
      "[  54/1500] train_loss: 3310.11991 valid_loss: 1367.34741\n",
      "Validation loss decreased (1886.366624 --> 1367.347412).  Saving model ...\n",
      "tensor(0.5385, grad_fn=<MeanBackward0>)\n",
      "[  55/1500] train_loss: 8268.33438 valid_loss: 4937.34601\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(0.5507, grad_fn=<MeanBackward0>)\n",
      "[  56/1500] train_loss: 4364.81702 valid_loss: 3479.07609\n",
      "EarlyStopping counter: 2 out of 600\n",
      "tensor(3.2900, grad_fn=<MeanBackward0>)\n",
      "[  57/1500] train_loss: 7839.60102 valid_loss: 2448.32154\n",
      "EarlyStopping counter: 3 out of 600\n",
      "tensor(0.7648, grad_fn=<MeanBackward0>)\n",
      "[  58/1500] train_loss: 3062.97308 valid_loss: 6515.59909\n",
      "EarlyStopping counter: 4 out of 600\n",
      "tensor(1.0060, grad_fn=<MeanBackward0>)\n",
      "[  59/1500] train_loss: 3286.13749 valid_loss: 5567.03781\n",
      "EarlyStopping counter: 5 out of 600\n",
      "tensor(1.5856, grad_fn=<MeanBackward0>)\n",
      "[  60/1500] train_loss: 1338.88046 valid_loss: 6693.11568\n",
      "EarlyStopping counter: 6 out of 600\n",
      "tensor(4.3655, grad_fn=<MeanBackward0>)\n",
      "[  61/1500] train_loss: 1892.60786 valid_loss: 4355.05915\n",
      "EarlyStopping counter: 7 out of 600\n",
      "tensor(0.4283, grad_fn=<MeanBackward0>)\n",
      "[  62/1500] train_loss: 6488.99395 valid_loss: 5527.39528\n",
      "EarlyStopping counter: 8 out of 600\n",
      "tensor(0.9761, grad_fn=<MeanBackward0>)\n",
      "[  63/1500] train_loss: 2336.19939 valid_loss: 4311.50589\n",
      "EarlyStopping counter: 9 out of 600\n",
      "tensor(0.7753, grad_fn=<MeanBackward0>)\n",
      "[  64/1500] train_loss: 2550.43059 valid_loss: 6981.34409\n",
      "EarlyStopping counter: 10 out of 600\n",
      "tensor(0.6659, grad_fn=<MeanBackward0>)\n",
      "[  65/1500] train_loss: 6467.65896 valid_loss: 2871.21462\n",
      "EarlyStopping counter: 11 out of 600\n",
      "tensor(3.1079, grad_fn=<MeanBackward0>)\n",
      "[  66/1500] train_loss: 903.14533 valid_loss: 1175.33787\n",
      "Validation loss decreased (1367.347412 --> 1175.337868).  Saving model ...\n",
      "tensor(4.0042, grad_fn=<MeanBackward0>)\n",
      "[  67/1500] train_loss: 992.96597 valid_loss: 5808.38367\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(3.4440, grad_fn=<MeanBackward0>)\n",
      "[  68/1500] train_loss: 2560.72628 valid_loss: 1485.93884\n",
      "EarlyStopping counter: 2 out of 600\n",
      "tensor(2.9143, grad_fn=<MeanBackward0>)\n",
      "[  69/1500] train_loss: 2707.45620 valid_loss: 1161.13814\n",
      "Validation loss decreased (1175.337868 --> 1161.138143).  Saving model ...\n",
      "tensor(0.5906, grad_fn=<MeanBackward0>)\n",
      "[  70/1500] train_loss: 4208.99024 valid_loss: 3325.05718\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(3.4308, grad_fn=<MeanBackward0>)\n",
      "[  71/1500] train_loss: 2892.32013 valid_loss: 2145.13037\n",
      "EarlyStopping counter: 2 out of 600\n",
      "tensor(3.1716, grad_fn=<MeanBackward0>)\n",
      "[  72/1500] train_loss: 2991.60061 valid_loss: 667.06670\n",
      "Validation loss decreased (1161.138143 --> 667.066702).  Saving model ...\n",
      "tensor(3.9446, grad_fn=<MeanBackward0>)\n",
      "[  73/1500] train_loss: 992.32128 valid_loss: 1237.73183\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(2.0085, grad_fn=<MeanBackward0>)\n",
      "[  74/1500] train_loss: 1045.52781 valid_loss: 2301.74579\n",
      "EarlyStopping counter: 2 out of 600\n",
      "tensor(1.6869, grad_fn=<MeanBackward0>)\n",
      "[  75/1500] train_loss: 1306.24946 valid_loss: 5091.98464\n",
      "EarlyStopping counter: 3 out of 600\n",
      "tensor(2.5201, grad_fn=<MeanBackward0>)\n",
      "[  76/1500] train_loss: 3077.84815 valid_loss: 3670.66461\n",
      "EarlyStopping counter: 4 out of 600\n",
      "tensor(3.4039, grad_fn=<MeanBackward0>)\n",
      "[  77/1500] train_loss: 1565.27680 valid_loss: 1960.44049\n",
      "EarlyStopping counter: 5 out of 600\n",
      "tensor(6.2221, grad_fn=<MeanBackward0>)\n",
      "[  78/1500] train_loss: 3539.13841 valid_loss: 4918.80687\n",
      "EarlyStopping counter: 6 out of 600\n",
      "tensor(3.6218, grad_fn=<MeanBackward0>)\n",
      "[  79/1500] train_loss: 509.49577 valid_loss: 554.60894\n",
      "Validation loss decreased (667.066702 --> 554.608939).  Saving model ...\n",
      "tensor(5.3522, grad_fn=<MeanBackward0>)\n",
      "[  80/1500] train_loss: 1208.91387 valid_loss: 1599.80892\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(4.4440, grad_fn=<MeanBackward0>)\n",
      "[  81/1500] train_loss: 1406.86054 valid_loss: 1061.23641\n",
      "EarlyStopping counter: 2 out of 600\n",
      "tensor(7.7541, grad_fn=<MeanBackward0>)\n",
      "[  82/1500] train_loss: 4094.55321 valid_loss: 1422.22811\n",
      "EarlyStopping counter: 3 out of 600\n",
      "tensor(3.3090, grad_fn=<MeanBackward0>)\n",
      "[  83/1500] train_loss: 1684.34536 valid_loss: 1892.07560\n",
      "EarlyStopping counter: 4 out of 600\n",
      "tensor(5.8619, grad_fn=<MeanBackward0>)\n",
      "[  84/1500] train_loss: 981.09310 valid_loss: 984.29261\n",
      "EarlyStopping counter: 5 out of 600\n",
      "tensor(1.8294, grad_fn=<MeanBackward0>)\n",
      "[  85/1500] train_loss: 1902.01869 valid_loss: 2620.24805\n",
      "EarlyStopping counter: 6 out of 600\n",
      "tensor(5.1575, grad_fn=<MeanBackward0>)\n",
      "[  86/1500] train_loss: 1800.52757 valid_loss: 699.92017\n",
      "EarlyStopping counter: 7 out of 600\n",
      "tensor(2.6072, grad_fn=<MeanBackward0>)\n",
      "[  87/1500] train_loss: 1564.34263 valid_loss: 1588.38152\n",
      "EarlyStopping counter: 8 out of 600\n",
      "tensor(2.3723, grad_fn=<MeanBackward0>)\n",
      "[  88/1500] train_loss: 1738.36009 valid_loss: 2449.11638\n",
      "EarlyStopping counter: 9 out of 600\n",
      "tensor(5.8349, grad_fn=<MeanBackward0>)\n",
      "[  89/1500] train_loss: 807.82980 valid_loss: 1680.38460\n",
      "EarlyStopping counter: 10 out of 600\n",
      "tensor(5.5413, grad_fn=<MeanBackward0>)\n",
      "[  90/1500] train_loss: 1346.72159 valid_loss: 2058.11303\n",
      "EarlyStopping counter: 11 out of 600\n",
      "tensor(4.5167, grad_fn=<MeanBackward0>)\n",
      "[  91/1500] train_loss: 286.21147 valid_loss: 1203.50855\n",
      "EarlyStopping counter: 12 out of 600\n",
      "tensor(3.1942, grad_fn=<MeanBackward0>)\n",
      "[  92/1500] train_loss: 2954.48804 valid_loss: 1295.70744\n",
      "EarlyStopping counter: 13 out of 600\n",
      "tensor(3.6193, grad_fn=<MeanBackward0>)\n",
      "[  93/1500] train_loss: 764.48297 valid_loss: 3278.10534\n",
      "EarlyStopping counter: 14 out of 600\n",
      "tensor(3.4486, grad_fn=<MeanBackward0>)\n",
      "[  94/1500] train_loss: 1019.70672 valid_loss: 783.13921\n",
      "EarlyStopping counter: 15 out of 600\n",
      "tensor(2.6719, grad_fn=<MeanBackward0>)\n",
      "[  95/1500] train_loss: 1684.01188 valid_loss: 298.45682\n",
      "Validation loss decreased (554.608939 --> 298.456824).  Saving model ...\n",
      "tensor(3.1353, grad_fn=<MeanBackward0>)\n",
      "[  96/1500] train_loss: 864.23218 valid_loss: 1334.81718\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(3.8101, grad_fn=<MeanBackward0>)\n",
      "[  97/1500] train_loss: 4477.62248 valid_loss: 1945.31274\n",
      "EarlyStopping counter: 2 out of 600\n",
      "tensor(5.0268, grad_fn=<MeanBackward0>)\n",
      "[  98/1500] train_loss: 1013.26414 valid_loss: 456.47954\n",
      "EarlyStopping counter: 3 out of 600\n",
      "tensor(6.1180, grad_fn=<MeanBackward0>)\n",
      "[  99/1500] train_loss: 874.17296 valid_loss: 721.64558\n",
      "EarlyStopping counter: 4 out of 600\n",
      "tensor(5.8304, grad_fn=<MeanBackward0>)\n",
      "[ 100/1500] train_loss: 1292.89721 valid_loss: 662.79543\n",
      "EarlyStopping counter: 5 out of 600\n",
      "tensor(11.1693, grad_fn=<MeanBackward0>)\n",
      "[ 101/1500] train_loss: 4178.98962 valid_loss: 2479.86314\n",
      "EarlyStopping counter: 6 out of 600\n",
      "tensor(6.6260, grad_fn=<MeanBackward0>)\n",
      "[ 102/1500] train_loss: 898.36029 valid_loss: 942.16467\n",
      "EarlyStopping counter: 7 out of 600\n",
      "tensor(4.0733, grad_fn=<MeanBackward0>)\n",
      "[ 103/1500] train_loss: 1367.27512 valid_loss: 2184.90531\n",
      "EarlyStopping counter: 8 out of 600\n",
      "tensor(7.6834, grad_fn=<MeanBackward0>)\n",
      "[ 104/1500] train_loss: 1488.74381 valid_loss: 2704.45248\n",
      "EarlyStopping counter: 9 out of 600\n",
      "tensor(4.8660, grad_fn=<MeanBackward0>)\n",
      "[ 105/1500] train_loss: 1792.71600 valid_loss: 1365.38720\n",
      "EarlyStopping counter: 10 out of 600\n",
      "tensor(4.6066, grad_fn=<MeanBackward0>)\n",
      "[ 106/1500] train_loss: 4406.73301 valid_loss: 1504.52441\n",
      "EarlyStopping counter: 11 out of 600\n",
      "tensor(8.3675, grad_fn=<MeanBackward0>)\n",
      "[ 107/1500] train_loss: 1475.68462 valid_loss: 373.11478\n",
      "EarlyStopping counter: 12 out of 600\n",
      "tensor(8.0876, grad_fn=<MeanBackward0>)\n",
      "[ 108/1500] train_loss: 1521.50741 valid_loss: 1087.84353\n",
      "EarlyStopping counter: 13 out of 600\n",
      "tensor(4.4050, grad_fn=<MeanBackward0>)\n",
      "[ 109/1500] train_loss: 2016.06023 valid_loss: 4105.28923\n",
      "EarlyStopping counter: 14 out of 600\n",
      "tensor(4.0491, grad_fn=<MeanBackward0>)\n",
      "[ 110/1500] train_loss: 3078.25044 valid_loss: 361.96747\n",
      "EarlyStopping counter: 15 out of 600\n",
      "tensor(5.5187, grad_fn=<MeanBackward0>)\n",
      "[ 111/1500] train_loss: 490.68307 valid_loss: 2662.08260\n",
      "EarlyStopping counter: 16 out of 600\n",
      "tensor(4.4723, grad_fn=<MeanBackward0>)\n",
      "[ 112/1500] train_loss: 651.11504 valid_loss: 4680.89370\n",
      "EarlyStopping counter: 17 out of 600\n",
      "tensor(5.1555, grad_fn=<MeanBackward0>)\n",
      "[ 113/1500] train_loss: 982.72185 valid_loss: 984.39556\n",
      "EarlyStopping counter: 18 out of 600\n",
      "tensor(9.0925, grad_fn=<MeanBackward0>)\n",
      "[ 114/1500] train_loss: 3246.35014 valid_loss: 1174.55046\n",
      "EarlyStopping counter: 19 out of 600\n",
      "tensor(3.9623, grad_fn=<MeanBackward0>)\n",
      "[ 115/1500] train_loss: 956.93235 valid_loss: 1861.60013\n",
      "EarlyStopping counter: 20 out of 600\n",
      "tensor(6.6433, grad_fn=<MeanBackward0>)\n",
      "[ 116/1500] train_loss: 1310.36997 valid_loss: 2626.20403\n",
      "EarlyStopping counter: 21 out of 600\n",
      "tensor(5.3136, grad_fn=<MeanBackward0>)\n",
      "[ 117/1500] train_loss: 473.09704 valid_loss: 526.15724\n",
      "EarlyStopping counter: 22 out of 600\n",
      "tensor(4.8768, grad_fn=<MeanBackward0>)\n",
      "[ 118/1500] train_loss: 826.81652 valid_loss: 3115.81361\n",
      "EarlyStopping counter: 23 out of 600\n",
      "tensor(3.5311, grad_fn=<MeanBackward0>)\n",
      "[ 119/1500] train_loss: 1811.97235 valid_loss: 1228.05910\n",
      "EarlyStopping counter: 24 out of 600\n",
      "tensor(3.2566, grad_fn=<MeanBackward0>)\n",
      "[ 120/1500] train_loss: 2355.20742 valid_loss: 2237.22346\n",
      "EarlyStopping counter: 25 out of 600\n",
      "tensor(7.1558, grad_fn=<MeanBackward0>)\n",
      "[ 121/1500] train_loss: 1931.19989 valid_loss: 695.89503\n",
      "EarlyStopping counter: 26 out of 600\n",
      "tensor(3.7539, grad_fn=<MeanBackward0>)\n",
      "[ 122/1500] train_loss: 4696.77293 valid_loss: 2322.50010\n",
      "EarlyStopping counter: 27 out of 600\n",
      "tensor(4.3507, grad_fn=<MeanBackward0>)\n",
      "[ 123/1500] train_loss: 174.60658 valid_loss: 889.04055\n",
      "EarlyStopping counter: 28 out of 600\n",
      "tensor(4.5196, grad_fn=<MeanBackward0>)\n",
      "[ 124/1500] train_loss: 151.78937 valid_loss: 618.31914\n",
      "EarlyStopping counter: 29 out of 600\n",
      "tensor(6.1471, grad_fn=<MeanBackward0>)\n",
      "[ 125/1500] train_loss: 1007.13355 valid_loss: 512.14131\n",
      "EarlyStopping counter: 30 out of 600\n",
      "tensor(3.2426, grad_fn=<MeanBackward0>)\n",
      "[ 126/1500] train_loss: 1379.15764 valid_loss: 475.82443\n",
      "EarlyStopping counter: 31 out of 600\n",
      "tensor(4.9224, grad_fn=<MeanBackward0>)\n",
      "[ 127/1500] train_loss: 262.33024 valid_loss: 1819.49887\n",
      "EarlyStopping counter: 32 out of 600\n",
      "tensor(3.8508, grad_fn=<MeanBackward0>)\n",
      "[ 128/1500] train_loss: 360.92537 valid_loss: 1574.44189\n",
      "EarlyStopping counter: 33 out of 600\n",
      "tensor(3.5497, grad_fn=<MeanBackward0>)\n",
      "[ 129/1500] train_loss: 3204.08311 valid_loss: 942.22149\n",
      "EarlyStopping counter: 34 out of 600\n",
      "tensor(3.3277, grad_fn=<MeanBackward0>)\n",
      "[ 130/1500] train_loss: 2786.65240 valid_loss: 1673.82298\n",
      "EarlyStopping counter: 35 out of 600\n",
      "tensor(4.1434, grad_fn=<MeanBackward0>)\n",
      "[ 131/1500] train_loss: 81.77610 valid_loss: 493.19419\n",
      "EarlyStopping counter: 36 out of 600\n",
      "tensor(8.6743, grad_fn=<MeanBackward0>)\n",
      "[ 132/1500] train_loss: 2774.74588 valid_loss: 2779.42800\n",
      "EarlyStopping counter: 37 out of 600\n",
      "tensor(3.4661, grad_fn=<MeanBackward0>)\n",
      "[ 133/1500] train_loss: 1801.36570 valid_loss: 872.21524\n",
      "EarlyStopping counter: 38 out of 600\n",
      "tensor(3.6967, grad_fn=<MeanBackward0>)\n",
      "[ 134/1500] train_loss: 688.99051 valid_loss: 4624.73430\n",
      "EarlyStopping counter: 39 out of 600\n",
      "tensor(3.1784, grad_fn=<MeanBackward0>)\n",
      "[ 135/1500] train_loss: 2478.09954 valid_loss: 995.68325\n",
      "EarlyStopping counter: 40 out of 600\n",
      "tensor(4.5240, grad_fn=<MeanBackward0>)\n",
      "[ 136/1500] train_loss: 96.49482 valid_loss: 2149.96573\n",
      "EarlyStopping counter: 41 out of 600\n",
      "tensor(4.6631, grad_fn=<MeanBackward0>)\n",
      "[ 137/1500] train_loss: 1322.73630 valid_loss: 2287.14717\n",
      "EarlyStopping counter: 42 out of 600\n",
      "tensor(7.8859, grad_fn=<MeanBackward0>)\n",
      "[ 138/1500] train_loss: 1743.98842 valid_loss: 1268.67683\n",
      "EarlyStopping counter: 43 out of 600\n",
      "tensor(3.3712, grad_fn=<MeanBackward0>)\n",
      "[ 139/1500] train_loss: 3754.60616 valid_loss: 141.80697\n",
      "Validation loss decreased (298.456824 --> 141.806969).  Saving model ...\n",
      "tensor(8.1303, grad_fn=<MeanBackward0>)\n",
      "[ 140/1500] train_loss: 1897.31507 valid_loss: 964.26362\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(3.4157, grad_fn=<MeanBackward0>)\n",
      "[ 141/1500] train_loss: 1378.03358 valid_loss: 1760.73558\n",
      "EarlyStopping counter: 2 out of 600\n",
      "tensor(3.5757, grad_fn=<MeanBackward0>)\n",
      "[ 142/1500] train_loss: 3851.35268 valid_loss: 526.43076\n",
      "EarlyStopping counter: 3 out of 600\n",
      "tensor(3.1360, grad_fn=<MeanBackward0>)\n",
      "[ 143/1500] train_loss: 1583.63564 valid_loss: 2384.45458\n",
      "EarlyStopping counter: 4 out of 600\n",
      "tensor(3.8913, grad_fn=<MeanBackward0>)\n",
      "[ 144/1500] train_loss: 4170.53416 valid_loss: 1810.25821\n",
      "EarlyStopping counter: 5 out of 600\n",
      "tensor(4.6116, grad_fn=<MeanBackward0>)\n",
      "[ 145/1500] train_loss: 309.34680 valid_loss: 140.98636\n",
      "Validation loss decreased (141.806969 --> 140.986356).  Saving model ...\n",
      "tensor(4.2979, grad_fn=<MeanBackward0>)\n",
      "[ 146/1500] train_loss: 160.11180 valid_loss: 2205.80385\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(7.3378, grad_fn=<MeanBackward0>)\n",
      "[ 147/1500] train_loss: 1163.66502 valid_loss: 109.82379\n",
      "Validation loss decreased (140.986356 --> 109.823788).  Saving model ...\n",
      "tensor(6.5754, grad_fn=<MeanBackward0>)\n",
      "[ 148/1500] train_loss: 687.60382 valid_loss: 1913.54224\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(4.8920, grad_fn=<MeanBackward0>)\n",
      "[ 149/1500] train_loss: 248.28985 valid_loss: 550.26774\n",
      "EarlyStopping counter: 2 out of 600\n",
      "tensor(5.0852, grad_fn=<MeanBackward0>)\n",
      "[ 150/1500] train_loss: 205.77714 valid_loss: 591.34790\n",
      "EarlyStopping counter: 3 out of 600\n",
      "tensor(4.2404, grad_fn=<MeanBackward0>)\n",
      "[ 151/1500] train_loss: 1375.48189 valid_loss: 283.97068\n",
      "EarlyStopping counter: 4 out of 600\n",
      "tensor(3.4210, grad_fn=<MeanBackward0>)\n",
      "[ 152/1500] train_loss: 3742.97365 valid_loss: 2647.12581\n",
      "EarlyStopping counter: 5 out of 600\n",
      "tensor(5.8612, grad_fn=<MeanBackward0>)\n",
      "[ 153/1500] train_loss: 878.56113 valid_loss: 358.97315\n",
      "EarlyStopping counter: 6 out of 600\n",
      "tensor(4.2727, grad_fn=<MeanBackward0>)\n",
      "[ 154/1500] train_loss: 893.18801 valid_loss: 820.48613\n",
      "EarlyStopping counter: 7 out of 600\n",
      "tensor(4.1900, grad_fn=<MeanBackward0>)\n",
      "[ 155/1500] train_loss: 257.17943 valid_loss: 1023.91616\n",
      "EarlyStopping counter: 8 out of 600\n",
      "tensor(5.4020, grad_fn=<MeanBackward0>)\n",
      "[ 156/1500] train_loss: 183.69986 valid_loss: 638.59943\n",
      "EarlyStopping counter: 9 out of 600\n",
      "tensor(5.3046, grad_fn=<MeanBackward0>)\n",
      "[ 157/1500] train_loss: 380.82383 valid_loss: 697.84327\n",
      "EarlyStopping counter: 10 out of 600\n",
      "tensor(3.3489, grad_fn=<MeanBackward0>)\n",
      "[ 158/1500] train_loss: 800.64567 valid_loss: 922.80719\n",
      "EarlyStopping counter: 11 out of 600\n",
      "tensor(4.0452, grad_fn=<MeanBackward0>)\n",
      "[ 159/1500] train_loss: 188.09365 valid_loss: 261.20112\n",
      "EarlyStopping counter: 12 out of 600\n",
      "tensor(4.6145, grad_fn=<MeanBackward0>)\n",
      "[ 160/1500] train_loss: 254.10451 valid_loss: 769.46983\n",
      "EarlyStopping counter: 13 out of 600\n",
      "tensor(5.4910, grad_fn=<MeanBackward0>)\n",
      "[ 161/1500] train_loss: 765.76442 valid_loss: 1884.35576\n",
      "EarlyStopping counter: 14 out of 600\n",
      "tensor(3.5622, grad_fn=<MeanBackward0>)\n",
      "[ 162/1500] train_loss: 2484.22446 valid_loss: 3143.85809\n",
      "EarlyStopping counter: 15 out of 600\n",
      "tensor(4.6289, grad_fn=<MeanBackward0>)\n",
      "[ 163/1500] train_loss: 389.87324 valid_loss: 551.77936\n",
      "EarlyStopping counter: 16 out of 600\n",
      "tensor(6.5718, grad_fn=<MeanBackward0>)\n",
      "[ 164/1500] train_loss: 557.05100 valid_loss: 937.01141\n",
      "EarlyStopping counter: 17 out of 600\n",
      "tensor(5.5590, grad_fn=<MeanBackward0>)\n",
      "[ 165/1500] train_loss: 793.09775 valid_loss: 1444.80176\n",
      "EarlyStopping counter: 18 out of 600\n",
      "tensor(6.2999, grad_fn=<MeanBackward0>)\n",
      "[ 166/1500] train_loss: 477.79736 valid_loss: 238.45226\n",
      "EarlyStopping counter: 19 out of 600\n",
      "tensor(4.9465, grad_fn=<MeanBackward0>)\n",
      "[ 167/1500] train_loss: 101.47402 valid_loss: 426.54438\n",
      "EarlyStopping counter: 20 out of 600\n",
      "tensor(4.4630, grad_fn=<MeanBackward0>)\n",
      "[ 168/1500] train_loss: 59.77155 valid_loss: 783.40955\n",
      "EarlyStopping counter: 21 out of 600\n",
      "tensor(7.7674, grad_fn=<MeanBackward0>)\n",
      "[ 169/1500] train_loss: 1526.00161 valid_loss: 152.17845\n",
      "EarlyStopping counter: 22 out of 600\n",
      "tensor(7.2470, grad_fn=<MeanBackward0>)\n",
      "[ 170/1500] train_loss: 1231.66946 valid_loss: 401.61772\n",
      "EarlyStopping counter: 23 out of 600\n",
      "tensor(3.4015, grad_fn=<MeanBackward0>)\n",
      "[ 171/1500] train_loss: 456.86558 valid_loss: 151.40067\n",
      "EarlyStopping counter: 24 out of 600\n",
      "tensor(6.0007, grad_fn=<MeanBackward0>)\n",
      "[ 172/1500] train_loss: 939.65571 valid_loss: 181.52592\n",
      "EarlyStopping counter: 25 out of 600\n",
      "tensor(5.1556, grad_fn=<MeanBackward0>)\n",
      "[ 173/1500] train_loss: 651.87505 valid_loss: 596.66196\n",
      "EarlyStopping counter: 26 out of 600\n",
      "tensor(4.0055, grad_fn=<MeanBackward0>)\n",
      "[ 174/1500] train_loss: 349.61208 valid_loss: 275.53387\n",
      "EarlyStopping counter: 27 out of 600\n",
      "tensor(4.2264, grad_fn=<MeanBackward0>)\n",
      "[ 175/1500] train_loss: 913.06767 valid_loss: 564.78052\n",
      "EarlyStopping counter: 28 out of 600\n",
      "tensor(5.4966, grad_fn=<MeanBackward0>)\n",
      "[ 176/1500] train_loss: 654.91896 valid_loss: 1306.48205\n",
      "EarlyStopping counter: 29 out of 600\n",
      "tensor(2.8681, grad_fn=<MeanBackward0>)\n",
      "[ 177/1500] train_loss: 2354.62119 valid_loss: 102.67306\n",
      "Validation loss decreased (109.823788 --> 102.673063).  Saving model ...\n",
      "tensor(6.1936, grad_fn=<MeanBackward0>)\n",
      "[ 178/1500] train_loss: 965.52473 valid_loss: 218.03078\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(2.6300, grad_fn=<MeanBackward0>)\n",
      "[ 179/1500] train_loss: 1329.54274 valid_loss: 1690.97894\n",
      "EarlyStopping counter: 2 out of 600\n",
      "tensor(3.7602, grad_fn=<MeanBackward0>)\n",
      "[ 180/1500] train_loss: 308.03514 valid_loss: 161.72875\n",
      "EarlyStopping counter: 3 out of 600\n",
      "tensor(4.6841, grad_fn=<MeanBackward0>)\n",
      "[ 181/1500] train_loss: 371.56412 valid_loss: 1037.80107\n",
      "EarlyStopping counter: 4 out of 600\n",
      "tensor(3.2437, grad_fn=<MeanBackward0>)\n",
      "[ 182/1500] train_loss: 276.75732 valid_loss: 1066.67800\n",
      "EarlyStopping counter: 5 out of 600\n",
      "tensor(6.4390, grad_fn=<MeanBackward0>)\n",
      "[ 183/1500] train_loss: 1540.27718 valid_loss: 172.76829\n",
      "EarlyStopping counter: 6 out of 600\n",
      "tensor(3.7859, grad_fn=<MeanBackward0>)\n",
      "[ 184/1500] train_loss: 104.54405 valid_loss: 542.42289\n",
      "EarlyStopping counter: 7 out of 600\n",
      "tensor(4.0982, grad_fn=<MeanBackward0>)\n",
      "[ 185/1500] train_loss: 335.78750 valid_loss: 489.57093\n",
      "EarlyStopping counter: 8 out of 600\n",
      "tensor(4.3985, grad_fn=<MeanBackward0>)\n",
      "[ 186/1500] train_loss: 107.97337 valid_loss: 209.52416\n",
      "EarlyStopping counter: 9 out of 600\n",
      "tensor(3.8765, grad_fn=<MeanBackward0>)\n",
      "[ 187/1500] train_loss: 1888.92627 valid_loss: 145.80371\n",
      "EarlyStopping counter: 10 out of 600\n",
      "tensor(3.0104, grad_fn=<MeanBackward0>)\n",
      "[ 188/1500] train_loss: 484.62662 valid_loss: 156.36764\n",
      "EarlyStopping counter: 11 out of 600\n",
      "tensor(2.7732, grad_fn=<MeanBackward0>)\n",
      "[ 189/1500] train_loss: 1703.91262 valid_loss: 172.65186\n",
      "EarlyStopping counter: 12 out of 600\n",
      "tensor(3.5808, grad_fn=<MeanBackward0>)\n",
      "[ 190/1500] train_loss: 204.64582 valid_loss: 197.91960\n",
      "EarlyStopping counter: 13 out of 600\n",
      "tensor(2.6707, grad_fn=<MeanBackward0>)\n",
      "[ 191/1500] train_loss: 777.06865 valid_loss: 1343.58321\n",
      "EarlyStopping counter: 14 out of 600\n",
      "tensor(4.3821, grad_fn=<MeanBackward0>)\n",
      "[ 192/1500] train_loss: 290.64789 valid_loss: 115.14589\n",
      "EarlyStopping counter: 15 out of 600\n",
      "tensor(2.8668, grad_fn=<MeanBackward0>)\n",
      "[ 193/1500] train_loss: 279.75217 valid_loss: 131.87721\n",
      "EarlyStopping counter: 16 out of 600\n",
      "tensor(2.6492, grad_fn=<MeanBackward0>)\n",
      "[ 194/1500] train_loss: 1837.66312 valid_loss: 606.73384\n",
      "EarlyStopping counter: 17 out of 600\n",
      "tensor(4.7376, grad_fn=<MeanBackward0>)\n",
      "[ 195/1500] train_loss: 582.41495 valid_loss: 977.99512\n",
      "EarlyStopping counter: 18 out of 600\n",
      "tensor(5.5468, grad_fn=<MeanBackward0>)\n",
      "[ 196/1500] train_loss: 1281.44781 valid_loss: 683.58662\n",
      "EarlyStopping counter: 19 out of 600\n",
      "tensor(2.9819, grad_fn=<MeanBackward0>)\n",
      "[ 197/1500] train_loss: 1593.03136 valid_loss: 1656.06009\n",
      "EarlyStopping counter: 20 out of 600\n",
      "tensor(2.9540, grad_fn=<MeanBackward0>)\n",
      "[ 198/1500] train_loss: 2152.22576 valid_loss: 192.35849\n",
      "EarlyStopping counter: 21 out of 600\n",
      "tensor(4.8058, grad_fn=<MeanBackward0>)\n",
      "[ 199/1500] train_loss: 438.28257 valid_loss: 831.85278\n",
      "EarlyStopping counter: 22 out of 600\n",
      "tensor(3.2788, grad_fn=<MeanBackward0>)\n",
      "[ 200/1500] train_loss: 1556.87249 valid_loss: 112.60014\n",
      "EarlyStopping counter: 23 out of 600\n",
      "tensor(3.1519, grad_fn=<MeanBackward0>)\n",
      "[ 201/1500] train_loss: 1453.46469 valid_loss: 647.89351\n",
      "EarlyStopping counter: 24 out of 600\n",
      "tensor(3.6042, grad_fn=<MeanBackward0>)\n",
      "[ 202/1500] train_loss: 145.68584 valid_loss: 164.90003\n",
      "EarlyStopping counter: 25 out of 600\n",
      "tensor(3.1865, grad_fn=<MeanBackward0>)\n",
      "[ 203/1500] train_loss: 294.50805 valid_loss: 283.98839\n",
      "EarlyStopping counter: 26 out of 600\n",
      "tensor(3.2159, grad_fn=<MeanBackward0>)\n",
      "[ 204/1500] train_loss: 316.30344 valid_loss: 407.33574\n",
      "EarlyStopping counter: 27 out of 600\n",
      "tensor(4.4783, grad_fn=<MeanBackward0>)\n",
      "[ 205/1500] train_loss: 169.51667 valid_loss: 331.60400\n",
      "EarlyStopping counter: 28 out of 600\n",
      "tensor(5.3804, grad_fn=<MeanBackward0>)\n",
      "[ 206/1500] train_loss: 391.04302 valid_loss: 592.21960\n",
      "EarlyStopping counter: 29 out of 600\n",
      "tensor(4.7892, grad_fn=<MeanBackward0>)\n",
      "[ 207/1500] train_loss: 263.36693 valid_loss: 311.04848\n",
      "EarlyStopping counter: 30 out of 600\n",
      "tensor(5.9572, grad_fn=<MeanBackward0>)\n",
      "[ 208/1500] train_loss: 1004.42398 valid_loss: 114.17837\n",
      "EarlyStopping counter: 31 out of 600\n",
      "tensor(6.3247, grad_fn=<MeanBackward0>)\n",
      "[ 209/1500] train_loss: 296.53238 valid_loss: 1220.19697\n",
      "EarlyStopping counter: 32 out of 600\n",
      "tensor(4.9507, grad_fn=<MeanBackward0>)\n",
      "[ 210/1500] train_loss: 172.90788 valid_loss: 411.92640\n",
      "EarlyStopping counter: 33 out of 600\n",
      "tensor(3.1744, grad_fn=<MeanBackward0>)\n",
      "[ 211/1500] train_loss: 503.11049 valid_loss: 579.16544\n",
      "EarlyStopping counter: 34 out of 600\n",
      "tensor(2.9028, grad_fn=<MeanBackward0>)\n",
      "[ 212/1500] train_loss: 434.99928 valid_loss: 310.30898\n",
      "EarlyStopping counter: 35 out of 600\n",
      "tensor(7.0064, grad_fn=<MeanBackward0>)\n",
      "[ 213/1500] train_loss: 1280.00569 valid_loss: 498.92538\n",
      "EarlyStopping counter: 36 out of 600\n",
      "tensor(3.9214, grad_fn=<MeanBackward0>)\n",
      "[ 214/1500] train_loss: 250.22872 valid_loss: 948.89267\n",
      "EarlyStopping counter: 37 out of 600\n",
      "tensor(7.4767, grad_fn=<MeanBackward0>)\n",
      "[ 215/1500] train_loss: 455.91715 valid_loss: 118.64906\n",
      "EarlyStopping counter: 38 out of 600\n",
      "tensor(3.9062, grad_fn=<MeanBackward0>)\n",
      "[ 216/1500] train_loss: 71.99296 valid_loss: 138.61877\n",
      "EarlyStopping counter: 39 out of 600\n",
      "tensor(5.0682, grad_fn=<MeanBackward0>)\n",
      "[ 217/1500] train_loss: 104.13132 valid_loss: 87.99754\n",
      "Validation loss decreased (102.673063 --> 87.997536).  Saving model ...\n",
      "tensor(6.2345, grad_fn=<MeanBackward0>)\n",
      "[ 218/1500] train_loss: 1048.41437 valid_loss: 551.41731\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(4.9466, grad_fn=<MeanBackward0>)\n",
      "[ 219/1500] train_loss: 616.00184 valid_loss: 402.47969\n",
      "EarlyStopping counter: 2 out of 600\n",
      "tensor(6.5551, grad_fn=<MeanBackward0>)\n",
      "[ 220/1500] train_loss: 494.21532 valid_loss: 217.35074\n",
      "EarlyStopping counter: 3 out of 600\n",
      "tensor(3.3546, grad_fn=<MeanBackward0>)\n",
      "[ 221/1500] train_loss: 518.35621 valid_loss: 460.43481\n",
      "EarlyStopping counter: 4 out of 600\n",
      "tensor(8.2418, grad_fn=<MeanBackward0>)\n",
      "[ 222/1500] train_loss: 1078.24397 valid_loss: 348.01711\n",
      "EarlyStopping counter: 5 out of 600\n",
      "tensor(4.4600, grad_fn=<MeanBackward0>)\n",
      "[ 223/1500] train_loss: 851.81221 valid_loss: 437.38080\n",
      "EarlyStopping counter: 6 out of 600\n",
      "tensor(4.3249, grad_fn=<MeanBackward0>)\n",
      "[ 224/1500] train_loss: 98.30168 valid_loss: 61.13306\n",
      "Validation loss decreased (87.997536 --> 61.133062).  Saving model ...\n",
      "tensor(6.1519, grad_fn=<MeanBackward0>)\n",
      "[ 225/1500] train_loss: 651.92254 valid_loss: 60.99964\n",
      "Validation loss decreased (61.133062 --> 60.999644).  Saving model ...\n",
      "tensor(4.7135, grad_fn=<MeanBackward0>)\n",
      "[ 226/1500] train_loss: 72.73484 valid_loss: 198.46945\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(3.9467, grad_fn=<MeanBackward0>)\n",
      "[ 227/1500] train_loss: 340.18305 valid_loss: 580.45172\n",
      "EarlyStopping counter: 2 out of 600\n",
      "tensor(4.3249, grad_fn=<MeanBackward0>)\n",
      "[ 228/1500] train_loss: 484.95347 valid_loss: 433.19874\n",
      "EarlyStopping counter: 3 out of 600\n",
      "tensor(4.9796, grad_fn=<MeanBackward0>)\n",
      "[ 229/1500] train_loss: 141.07045 valid_loss: 907.35422\n",
      "EarlyStopping counter: 4 out of 600\n",
      "tensor(3.3683, grad_fn=<MeanBackward0>)\n",
      "[ 230/1500] train_loss: 827.21331 valid_loss: 141.31473\n",
      "EarlyStopping counter: 5 out of 600\n",
      "tensor(4.0983, grad_fn=<MeanBackward0>)\n",
      "[ 231/1500] train_loss: 63.67053 valid_loss: 625.85382\n",
      "EarlyStopping counter: 6 out of 600\n",
      "tensor(3.7133, grad_fn=<MeanBackward0>)\n",
      "[ 232/1500] train_loss: 325.92467 valid_loss: 96.45880\n",
      "EarlyStopping counter: 7 out of 600\n",
      "tensor(4.5067, grad_fn=<MeanBackward0>)\n",
      "[ 233/1500] train_loss: 502.34394 valid_loss: 408.23614\n",
      "EarlyStopping counter: 8 out of 600\n",
      "tensor(3.3793, grad_fn=<MeanBackward0>)\n",
      "[ 234/1500] train_loss: 203.57677 valid_loss: 396.30241\n",
      "EarlyStopping counter: 9 out of 600\n",
      "tensor(4.4617, grad_fn=<MeanBackward0>)\n",
      "[ 235/1500] train_loss: 316.67382 valid_loss: 716.43846\n",
      "EarlyStopping counter: 10 out of 600\n",
      "tensor(3.7988, grad_fn=<MeanBackward0>)\n",
      "[ 236/1500] train_loss: 500.93318 valid_loss: 44.82039\n",
      "Validation loss decreased (60.999644 --> 44.820394).  Saving model ...\n",
      "tensor(6.3330, grad_fn=<MeanBackward0>)\n",
      "[ 237/1500] train_loss: 569.92661 valid_loss: 510.80200\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(4.3367, grad_fn=<MeanBackward0>)\n",
      "[ 238/1500] train_loss: 304.84537 valid_loss: 137.13552\n",
      "EarlyStopping counter: 2 out of 600\n",
      "tensor(3.7827, grad_fn=<MeanBackward0>)\n",
      "[ 239/1500] train_loss: 70.11848 valid_loss: 276.55623\n",
      "EarlyStopping counter: 3 out of 600\n",
      "tensor(3.4668, grad_fn=<MeanBackward0>)\n",
      "[ 240/1500] train_loss: 272.00916 valid_loss: 329.45063\n",
      "EarlyStopping counter: 4 out of 600\n",
      "tensor(4.9530, grad_fn=<MeanBackward0>)\n",
      "[ 241/1500] train_loss: 1365.79028 valid_loss: 625.30304\n",
      "EarlyStopping counter: 5 out of 600\n",
      "tensor(4.6902, grad_fn=<MeanBackward0>)\n",
      "[ 242/1500] train_loss: 220.17889 valid_loss: 800.23161\n",
      "EarlyStopping counter: 6 out of 600\n",
      "tensor(5.9082, grad_fn=<MeanBackward0>)\n",
      "[ 243/1500] train_loss: 313.41372 valid_loss: 531.18434\n",
      "EarlyStopping counter: 7 out of 600\n",
      "tensor(5.0454, grad_fn=<MeanBackward0>)\n",
      "[ 244/1500] train_loss: 1568.06071 valid_loss: 90.18534\n",
      "EarlyStopping counter: 8 out of 600\n",
      "tensor(3.5364, grad_fn=<MeanBackward0>)\n",
      "[ 245/1500] train_loss: 106.05406 valid_loss: 636.28994\n",
      "EarlyStopping counter: 9 out of 600\n",
      "tensor(4.7030, grad_fn=<MeanBackward0>)\n",
      "[ 246/1500] train_loss: 512.01976 valid_loss: 106.89600\n",
      "EarlyStopping counter: 10 out of 600\n",
      "tensor(5.2739, grad_fn=<MeanBackward0>)\n",
      "[ 247/1500] train_loss: 386.57176 valid_loss: 94.29033\n",
      "EarlyStopping counter: 11 out of 600\n",
      "tensor(4.1542, grad_fn=<MeanBackward0>)\n",
      "[ 248/1500] train_loss: 208.87473 valid_loss: 176.92350\n",
      "EarlyStopping counter: 12 out of 600\n",
      "tensor(6.0854, grad_fn=<MeanBackward0>)\n",
      "[ 249/1500] train_loss: 259.22069 valid_loss: 105.74083\n",
      "EarlyStopping counter: 13 out of 600\n",
      "tensor(8.3123, grad_fn=<MeanBackward0>)\n",
      "[ 250/1500] train_loss: 1512.86781 valid_loss: 1315.80821\n",
      "EarlyStopping counter: 14 out of 600\n",
      "tensor(6.4652, grad_fn=<MeanBackward0>)\n",
      "[ 251/1500] train_loss: 1038.88050 valid_loss: 91.36916\n",
      "EarlyStopping counter: 15 out of 600\n",
      "tensor(4.6787, grad_fn=<MeanBackward0>)\n",
      "[ 252/1500] train_loss: 298.04437 valid_loss: 137.27428\n",
      "EarlyStopping counter: 16 out of 600\n",
      "tensor(4.3706, grad_fn=<MeanBackward0>)\n",
      "[ 253/1500] train_loss: 115.07764 valid_loss: 276.22760\n",
      "EarlyStopping counter: 17 out of 600\n",
      "tensor(6.9665, grad_fn=<MeanBackward0>)\n",
      "[ 254/1500] train_loss: 982.72154 valid_loss: 191.17663\n",
      "EarlyStopping counter: 18 out of 600\n",
      "tensor(4.4983, grad_fn=<MeanBackward0>)\n",
      "[ 255/1500] train_loss: 280.90514 valid_loss: 120.83709\n",
      "EarlyStopping counter: 19 out of 600\n",
      "tensor(3.9450, grad_fn=<MeanBackward0>)\n",
      "[ 256/1500] train_loss: 85.18140 valid_loss: 230.12952\n",
      "EarlyStopping counter: 20 out of 600\n",
      "tensor(6.0272, grad_fn=<MeanBackward0>)\n",
      "[ 257/1500] train_loss: 699.98691 valid_loss: 173.63920\n",
      "EarlyStopping counter: 21 out of 600\n",
      "tensor(3.8883, grad_fn=<MeanBackward0>)\n",
      "[ 258/1500] train_loss: 89.76297 valid_loss: 706.71100\n",
      "EarlyStopping counter: 22 out of 600\n",
      "tensor(5.6799, grad_fn=<MeanBackward0>)\n",
      "[ 259/1500] train_loss: 527.71667 valid_loss: 477.03277\n",
      "EarlyStopping counter: 23 out of 600\n",
      "tensor(3.8385, grad_fn=<MeanBackward0>)\n",
      "[ 260/1500] train_loss: 121.86632 valid_loss: 184.63652\n",
      "EarlyStopping counter: 24 out of 600\n",
      "tensor(6.5418, grad_fn=<MeanBackward0>)\n",
      "[ 261/1500] train_loss: 397.20804 valid_loss: 62.86908\n",
      "EarlyStopping counter: 25 out of 600\n",
      "tensor(3.9273, grad_fn=<MeanBackward0>)\n",
      "[ 262/1500] train_loss: 484.77299 valid_loss: 268.63590\n",
      "EarlyStopping counter: 26 out of 600\n",
      "tensor(2.6658, grad_fn=<MeanBackward0>)\n",
      "[ 263/1500] train_loss: 344.83035 valid_loss: 320.03171\n",
      "EarlyStopping counter: 27 out of 600\n",
      "tensor(5.5652, grad_fn=<MeanBackward0>)\n",
      "[ 264/1500] train_loss: 414.37243 valid_loss: 714.09843\n",
      "EarlyStopping counter: 28 out of 600\n",
      "tensor(3.9128, grad_fn=<MeanBackward0>)\n",
      "[ 265/1500] train_loss: 104.60391 valid_loss: 74.50242\n",
      "EarlyStopping counter: 29 out of 600\n",
      "tensor(5.0045, grad_fn=<MeanBackward0>)\n",
      "[ 266/1500] train_loss: 575.72246 valid_loss: 483.30624\n",
      "EarlyStopping counter: 30 out of 600\n",
      "tensor(6.3420, grad_fn=<MeanBackward0>)\n",
      "[ 267/1500] train_loss: 494.20941 valid_loss: 191.84467\n",
      "EarlyStopping counter: 31 out of 600\n",
      "tensor(5.0869, grad_fn=<MeanBackward0>)\n",
      "[ 268/1500] train_loss: 89.64181 valid_loss: 335.63214\n",
      "EarlyStopping counter: 32 out of 600\n",
      "tensor(3.6663, grad_fn=<MeanBackward0>)\n",
      "[ 269/1500] train_loss: 86.43355 valid_loss: 58.67176\n",
      "EarlyStopping counter: 33 out of 600\n",
      "tensor(4.8600, grad_fn=<MeanBackward0>)\n",
      "[ 270/1500] train_loss: 241.87898 valid_loss: 286.82837\n",
      "EarlyStopping counter: 34 out of 600\n",
      "tensor(3.8250, grad_fn=<MeanBackward0>)\n",
      "[ 271/1500] train_loss: 243.04944 valid_loss: 384.90813\n",
      "EarlyStopping counter: 35 out of 600\n",
      "tensor(4.7816, grad_fn=<MeanBackward0>)\n",
      "[ 272/1500] train_loss: 1053.50630 valid_loss: 137.34440\n",
      "EarlyStopping counter: 36 out of 600\n",
      "tensor(3.2771, grad_fn=<MeanBackward0>)\n",
      "[ 273/1500] train_loss: 298.37939 valid_loss: 125.52300\n",
      "EarlyStopping counter: 37 out of 600\n",
      "tensor(3.7198, grad_fn=<MeanBackward0>)\n",
      "[ 274/1500] train_loss: 101.94333 valid_loss: 312.62783\n",
      "EarlyStopping counter: 38 out of 600\n",
      "tensor(4.6065, grad_fn=<MeanBackward0>)\n",
      "[ 275/1500] train_loss: 494.55295 valid_loss: 188.33204\n",
      "EarlyStopping counter: 39 out of 600\n",
      "tensor(4.4354, grad_fn=<MeanBackward0>)\n",
      "[ 276/1500] train_loss: 248.79987 valid_loss: 426.09097\n",
      "EarlyStopping counter: 40 out of 600\n",
      "tensor(4.1616, grad_fn=<MeanBackward0>)\n",
      "[ 277/1500] train_loss: 614.43264 valid_loss: 118.09022\n",
      "EarlyStopping counter: 41 out of 600\n",
      "tensor(2.8595, grad_fn=<MeanBackward0>)\n",
      "[ 278/1500] train_loss: 786.16313 valid_loss: 823.71292\n",
      "EarlyStopping counter: 42 out of 600\n",
      "tensor(4.8758, grad_fn=<MeanBackward0>)\n",
      "[ 279/1500] train_loss: 313.11177 valid_loss: 249.69015\n",
      "EarlyStopping counter: 43 out of 600\n",
      "tensor(3.8704, grad_fn=<MeanBackward0>)\n",
      "[ 280/1500] train_loss: 166.38385 valid_loss: 61.91556\n",
      "EarlyStopping counter: 44 out of 600\n",
      "tensor(5.3744, grad_fn=<MeanBackward0>)\n",
      "[ 281/1500] train_loss: 145.76774 valid_loss: 130.85031\n",
      "EarlyStopping counter: 45 out of 600\n",
      "tensor(4.7352, grad_fn=<MeanBackward0>)\n",
      "[ 282/1500] train_loss: 117.37993 valid_loss: 389.16299\n",
      "EarlyStopping counter: 46 out of 600\n",
      "tensor(3.7287, grad_fn=<MeanBackward0>)\n",
      "[ 283/1500] train_loss: 449.60601 valid_loss: 432.55798\n",
      "EarlyStopping counter: 47 out of 600\n",
      "tensor(5.0686, grad_fn=<MeanBackward0>)\n",
      "[ 284/1500] train_loss: 115.32799 valid_loss: 221.22507\n",
      "EarlyStopping counter: 48 out of 600\n",
      "tensor(4.6925, grad_fn=<MeanBackward0>)\n",
      "[ 285/1500] train_loss: 462.61664 valid_loss: 100.32065\n",
      "EarlyStopping counter: 49 out of 600\n",
      "tensor(4.7987, grad_fn=<MeanBackward0>)\n",
      "[ 286/1500] train_loss: 445.48001 valid_loss: 303.24900\n",
      "EarlyStopping counter: 50 out of 600\n",
      "tensor(4.6417, grad_fn=<MeanBackward0>)\n",
      "[ 287/1500] train_loss: 383.21039 valid_loss: 89.99410\n",
      "EarlyStopping counter: 51 out of 600\n",
      "tensor(6.5952, grad_fn=<MeanBackward0>)\n",
      "[ 288/1500] train_loss: 564.72360 valid_loss: 148.29899\n",
      "EarlyStopping counter: 52 out of 600\n",
      "tensor(4.7944, grad_fn=<MeanBackward0>)\n",
      "[ 289/1500] train_loss: 340.94066 valid_loss: 569.14974\n",
      "EarlyStopping counter: 53 out of 600\n",
      "tensor(5.6469, grad_fn=<MeanBackward0>)\n",
      "[ 290/1500] train_loss: 399.59133 valid_loss: 151.72550\n",
      "EarlyStopping counter: 54 out of 600\n",
      "tensor(6.6664, grad_fn=<MeanBackward0>)\n",
      "[ 291/1500] train_loss: 501.17674 valid_loss: 334.37757\n",
      "EarlyStopping counter: 55 out of 600\n",
      "tensor(5.1435, grad_fn=<MeanBackward0>)\n",
      "[ 292/1500] train_loss: 613.63173 valid_loss: 295.64967\n",
      "EarlyStopping counter: 56 out of 600\n",
      "tensor(4.7996, grad_fn=<MeanBackward0>)\n",
      "[ 293/1500] train_loss: 915.06092 valid_loss: 262.70640\n",
      "EarlyStopping counter: 57 out of 600\n",
      "tensor(4.3222, grad_fn=<MeanBackward0>)\n",
      "[ 294/1500] train_loss: 333.12135 valid_loss: 239.41073\n",
      "EarlyStopping counter: 58 out of 600\n",
      "tensor(3.1376, grad_fn=<MeanBackward0>)\n",
      "[ 295/1500] train_loss: 720.53084 valid_loss: 386.83746\n",
      "EarlyStopping counter: 59 out of 600\n",
      "tensor(3.8199, grad_fn=<MeanBackward0>)\n",
      "[ 296/1500] train_loss: 269.85468 valid_loss: 513.16158\n",
      "EarlyStopping counter: 60 out of 600\n",
      "tensor(5.8894, grad_fn=<MeanBackward0>)\n",
      "[ 297/1500] train_loss: 388.43387 valid_loss: 382.93024\n",
      "EarlyStopping counter: 61 out of 600\n",
      "tensor(4.2635, grad_fn=<MeanBackward0>)\n",
      "[ 298/1500] train_loss: 227.10127 valid_loss: 132.96766\n",
      "EarlyStopping counter: 62 out of 600\n",
      "tensor(6.4115, grad_fn=<MeanBackward0>)\n",
      "[ 299/1500] train_loss: 300.40246 valid_loss: 455.29114\n",
      "EarlyStopping counter: 63 out of 600\n",
      "tensor(4.3615, grad_fn=<MeanBackward0>)\n",
      "[ 300/1500] train_loss: 404.95871 valid_loss: 551.00498\n",
      "EarlyStopping counter: 64 out of 600\n",
      "tensor(5.3097, grad_fn=<MeanBackward0>)\n",
      "[ 301/1500] train_loss: 194.85149 valid_loss: 388.19563\n",
      "EarlyStopping counter: 65 out of 600\n",
      "tensor(3.1998, grad_fn=<MeanBackward0>)\n",
      "[ 302/1500] train_loss: 725.40249 valid_loss: 444.09015\n",
      "EarlyStopping counter: 66 out of 600\n",
      "tensor(3.5576, grad_fn=<MeanBackward0>)\n",
      "[ 303/1500] train_loss: 326.19523 valid_loss: 98.90495\n",
      "EarlyStopping counter: 67 out of 600\n",
      "tensor(3.7980, grad_fn=<MeanBackward0>)\n",
      "[ 304/1500] train_loss: 323.23311 valid_loss: 170.23494\n",
      "EarlyStopping counter: 68 out of 600\n",
      "tensor(5.4347, grad_fn=<MeanBackward0>)\n",
      "[ 305/1500] train_loss: 298.93741 valid_loss: 474.81392\n",
      "EarlyStopping counter: 69 out of 600\n",
      "tensor(3.8592, grad_fn=<MeanBackward0>)\n",
      "[ 306/1500] train_loss: 257.24767 valid_loss: 107.56754\n",
      "EarlyStopping counter: 70 out of 600\n",
      "tensor(4.8531, grad_fn=<MeanBackward0>)\n",
      "[ 307/1500] train_loss: 98.02969 valid_loss: 237.02296\n",
      "EarlyStopping counter: 71 out of 600\n",
      "tensor(3.7359, grad_fn=<MeanBackward0>)\n",
      "[ 308/1500] train_loss: 364.29323 valid_loss: 316.96581\n",
      "EarlyStopping counter: 72 out of 600\n",
      "tensor(4.9806, grad_fn=<MeanBackward0>)\n",
      "[ 309/1500] train_loss: 308.49010 valid_loss: 524.13951\n",
      "EarlyStopping counter: 73 out of 600\n",
      "tensor(4.8711, grad_fn=<MeanBackward0>)\n",
      "[ 310/1500] train_loss: 336.67190 valid_loss: 227.45024\n",
      "EarlyStopping counter: 74 out of 600\n",
      "tensor(5.1094, grad_fn=<MeanBackward0>)\n",
      "[ 311/1500] train_loss: 164.10231 valid_loss: 133.26592\n",
      "EarlyStopping counter: 75 out of 600\n",
      "tensor(4.5731, grad_fn=<MeanBackward0>)\n",
      "[ 312/1500] train_loss: 75.82220 valid_loss: 177.12415\n",
      "EarlyStopping counter: 76 out of 600\n",
      "tensor(3.5792, grad_fn=<MeanBackward0>)\n",
      "[ 313/1500] train_loss: 462.96916 valid_loss: 487.24040\n",
      "EarlyStopping counter: 77 out of 600\n",
      "tensor(3.8189, grad_fn=<MeanBackward0>)\n",
      "[ 314/1500] train_loss: 253.05677 valid_loss: 367.65646\n",
      "EarlyStopping counter: 78 out of 600\n",
      "tensor(4.7971, grad_fn=<MeanBackward0>)\n",
      "[ 315/1500] train_loss: 133.81264 valid_loss: 79.21113\n",
      "EarlyStopping counter: 79 out of 600\n",
      "tensor(4.0765, grad_fn=<MeanBackward0>)\n",
      "[ 316/1500] train_loss: 111.87005 valid_loss: 309.12908\n",
      "EarlyStopping counter: 80 out of 600\n",
      "tensor(3.5614, grad_fn=<MeanBackward0>)\n",
      "[ 317/1500] train_loss: 46.55739 valid_loss: 185.53824\n",
      "EarlyStopping counter: 81 out of 600\n",
      "tensor(5.3295, grad_fn=<MeanBackward0>)\n",
      "[ 318/1500] train_loss: 406.64341 valid_loss: 470.81820\n",
      "EarlyStopping counter: 82 out of 600\n",
      "tensor(4.4823, grad_fn=<MeanBackward0>)\n",
      "[ 319/1500] train_loss: 302.25085 valid_loss: 118.70693\n",
      "EarlyStopping counter: 83 out of 600\n",
      "tensor(4.7307, grad_fn=<MeanBackward0>)\n",
      "[ 320/1500] train_loss: 642.47393 valid_loss: 525.17199\n",
      "EarlyStopping counter: 84 out of 600\n",
      "tensor(4.9452, grad_fn=<MeanBackward0>)\n",
      "[ 321/1500] train_loss: 293.03944 valid_loss: 336.90066\n",
      "EarlyStopping counter: 85 out of 600\n",
      "tensor(5.3933, grad_fn=<MeanBackward0>)\n",
      "[ 322/1500] train_loss: 295.41038 valid_loss: 327.65495\n",
      "EarlyStopping counter: 86 out of 600\n",
      "tensor(6.0667, grad_fn=<MeanBackward0>)\n",
      "[ 323/1500] train_loss: 237.85649 valid_loss: 249.21296\n",
      "EarlyStopping counter: 87 out of 600\n",
      "tensor(3.9365, grad_fn=<MeanBackward0>)\n",
      "[ 324/1500] train_loss: 155.04398 valid_loss: 329.28359\n",
      "EarlyStopping counter: 88 out of 600\n",
      "tensor(5.7687, grad_fn=<MeanBackward0>)\n",
      "[ 325/1500] train_loss: 239.85465 valid_loss: 592.89462\n",
      "EarlyStopping counter: 89 out of 600\n",
      "tensor(5.4605, grad_fn=<MeanBackward0>)\n",
      "[ 326/1500] train_loss: 403.13666 valid_loss: 111.28814\n",
      "EarlyStopping counter: 90 out of 600\n",
      "tensor(4.6509, grad_fn=<MeanBackward0>)\n",
      "[ 327/1500] train_loss: 76.03214 valid_loss: 488.05344\n",
      "EarlyStopping counter: 91 out of 600\n",
      "tensor(4.6555, grad_fn=<MeanBackward0>)\n",
      "[ 328/1500] train_loss: 394.11297 valid_loss: 93.07341\n",
      "EarlyStopping counter: 92 out of 600\n",
      "tensor(4.7195, grad_fn=<MeanBackward0>)\n",
      "[ 329/1500] train_loss: 116.75243 valid_loss: 223.29338\n",
      "EarlyStopping counter: 93 out of 600\n",
      "tensor(4.4269, grad_fn=<MeanBackward0>)\n",
      "[ 330/1500] train_loss: 201.45659 valid_loss: 275.39437\n",
      "EarlyStopping counter: 94 out of 600\n",
      "tensor(4.3331, grad_fn=<MeanBackward0>)\n",
      "[ 331/1500] train_loss: 106.33401 valid_loss: 339.22396\n",
      "EarlyStopping counter: 95 out of 600\n",
      "tensor(5.5666, grad_fn=<MeanBackward0>)\n",
      "[ 332/1500] train_loss: 402.17288 valid_loss: 50.46875\n",
      "EarlyStopping counter: 96 out of 600\n",
      "tensor(4.9739, grad_fn=<MeanBackward0>)\n",
      "[ 333/1500] train_loss: 271.56084 valid_loss: 166.90944\n",
      "EarlyStopping counter: 97 out of 600\n",
      "tensor(5.9878, grad_fn=<MeanBackward0>)\n",
      "[ 334/1500] train_loss: 95.15258 valid_loss: 625.11659\n",
      "EarlyStopping counter: 98 out of 600\n",
      "tensor(4.3000, grad_fn=<MeanBackward0>)\n",
      "[ 335/1500] train_loss: 220.54507 valid_loss: 93.44804\n",
      "EarlyStopping counter: 99 out of 600\n",
      "tensor(3.6170, grad_fn=<MeanBackward0>)\n",
      "[ 336/1500] train_loss: 208.46036 valid_loss: 383.63680\n",
      "EarlyStopping counter: 100 out of 600\n",
      "tensor(5.7908, grad_fn=<MeanBackward0>)\n",
      "[ 337/1500] train_loss: 217.85804 valid_loss: 355.95813\n",
      "EarlyStopping counter: 101 out of 600\n",
      "tensor(3.4930, grad_fn=<MeanBackward0>)\n",
      "[ 338/1500] train_loss: 186.95407 valid_loss: 458.12573\n",
      "EarlyStopping counter: 102 out of 600\n",
      "tensor(3.2581, grad_fn=<MeanBackward0>)\n",
      "[ 339/1500] train_loss: 247.97960 valid_loss: 425.03430\n",
      "EarlyStopping counter: 103 out of 600\n",
      "tensor(5.6287, grad_fn=<MeanBackward0>)\n",
      "[ 340/1500] train_loss: 480.03352 valid_loss: 771.29018\n",
      "EarlyStopping counter: 104 out of 600\n",
      "tensor(6.0754, grad_fn=<MeanBackward0>)\n",
      "[ 341/1500] train_loss: 479.84599 valid_loss: 342.69231\n",
      "EarlyStopping counter: 105 out of 600\n",
      "tensor(4.2059, grad_fn=<MeanBackward0>)\n",
      "[ 342/1500] train_loss: 142.07841 valid_loss: 314.21466\n",
      "EarlyStopping counter: 106 out of 600\n",
      "tensor(5.8566, grad_fn=<MeanBackward0>)\n",
      "[ 343/1500] train_loss: 145.72278 valid_loss: 141.21295\n",
      "EarlyStopping counter: 107 out of 600\n",
      "tensor(6.4033, grad_fn=<MeanBackward0>)\n",
      "[ 344/1500] train_loss: 348.16128 valid_loss: 111.03781\n",
      "EarlyStopping counter: 108 out of 600\n",
      "tensor(5.3324, grad_fn=<MeanBackward0>)\n",
      "[ 345/1500] train_loss: 144.87348 valid_loss: 91.26123\n",
      "EarlyStopping counter: 109 out of 600\n",
      "tensor(4.8307, grad_fn=<MeanBackward0>)\n",
      "[ 346/1500] train_loss: 121.28981 valid_loss: 363.41439\n",
      "EarlyStopping counter: 110 out of 600\n",
      "tensor(5.2878, grad_fn=<MeanBackward0>)\n",
      "[ 347/1500] train_loss: 146.96590 valid_loss: 121.16000\n",
      "EarlyStopping counter: 111 out of 600\n",
      "tensor(5.7096, grad_fn=<MeanBackward0>)\n",
      "[ 348/1500] train_loss: 170.76081 valid_loss: 110.79190\n",
      "EarlyStopping counter: 112 out of 600\n",
      "tensor(4.6659, grad_fn=<MeanBackward0>)\n",
      "[ 349/1500] train_loss: 213.84262 valid_loss: 366.96184\n",
      "EarlyStopping counter: 113 out of 600\n",
      "tensor(4.8406, grad_fn=<MeanBackward0>)\n",
      "[ 350/1500] train_loss: 62.48105 valid_loss: 231.34751\n",
      "EarlyStopping counter: 114 out of 600\n",
      "tensor(3.7895, grad_fn=<MeanBackward0>)\n",
      "[ 351/1500] train_loss: 100.24481 valid_loss: 98.12513\n",
      "EarlyStopping counter: 115 out of 600\n",
      "tensor(4.1316, grad_fn=<MeanBackward0>)\n",
      "[ 352/1500] train_loss: 456.79625 valid_loss: 228.62467\n",
      "EarlyStopping counter: 116 out of 600\n",
      "tensor(4.2115, grad_fn=<MeanBackward0>)\n",
      "[ 353/1500] train_loss: 516.14058 valid_loss: 64.91204\n",
      "EarlyStopping counter: 117 out of 600\n",
      "tensor(3.9833, grad_fn=<MeanBackward0>)\n",
      "[ 354/1500] train_loss: 412.62325 valid_loss: 185.16912\n",
      "EarlyStopping counter: 118 out of 600\n",
      "tensor(4.2514, grad_fn=<MeanBackward0>)\n",
      "[ 355/1500] train_loss: 709.80437 valid_loss: 445.32146\n",
      "EarlyStopping counter: 119 out of 600\n",
      "tensor(3.7039, grad_fn=<MeanBackward0>)\n",
      "[ 356/1500] train_loss: 174.57046 valid_loss: 148.76548\n",
      "EarlyStopping counter: 120 out of 600\n",
      "tensor(4.2678, grad_fn=<MeanBackward0>)\n",
      "[ 357/1500] train_loss: 536.45265 valid_loss: 205.47140\n",
      "EarlyStopping counter: 121 out of 600\n",
      "tensor(3.5193, grad_fn=<MeanBackward0>)\n",
      "[ 358/1500] train_loss: 244.52211 valid_loss: 160.88466\n",
      "EarlyStopping counter: 122 out of 600\n",
      "tensor(4.5097, grad_fn=<MeanBackward0>)\n",
      "[ 359/1500] train_loss: 228.73724 valid_loss: 213.64749\n",
      "EarlyStopping counter: 123 out of 600\n",
      "tensor(3.3174, grad_fn=<MeanBackward0>)\n",
      "[ 360/1500] train_loss: 95.19741 valid_loss: 113.55699\n",
      "EarlyStopping counter: 124 out of 600\n",
      "tensor(3.6214, grad_fn=<MeanBackward0>)\n",
      "[ 361/1500] train_loss: 235.36689 valid_loss: 336.21529\n",
      "EarlyStopping counter: 125 out of 600\n",
      "tensor(4.6168, grad_fn=<MeanBackward0>)\n",
      "[ 362/1500] train_loss: 216.92333 valid_loss: 216.70246\n",
      "EarlyStopping counter: 126 out of 600\n",
      "tensor(4.6761, grad_fn=<MeanBackward0>)\n",
      "[ 363/1500] train_loss: 353.98366 valid_loss: 615.12770\n",
      "EarlyStopping counter: 127 out of 600\n",
      "tensor(5.5097, grad_fn=<MeanBackward0>)\n",
      "[ 364/1500] train_loss: 445.80347 valid_loss: 615.07689\n",
      "EarlyStopping counter: 128 out of 600\n",
      "tensor(5.5597, grad_fn=<MeanBackward0>)\n",
      "[ 365/1500] train_loss: 208.60529 valid_loss: 589.29755\n",
      "EarlyStopping counter: 129 out of 600\n",
      "tensor(4.0497, grad_fn=<MeanBackward0>)\n",
      "[ 366/1500] train_loss: 98.45842 valid_loss: 491.64987\n",
      "EarlyStopping counter: 130 out of 600\n",
      "tensor(4.7377, grad_fn=<MeanBackward0>)\n",
      "[ 367/1500] train_loss: 524.67942 valid_loss: 53.07165\n",
      "EarlyStopping counter: 131 out of 600\n",
      "tensor(4.6438, grad_fn=<MeanBackward0>)\n",
      "[ 368/1500] train_loss: 112.91137 valid_loss: 96.40629\n",
      "EarlyStopping counter: 132 out of 600\n",
      "tensor(5.4024, grad_fn=<MeanBackward0>)\n",
      "[ 369/1500] train_loss: 583.26453 valid_loss: 229.65352\n",
      "EarlyStopping counter: 133 out of 600\n",
      "tensor(4.9211, grad_fn=<MeanBackward0>)\n",
      "[ 370/1500] train_loss: 271.12649 valid_loss: 154.93584\n",
      "EarlyStopping counter: 134 out of 600\n",
      "tensor(4.1429, grad_fn=<MeanBackward0>)\n",
      "[ 371/1500] train_loss: 218.17925 valid_loss: 53.55736\n",
      "EarlyStopping counter: 135 out of 600\n",
      "tensor(5.0039, grad_fn=<MeanBackward0>)\n",
      "[ 372/1500] train_loss: 102.94734 valid_loss: 483.75027\n",
      "EarlyStopping counter: 136 out of 600\n",
      "tensor(5.3875, grad_fn=<MeanBackward0>)\n",
      "[ 373/1500] train_loss: 547.21345 valid_loss: 315.68094\n",
      "EarlyStopping counter: 137 out of 600\n",
      "tensor(4.3228, grad_fn=<MeanBackward0>)\n",
      "[ 374/1500] train_loss: 69.77530 valid_loss: 521.78782\n",
      "EarlyStopping counter: 138 out of 600\n",
      "tensor(6.0947, grad_fn=<MeanBackward0>)\n",
      "[ 375/1500] train_loss: 174.56150 valid_loss: 89.48671\n",
      "EarlyStopping counter: 139 out of 600\n",
      "tensor(4.5213, grad_fn=<MeanBackward0>)\n",
      "[ 376/1500] train_loss: 201.66131 valid_loss: 118.25644\n",
      "EarlyStopping counter: 140 out of 600\n",
      "tensor(3.4695, grad_fn=<MeanBackward0>)\n",
      "[ 377/1500] train_loss: 192.57005 valid_loss: 110.36767\n",
      "EarlyStopping counter: 141 out of 600\n",
      "tensor(6.2119, grad_fn=<MeanBackward0>)\n",
      "[ 378/1500] train_loss: 197.00683 valid_loss: 237.86140\n",
      "EarlyStopping counter: 142 out of 600\n",
      "tensor(5.4248, grad_fn=<MeanBackward0>)\n",
      "[ 379/1500] train_loss: 531.28842 valid_loss: 106.73930\n",
      "EarlyStopping counter: 143 out of 600\n",
      "tensor(4.0770, grad_fn=<MeanBackward0>)\n",
      "[ 380/1500] train_loss: 202.51213 valid_loss: 116.80961\n",
      "EarlyStopping counter: 144 out of 600\n",
      "tensor(6.1988, grad_fn=<MeanBackward0>)\n",
      "[ 381/1500] train_loss: 420.99701 valid_loss: 81.59957\n",
      "EarlyStopping counter: 145 out of 600\n",
      "tensor(3.9546, grad_fn=<MeanBackward0>)\n",
      "[ 382/1500] train_loss: 344.61453 valid_loss: 380.04949\n",
      "EarlyStopping counter: 146 out of 600\n",
      "tensor(3.3186, grad_fn=<MeanBackward0>)\n",
      "[ 383/1500] train_loss: 143.30453 valid_loss: 227.47043\n",
      "EarlyStopping counter: 147 out of 600\n",
      "tensor(3.1086, grad_fn=<MeanBackward0>)\n",
      "[ 384/1500] train_loss: 82.81646 valid_loss: 275.79408\n",
      "EarlyStopping counter: 148 out of 600\n",
      "tensor(4.3720, grad_fn=<MeanBackward0>)\n",
      "[ 385/1500] train_loss: 102.66974 valid_loss: 550.79787\n",
      "EarlyStopping counter: 149 out of 600\n",
      "tensor(5.4536, grad_fn=<MeanBackward0>)\n",
      "[ 386/1500] train_loss: 256.83127 valid_loss: 91.43059\n",
      "EarlyStopping counter: 150 out of 600\n",
      "tensor(5.0681, grad_fn=<MeanBackward0>)\n",
      "[ 387/1500] train_loss: 256.29261 valid_loss: 67.16804\n",
      "EarlyStopping counter: 151 out of 600\n",
      "tensor(4.1603, grad_fn=<MeanBackward0>)\n",
      "[ 388/1500] train_loss: 119.59078 valid_loss: 59.08283\n",
      "EarlyStopping counter: 152 out of 600\n",
      "tensor(5.5290, grad_fn=<MeanBackward0>)\n",
      "[ 389/1500] train_loss: 71.10362 valid_loss: 480.86848\n",
      "EarlyStopping counter: 153 out of 600\n",
      "tensor(5.9826, grad_fn=<MeanBackward0>)\n",
      "[ 390/1500] train_loss: 220.67763 valid_loss: 89.67951\n",
      "EarlyStopping counter: 154 out of 600\n",
      "tensor(3.0740, grad_fn=<MeanBackward0>)\n",
      "[ 391/1500] train_loss: 287.51957 valid_loss: 130.11007\n",
      "EarlyStopping counter: 155 out of 600\n",
      "tensor(4.5327, grad_fn=<MeanBackward0>)\n",
      "[ 392/1500] train_loss: 61.74525 valid_loss: 84.78879\n",
      "EarlyStopping counter: 156 out of 600\n",
      "tensor(4.3636, grad_fn=<MeanBackward0>)\n",
      "[ 393/1500] train_loss: 259.26900 valid_loss: 196.11551\n",
      "EarlyStopping counter: 157 out of 600\n",
      "tensor(5.7964, grad_fn=<MeanBackward0>)\n",
      "[ 394/1500] train_loss: 111.33219 valid_loss: 116.01270\n",
      "EarlyStopping counter: 158 out of 600\n",
      "tensor(4.3351, grad_fn=<MeanBackward0>)\n",
      "[ 395/1500] train_loss: 544.43494 valid_loss: 68.83881\n",
      "EarlyStopping counter: 159 out of 600\n",
      "tensor(6.0434, grad_fn=<MeanBackward0>)\n",
      "[ 396/1500] train_loss: 153.17605 valid_loss: 38.23785\n",
      "Validation loss decreased (44.820394 --> 38.237847).  Saving model ...\n",
      "tensor(3.7194, grad_fn=<MeanBackward0>)\n",
      "[ 397/1500] train_loss: 280.17949 valid_loss: 123.06219\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(5.3169, grad_fn=<MeanBackward0>)\n",
      "[ 398/1500] train_loss: 68.04038 valid_loss: 76.27448\n",
      "EarlyStopping counter: 2 out of 600\n",
      "tensor(7.1305, grad_fn=<MeanBackward0>)\n",
      "[ 399/1500] train_loss: 267.95820 valid_loss: 47.20657\n",
      "EarlyStopping counter: 3 out of 600\n",
      "tensor(5.2915, grad_fn=<MeanBackward0>)\n",
      "[ 400/1500] train_loss: 123.39347 valid_loss: 76.31880\n",
      "EarlyStopping counter: 4 out of 600\n",
      "tensor(4.8452, grad_fn=<MeanBackward0>)\n",
      "[ 401/1500] train_loss: 78.52408 valid_loss: 93.07493\n",
      "EarlyStopping counter: 5 out of 600\n",
      "tensor(4.2490, grad_fn=<MeanBackward0>)\n",
      "[ 402/1500] train_loss: 630.47636 valid_loss: 60.23299\n",
      "EarlyStopping counter: 6 out of 600\n",
      "tensor(4.5381, grad_fn=<MeanBackward0>)\n",
      "[ 403/1500] train_loss: 29.16428 valid_loss: 76.46652\n",
      "EarlyStopping counter: 7 out of 600\n",
      "tensor(3.1122, grad_fn=<MeanBackward0>)\n",
      "[ 404/1500] train_loss: 127.55598 valid_loss: 367.13226\n",
      "EarlyStopping counter: 8 out of 600\n",
      "tensor(3.6926, grad_fn=<MeanBackward0>)\n",
      "[ 405/1500] train_loss: 69.40180 valid_loss: 46.13794\n",
      "EarlyStopping counter: 9 out of 600\n",
      "tensor(3.9443, grad_fn=<MeanBackward0>)\n",
      "[ 406/1500] train_loss: 82.41747 valid_loss: 166.17327\n",
      "EarlyStopping counter: 10 out of 600\n",
      "tensor(5.3837, grad_fn=<MeanBackward0>)\n",
      "[ 407/1500] train_loss: 90.79744 valid_loss: 227.74231\n",
      "EarlyStopping counter: 11 out of 600\n",
      "tensor(5.3856, grad_fn=<MeanBackward0>)\n",
      "[ 408/1500] train_loss: 144.40737 valid_loss: 151.94103\n",
      "EarlyStopping counter: 12 out of 600\n",
      "tensor(4.0845, grad_fn=<MeanBackward0>)\n",
      "[ 409/1500] train_loss: 88.26754 valid_loss: 74.79656\n",
      "EarlyStopping counter: 13 out of 600\n",
      "tensor(4.7818, grad_fn=<MeanBackward0>)\n",
      "[ 410/1500] train_loss: 221.48690 valid_loss: 61.57278\n",
      "EarlyStopping counter: 14 out of 600\n",
      "tensor(4.3289, grad_fn=<MeanBackward0>)\n",
      "[ 411/1500] train_loss: 86.50234 valid_loss: 149.92523\n",
      "EarlyStopping counter: 15 out of 600\n",
      "tensor(4.8710, grad_fn=<MeanBackward0>)\n",
      "[ 412/1500] train_loss: 79.30890 valid_loss: 58.18980\n",
      "EarlyStopping counter: 16 out of 600\n",
      "tensor(6.1322, grad_fn=<MeanBackward0>)\n",
      "[ 413/1500] train_loss: 85.51481 valid_loss: 52.96244\n",
      "EarlyStopping counter: 17 out of 600\n",
      "tensor(4.5917, grad_fn=<MeanBackward0>)\n",
      "[ 414/1500] train_loss: 107.05864 valid_loss: 86.27041\n",
      "EarlyStopping counter: 18 out of 600\n",
      "tensor(3.7749, grad_fn=<MeanBackward0>)\n",
      "[ 415/1500] train_loss: 118.38727 valid_loss: 59.76212\n",
      "EarlyStopping counter: 19 out of 600\n",
      "tensor(6.1717, grad_fn=<MeanBackward0>)\n",
      "[ 416/1500] train_loss: 80.22886 valid_loss: 193.28904\n",
      "EarlyStopping counter: 20 out of 600\n",
      "tensor(5.5608, grad_fn=<MeanBackward0>)\n",
      "[ 417/1500] train_loss: 167.28111 valid_loss: 102.81443\n",
      "EarlyStopping counter: 21 out of 600\n",
      "tensor(4.5504, grad_fn=<MeanBackward0>)\n",
      "[ 418/1500] train_loss: 43.22608 valid_loss: 58.45330\n",
      "EarlyStopping counter: 22 out of 600\n",
      "tensor(5.4912, grad_fn=<MeanBackward0>)\n",
      "[ 419/1500] train_loss: 64.19848 valid_loss: 77.73213\n",
      "EarlyStopping counter: 23 out of 600\n",
      "tensor(5.2167, grad_fn=<MeanBackward0>)\n",
      "[ 420/1500] train_loss: 43.08939 valid_loss: 90.96853\n",
      "EarlyStopping counter: 24 out of 600\n",
      "tensor(5.1876, grad_fn=<MeanBackward0>)\n",
      "[ 421/1500] train_loss: 56.03643 valid_loss: 26.70102\n",
      "Validation loss decreased (38.237847 --> 26.701022).  Saving model ...\n",
      "tensor(4.2900, grad_fn=<MeanBackward0>)\n",
      "[ 422/1500] train_loss: 48.15424 valid_loss: 50.18543\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(3.4471, grad_fn=<MeanBackward0>)\n",
      "[ 423/1500] train_loss: 174.70141 valid_loss: 37.39617\n",
      "EarlyStopping counter: 2 out of 600\n",
      "tensor(3.7530, grad_fn=<MeanBackward0>)\n",
      "[ 424/1500] train_loss: 33.71080 valid_loss: 75.05147\n",
      "EarlyStopping counter: 3 out of 600\n",
      "tensor(4.5744, grad_fn=<MeanBackward0>)\n",
      "[ 425/1500] train_loss: 130.11188 valid_loss: 98.31008\n",
      "EarlyStopping counter: 4 out of 600\n",
      "tensor(4.7469, grad_fn=<MeanBackward0>)\n",
      "[ 426/1500] train_loss: 54.59384 valid_loss: 39.89940\n",
      "EarlyStopping counter: 5 out of 600\n",
      "tensor(4.2627, grad_fn=<MeanBackward0>)\n",
      "[ 427/1500] train_loss: 455.28166 valid_loss: 67.23013\n",
      "EarlyStopping counter: 6 out of 600\n",
      "tensor(4.7024, grad_fn=<MeanBackward0>)\n",
      "[ 428/1500] train_loss: 62.63954 valid_loss: 45.99837\n",
      "EarlyStopping counter: 7 out of 600\n",
      "tensor(3.5870, grad_fn=<MeanBackward0>)\n",
      "[ 429/1500] train_loss: 80.07324 valid_loss: 47.90950\n",
      "EarlyStopping counter: 8 out of 600\n",
      "tensor(4.5500, grad_fn=<MeanBackward0>)\n",
      "[ 430/1500] train_loss: 31.63277 valid_loss: 25.35931\n",
      "Validation loss decreased (26.701022 --> 25.359311).  Saving model ...\n",
      "tensor(3.3946, grad_fn=<MeanBackward0>)\n",
      "[ 431/1500] train_loss: 65.60463 valid_loss: 53.16993\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(3.7769, grad_fn=<MeanBackward0>)\n",
      "[ 432/1500] train_loss: 52.18801 valid_loss: 209.87552\n",
      "EarlyStopping counter: 2 out of 600\n",
      "tensor(5.6184, grad_fn=<MeanBackward0>)\n",
      "[ 433/1500] train_loss: 90.35237 valid_loss: 85.07323\n",
      "EarlyStopping counter: 3 out of 600\n",
      "tensor(5.2434, grad_fn=<MeanBackward0>)\n",
      "[ 434/1500] train_loss: 60.54074 valid_loss: 31.85393\n",
      "EarlyStopping counter: 4 out of 600\n",
      "tensor(5.7171, grad_fn=<MeanBackward0>)\n",
      "[ 435/1500] train_loss: 75.25834 valid_loss: 27.29375\n",
      "EarlyStopping counter: 5 out of 600\n",
      "tensor(4.3389, grad_fn=<MeanBackward0>)\n",
      "[ 436/1500] train_loss: 58.93935 valid_loss: 39.62468\n",
      "EarlyStopping counter: 6 out of 600\n",
      "tensor(6.5720, grad_fn=<MeanBackward0>)\n",
      "[ 437/1500] train_loss: 88.47467 valid_loss: 44.53819\n",
      "EarlyStopping counter: 7 out of 600\n",
      "tensor(3.3174, grad_fn=<MeanBackward0>)\n",
      "[ 438/1500] train_loss: 108.66983 valid_loss: 209.65784\n",
      "EarlyStopping counter: 8 out of 600\n",
      "tensor(3.5916, grad_fn=<MeanBackward0>)\n",
      "[ 439/1500] train_loss: 57.73417 valid_loss: 219.28177\n",
      "EarlyStopping counter: 9 out of 600\n",
      "tensor(4.1154, grad_fn=<MeanBackward0>)\n",
      "[ 440/1500] train_loss: 317.32079 valid_loss: 44.46565\n",
      "EarlyStopping counter: 10 out of 600\n",
      "tensor(4.7846, grad_fn=<MeanBackward0>)\n",
      "[ 441/1500] train_loss: 134.07003 valid_loss: 154.61844\n",
      "EarlyStopping counter: 11 out of 600\n",
      "tensor(3.6342, grad_fn=<MeanBackward0>)\n",
      "[ 442/1500] train_loss: 259.01784 valid_loss: 118.49039\n",
      "EarlyStopping counter: 12 out of 600\n",
      "tensor(3.6738, grad_fn=<MeanBackward0>)\n",
      "[ 443/1500] train_loss: 28.62226 valid_loss: 167.43938\n",
      "EarlyStopping counter: 13 out of 600\n",
      "tensor(3.7876, grad_fn=<MeanBackward0>)\n",
      "[ 444/1500] train_loss: 71.58644 valid_loss: 127.45707\n",
      "EarlyStopping counter: 14 out of 600\n",
      "tensor(5.2469, grad_fn=<MeanBackward0>)\n",
      "[ 445/1500] train_loss: 80.78710 valid_loss: 29.51152\n",
      "EarlyStopping counter: 15 out of 600\n",
      "tensor(4.0904, grad_fn=<MeanBackward0>)\n",
      "[ 446/1500] train_loss: 24.80030 valid_loss: 22.96323\n",
      "Validation loss decreased (25.359311 --> 22.963230).  Saving model ...\n",
      "tensor(4.8800, grad_fn=<MeanBackward0>)\n",
      "[ 447/1500] train_loss: 41.67614 valid_loss: 89.17758\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(6.0400, grad_fn=<MeanBackward0>)\n",
      "[ 448/1500] train_loss: 257.41558 valid_loss: 95.26607\n",
      "EarlyStopping counter: 2 out of 600\n",
      "tensor(3.4554, grad_fn=<MeanBackward0>)\n",
      "[ 449/1500] train_loss: 115.27060 valid_loss: 110.34160\n",
      "EarlyStopping counter: 3 out of 600\n",
      "tensor(3.7210, grad_fn=<MeanBackward0>)\n",
      "[ 450/1500] train_loss: 49.43197 valid_loss: 147.93328\n",
      "EarlyStopping counter: 4 out of 600\n",
      "tensor(3.2538, grad_fn=<MeanBackward0>)\n",
      "[ 451/1500] train_loss: 110.67959 valid_loss: 73.33568\n",
      "EarlyStopping counter: 5 out of 600\n",
      "tensor(5.6813, grad_fn=<MeanBackward0>)\n",
      "[ 452/1500] train_loss: 155.57466 valid_loss: 39.32260\n",
      "EarlyStopping counter: 6 out of 600\n",
      "tensor(4.9298, grad_fn=<MeanBackward0>)\n",
      "[ 453/1500] train_loss: 102.52275 valid_loss: 195.82151\n",
      "EarlyStopping counter: 7 out of 600\n",
      "tensor(5.9831, grad_fn=<MeanBackward0>)\n",
      "[ 454/1500] train_loss: 80.72958 valid_loss: 183.93858\n",
      "EarlyStopping counter: 8 out of 600\n",
      "tensor(5.0324, grad_fn=<MeanBackward0>)\n",
      "[ 455/1500] train_loss: 118.97912 valid_loss: 79.35092\n",
      "EarlyStopping counter: 9 out of 600\n",
      "tensor(5.2402, grad_fn=<MeanBackward0>)\n",
      "[ 456/1500] train_loss: 182.88442 valid_loss: 81.50173\n",
      "EarlyStopping counter: 10 out of 600\n",
      "tensor(5.8016, grad_fn=<MeanBackward0>)\n",
      "[ 457/1500] train_loss: 152.89719 valid_loss: 34.25097\n",
      "EarlyStopping counter: 11 out of 600\n",
      "tensor(5.6809, grad_fn=<MeanBackward0>)\n",
      "[ 458/1500] train_loss: 84.36049 valid_loss: 30.25284\n",
      "EarlyStopping counter: 12 out of 600\n",
      "tensor(4.3253, grad_fn=<MeanBackward0>)\n",
      "[ 459/1500] train_loss: 309.24440 valid_loss: 68.95121\n",
      "EarlyStopping counter: 13 out of 600\n",
      "tensor(3.7309, grad_fn=<MeanBackward0>)\n",
      "[ 460/1500] train_loss: 100.57225 valid_loss: 139.58479\n",
      "EarlyStopping counter: 14 out of 600\n",
      "tensor(6.0542, grad_fn=<MeanBackward0>)\n",
      "[ 461/1500] train_loss: 213.15663 valid_loss: 163.27772\n",
      "EarlyStopping counter: 15 out of 600\n",
      "tensor(6.3479, grad_fn=<MeanBackward0>)\n",
      "[ 462/1500] train_loss: 171.06630 valid_loss: 28.02201\n",
      "EarlyStopping counter: 16 out of 600\n",
      "tensor(5.4662, grad_fn=<MeanBackward0>)\n",
      "[ 463/1500] train_loss: 59.52742 valid_loss: 151.37252\n",
      "EarlyStopping counter: 17 out of 600\n",
      "tensor(5.1209, grad_fn=<MeanBackward0>)\n",
      "[ 464/1500] train_loss: 74.85348 valid_loss: 36.70001\n",
      "EarlyStopping counter: 18 out of 600\n",
      "tensor(6.1757, grad_fn=<MeanBackward0>)\n",
      "[ 465/1500] train_loss: 149.75178 valid_loss: 153.80571\n",
      "EarlyStopping counter: 19 out of 600\n",
      "tensor(4.1190, grad_fn=<MeanBackward0>)\n",
      "[ 466/1500] train_loss: 133.49422 valid_loss: 68.54376\n",
      "EarlyStopping counter: 20 out of 600\n",
      "tensor(4.2519, grad_fn=<MeanBackward0>)\n",
      "[ 467/1500] train_loss: 275.57287 valid_loss: 51.61323\n",
      "EarlyStopping counter: 21 out of 600\n",
      "tensor(3.1903, grad_fn=<MeanBackward0>)\n",
      "[ 468/1500] train_loss: 55.03815 valid_loss: 491.49242\n",
      "EarlyStopping counter: 22 out of 600\n",
      "tensor(2.8854, grad_fn=<MeanBackward0>)\n",
      "[ 469/1500] train_loss: 229.42272 valid_loss: 468.65347\n",
      "EarlyStopping counter: 23 out of 600\n",
      "tensor(4.3413, grad_fn=<MeanBackward0>)\n",
      "[ 470/1500] train_loss: 117.95093 valid_loss: 113.80154\n",
      "EarlyStopping counter: 24 out of 600\n",
      "tensor(3.6141, grad_fn=<MeanBackward0>)\n",
      "[ 471/1500] train_loss: 40.55636 valid_loss: 23.49440\n",
      "EarlyStopping counter: 25 out of 600\n",
      "tensor(5.6790, grad_fn=<MeanBackward0>)\n",
      "[ 472/1500] train_loss: 378.86691 valid_loss: 66.05845\n",
      "EarlyStopping counter: 26 out of 600\n",
      "tensor(4.1405, grad_fn=<MeanBackward0>)\n",
      "[ 473/1500] train_loss: 93.71475 valid_loss: 82.83181\n",
      "EarlyStopping counter: 27 out of 600\n",
      "tensor(5.4265, grad_fn=<MeanBackward0>)\n",
      "[ 474/1500] train_loss: 141.87835 valid_loss: 150.47001\n",
      "EarlyStopping counter: 28 out of 600\n",
      "tensor(4.7389, grad_fn=<MeanBackward0>)\n",
      "[ 475/1500] train_loss: 614.07216 valid_loss: 21.39151\n",
      "Validation loss decreased (22.963230 --> 21.391512).  Saving model ...\n",
      "tensor(4.7507, grad_fn=<MeanBackward0>)\n",
      "[ 476/1500] train_loss: 56.47070 valid_loss: 227.90580\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(5.9444, grad_fn=<MeanBackward0>)\n",
      "[ 477/1500] train_loss: 219.88147 valid_loss: 212.46648\n",
      "EarlyStopping counter: 2 out of 600\n",
      "tensor(6.3526, grad_fn=<MeanBackward0>)\n",
      "[ 478/1500] train_loss: 643.88686 valid_loss: 203.87520\n",
      "EarlyStopping counter: 3 out of 600\n",
      "tensor(4.4389, grad_fn=<MeanBackward0>)\n",
      "[ 479/1500] train_loss: 126.57591 valid_loss: 144.31217\n",
      "EarlyStopping counter: 4 out of 600\n",
      "tensor(6.0158, grad_fn=<MeanBackward0>)\n",
      "[ 480/1500] train_loss: 164.96157 valid_loss: 135.40968\n",
      "EarlyStopping counter: 5 out of 600\n",
      "tensor(4.5236, grad_fn=<MeanBackward0>)\n",
      "[ 481/1500] train_loss: 79.71261 valid_loss: 44.78447\n",
      "EarlyStopping counter: 6 out of 600\n",
      "tensor(4.8205, grad_fn=<MeanBackward0>)\n",
      "[ 482/1500] train_loss: 171.43372 valid_loss: 45.76403\n",
      "EarlyStopping counter: 7 out of 600\n",
      "tensor(3.6013, grad_fn=<MeanBackward0>)\n",
      "[ 483/1500] train_loss: 71.97784 valid_loss: 170.43983\n",
      "EarlyStopping counter: 8 out of 600\n",
      "tensor(3.9070, grad_fn=<MeanBackward0>)\n",
      "[ 484/1500] train_loss: 125.15950 valid_loss: 41.41998\n",
      "EarlyStopping counter: 9 out of 600\n",
      "tensor(3.7933, grad_fn=<MeanBackward0>)\n",
      "[ 485/1500] train_loss: 49.42282 valid_loss: 272.79447\n",
      "EarlyStopping counter: 10 out of 600\n",
      "tensor(4.8653, grad_fn=<MeanBackward0>)\n",
      "[ 486/1500] train_loss: 194.33234 valid_loss: 44.00985\n",
      "EarlyStopping counter: 11 out of 600\n",
      "tensor(6.5825, grad_fn=<MeanBackward0>)\n",
      "[ 487/1500] train_loss: 451.82724 valid_loss: 84.70871\n",
      "EarlyStopping counter: 12 out of 600\n",
      "tensor(6.4934, grad_fn=<MeanBackward0>)\n",
      "[ 488/1500] train_loss: 493.98637 valid_loss: 75.45935\n",
      "EarlyStopping counter: 13 out of 600\n",
      "tensor(5.0715, grad_fn=<MeanBackward0>)\n",
      "[ 489/1500] train_loss: 213.67942 valid_loss: 60.50224\n",
      "EarlyStopping counter: 14 out of 600\n",
      "tensor(5.0883, grad_fn=<MeanBackward0>)\n",
      "[ 490/1500] train_loss: 86.72291 valid_loss: 69.95362\n",
      "EarlyStopping counter: 15 out of 600\n",
      "tensor(3.8781, grad_fn=<MeanBackward0>)\n",
      "[ 491/1500] train_loss: 41.64465 valid_loss: 201.04791\n",
      "EarlyStopping counter: 16 out of 600\n",
      "tensor(4.8786, grad_fn=<MeanBackward0>)\n",
      "[ 492/1500] train_loss: 121.03014 valid_loss: 53.35311\n",
      "EarlyStopping counter: 17 out of 600\n",
      "tensor(2.7383, grad_fn=<MeanBackward0>)\n",
      "[ 493/1500] train_loss: 271.13034 valid_loss: 259.23108\n",
      "EarlyStopping counter: 18 out of 600\n",
      "tensor(4.0960, grad_fn=<MeanBackward0>)\n",
      "[ 494/1500] train_loss: 56.09188 valid_loss: 490.37768\n",
      "EarlyStopping counter: 19 out of 600\n",
      "tensor(5.2782, grad_fn=<MeanBackward0>)\n",
      "[ 495/1500] train_loss: 359.81732 valid_loss: 40.29018\n",
      "EarlyStopping counter: 20 out of 600\n",
      "tensor(4.9014, grad_fn=<MeanBackward0>)\n",
      "[ 496/1500] train_loss: 211.58448 valid_loss: 255.22929\n",
      "EarlyStopping counter: 21 out of 600\n",
      "tensor(3.5028, grad_fn=<MeanBackward0>)\n",
      "[ 497/1500] train_loss: 128.84516 valid_loss: 118.30542\n",
      "EarlyStopping counter: 22 out of 600\n",
      "tensor(3.4356, grad_fn=<MeanBackward0>)\n",
      "[ 498/1500] train_loss: 67.94447 valid_loss: 161.39902\n",
      "EarlyStopping counter: 23 out of 600\n",
      "tensor(3.5346, grad_fn=<MeanBackward0>)\n",
      "[ 499/1500] train_loss: 187.06158 valid_loss: 79.86599\n",
      "EarlyStopping counter: 24 out of 600\n",
      "tensor(4.2890, grad_fn=<MeanBackward0>)\n",
      "[ 500/1500] train_loss: 364.39626 valid_loss: 126.79682\n",
      "EarlyStopping counter: 25 out of 600\n",
      "tensor(4.6799, grad_fn=<MeanBackward0>)\n",
      "[ 501/1500] train_loss: 154.42310 valid_loss: 226.31077\n",
      "EarlyStopping counter: 26 out of 600\n",
      "tensor(5.4756, grad_fn=<MeanBackward0>)\n",
      "[ 502/1500] train_loss: 186.80352 valid_loss: 101.80318\n",
      "EarlyStopping counter: 27 out of 600\n",
      "tensor(5.9478, grad_fn=<MeanBackward0>)\n",
      "[ 503/1500] train_loss: 224.26158 valid_loss: 80.06500\n",
      "EarlyStopping counter: 28 out of 600\n",
      "tensor(4.0538, grad_fn=<MeanBackward0>)\n",
      "[ 504/1500] train_loss: 81.20102 valid_loss: 320.04413\n",
      "EarlyStopping counter: 29 out of 600\n",
      "tensor(3.0652, grad_fn=<MeanBackward0>)\n",
      "[ 505/1500] train_loss: 1189.56495 valid_loss: 69.14188\n",
      "EarlyStopping counter: 30 out of 600\n",
      "tensor(4.7405, grad_fn=<MeanBackward0>)\n",
      "[ 506/1500] train_loss: 37.52955 valid_loss: 46.42780\n",
      "EarlyStopping counter: 31 out of 600\n",
      "tensor(3.0687, grad_fn=<MeanBackward0>)\n",
      "[ 507/1500] train_loss: 468.22566 valid_loss: 283.61362\n",
      "EarlyStopping counter: 32 out of 600\n",
      "tensor(5.1630, grad_fn=<MeanBackward0>)\n",
      "[ 508/1500] train_loss: 262.94899 valid_loss: 428.96550\n",
      "EarlyStopping counter: 33 out of 600\n",
      "tensor(4.7247, grad_fn=<MeanBackward0>)\n",
      "[ 509/1500] train_loss: 89.06034 valid_loss: 83.26545\n",
      "EarlyStopping counter: 34 out of 600\n",
      "tensor(7.0838, grad_fn=<MeanBackward0>)\n",
      "[ 510/1500] train_loss: 300.55334 valid_loss: 190.41721\n",
      "EarlyStopping counter: 35 out of 600\n",
      "tensor(4.9361, grad_fn=<MeanBackward0>)\n",
      "[ 511/1500] train_loss: 123.05719 valid_loss: 88.37908\n",
      "EarlyStopping counter: 36 out of 600\n",
      "tensor(3.6041, grad_fn=<MeanBackward0>)\n",
      "[ 512/1500] train_loss: 773.64309 valid_loss: 250.31157\n",
      "EarlyStopping counter: 37 out of 600\n",
      "tensor(4.1126, grad_fn=<MeanBackward0>)\n",
      "[ 513/1500] train_loss: 75.59868 valid_loss: 68.48327\n",
      "EarlyStopping counter: 38 out of 600\n",
      "tensor(3.2477, grad_fn=<MeanBackward0>)\n",
      "[ 514/1500] train_loss: 105.23972 valid_loss: 250.02727\n",
      "EarlyStopping counter: 39 out of 600\n",
      "tensor(3.6018, grad_fn=<MeanBackward0>)\n",
      "[ 515/1500] train_loss: 163.17027 valid_loss: 141.14902\n",
      "EarlyStopping counter: 40 out of 600\n",
      "tensor(3.6006, grad_fn=<MeanBackward0>)\n",
      "[ 516/1500] train_loss: 214.97483 valid_loss: 36.45001\n",
      "EarlyStopping counter: 41 out of 600\n",
      "tensor(3.4746, grad_fn=<MeanBackward0>)\n",
      "[ 517/1500] train_loss: 59.34801 valid_loss: 265.97206\n",
      "EarlyStopping counter: 42 out of 600\n",
      "tensor(5.1213, grad_fn=<MeanBackward0>)\n",
      "[ 518/1500] train_loss: 295.71871 valid_loss: 216.87909\n",
      "EarlyStopping counter: 43 out of 600\n",
      "tensor(3.9429, grad_fn=<MeanBackward0>)\n",
      "[ 519/1500] train_loss: 83.23791 valid_loss: 235.95669\n",
      "EarlyStopping counter: 44 out of 600\n",
      "tensor(4.9104, grad_fn=<MeanBackward0>)\n",
      "[ 520/1500] train_loss: 144.86281 valid_loss: 41.86569\n",
      "EarlyStopping counter: 45 out of 600\n",
      "tensor(4.5612, grad_fn=<MeanBackward0>)\n",
      "[ 521/1500] train_loss: 265.70976 valid_loss: 97.90461\n",
      "EarlyStopping counter: 46 out of 600\n",
      "tensor(4.2882, grad_fn=<MeanBackward0>)\n",
      "[ 522/1500] train_loss: 31.93158 valid_loss: 271.16345\n",
      "EarlyStopping counter: 47 out of 600\n",
      "tensor(5.5365, grad_fn=<MeanBackward0>)\n",
      "[ 523/1500] train_loss: 144.79232 valid_loss: 65.11922\n",
      "EarlyStopping counter: 48 out of 600\n",
      "tensor(3.6028, grad_fn=<MeanBackward0>)\n",
      "[ 524/1500] train_loss: 253.84005 valid_loss: 31.78427\n",
      "EarlyStopping counter: 49 out of 600\n",
      "tensor(4.3756, grad_fn=<MeanBackward0>)\n",
      "[ 525/1500] train_loss: 195.98440 valid_loss: 81.00566\n",
      "EarlyStopping counter: 50 out of 600\n",
      "tensor(6.3044, grad_fn=<MeanBackward0>)\n",
      "[ 526/1500] train_loss: 196.67096 valid_loss: 193.46706\n",
      "EarlyStopping counter: 51 out of 600\n",
      "tensor(4.1070, grad_fn=<MeanBackward0>)\n",
      "[ 527/1500] train_loss: 45.78780 valid_loss: 60.27033\n",
      "EarlyStopping counter: 52 out of 600\n",
      "tensor(3.5870, grad_fn=<MeanBackward0>)\n",
      "[ 528/1500] train_loss: 87.98021 valid_loss: 21.33437\n",
      "Validation loss decreased (21.391512 --> 21.334372).  Saving model ...\n",
      "tensor(3.6879, grad_fn=<MeanBackward0>)\n",
      "[ 529/1500] train_loss: 265.76157 valid_loss: 63.66520\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(3.5674, grad_fn=<MeanBackward0>)\n",
      "[ 530/1500] train_loss: 90.55122 valid_loss: 315.74950\n",
      "EarlyStopping counter: 2 out of 600\n",
      "tensor(4.8145, grad_fn=<MeanBackward0>)\n",
      "[ 531/1500] train_loss: 139.89710 valid_loss: 160.02611\n",
      "EarlyStopping counter: 3 out of 600\n",
      "tensor(5.8920, grad_fn=<MeanBackward0>)\n",
      "[ 532/1500] train_loss: 91.40673 valid_loss: 242.12734\n",
      "EarlyStopping counter: 4 out of 600\n",
      "tensor(4.3357, grad_fn=<MeanBackward0>)\n",
      "[ 533/1500] train_loss: 159.78676 valid_loss: 117.53891\n",
      "EarlyStopping counter: 5 out of 600\n",
      "tensor(4.0866, grad_fn=<MeanBackward0>)\n",
      "[ 534/1500] train_loss: 276.21797 valid_loss: 95.19074\n",
      "EarlyStopping counter: 6 out of 600\n",
      "tensor(5.8012, grad_fn=<MeanBackward0>)\n",
      "[ 535/1500] train_loss: 89.08745 valid_loss: 66.82043\n",
      "EarlyStopping counter: 7 out of 600\n",
      "tensor(3.9335, grad_fn=<MeanBackward0>)\n",
      "[ 536/1500] train_loss: 142.35354 valid_loss: 57.81919\n",
      "EarlyStopping counter: 8 out of 600\n",
      "tensor(2.9513, grad_fn=<MeanBackward0>)\n",
      "[ 537/1500] train_loss: 97.99777 valid_loss: 93.02588\n",
      "EarlyStopping counter: 9 out of 600\n",
      "tensor(3.4945, grad_fn=<MeanBackward0>)\n",
      "[ 538/1500] train_loss: 22.09017 valid_loss: 64.64877\n",
      "EarlyStopping counter: 10 out of 600\n",
      "tensor(2.5783, grad_fn=<MeanBackward0>)\n",
      "[ 539/1500] train_loss: 130.12798 valid_loss: 42.58749\n",
      "EarlyStopping counter: 11 out of 600\n",
      "tensor(4.8597, grad_fn=<MeanBackward0>)\n",
      "[ 540/1500] train_loss: 258.05658 valid_loss: 179.67785\n",
      "EarlyStopping counter: 12 out of 600\n",
      "tensor(4.7818, grad_fn=<MeanBackward0>)\n",
      "[ 541/1500] train_loss: 178.99394 valid_loss: 112.93259\n",
      "EarlyStopping counter: 13 out of 600\n",
      "tensor(3.4327, grad_fn=<MeanBackward0>)\n",
      "[ 542/1500] train_loss: 79.95654 valid_loss: 48.37105\n",
      "EarlyStopping counter: 14 out of 600\n",
      "tensor(5.9288, grad_fn=<MeanBackward0>)\n",
      "[ 543/1500] train_loss: 336.26103 valid_loss: 179.38181\n",
      "EarlyStopping counter: 15 out of 600\n",
      "tensor(5.0028, grad_fn=<MeanBackward0>)\n",
      "[ 544/1500] train_loss: 60.72159 valid_loss: 40.56685\n",
      "EarlyStopping counter: 16 out of 600\n",
      "tensor(3.0579, grad_fn=<MeanBackward0>)\n",
      "[ 545/1500] train_loss: 58.52563 valid_loss: 66.14297\n",
      "EarlyStopping counter: 17 out of 600\n",
      "tensor(3.7758, grad_fn=<MeanBackward0>)\n",
      "[ 546/1500] train_loss: 42.12766 valid_loss: 82.48816\n",
      "EarlyStopping counter: 18 out of 600\n",
      "tensor(3.8923, grad_fn=<MeanBackward0>)\n",
      "[ 547/1500] train_loss: 58.95086 valid_loss: 154.48189\n",
      "EarlyStopping counter: 19 out of 600\n",
      "tensor(5.5443, grad_fn=<MeanBackward0>)\n",
      "[ 548/1500] train_loss: 85.57761 valid_loss: 49.56327\n",
      "EarlyStopping counter: 20 out of 600\n",
      "tensor(4.8632, grad_fn=<MeanBackward0>)\n",
      "[ 549/1500] train_loss: 85.44145 valid_loss: 97.14925\n",
      "EarlyStopping counter: 21 out of 600\n",
      "tensor(5.0171, grad_fn=<MeanBackward0>)\n",
      "[ 550/1500] train_loss: 92.13597 valid_loss: 41.06103\n",
      "EarlyStopping counter: 22 out of 600\n",
      "tensor(3.1745, grad_fn=<MeanBackward0>)\n",
      "[ 551/1500] train_loss: 161.74737 valid_loss: 103.47485\n",
      "EarlyStopping counter: 23 out of 600\n",
      "tensor(5.2197, grad_fn=<MeanBackward0>)\n",
      "[ 552/1500] train_loss: 119.26758 valid_loss: 84.08334\n",
      "EarlyStopping counter: 24 out of 600\n",
      "tensor(2.9673, grad_fn=<MeanBackward0>)\n",
      "[ 553/1500] train_loss: 49.53832 valid_loss: 67.97119\n",
      "EarlyStopping counter: 25 out of 600\n",
      "tensor(5.3032, grad_fn=<MeanBackward0>)\n",
      "[ 554/1500] train_loss: 65.31191 valid_loss: 99.10710\n",
      "EarlyStopping counter: 26 out of 600\n",
      "tensor(5.4576, grad_fn=<MeanBackward0>)\n",
      "[ 555/1500] train_loss: 49.53618 valid_loss: 111.04141\n",
      "EarlyStopping counter: 27 out of 600\n",
      "tensor(3.0798, grad_fn=<MeanBackward0>)\n",
      "[ 556/1500] train_loss: 89.76168 valid_loss: 65.08736\n",
      "EarlyStopping counter: 28 out of 600\n",
      "tensor(3.7428, grad_fn=<MeanBackward0>)\n",
      "[ 557/1500] train_loss: 126.04533 valid_loss: 89.96731\n",
      "EarlyStopping counter: 29 out of 600\n",
      "tensor(3.8948, grad_fn=<MeanBackward0>)\n",
      "[ 558/1500] train_loss: 66.81645 valid_loss: 34.60123\n",
      "EarlyStopping counter: 30 out of 600\n",
      "tensor(4.5120, grad_fn=<MeanBackward0>)\n",
      "[ 559/1500] train_loss: 104.35762 valid_loss: 84.57183\n",
      "EarlyStopping counter: 31 out of 600\n",
      "tensor(2.9778, grad_fn=<MeanBackward0>)\n",
      "[ 560/1500] train_loss: 230.00269 valid_loss: 62.63252\n",
      "EarlyStopping counter: 32 out of 600\n",
      "tensor(6.4020, grad_fn=<MeanBackward0>)\n",
      "[ 561/1500] train_loss: 104.40045 valid_loss: 66.55079\n",
      "EarlyStopping counter: 33 out of 600\n",
      "tensor(6.7067, grad_fn=<MeanBackward0>)\n",
      "[ 562/1500] train_loss: 101.25633 valid_loss: 63.18427\n",
      "EarlyStopping counter: 34 out of 600\n",
      "tensor(3.1724, grad_fn=<MeanBackward0>)\n",
      "[ 563/1500] train_loss: 170.92469 valid_loss: 33.91662\n",
      "EarlyStopping counter: 35 out of 600\n",
      "tensor(4.1798, grad_fn=<MeanBackward0>)\n",
      "[ 564/1500] train_loss: 43.04416 valid_loss: 52.65308\n",
      "EarlyStopping counter: 36 out of 600\n",
      "tensor(6.6336, grad_fn=<MeanBackward0>)\n",
      "[ 565/1500] train_loss: 268.25422 valid_loss: 79.09669\n",
      "EarlyStopping counter: 37 out of 600\n",
      "tensor(5.3789, grad_fn=<MeanBackward0>)\n",
      "[ 566/1500] train_loss: 123.56756 valid_loss: 81.37393\n",
      "EarlyStopping counter: 38 out of 600\n",
      "tensor(3.3538, grad_fn=<MeanBackward0>)\n",
      "[ 567/1500] train_loss: 44.14274 valid_loss: 154.69352\n",
      "EarlyStopping counter: 39 out of 600\n",
      "tensor(5.1368, grad_fn=<MeanBackward0>)\n",
      "[ 568/1500] train_loss: 88.73451 valid_loss: 58.34891\n",
      "EarlyStopping counter: 40 out of 600\n",
      "tensor(4.4616, grad_fn=<MeanBackward0>)\n",
      "[ 569/1500] train_loss: 79.26890 valid_loss: 18.44272\n",
      "Validation loss decreased (21.334372 --> 18.442720).  Saving model ...\n",
      "tensor(5.3903, grad_fn=<MeanBackward0>)\n",
      "[ 570/1500] train_loss: 139.43800 valid_loss: 48.98958\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(4.3947, grad_fn=<MeanBackward0>)\n",
      "[ 571/1500] train_loss: 63.02016 valid_loss: 46.54191\n",
      "EarlyStopping counter: 2 out of 600\n",
      "tensor(5.5259, grad_fn=<MeanBackward0>)\n",
      "[ 572/1500] train_loss: 161.72060 valid_loss: 22.90127\n",
      "EarlyStopping counter: 3 out of 600\n",
      "tensor(4.6190, grad_fn=<MeanBackward0>)\n",
      "[ 573/1500] train_loss: 93.16080 valid_loss: 69.03839\n",
      "EarlyStopping counter: 4 out of 600\n",
      "tensor(3.7053, grad_fn=<MeanBackward0>)\n",
      "[ 574/1500] train_loss: 98.63951 valid_loss: 74.31213\n",
      "EarlyStopping counter: 5 out of 600\n",
      "tensor(3.3714, grad_fn=<MeanBackward0>)\n",
      "[ 575/1500] train_loss: 25.28588 valid_loss: 72.94726\n",
      "EarlyStopping counter: 6 out of 600\n",
      "tensor(4.4925, grad_fn=<MeanBackward0>)\n",
      "[ 576/1500] train_loss: 163.65436 valid_loss: 118.19375\n",
      "EarlyStopping counter: 7 out of 600\n",
      "tensor(4.6359, grad_fn=<MeanBackward0>)\n",
      "[ 577/1500] train_loss: 95.72486 valid_loss: 43.81914\n",
      "EarlyStopping counter: 8 out of 600\n",
      "tensor(3.9617, grad_fn=<MeanBackward0>)\n",
      "[ 578/1500] train_loss: 31.28980 valid_loss: 36.07820\n",
      "EarlyStopping counter: 9 out of 600\n",
      "tensor(4.1521, grad_fn=<MeanBackward0>)\n",
      "[ 579/1500] train_loss: 352.95146 valid_loss: 25.33028\n",
      "EarlyStopping counter: 10 out of 600\n",
      "tensor(4.9053, grad_fn=<MeanBackward0>)\n",
      "[ 580/1500] train_loss: 87.06464 valid_loss: 21.30817\n",
      "EarlyStopping counter: 11 out of 600\n",
      "tensor(3.4733, grad_fn=<MeanBackward0>)\n",
      "[ 581/1500] train_loss: 64.06912 valid_loss: 38.63853\n",
      "EarlyStopping counter: 12 out of 600\n",
      "tensor(5.0316, grad_fn=<MeanBackward0>)\n",
      "[ 582/1500] train_loss: 33.50427 valid_loss: 39.22073\n",
      "EarlyStopping counter: 13 out of 600\n",
      "tensor(4.2149, grad_fn=<MeanBackward0>)\n",
      "[ 583/1500] train_loss: 44.76045 valid_loss: 131.21024\n",
      "EarlyStopping counter: 14 out of 600\n",
      "tensor(6.4153, grad_fn=<MeanBackward0>)\n",
      "[ 584/1500] train_loss: 115.49118 valid_loss: 139.94403\n",
      "EarlyStopping counter: 15 out of 600\n",
      "tensor(5.0420, grad_fn=<MeanBackward0>)\n",
      "[ 585/1500] train_loss: 126.62724 valid_loss: 88.38214\n",
      "EarlyStopping counter: 16 out of 600\n",
      "tensor(6.2202, grad_fn=<MeanBackward0>)\n",
      "[ 586/1500] train_loss: 108.64778 valid_loss: 38.14492\n",
      "EarlyStopping counter: 17 out of 600\n",
      "tensor(5.4039, grad_fn=<MeanBackward0>)\n",
      "[ 587/1500] train_loss: 76.28082 valid_loss: 38.93680\n",
      "EarlyStopping counter: 18 out of 600\n",
      "tensor(6.5374, grad_fn=<MeanBackward0>)\n",
      "[ 588/1500] train_loss: 107.57599 valid_loss: 43.38031\n",
      "EarlyStopping counter: 19 out of 600\n",
      "tensor(4.0603, grad_fn=<MeanBackward0>)\n",
      "[ 589/1500] train_loss: 93.16142 valid_loss: 28.25089\n",
      "EarlyStopping counter: 20 out of 600\n",
      "tensor(3.6318, grad_fn=<MeanBackward0>)\n",
      "[ 590/1500] train_loss: 23.41246 valid_loss: 51.00487\n",
      "EarlyStopping counter: 21 out of 600\n",
      "tensor(5.0599, grad_fn=<MeanBackward0>)\n",
      "[ 591/1500] train_loss: 105.00738 valid_loss: 49.91269\n",
      "EarlyStopping counter: 22 out of 600\n",
      "tensor(3.5961, grad_fn=<MeanBackward0>)\n",
      "[ 592/1500] train_loss: 175.36704 valid_loss: 119.00404\n",
      "EarlyStopping counter: 23 out of 600\n",
      "tensor(4.0807, grad_fn=<MeanBackward0>)\n",
      "[ 593/1500] train_loss: 29.80051 valid_loss: 75.12428\n",
      "EarlyStopping counter: 24 out of 600\n",
      "tensor(5.2095, grad_fn=<MeanBackward0>)\n",
      "[ 594/1500] train_loss: 64.63095 valid_loss: 27.56995\n",
      "EarlyStopping counter: 25 out of 600\n",
      "tensor(3.5639, grad_fn=<MeanBackward0>)\n",
      "[ 595/1500] train_loss: 134.18129 valid_loss: 24.36603\n",
      "EarlyStopping counter: 26 out of 600\n",
      "tensor(4.7184, grad_fn=<MeanBackward0>)\n",
      "[ 596/1500] train_loss: 77.26425 valid_loss: 228.43354\n",
      "EarlyStopping counter: 27 out of 600\n",
      "tensor(3.9252, grad_fn=<MeanBackward0>)\n",
      "[ 597/1500] train_loss: 16.01699 valid_loss: 48.73521\n",
      "EarlyStopping counter: 28 out of 600\n",
      "tensor(3.5229, grad_fn=<MeanBackward0>)\n",
      "[ 598/1500] train_loss: 52.42820 valid_loss: 25.79296\n",
      "EarlyStopping counter: 29 out of 600\n",
      "tensor(4.5280, grad_fn=<MeanBackward0>)\n",
      "[ 599/1500] train_loss: 54.87925 valid_loss: 27.03270\n",
      "EarlyStopping counter: 30 out of 600\n",
      "tensor(3.2813, grad_fn=<MeanBackward0>)\n",
      "[ 600/1500] train_loss: 97.42298 valid_loss: 37.85600\n",
      "EarlyStopping counter: 31 out of 600\n",
      "tensor(4.2242, grad_fn=<MeanBackward0>)\n",
      "[ 601/1500] train_loss: 46.66939 valid_loss: 24.39520\n",
      "EarlyStopping counter: 32 out of 600\n",
      "tensor(4.1300, grad_fn=<MeanBackward0>)\n",
      "[ 602/1500] train_loss: 63.94758 valid_loss: 215.51234\n",
      "EarlyStopping counter: 33 out of 600\n",
      "tensor(4.6725, grad_fn=<MeanBackward0>)\n",
      "[ 603/1500] train_loss: 60.86248 valid_loss: 43.35229\n",
      "EarlyStopping counter: 34 out of 600\n",
      "tensor(3.5606, grad_fn=<MeanBackward0>)\n",
      "[ 604/1500] train_loss: 29.49049 valid_loss: 173.11013\n",
      "EarlyStopping counter: 35 out of 600\n",
      "tensor(5.0237, grad_fn=<MeanBackward0>)\n",
      "[ 605/1500] train_loss: 127.66746 valid_loss: 57.47170\n",
      "EarlyStopping counter: 36 out of 600\n",
      "tensor(4.0518, grad_fn=<MeanBackward0>)\n",
      "[ 606/1500] train_loss: 28.98252 valid_loss: 169.43309\n",
      "EarlyStopping counter: 37 out of 600\n",
      "tensor(5.2244, grad_fn=<MeanBackward0>)\n",
      "[ 607/1500] train_loss: 119.68547 valid_loss: 22.02038\n",
      "EarlyStopping counter: 38 out of 600\n",
      "tensor(5.3412, grad_fn=<MeanBackward0>)\n",
      "[ 608/1500] train_loss: 56.92543 valid_loss: 44.82000\n",
      "EarlyStopping counter: 39 out of 600\n",
      "tensor(5.9979, grad_fn=<MeanBackward0>)\n",
      "[ 609/1500] train_loss: 86.20757 valid_loss: 39.57483\n",
      "EarlyStopping counter: 40 out of 600\n",
      "tensor(4.2001, grad_fn=<MeanBackward0>)\n",
      "[ 610/1500] train_loss: 51.08168 valid_loss: 57.43332\n",
      "EarlyStopping counter: 41 out of 600\n",
      "tensor(3.5230, grad_fn=<MeanBackward0>)\n",
      "[ 611/1500] train_loss: 28.68017 valid_loss: 76.77324\n",
      "EarlyStopping counter: 42 out of 600\n",
      "tensor(3.1020, grad_fn=<MeanBackward0>)\n",
      "[ 612/1500] train_loss: 161.96649 valid_loss: 131.59893\n",
      "EarlyStopping counter: 43 out of 600\n",
      "tensor(4.0659, grad_fn=<MeanBackward0>)\n",
      "[ 613/1500] train_loss: 53.51939 valid_loss: 22.86401\n",
      "EarlyStopping counter: 44 out of 600\n",
      "tensor(3.9505, grad_fn=<MeanBackward0>)\n",
      "[ 614/1500] train_loss: 43.04409 valid_loss: 26.02606\n",
      "EarlyStopping counter: 45 out of 600\n",
      "tensor(5.1332, grad_fn=<MeanBackward0>)\n",
      "[ 615/1500] train_loss: 87.00830 valid_loss: 151.00682\n",
      "EarlyStopping counter: 46 out of 600\n",
      "tensor(5.3827, grad_fn=<MeanBackward0>)\n",
      "[ 616/1500] train_loss: 278.76280 valid_loss: 16.26488\n",
      "Validation loss decreased (18.442720 --> 16.264876).  Saving model ...\n",
      "tensor(3.4095, grad_fn=<MeanBackward0>)\n",
      "[ 617/1500] train_loss: 70.08592 valid_loss: 71.77516\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(5.0744, grad_fn=<MeanBackward0>)\n",
      "[ 618/1500] train_loss: 36.59067 valid_loss: 85.03353\n",
      "EarlyStopping counter: 2 out of 600\n",
      "tensor(4.8175, grad_fn=<MeanBackward0>)\n",
      "[ 619/1500] train_loss: 84.07436 valid_loss: 226.45038\n",
      "EarlyStopping counter: 3 out of 600\n",
      "tensor(6.6173, grad_fn=<MeanBackward0>)\n",
      "[ 620/1500] train_loss: 146.82038 valid_loss: 23.95135\n",
      "EarlyStopping counter: 4 out of 600\n",
      "tensor(5.3558, grad_fn=<MeanBackward0>)\n",
      "[ 621/1500] train_loss: 56.03528 valid_loss: 41.31689\n",
      "EarlyStopping counter: 5 out of 600\n",
      "tensor(3.6219, grad_fn=<MeanBackward0>)\n",
      "[ 622/1500] train_loss: 63.55957 valid_loss: 116.35638\n",
      "EarlyStopping counter: 6 out of 600\n",
      "tensor(4.9838, grad_fn=<MeanBackward0>)\n",
      "[ 623/1500] train_loss: 105.02469 valid_loss: 255.26325\n",
      "EarlyStopping counter: 7 out of 600\n",
      "tensor(3.3210, grad_fn=<MeanBackward0>)\n",
      "[ 624/1500] train_loss: 172.01875 valid_loss: 24.52168\n",
      "EarlyStopping counter: 8 out of 600\n",
      "tensor(5.3109, grad_fn=<MeanBackward0>)\n",
      "[ 625/1500] train_loss: 75.18599 valid_loss: 202.04026\n",
      "EarlyStopping counter: 9 out of 600\n",
      "tensor(4.2727, grad_fn=<MeanBackward0>)\n",
      "[ 626/1500] train_loss: 38.47747 valid_loss: 345.58199\n",
      "EarlyStopping counter: 10 out of 600\n",
      "tensor(4.5675, grad_fn=<MeanBackward0>)\n",
      "[ 627/1500] train_loss: 407.11318 valid_loss: 17.64706\n",
      "EarlyStopping counter: 11 out of 600\n",
      "tensor(3.8155, grad_fn=<MeanBackward0>)\n",
      "[ 628/1500] train_loss: 31.95578 valid_loss: 127.67103\n",
      "EarlyStopping counter: 12 out of 600\n",
      "tensor(3.3701, grad_fn=<MeanBackward0>)\n",
      "[ 629/1500] train_loss: 100.50370 valid_loss: 195.45693\n",
      "EarlyStopping counter: 13 out of 600\n",
      "tensor(3.3454, grad_fn=<MeanBackward0>)\n",
      "[ 630/1500] train_loss: 18.08200 valid_loss: 223.73876\n",
      "EarlyStopping counter: 14 out of 600\n",
      "tensor(5.1289, grad_fn=<MeanBackward0>)\n",
      "[ 631/1500] train_loss: 206.28210 valid_loss: 442.94728\n",
      "EarlyStopping counter: 15 out of 600\n",
      "tensor(6.1677, grad_fn=<MeanBackward0>)\n",
      "[ 632/1500] train_loss: 300.41221 valid_loss: 54.86609\n",
      "EarlyStopping counter: 16 out of 600\n",
      "tensor(3.2567, grad_fn=<MeanBackward0>)\n",
      "[ 633/1500] train_loss: 88.76770 valid_loss: 69.99670\n",
      "EarlyStopping counter: 17 out of 600\n",
      "tensor(6.0580, grad_fn=<MeanBackward0>)\n",
      "[ 634/1500] train_loss: 106.06910 valid_loss: 41.75862\n",
      "EarlyStopping counter: 18 out of 600\n",
      "tensor(5.4239, grad_fn=<MeanBackward0>)\n",
      "[ 635/1500] train_loss: 165.55359 valid_loss: 20.51790\n",
      "EarlyStopping counter: 19 out of 600\n",
      "tensor(4.6600, grad_fn=<MeanBackward0>)\n",
      "[ 636/1500] train_loss: 53.43217 valid_loss: 40.73468\n",
      "EarlyStopping counter: 20 out of 600\n",
      "tensor(4.8416, grad_fn=<MeanBackward0>)\n",
      "[ 637/1500] train_loss: 68.74433 valid_loss: 105.76749\n",
      "EarlyStopping counter: 21 out of 600\n",
      "tensor(5.0566, grad_fn=<MeanBackward0>)\n",
      "[ 638/1500] train_loss: 39.41178 valid_loss: 113.60095\n",
      "EarlyStopping counter: 22 out of 600\n",
      "tensor(4.8872, grad_fn=<MeanBackward0>)\n",
      "[ 639/1500] train_loss: 291.81243 valid_loss: 53.86719\n",
      "EarlyStopping counter: 23 out of 600\n",
      "tensor(5.9347, grad_fn=<MeanBackward0>)\n",
      "[ 640/1500] train_loss: 202.34553 valid_loss: 44.83047\n",
      "EarlyStopping counter: 24 out of 600\n",
      "tensor(5.8040, grad_fn=<MeanBackward0>)\n",
      "[ 641/1500] train_loss: 174.84572 valid_loss: 75.90262\n",
      "EarlyStopping counter: 25 out of 600\n",
      "tensor(3.3913, grad_fn=<MeanBackward0>)\n",
      "[ 642/1500] train_loss: 29.44153 valid_loss: 21.10277\n",
      "EarlyStopping counter: 26 out of 600\n",
      "tensor(4.3117, grad_fn=<MeanBackward0>)\n",
      "[ 643/1500] train_loss: 103.60583 valid_loss: 92.36932\n",
      "EarlyStopping counter: 27 out of 600\n",
      "tensor(3.2414, grad_fn=<MeanBackward0>)\n",
      "[ 644/1500] train_loss: 28.19731 valid_loss: 609.06181\n",
      "EarlyStopping counter: 28 out of 600\n",
      "tensor(3.6222, grad_fn=<MeanBackward0>)\n",
      "[ 645/1500] train_loss: 59.18597 valid_loss: 237.21783\n",
      "EarlyStopping counter: 29 out of 600\n",
      "tensor(4.2025, grad_fn=<MeanBackward0>)\n",
      "[ 646/1500] train_loss: 424.53673 valid_loss: 901.99750\n",
      "EarlyStopping counter: 30 out of 600\n",
      "tensor(4.8391, grad_fn=<MeanBackward0>)\n",
      "[ 647/1500] train_loss: 89.77399 valid_loss: 77.60367\n",
      "EarlyStopping counter: 31 out of 600\n",
      "tensor(6.2085, grad_fn=<MeanBackward0>)\n",
      "[ 648/1500] train_loss: 699.13596 valid_loss: 143.46117\n",
      "EarlyStopping counter: 32 out of 600\n",
      "tensor(5.2771, grad_fn=<MeanBackward0>)\n",
      "[ 649/1500] train_loss: 352.28765 valid_loss: 66.15044\n",
      "EarlyStopping counter: 33 out of 600\n",
      "tensor(4.2320, grad_fn=<MeanBackward0>)\n",
      "[ 650/1500] train_loss: 68.36203 valid_loss: 43.42185\n",
      "EarlyStopping counter: 34 out of 600\n",
      "tensor(5.4135, grad_fn=<MeanBackward0>)\n",
      "[ 651/1500] train_loss: 584.03804 valid_loss: 83.63719\n",
      "EarlyStopping counter: 35 out of 600\n",
      "tensor(4.0175, grad_fn=<MeanBackward0>)\n",
      "[ 652/1500] train_loss: 47.91845 valid_loss: 76.73728\n",
      "EarlyStopping counter: 36 out of 600\n",
      "tensor(3.4694, grad_fn=<MeanBackward0>)\n",
      "[ 653/1500] train_loss: 249.47480 valid_loss: 246.74971\n",
      "EarlyStopping counter: 37 out of 600\n",
      "tensor(5.6662, grad_fn=<MeanBackward0>)\n",
      "[ 654/1500] train_loss: 195.31051 valid_loss: 243.79534\n",
      "EarlyStopping counter: 38 out of 600\n",
      "tensor(4.1847, grad_fn=<MeanBackward0>)\n",
      "[ 655/1500] train_loss: 193.64780 valid_loss: 107.70437\n",
      "EarlyStopping counter: 39 out of 600\n",
      "tensor(3.5152, grad_fn=<MeanBackward0>)\n",
      "[ 656/1500] train_loss: 40.05538 valid_loss: 42.51736\n",
      "EarlyStopping counter: 40 out of 600\n",
      "tensor(4.3611, grad_fn=<MeanBackward0>)\n",
      "[ 657/1500] train_loss: 292.51797 valid_loss: 254.83569\n",
      "EarlyStopping counter: 41 out of 600\n",
      "tensor(6.2193, grad_fn=<MeanBackward0>)\n",
      "[ 658/1500] train_loss: 176.21350 valid_loss: 37.28534\n",
      "EarlyStopping counter: 42 out of 600\n",
      "tensor(3.6585, grad_fn=<MeanBackward0>)\n",
      "[ 659/1500] train_loss: 44.18119 valid_loss: 55.80659\n",
      "EarlyStopping counter: 43 out of 600\n",
      "tensor(4.9252, grad_fn=<MeanBackward0>)\n",
      "[ 660/1500] train_loss: 91.19574 valid_loss: 19.34351\n",
      "EarlyStopping counter: 44 out of 600\n",
      "tensor(4.2579, grad_fn=<MeanBackward0>)\n",
      "[ 661/1500] train_loss: 52.42418 valid_loss: 161.45489\n",
      "EarlyStopping counter: 45 out of 600\n",
      "tensor(3.5163, grad_fn=<MeanBackward0>)\n",
      "[ 662/1500] train_loss: 24.22291 valid_loss: 211.93306\n",
      "EarlyStopping counter: 46 out of 600\n",
      "tensor(6.0377, grad_fn=<MeanBackward0>)\n",
      "[ 663/1500] train_loss: 114.92319 valid_loss: 279.39920\n",
      "EarlyStopping counter: 47 out of 600\n",
      "tensor(3.5396, grad_fn=<MeanBackward0>)\n",
      "[ 664/1500] train_loss: 142.24638 valid_loss: 313.63321\n",
      "EarlyStopping counter: 48 out of 600\n",
      "tensor(4.2184, grad_fn=<MeanBackward0>)\n",
      "[ 665/1500] train_loss: 247.83783 valid_loss: 206.81278\n",
      "EarlyStopping counter: 49 out of 600\n",
      "tensor(4.7016, grad_fn=<MeanBackward0>)\n",
      "[ 666/1500] train_loss: 38.86613 valid_loss: 104.68486\n",
      "EarlyStopping counter: 50 out of 600\n",
      "tensor(4.4689, grad_fn=<MeanBackward0>)\n",
      "[ 667/1500] train_loss: 268.49601 valid_loss: 165.60777\n",
      "EarlyStopping counter: 51 out of 600\n",
      "tensor(7.3995, grad_fn=<MeanBackward0>)\n",
      "[ 668/1500] train_loss: 171.24483 valid_loss: 74.28692\n",
      "EarlyStopping counter: 52 out of 600\n",
      "tensor(5.3111, grad_fn=<MeanBackward0>)\n",
      "[ 669/1500] train_loss: 146.25254 valid_loss: 22.69401\n",
      "EarlyStopping counter: 53 out of 600\n",
      "tensor(5.2380, grad_fn=<MeanBackward0>)\n",
      "[ 670/1500] train_loss: 140.25690 valid_loss: 79.18275\n",
      "EarlyStopping counter: 54 out of 600\n",
      "tensor(3.1547, grad_fn=<MeanBackward0>)\n",
      "[ 671/1500] train_loss: 82.30360 valid_loss: 91.90250\n",
      "EarlyStopping counter: 55 out of 600\n",
      "tensor(5.5489, grad_fn=<MeanBackward0>)\n",
      "[ 672/1500] train_loss: 284.84094 valid_loss: 81.80997\n",
      "EarlyStopping counter: 56 out of 600\n",
      "tensor(3.0623, grad_fn=<MeanBackward0>)\n",
      "[ 673/1500] train_loss: 60.76598 valid_loss: 32.84493\n",
      "EarlyStopping counter: 57 out of 600\n",
      "tensor(4.2199, grad_fn=<MeanBackward0>)\n",
      "[ 674/1500] train_loss: 63.36484 valid_loss: 273.09499\n",
      "EarlyStopping counter: 58 out of 600\n",
      "tensor(3.2645, grad_fn=<MeanBackward0>)\n",
      "[ 675/1500] train_loss: 256.58248 valid_loss: 145.38556\n",
      "EarlyStopping counter: 59 out of 600\n",
      "tensor(3.1059, grad_fn=<MeanBackward0>)\n",
      "[ 676/1500] train_loss: 65.73413 valid_loss: 81.73661\n",
      "EarlyStopping counter: 60 out of 600\n",
      "tensor(5.4258, grad_fn=<MeanBackward0>)\n",
      "[ 677/1500] train_loss: 147.78501 valid_loss: 57.76212\n",
      "EarlyStopping counter: 61 out of 600\n",
      "tensor(5.2264, grad_fn=<MeanBackward0>)\n",
      "[ 678/1500] train_loss: 241.26126 valid_loss: 54.49990\n",
      "EarlyStopping counter: 62 out of 600\n",
      "tensor(3.3188, grad_fn=<MeanBackward0>)\n",
      "[ 679/1500] train_loss: 41.64102 valid_loss: 108.26214\n",
      "EarlyStopping counter: 63 out of 600\n",
      "tensor(5.5085, grad_fn=<MeanBackward0>)\n",
      "[ 680/1500] train_loss: 207.63919 valid_loss: 55.04435\n",
      "EarlyStopping counter: 64 out of 600\n",
      "tensor(3.6124, grad_fn=<MeanBackward0>)\n",
      "[ 681/1500] train_loss: 75.49455 valid_loss: 327.06329\n",
      "EarlyStopping counter: 65 out of 600\n",
      "tensor(6.1143, grad_fn=<MeanBackward0>)\n",
      "[ 682/1500] train_loss: 95.03998 valid_loss: 25.76849\n",
      "EarlyStopping counter: 66 out of 600\n",
      "tensor(4.6860, grad_fn=<MeanBackward0>)\n",
      "[ 683/1500] train_loss: 36.53089 valid_loss: 31.84090\n",
      "EarlyStopping counter: 67 out of 600\n",
      "tensor(3.6202, grad_fn=<MeanBackward0>)\n",
      "[ 684/1500] train_loss: 269.35736 valid_loss: 67.46777\n",
      "EarlyStopping counter: 68 out of 600\n",
      "tensor(4.9149, grad_fn=<MeanBackward0>)\n",
      "[ 685/1500] train_loss: 60.62181 valid_loss: 58.76954\n",
      "EarlyStopping counter: 69 out of 600\n",
      "tensor(5.3476, grad_fn=<MeanBackward0>)\n",
      "[ 686/1500] train_loss: 177.71625 valid_loss: 124.85087\n",
      "EarlyStopping counter: 70 out of 600\n",
      "tensor(6.5255, grad_fn=<MeanBackward0>)\n",
      "[ 687/1500] train_loss: 95.76944 valid_loss: 23.13815\n",
      "EarlyStopping counter: 71 out of 600\n",
      "tensor(3.7117, grad_fn=<MeanBackward0>)\n",
      "[ 688/1500] train_loss: 208.29936 valid_loss: 21.20292\n",
      "EarlyStopping counter: 72 out of 600\n",
      "tensor(3.3919, grad_fn=<MeanBackward0>)\n",
      "[ 689/1500] train_loss: 80.49141 valid_loss: 32.76123\n",
      "EarlyStopping counter: 73 out of 600\n",
      "tensor(5.5613, grad_fn=<MeanBackward0>)\n",
      "[ 690/1500] train_loss: 46.35595 valid_loss: 26.20885\n",
      "EarlyStopping counter: 74 out of 600\n",
      "tensor(3.4143, grad_fn=<MeanBackward0>)\n",
      "[ 691/1500] train_loss: 35.30349 valid_loss: 26.89780\n",
      "EarlyStopping counter: 75 out of 600\n",
      "tensor(4.3115, grad_fn=<MeanBackward0>)\n",
      "[ 692/1500] train_loss: 84.19954 valid_loss: 39.65140\n",
      "EarlyStopping counter: 76 out of 600\n",
      "tensor(3.4784, grad_fn=<MeanBackward0>)\n",
      "[ 693/1500] train_loss: 31.47670 valid_loss: 380.24058\n",
      "EarlyStopping counter: 77 out of 600\n",
      "tensor(4.4019, grad_fn=<MeanBackward0>)\n",
      "[ 694/1500] train_loss: 135.80979 valid_loss: 187.37571\n",
      "EarlyStopping counter: 78 out of 600\n",
      "tensor(6.2528, grad_fn=<MeanBackward0>)\n",
      "[ 695/1500] train_loss: 648.61572 valid_loss: 67.19817\n",
      "EarlyStopping counter: 79 out of 600\n",
      "tensor(5.2207, grad_fn=<MeanBackward0>)\n",
      "[ 696/1500] train_loss: 183.56125 valid_loss: 82.12787\n",
      "EarlyStopping counter: 80 out of 600\n",
      "tensor(5.4108, grad_fn=<MeanBackward0>)\n",
      "[ 697/1500] train_loss: 49.09787 valid_loss: 44.53719\n",
      "EarlyStopping counter: 81 out of 600\n",
      "tensor(3.8706, grad_fn=<MeanBackward0>)\n",
      "[ 698/1500] train_loss: 75.87713 valid_loss: 112.04939\n",
      "EarlyStopping counter: 82 out of 600\n",
      "tensor(3.4993, grad_fn=<MeanBackward0>)\n",
      "[ 699/1500] train_loss: 113.60681 valid_loss: 231.38193\n",
      "EarlyStopping counter: 83 out of 600\n",
      "tensor(6.9531, grad_fn=<MeanBackward0>)\n",
      "[ 700/1500] train_loss: 196.75946 valid_loss: 24.94739\n",
      "EarlyStopping counter: 84 out of 600\n",
      "tensor(5.5012, grad_fn=<MeanBackward0>)\n",
      "[ 701/1500] train_loss: 186.66305 valid_loss: 127.94359\n",
      "EarlyStopping counter: 85 out of 600\n",
      "tensor(6.5059, grad_fn=<MeanBackward0>)\n",
      "[ 702/1500] train_loss: 225.45380 valid_loss: 28.66575\n",
      "EarlyStopping counter: 86 out of 600\n",
      "tensor(3.7125, grad_fn=<MeanBackward0>)\n",
      "[ 703/1500] train_loss: 64.77898 valid_loss: 67.78471\n",
      "EarlyStopping counter: 87 out of 600\n",
      "tensor(3.6374, grad_fn=<MeanBackward0>)\n",
      "[ 704/1500] train_loss: 128.59113 valid_loss: 47.24985\n",
      "EarlyStopping counter: 88 out of 600\n",
      "tensor(3.2167, grad_fn=<MeanBackward0>)\n",
      "[ 705/1500] train_loss: 31.10099 valid_loss: 172.32710\n",
      "EarlyStopping counter: 89 out of 600\n",
      "tensor(3.3521, grad_fn=<MeanBackward0>)\n",
      "[ 706/1500] train_loss: 118.84318 valid_loss: 56.68118\n",
      "EarlyStopping counter: 90 out of 600\n",
      "tensor(5.7454, grad_fn=<MeanBackward0>)\n",
      "[ 707/1500] train_loss: 158.67373 valid_loss: 48.34619\n",
      "EarlyStopping counter: 91 out of 600\n",
      "tensor(3.3243, grad_fn=<MeanBackward0>)\n",
      "[ 708/1500] train_loss: 47.94909 valid_loss: 206.70164\n",
      "EarlyStopping counter: 92 out of 600\n",
      "tensor(5.7594, grad_fn=<MeanBackward0>)\n",
      "[ 709/1500] train_loss: 86.76352 valid_loss: 24.98289\n",
      "EarlyStopping counter: 93 out of 600\n",
      "tensor(5.7848, grad_fn=<MeanBackward0>)\n",
      "[ 710/1500] train_loss: 69.15202 valid_loss: 34.04761\n",
      "EarlyStopping counter: 94 out of 600\n",
      "tensor(2.9832, grad_fn=<MeanBackward0>)\n",
      "[ 711/1500] train_loss: 63.04096 valid_loss: 131.64034\n",
      "EarlyStopping counter: 95 out of 600\n",
      "tensor(6.0633, grad_fn=<MeanBackward0>)\n",
      "[ 712/1500] train_loss: 97.32799 valid_loss: 137.23188\n",
      "EarlyStopping counter: 96 out of 600\n",
      "tensor(4.7433, grad_fn=<MeanBackward0>)\n",
      "[ 713/1500] train_loss: 287.80182 valid_loss: 39.42694\n",
      "EarlyStopping counter: 97 out of 600\n",
      "tensor(5.1147, grad_fn=<MeanBackward0>)\n",
      "[ 714/1500] train_loss: 166.68051 valid_loss: 27.72922\n",
      "EarlyStopping counter: 98 out of 600\n",
      "tensor(5.0481, grad_fn=<MeanBackward0>)\n",
      "[ 715/1500] train_loss: 85.95153 valid_loss: 50.22097\n",
      "EarlyStopping counter: 99 out of 600\n",
      "tensor(5.0117, grad_fn=<MeanBackward0>)\n",
      "[ 716/1500] train_loss: 52.25614 valid_loss: 39.39439\n",
      "EarlyStopping counter: 100 out of 600\n",
      "tensor(5.8822, grad_fn=<MeanBackward0>)\n",
      "[ 717/1500] train_loss: 92.65119 valid_loss: 115.49238\n",
      "EarlyStopping counter: 101 out of 600\n",
      "tensor(4.9476, grad_fn=<MeanBackward0>)\n",
      "[ 718/1500] train_loss: 82.68900 valid_loss: 116.44541\n",
      "EarlyStopping counter: 102 out of 600\n",
      "tensor(3.7162, grad_fn=<MeanBackward0>)\n",
      "[ 719/1500] train_loss: 28.65188 valid_loss: 87.86376\n",
      "EarlyStopping counter: 103 out of 600\n",
      "tensor(4.3040, grad_fn=<MeanBackward0>)\n",
      "[ 720/1500] train_loss: 50.55699 valid_loss: 92.17394\n",
      "EarlyStopping counter: 104 out of 600\n",
      "tensor(5.3506, grad_fn=<MeanBackward0>)\n",
      "[ 721/1500] train_loss: 38.53045 valid_loss: 19.19414\n",
      "EarlyStopping counter: 105 out of 600\n",
      "tensor(3.3992, grad_fn=<MeanBackward0>)\n",
      "[ 722/1500] train_loss: 42.67537 valid_loss: 28.18684\n",
      "EarlyStopping counter: 106 out of 600\n",
      "tensor(5.1982, grad_fn=<MeanBackward0>)\n",
      "[ 723/1500] train_loss: 72.65849 valid_loss: 162.91532\n",
      "EarlyStopping counter: 107 out of 600\n",
      "tensor(3.9047, grad_fn=<MeanBackward0>)\n",
      "[ 724/1500] train_loss: 82.19978 valid_loss: 102.92763\n",
      "EarlyStopping counter: 108 out of 600\n",
      "tensor(6.6516, grad_fn=<MeanBackward0>)\n",
      "[ 725/1500] train_loss: 176.62593 valid_loss: 122.77736\n",
      "EarlyStopping counter: 109 out of 600\n",
      "tensor(3.4177, grad_fn=<MeanBackward0>)\n",
      "[ 726/1500] train_loss: 30.44078 valid_loss: 238.42301\n",
      "EarlyStopping counter: 110 out of 600\n",
      "tensor(3.6661, grad_fn=<MeanBackward0>)\n",
      "[ 727/1500] train_loss: 38.68994 valid_loss: 36.73530\n",
      "EarlyStopping counter: 111 out of 600\n",
      "tensor(3.7344, grad_fn=<MeanBackward0>)\n",
      "[ 728/1500] train_loss: 28.38695 valid_loss: 361.93498\n",
      "EarlyStopping counter: 112 out of 600\n",
      "tensor(3.0750, grad_fn=<MeanBackward0>)\n",
      "[ 729/1500] train_loss: 15.92613 valid_loss: 115.42203\n",
      "EarlyStopping counter: 113 out of 600\n",
      "tensor(7.3734, grad_fn=<MeanBackward0>)\n",
      "[ 730/1500] train_loss: 309.40552 valid_loss: 219.98074\n",
      "EarlyStopping counter: 114 out of 600\n",
      "tensor(5.0623, grad_fn=<MeanBackward0>)\n",
      "[ 731/1500] train_loss: 217.39366 valid_loss: 201.19404\n",
      "EarlyStopping counter: 115 out of 600\n",
      "tensor(3.2294, grad_fn=<MeanBackward0>)\n",
      "[ 732/1500] train_loss: 21.41799 valid_loss: 76.66373\n",
      "EarlyStopping counter: 116 out of 600\n",
      "tensor(5.7349, grad_fn=<MeanBackward0>)\n",
      "[ 733/1500] train_loss: 30.48904 valid_loss: 25.60031\n",
      "EarlyStopping counter: 117 out of 600\n",
      "tensor(3.6879, grad_fn=<MeanBackward0>)\n",
      "[ 734/1500] train_loss: 69.96808 valid_loss: 68.02845\n",
      "EarlyStopping counter: 118 out of 600\n",
      "tensor(6.0041, grad_fn=<MeanBackward0>)\n",
      "[ 735/1500] train_loss: 73.37098 valid_loss: 43.98631\n",
      "EarlyStopping counter: 119 out of 600\n",
      "tensor(5.2271, grad_fn=<MeanBackward0>)\n",
      "[ 736/1500] train_loss: 265.87003 valid_loss: 63.20006\n",
      "EarlyStopping counter: 120 out of 600\n",
      "tensor(3.6226, grad_fn=<MeanBackward0>)\n",
      "[ 737/1500] train_loss: 22.28420 valid_loss: 70.03971\n",
      "EarlyStopping counter: 121 out of 600\n",
      "tensor(3.0243, grad_fn=<MeanBackward0>)\n",
      "[ 738/1500] train_loss: 28.83960 valid_loss: 120.67382\n",
      "EarlyStopping counter: 122 out of 600\n",
      "tensor(5.0357, grad_fn=<MeanBackward0>)\n",
      "[ 739/1500] train_loss: 46.73935 valid_loss: 35.43832\n",
      "EarlyStopping counter: 123 out of 600\n",
      "tensor(4.7430, grad_fn=<MeanBackward0>)\n",
      "[ 740/1500] train_loss: 40.37201 valid_loss: 55.46985\n",
      "EarlyStopping counter: 124 out of 600\n",
      "tensor(3.1141, grad_fn=<MeanBackward0>)\n",
      "[ 741/1500] train_loss: 40.76775 valid_loss: 42.97322\n",
      "EarlyStopping counter: 125 out of 600\n",
      "tensor(5.1098, grad_fn=<MeanBackward0>)\n",
      "[ 742/1500] train_loss: 122.05272 valid_loss: 73.70927\n",
      "EarlyStopping counter: 126 out of 600\n",
      "tensor(5.3619, grad_fn=<MeanBackward0>)\n",
      "[ 743/1500] train_loss: 150.95031 valid_loss: 105.57778\n",
      "EarlyStopping counter: 127 out of 600\n",
      "tensor(2.9574, grad_fn=<MeanBackward0>)\n",
      "[ 744/1500] train_loss: 49.96376 valid_loss: 25.10410\n",
      "EarlyStopping counter: 128 out of 600\n",
      "tensor(4.7836, grad_fn=<MeanBackward0>)\n",
      "[ 745/1500] train_loss: 67.57464 valid_loss: 143.19134\n",
      "EarlyStopping counter: 129 out of 600\n",
      "tensor(4.5148, grad_fn=<MeanBackward0>)\n",
      "[ 746/1500] train_loss: 138.46595 valid_loss: 41.11340\n",
      "EarlyStopping counter: 130 out of 600\n",
      "tensor(3.1964, grad_fn=<MeanBackward0>)\n",
      "[ 747/1500] train_loss: 16.66141 valid_loss: 49.31274\n",
      "EarlyStopping counter: 131 out of 600\n",
      "tensor(3.1486, grad_fn=<MeanBackward0>)\n",
      "[ 748/1500] train_loss: 40.83721 valid_loss: 103.99963\n",
      "EarlyStopping counter: 132 out of 600\n",
      "tensor(4.7534, grad_fn=<MeanBackward0>)\n",
      "[ 749/1500] train_loss: 60.07134 valid_loss: 64.57463\n",
      "EarlyStopping counter: 133 out of 600\n",
      "tensor(3.5122, grad_fn=<MeanBackward0>)\n",
      "[ 750/1500] train_loss: 27.36651 valid_loss: 136.98682\n",
      "EarlyStopping counter: 134 out of 600\n",
      "tensor(3.2083, grad_fn=<MeanBackward0>)\n",
      "[ 751/1500] train_loss: 92.14624 valid_loss: 78.48396\n",
      "EarlyStopping counter: 135 out of 600\n",
      "tensor(6.1310, grad_fn=<MeanBackward0>)\n",
      "[ 752/1500] train_loss: 101.21820 valid_loss: 77.83936\n",
      "EarlyStopping counter: 136 out of 600\n",
      "tensor(4.3157, grad_fn=<MeanBackward0>)\n",
      "[ 753/1500] train_loss: 38.03584 valid_loss: 54.05660\n",
      "EarlyStopping counter: 137 out of 600\n",
      "tensor(5.8295, grad_fn=<MeanBackward0>)\n",
      "[ 754/1500] train_loss: 139.48854 valid_loss: 43.86529\n",
      "EarlyStopping counter: 138 out of 600\n",
      "tensor(4.3224, grad_fn=<MeanBackward0>)\n",
      "[ 755/1500] train_loss: 24.69467 valid_loss: 39.76627\n",
      "EarlyStopping counter: 139 out of 600\n",
      "tensor(5.7985, grad_fn=<MeanBackward0>)\n",
      "[ 756/1500] train_loss: 47.51902 valid_loss: 47.82761\n",
      "EarlyStopping counter: 140 out of 600\n",
      "tensor(4.0900, grad_fn=<MeanBackward0>)\n",
      "[ 757/1500] train_loss: 36.42959 valid_loss: 44.74681\n",
      "EarlyStopping counter: 141 out of 600\n",
      "tensor(5.7236, grad_fn=<MeanBackward0>)\n",
      "[ 758/1500] train_loss: 123.34057 valid_loss: 21.56580\n",
      "EarlyStopping counter: 142 out of 600\n",
      "tensor(5.9413, grad_fn=<MeanBackward0>)\n",
      "[ 759/1500] train_loss: 120.20311 valid_loss: 86.31281\n",
      "EarlyStopping counter: 143 out of 600\n",
      "tensor(5.3254, grad_fn=<MeanBackward0>)\n",
      "[ 760/1500] train_loss: 94.77433 valid_loss: 76.29947\n",
      "EarlyStopping counter: 144 out of 600\n",
      "tensor(6.2207, grad_fn=<MeanBackward0>)\n",
      "[ 761/1500] train_loss: 132.51197 valid_loss: 14.51397\n",
      "Validation loss decreased (16.264876 --> 14.513970).  Saving model ...\n",
      "tensor(4.5069, grad_fn=<MeanBackward0>)\n",
      "[ 762/1500] train_loss: 31.75210 valid_loss: 33.97647\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(4.4365, grad_fn=<MeanBackward0>)\n",
      "[ 763/1500] train_loss: 52.23430 valid_loss: 39.51132\n",
      "EarlyStopping counter: 2 out of 600\n",
      "tensor(2.7184, grad_fn=<MeanBackward0>)\n",
      "[ 764/1500] train_loss: 263.74099 valid_loss: 83.87728\n",
      "EarlyStopping counter: 3 out of 600\n",
      "tensor(4.1609, grad_fn=<MeanBackward0>)\n",
      "[ 765/1500] train_loss: 44.28384 valid_loss: 23.98467\n",
      "EarlyStopping counter: 4 out of 600\n",
      "tensor(3.0915, grad_fn=<MeanBackward0>)\n",
      "[ 766/1500] train_loss: 42.97570 valid_loss: 286.02958\n",
      "EarlyStopping counter: 5 out of 600\n",
      "tensor(4.0322, grad_fn=<MeanBackward0>)\n",
      "[ 767/1500] train_loss: 72.05789 valid_loss: 205.12616\n",
      "EarlyStopping counter: 6 out of 600\n",
      "tensor(3.8427, grad_fn=<MeanBackward0>)\n",
      "[ 768/1500] train_loss: 46.13102 valid_loss: 96.44928\n",
      "EarlyStopping counter: 7 out of 600\n",
      "tensor(4.7427, grad_fn=<MeanBackward0>)\n",
      "[ 769/1500] train_loss: 60.53049 valid_loss: 288.25895\n",
      "EarlyStopping counter: 8 out of 600\n",
      "tensor(3.6089, grad_fn=<MeanBackward0>)\n",
      "[ 770/1500] train_loss: 103.26315 valid_loss: 20.21197\n",
      "EarlyStopping counter: 9 out of 600\n",
      "tensor(4.2518, grad_fn=<MeanBackward0>)\n",
      "[ 771/1500] train_loss: 118.34114 valid_loss: 462.97230\n",
      "EarlyStopping counter: 10 out of 600\n",
      "tensor(3.3813, grad_fn=<MeanBackward0>)\n",
      "[ 772/1500] train_loss: 41.22893 valid_loss: 136.57985\n",
      "EarlyStopping counter: 11 out of 600\n",
      "tensor(4.6162, grad_fn=<MeanBackward0>)\n",
      "[ 773/1500] train_loss: 54.71143 valid_loss: 27.94623\n",
      "EarlyStopping counter: 12 out of 600\n",
      "tensor(5.0564, grad_fn=<MeanBackward0>)\n",
      "[ 774/1500] train_loss: 51.88199 valid_loss: 45.85762\n",
      "EarlyStopping counter: 13 out of 600\n",
      "tensor(4.5779, grad_fn=<MeanBackward0>)\n",
      "[ 775/1500] train_loss: 29.38015 valid_loss: 38.99468\n",
      "EarlyStopping counter: 14 out of 600\n",
      "tensor(5.9576, grad_fn=<MeanBackward0>)\n",
      "[ 776/1500] train_loss: 61.02781 valid_loss: 28.89298\n",
      "EarlyStopping counter: 15 out of 600\n",
      "tensor(3.9937, grad_fn=<MeanBackward0>)\n",
      "[ 777/1500] train_loss: 50.55286 valid_loss: 39.08688\n",
      "EarlyStopping counter: 16 out of 600\n",
      "tensor(5.6590, grad_fn=<MeanBackward0>)\n",
      "[ 778/1500] train_loss: 49.43164 valid_loss: 44.15826\n",
      "EarlyStopping counter: 17 out of 600\n",
      "tensor(3.8680, grad_fn=<MeanBackward0>)\n",
      "[ 779/1500] train_loss: 56.08662 valid_loss: 92.02391\n",
      "EarlyStopping counter: 18 out of 600\n",
      "tensor(3.3439, grad_fn=<MeanBackward0>)\n",
      "[ 780/1500] train_loss: 21.61428 valid_loss: 41.10728\n",
      "EarlyStopping counter: 19 out of 600\n",
      "tensor(5.8065, grad_fn=<MeanBackward0>)\n",
      "[ 781/1500] train_loss: 111.82252 valid_loss: 42.13485\n",
      "EarlyStopping counter: 20 out of 600\n",
      "tensor(3.4817, grad_fn=<MeanBackward0>)\n",
      "[ 782/1500] train_loss: 51.40311 valid_loss: 35.74962\n",
      "EarlyStopping counter: 21 out of 600\n",
      "tensor(4.9544, grad_fn=<MeanBackward0>)\n",
      "[ 783/1500] train_loss: 77.83822 valid_loss: 63.44662\n",
      "EarlyStopping counter: 22 out of 600\n",
      "tensor(4.2811, grad_fn=<MeanBackward0>)\n",
      "[ 784/1500] train_loss: 65.77392 valid_loss: 23.03132\n",
      "EarlyStopping counter: 23 out of 600\n",
      "tensor(5.4631, grad_fn=<MeanBackward0>)\n",
      "[ 785/1500] train_loss: 101.40554 valid_loss: 75.14122\n",
      "EarlyStopping counter: 24 out of 600\n",
      "tensor(4.1056, grad_fn=<MeanBackward0>)\n",
      "[ 786/1500] train_loss: 125.40253 valid_loss: 48.25378\n",
      "EarlyStopping counter: 25 out of 600\n",
      "tensor(3.3750, grad_fn=<MeanBackward0>)\n",
      "[ 787/1500] train_loss: 33.27674 valid_loss: 23.67555\n",
      "EarlyStopping counter: 26 out of 600\n",
      "tensor(3.2766, grad_fn=<MeanBackward0>)\n",
      "[ 788/1500] train_loss: 37.14087 valid_loss: 14.07791\n",
      "Validation loss decreased (14.513970 --> 14.077909).  Saving model ...\n",
      "tensor(4.7634, grad_fn=<MeanBackward0>)\n",
      "[ 789/1500] train_loss: 67.87335 valid_loss: 14.29688\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(4.0557, grad_fn=<MeanBackward0>)\n",
      "[ 790/1500] train_loss: 31.03112 valid_loss: 117.41065\n",
      "EarlyStopping counter: 2 out of 600\n",
      "tensor(5.1315, grad_fn=<MeanBackward0>)\n",
      "[ 791/1500] train_loss: 106.27365 valid_loss: 53.05859\n",
      "EarlyStopping counter: 3 out of 600\n",
      "tensor(5.8791, grad_fn=<MeanBackward0>)\n",
      "[ 792/1500] train_loss: 121.48454 valid_loss: 11.01887\n",
      "Validation loss decreased (14.077909 --> 11.018870).  Saving model ...\n",
      "tensor(4.0141, grad_fn=<MeanBackward0>)\n",
      "[ 793/1500] train_loss: 35.64014 valid_loss: 54.98158\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(4.3860, grad_fn=<MeanBackward0>)\n",
      "[ 794/1500] train_loss: 154.62773 valid_loss: 112.99670\n",
      "EarlyStopping counter: 2 out of 600\n",
      "tensor(3.5405, grad_fn=<MeanBackward0>)\n",
      "[ 795/1500] train_loss: 63.04443 valid_loss: 122.10264\n",
      "EarlyStopping counter: 3 out of 600\n",
      "tensor(5.7608, grad_fn=<MeanBackward0>)\n",
      "[ 796/1500] train_loss: 170.28690 valid_loss: 51.99007\n",
      "EarlyStopping counter: 4 out of 600\n",
      "tensor(2.7923, grad_fn=<MeanBackward0>)\n",
      "[ 797/1500] train_loss: 178.87505 valid_loss: 32.87453\n",
      "EarlyStopping counter: 5 out of 600\n",
      "tensor(4.0910, grad_fn=<MeanBackward0>)\n",
      "[ 798/1500] train_loss: 44.53159 valid_loss: 84.08230\n",
      "EarlyStopping counter: 6 out of 600\n",
      "tensor(3.4535, grad_fn=<MeanBackward0>)\n",
      "[ 799/1500] train_loss: 44.17437 valid_loss: 29.80988\n",
      "EarlyStopping counter: 7 out of 600\n",
      "tensor(4.6286, grad_fn=<MeanBackward0>)\n",
      "[ 800/1500] train_loss: 47.86452 valid_loss: 60.72838\n",
      "EarlyStopping counter: 8 out of 600\n",
      "tensor(6.7218, grad_fn=<MeanBackward0>)\n",
      "[ 801/1500] train_loss: 136.87647 valid_loss: 78.65110\n",
      "EarlyStopping counter: 9 out of 600\n",
      "tensor(4.7971, grad_fn=<MeanBackward0>)\n",
      "[ 802/1500] train_loss: 57.39403 valid_loss: 39.23669\n",
      "EarlyStopping counter: 10 out of 600\n",
      "tensor(4.0256, grad_fn=<MeanBackward0>)\n",
      "[ 803/1500] train_loss: 80.59280 valid_loss: 64.74391\n",
      "EarlyStopping counter: 11 out of 600\n",
      "tensor(5.1497, grad_fn=<MeanBackward0>)\n",
      "[ 804/1500] train_loss: 219.39548 valid_loss: 83.49842\n",
      "EarlyStopping counter: 12 out of 600\n",
      "tensor(3.7735, grad_fn=<MeanBackward0>)\n",
      "[ 805/1500] train_loss: 49.64071 valid_loss: 79.54297\n",
      "EarlyStopping counter: 13 out of 600\n",
      "tensor(3.3521, grad_fn=<MeanBackward0>)\n",
      "[ 806/1500] train_loss: 32.99595 valid_loss: 82.80674\n",
      "EarlyStopping counter: 14 out of 600\n",
      "tensor(5.5116, grad_fn=<MeanBackward0>)\n",
      "[ 807/1500] train_loss: 70.47000 valid_loss: 66.08463\n",
      "EarlyStopping counter: 15 out of 600\n",
      "tensor(6.1295, grad_fn=<MeanBackward0>)\n",
      "[ 808/1500] train_loss: 91.32645 valid_loss: 49.81917\n",
      "EarlyStopping counter: 16 out of 600\n",
      "tensor(3.3743, grad_fn=<MeanBackward0>)\n",
      "[ 809/1500] train_loss: 22.29337 valid_loss: 25.46057\n",
      "EarlyStopping counter: 17 out of 600\n",
      "tensor(6.5271, grad_fn=<MeanBackward0>)\n",
      "[ 810/1500] train_loss: 67.11716 valid_loss: 32.79915\n",
      "EarlyStopping counter: 18 out of 600\n",
      "tensor(5.2649, grad_fn=<MeanBackward0>)\n",
      "[ 811/1500] train_loss: 111.65924 valid_loss: 80.57325\n",
      "EarlyStopping counter: 19 out of 600\n",
      "tensor(3.8087, grad_fn=<MeanBackward0>)\n",
      "[ 812/1500] train_loss: 53.82348 valid_loss: 44.14327\n",
      "EarlyStopping counter: 20 out of 600\n",
      "tensor(6.5423, grad_fn=<MeanBackward0>)\n",
      "[ 813/1500] train_loss: 74.60334 valid_loss: 31.52191\n",
      "EarlyStopping counter: 21 out of 600\n",
      "tensor(5.3765, grad_fn=<MeanBackward0>)\n",
      "[ 814/1500] train_loss: 79.59740 valid_loss: 33.55858\n",
      "EarlyStopping counter: 22 out of 600\n",
      "tensor(3.5276, grad_fn=<MeanBackward0>)\n",
      "[ 815/1500] train_loss: 17.00001 valid_loss: 72.75101\n",
      "EarlyStopping counter: 23 out of 600\n",
      "tensor(5.5299, grad_fn=<MeanBackward0>)\n",
      "[ 816/1500] train_loss: 60.46209 valid_loss: 106.73258\n",
      "EarlyStopping counter: 24 out of 600\n",
      "tensor(4.6977, grad_fn=<MeanBackward0>)\n",
      "[ 817/1500] train_loss: 25.00294 valid_loss: 36.25487\n",
      "EarlyStopping counter: 25 out of 600\n",
      "tensor(5.1274, grad_fn=<MeanBackward0>)\n",
      "[ 818/1500] train_loss: 67.72536 valid_loss: 26.35864\n",
      "EarlyStopping counter: 26 out of 600\n",
      "tensor(4.7226, grad_fn=<MeanBackward0>)\n",
      "[ 819/1500] train_loss: 106.22033 valid_loss: 10.95751\n",
      "Validation loss decreased (11.018870 --> 10.957507).  Saving model ...\n",
      "tensor(4.6062, grad_fn=<MeanBackward0>)\n",
      "[ 820/1500] train_loss: 41.08519 valid_loss: 83.52381\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(4.9531, grad_fn=<MeanBackward0>)\n",
      "[ 821/1500] train_loss: 199.98985 valid_loss: 33.85326\n",
      "EarlyStopping counter: 2 out of 600\n",
      "tensor(4.1188, grad_fn=<MeanBackward0>)\n",
      "[ 822/1500] train_loss: 14.76739 valid_loss: 53.09293\n",
      "EarlyStopping counter: 3 out of 600\n",
      "tensor(3.6990, grad_fn=<MeanBackward0>)\n",
      "[ 823/1500] train_loss: 29.78403 valid_loss: 56.76063\n",
      "EarlyStopping counter: 4 out of 600\n",
      "tensor(4.1393, grad_fn=<MeanBackward0>)\n",
      "[ 824/1500] train_loss: 44.81483 valid_loss: 35.15959\n",
      "EarlyStopping counter: 5 out of 600\n",
      "tensor(3.9752, grad_fn=<MeanBackward0>)\n",
      "[ 825/1500] train_loss: 40.04938 valid_loss: 78.43885\n",
      "EarlyStopping counter: 6 out of 600\n",
      "tensor(3.5291, grad_fn=<MeanBackward0>)\n",
      "[ 826/1500] train_loss: 31.82810 valid_loss: 42.69612\n",
      "EarlyStopping counter: 7 out of 600\n",
      "tensor(4.0201, grad_fn=<MeanBackward0>)\n",
      "[ 827/1500] train_loss: 37.78099 valid_loss: 88.60357\n",
      "EarlyStopping counter: 8 out of 600\n",
      "tensor(6.4426, grad_fn=<MeanBackward0>)\n",
      "[ 828/1500] train_loss: 74.00775 valid_loss: 79.68632\n",
      "EarlyStopping counter: 9 out of 600\n",
      "tensor(4.0806, grad_fn=<MeanBackward0>)\n",
      "[ 829/1500] train_loss: 16.49941 valid_loss: 11.65005\n",
      "EarlyStopping counter: 10 out of 600\n",
      "tensor(5.1677, grad_fn=<MeanBackward0>)\n",
      "[ 830/1500] train_loss: 91.00040 valid_loss: 31.74344\n",
      "EarlyStopping counter: 11 out of 600\n",
      "tensor(5.7614, grad_fn=<MeanBackward0>)\n",
      "[ 831/1500] train_loss: 61.97177 valid_loss: 26.72664\n",
      "EarlyStopping counter: 12 out of 600\n",
      "tensor(2.9002, grad_fn=<MeanBackward0>)\n",
      "[ 832/1500] train_loss: 31.10973 valid_loss: 240.39335\n",
      "EarlyStopping counter: 13 out of 600\n",
      "tensor(4.7631, grad_fn=<MeanBackward0>)\n",
      "[ 833/1500] train_loss: 72.69016 valid_loss: 20.26754\n",
      "EarlyStopping counter: 14 out of 600\n",
      "tensor(3.4814, grad_fn=<MeanBackward0>)\n",
      "[ 834/1500] train_loss: 41.15045 valid_loss: 206.84855\n",
      "EarlyStopping counter: 15 out of 600\n",
      "tensor(4.6469, grad_fn=<MeanBackward0>)\n",
      "[ 835/1500] train_loss: 102.45208 valid_loss: 30.09143\n",
      "EarlyStopping counter: 16 out of 600\n",
      "tensor(4.6319, grad_fn=<MeanBackward0>)\n",
      "[ 836/1500] train_loss: 140.22036 valid_loss: 135.93329\n",
      "EarlyStopping counter: 17 out of 600\n",
      "tensor(5.3787, grad_fn=<MeanBackward0>)\n",
      "[ 837/1500] train_loss: 93.79629 valid_loss: 31.57717\n",
      "EarlyStopping counter: 18 out of 600\n",
      "tensor(3.2116, grad_fn=<MeanBackward0>)\n",
      "[ 838/1500] train_loss: 22.98897 valid_loss: 152.68656\n",
      "EarlyStopping counter: 19 out of 600\n",
      "tensor(4.3613, grad_fn=<MeanBackward0>)\n",
      "[ 839/1500] train_loss: 23.33180 valid_loss: 79.71982\n",
      "EarlyStopping counter: 20 out of 600\n",
      "tensor(6.0964, grad_fn=<MeanBackward0>)\n",
      "[ 840/1500] train_loss: 148.73218 valid_loss: 165.29916\n",
      "EarlyStopping counter: 21 out of 600\n",
      "tensor(3.6018, grad_fn=<MeanBackward0>)\n",
      "[ 841/1500] train_loss: 13.82524 valid_loss: 69.42818\n",
      "EarlyStopping counter: 22 out of 600\n",
      "tensor(5.6455, grad_fn=<MeanBackward0>)\n",
      "[ 842/1500] train_loss: 90.82779 valid_loss: 91.92016\n",
      "EarlyStopping counter: 23 out of 600\n",
      "tensor(3.3004, grad_fn=<MeanBackward0>)\n",
      "[ 843/1500] train_loss: 152.80669 valid_loss: 45.46141\n",
      "EarlyStopping counter: 24 out of 600\n",
      "tensor(3.0510, grad_fn=<MeanBackward0>)\n",
      "[ 844/1500] train_loss: 26.06255 valid_loss: 109.21859\n",
      "EarlyStopping counter: 25 out of 600\n",
      "tensor(4.5332, grad_fn=<MeanBackward0>)\n",
      "[ 845/1500] train_loss: 126.10794 valid_loss: 172.70941\n",
      "EarlyStopping counter: 26 out of 600\n",
      "tensor(3.7652, grad_fn=<MeanBackward0>)\n",
      "[ 846/1500] train_loss: 20.36272 valid_loss: 223.08988\n",
      "EarlyStopping counter: 27 out of 600\n",
      "tensor(4.7397, grad_fn=<MeanBackward0>)\n",
      "[ 847/1500] train_loss: 65.64702 valid_loss: 76.33058\n",
      "EarlyStopping counter: 28 out of 600\n",
      "tensor(3.4927, grad_fn=<MeanBackward0>)\n",
      "[ 848/1500] train_loss: 56.26250 valid_loss: 29.20156\n",
      "EarlyStopping counter: 29 out of 600\n",
      "tensor(6.1466, grad_fn=<MeanBackward0>)\n",
      "[ 849/1500] train_loss: 217.32678 valid_loss: 93.03886\n",
      "EarlyStopping counter: 30 out of 600\n",
      "tensor(4.8978, grad_fn=<MeanBackward0>)\n",
      "[ 850/1500] train_loss: 60.37395 valid_loss: 85.58053\n",
      "EarlyStopping counter: 31 out of 600\n",
      "tensor(3.7059, grad_fn=<MeanBackward0>)\n",
      "[ 851/1500] train_loss: 102.94902 valid_loss: 82.74773\n",
      "EarlyStopping counter: 32 out of 600\n",
      "tensor(5.1590, grad_fn=<MeanBackward0>)\n",
      "[ 852/1500] train_loss: 76.70616 valid_loss: 75.90604\n",
      "EarlyStopping counter: 33 out of 600\n",
      "tensor(3.8458, grad_fn=<MeanBackward0>)\n",
      "[ 853/1500] train_loss: 57.61691 valid_loss: 21.29385\n",
      "EarlyStopping counter: 34 out of 600\n",
      "tensor(3.5053, grad_fn=<MeanBackward0>)\n",
      "[ 854/1500] train_loss: 96.01269 valid_loss: 30.03814\n",
      "EarlyStopping counter: 35 out of 600\n",
      "tensor(3.1535, grad_fn=<MeanBackward0>)\n",
      "[ 855/1500] train_loss: 16.53632 valid_loss: 30.92231\n",
      "EarlyStopping counter: 36 out of 600\n",
      "tensor(3.1480, grad_fn=<MeanBackward0>)\n",
      "[ 856/1500] train_loss: 187.72445 valid_loss: 59.68951\n",
      "EarlyStopping counter: 37 out of 600\n",
      "tensor(3.0960, grad_fn=<MeanBackward0>)\n",
      "[ 857/1500] train_loss: 45.16602 valid_loss: 100.14534\n",
      "EarlyStopping counter: 38 out of 600\n",
      "tensor(4.9919, grad_fn=<MeanBackward0>)\n",
      "[ 858/1500] train_loss: 71.29200 valid_loss: 48.95834\n",
      "EarlyStopping counter: 39 out of 600\n",
      "tensor(3.8413, grad_fn=<MeanBackward0>)\n",
      "[ 859/1500] train_loss: 66.90938 valid_loss: 100.55704\n",
      "EarlyStopping counter: 40 out of 600\n",
      "tensor(3.1773, grad_fn=<MeanBackward0>)\n",
      "[ 860/1500] train_loss: 42.33203 valid_loss: 108.33742\n",
      "EarlyStopping counter: 41 out of 600\n",
      "tensor(3.1510, grad_fn=<MeanBackward0>)\n",
      "[ 861/1500] train_loss: 136.63328 valid_loss: 33.23134\n",
      "EarlyStopping counter: 42 out of 600\n",
      "tensor(3.7336, grad_fn=<MeanBackward0>)\n",
      "[ 862/1500] train_loss: 129.73329 valid_loss: 185.58219\n",
      "EarlyStopping counter: 43 out of 600\n",
      "tensor(3.3462, grad_fn=<MeanBackward0>)\n",
      "[ 863/1500] train_loss: 40.18173 valid_loss: 49.33585\n",
      "EarlyStopping counter: 44 out of 600\n",
      "tensor(4.7394, grad_fn=<MeanBackward0>)\n",
      "[ 864/1500] train_loss: 135.16305 valid_loss: 67.20818\n",
      "EarlyStopping counter: 45 out of 600\n",
      "tensor(5.1297, grad_fn=<MeanBackward0>)\n",
      "[ 865/1500] train_loss: 41.16666 valid_loss: 49.83012\n",
      "EarlyStopping counter: 46 out of 600\n",
      "tensor(5.7988, grad_fn=<MeanBackward0>)\n",
      "[ 866/1500] train_loss: 65.60967 valid_loss: 35.97825\n",
      "EarlyStopping counter: 47 out of 600\n",
      "tensor(3.9682, grad_fn=<MeanBackward0>)\n",
      "[ 867/1500] train_loss: 49.29626 valid_loss: 34.04915\n",
      "EarlyStopping counter: 48 out of 600\n",
      "tensor(4.1790, grad_fn=<MeanBackward0>)\n",
      "[ 868/1500] train_loss: 72.04342 valid_loss: 74.90203\n",
      "EarlyStopping counter: 49 out of 600\n",
      "tensor(5.2209, grad_fn=<MeanBackward0>)\n",
      "[ 869/1500] train_loss: 52.27332 valid_loss: 60.59751\n",
      "EarlyStopping counter: 50 out of 600\n",
      "tensor(5.0775, grad_fn=<MeanBackward0>)\n",
      "[ 870/1500] train_loss: 122.82790 valid_loss: 62.90323\n",
      "EarlyStopping counter: 51 out of 600\n",
      "tensor(4.2346, grad_fn=<MeanBackward0>)\n",
      "[ 871/1500] train_loss: 75.10831 valid_loss: 72.88306\n",
      "EarlyStopping counter: 52 out of 600\n",
      "tensor(4.3662, grad_fn=<MeanBackward0>)\n",
      "[ 872/1500] train_loss: 95.48270 valid_loss: 68.45654\n",
      "EarlyStopping counter: 53 out of 600\n",
      "tensor(3.5051, grad_fn=<MeanBackward0>)\n",
      "[ 873/1500] train_loss: 45.23088 valid_loss: 25.39013\n",
      "EarlyStopping counter: 54 out of 600\n",
      "tensor(3.5979, grad_fn=<MeanBackward0>)\n",
      "[ 874/1500] train_loss: 30.96118 valid_loss: 30.56152\n",
      "EarlyStopping counter: 55 out of 600\n",
      "tensor(4.7632, grad_fn=<MeanBackward0>)\n",
      "[ 875/1500] train_loss: 43.20185 valid_loss: 395.43922\n",
      "EarlyStopping counter: 56 out of 600\n",
      "tensor(5.7864, grad_fn=<MeanBackward0>)\n",
      "[ 876/1500] train_loss: 249.22314 valid_loss: 37.28411\n",
      "EarlyStopping counter: 57 out of 600\n",
      "tensor(3.8948, grad_fn=<MeanBackward0>)\n",
      "[ 877/1500] train_loss: 27.67245 valid_loss: 166.62138\n",
      "EarlyStopping counter: 58 out of 600\n",
      "tensor(4.6488, grad_fn=<MeanBackward0>)\n",
      "[ 878/1500] train_loss: 26.37045 valid_loss: 168.25472\n",
      "EarlyStopping counter: 59 out of 600\n",
      "tensor(6.2245, grad_fn=<MeanBackward0>)\n",
      "[ 879/1500] train_loss: 46.05990 valid_loss: 25.63235\n",
      "EarlyStopping counter: 60 out of 600\n",
      "tensor(3.4050, grad_fn=<MeanBackward0>)\n",
      "[ 880/1500] train_loss: 177.43807 valid_loss: 40.41858\n",
      "EarlyStopping counter: 61 out of 600\n",
      "tensor(5.3484, grad_fn=<MeanBackward0>)\n",
      "[ 881/1500] train_loss: 59.88680 valid_loss: 25.64085\n",
      "EarlyStopping counter: 62 out of 600\n",
      "tensor(3.5222, grad_fn=<MeanBackward0>)\n",
      "[ 882/1500] train_loss: 37.70501 valid_loss: 33.91800\n",
      "EarlyStopping counter: 63 out of 600\n",
      "tensor(3.3320, grad_fn=<MeanBackward0>)\n",
      "[ 883/1500] train_loss: 91.79863 valid_loss: 38.86464\n",
      "EarlyStopping counter: 64 out of 600\n",
      "tensor(5.2246, grad_fn=<MeanBackward0>)\n",
      "[ 884/1500] train_loss: 33.78488 valid_loss: 26.55226\n",
      "EarlyStopping counter: 65 out of 600\n",
      "tensor(3.3981, grad_fn=<MeanBackward0>)\n",
      "[ 885/1500] train_loss: 30.56393 valid_loss: 10.70839\n",
      "Validation loss decreased (10.957507 --> 10.708387).  Saving model ...\n",
      "tensor(4.7208, grad_fn=<MeanBackward0>)\n",
      "[ 886/1500] train_loss: 33.13582 valid_loss: 76.72633\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(3.5958, grad_fn=<MeanBackward0>)\n",
      "[ 887/1500] train_loss: 13.51432 valid_loss: 80.22947\n",
      "EarlyStopping counter: 2 out of 600\n",
      "tensor(5.0633, grad_fn=<MeanBackward0>)\n",
      "[ 888/1500] train_loss: 55.73534 valid_loss: 139.12522\n",
      "EarlyStopping counter: 3 out of 600\n",
      "tensor(3.6881, grad_fn=<MeanBackward0>)\n",
      "[ 889/1500] train_loss: 67.19918 valid_loss: 17.13493\n",
      "EarlyStopping counter: 4 out of 600\n",
      "tensor(4.8172, grad_fn=<MeanBackward0>)\n",
      "[ 890/1500] train_loss: 23.46592 valid_loss: 19.78325\n",
      "EarlyStopping counter: 5 out of 600\n",
      "tensor(5.2276, grad_fn=<MeanBackward0>)\n",
      "[ 891/1500] train_loss: 26.44625 valid_loss: 31.68404\n",
      "EarlyStopping counter: 6 out of 600\n",
      "tensor(5.3181, grad_fn=<MeanBackward0>)\n",
      "[ 892/1500] train_loss: 62.67910 valid_loss: 86.97994\n",
      "EarlyStopping counter: 7 out of 600\n",
      "tensor(5.1003, grad_fn=<MeanBackward0>)\n",
      "[ 893/1500] train_loss: 201.78504 valid_loss: 12.25035\n",
      "EarlyStopping counter: 8 out of 600\n",
      "tensor(3.2273, grad_fn=<MeanBackward0>)\n",
      "[ 894/1500] train_loss: 29.35328 valid_loss: 45.63505\n",
      "EarlyStopping counter: 9 out of 600\n",
      "tensor(4.6983, grad_fn=<MeanBackward0>)\n",
      "[ 895/1500] train_loss: 21.66765 valid_loss: 99.93998\n",
      "EarlyStopping counter: 10 out of 600\n",
      "tensor(6.1996, grad_fn=<MeanBackward0>)\n",
      "[ 896/1500] train_loss: 93.24160 valid_loss: 42.30282\n",
      "EarlyStopping counter: 11 out of 600\n",
      "tensor(4.3549, grad_fn=<MeanBackward0>)\n",
      "[ 897/1500] train_loss: 53.17377 valid_loss: 58.22581\n",
      "EarlyStopping counter: 12 out of 600\n",
      "tensor(5.8372, grad_fn=<MeanBackward0>)\n",
      "[ 898/1500] train_loss: 90.31169 valid_loss: 110.48061\n",
      "EarlyStopping counter: 13 out of 600\n",
      "tensor(3.6784, grad_fn=<MeanBackward0>)\n",
      "[ 899/1500] train_loss: 76.13101 valid_loss: 63.21553\n",
      "EarlyStopping counter: 14 out of 600\n",
      "tensor(6.1516, grad_fn=<MeanBackward0>)\n",
      "[ 900/1500] train_loss: 102.62786 valid_loss: 18.17799\n",
      "EarlyStopping counter: 15 out of 600\n",
      "tensor(5.6814, grad_fn=<MeanBackward0>)\n",
      "[ 901/1500] train_loss: 61.75791 valid_loss: 63.70621\n",
      "EarlyStopping counter: 16 out of 600\n",
      "tensor(4.8446, grad_fn=<MeanBackward0>)\n",
      "[ 902/1500] train_loss: 49.67998 valid_loss: 10.03581\n",
      "Validation loss decreased (10.708387 --> 10.035813).  Saving model ...\n",
      "tensor(3.4110, grad_fn=<MeanBackward0>)\n",
      "[ 903/1500] train_loss: 58.79475 valid_loss: 33.36588\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(4.8156, grad_fn=<MeanBackward0>)\n",
      "[ 904/1500] train_loss: 35.09130 valid_loss: 69.92846\n",
      "EarlyStopping counter: 2 out of 600\n",
      "tensor(4.1521, grad_fn=<MeanBackward0>)\n",
      "[ 905/1500] train_loss: 33.45303 valid_loss: 33.34987\n",
      "EarlyStopping counter: 3 out of 600\n",
      "tensor(3.0460, grad_fn=<MeanBackward0>)\n",
      "[ 906/1500] train_loss: 17.30186 valid_loss: 28.38242\n",
      "EarlyStopping counter: 4 out of 600\n",
      "tensor(4.5304, grad_fn=<MeanBackward0>)\n",
      "[ 907/1500] train_loss: 116.31265 valid_loss: 81.95369\n",
      "EarlyStopping counter: 5 out of 600\n",
      "tensor(3.6435, grad_fn=<MeanBackward0>)\n",
      "[ 908/1500] train_loss: 48.27030 valid_loss: 166.14343\n",
      "EarlyStopping counter: 6 out of 600\n",
      "tensor(3.2455, grad_fn=<MeanBackward0>)\n",
      "[ 909/1500] train_loss: 71.67771 valid_loss: 24.00704\n",
      "EarlyStopping counter: 7 out of 600\n",
      "tensor(3.1256, grad_fn=<MeanBackward0>)\n",
      "[ 910/1500] train_loss: 38.26966 valid_loss: 49.04769\n",
      "EarlyStopping counter: 8 out of 600\n",
      "tensor(5.2225, grad_fn=<MeanBackward0>)\n",
      "[ 911/1500] train_loss: 74.57760 valid_loss: 44.49987\n",
      "EarlyStopping counter: 9 out of 600\n",
      "tensor(3.6364, grad_fn=<MeanBackward0>)\n",
      "[ 912/1500] train_loss: 20.22773 valid_loss: 31.65503\n",
      "EarlyStopping counter: 10 out of 600\n",
      "tensor(3.2195, grad_fn=<MeanBackward0>)\n",
      "[ 913/1500] train_loss: 43.89920 valid_loss: 61.31735\n",
      "EarlyStopping counter: 11 out of 600\n",
      "tensor(5.7331, grad_fn=<MeanBackward0>)\n",
      "[ 914/1500] train_loss: 63.15934 valid_loss: 107.81089\n",
      "EarlyStopping counter: 12 out of 600\n",
      "tensor(5.5922, grad_fn=<MeanBackward0>)\n",
      "[ 915/1500] train_loss: 33.71971 valid_loss: 51.77322\n",
      "EarlyStopping counter: 13 out of 600\n",
      "tensor(3.1519, grad_fn=<MeanBackward0>)\n",
      "[ 916/1500] train_loss: 28.55122 valid_loss: 10.02836\n",
      "Validation loss decreased (10.035813 --> 10.028363).  Saving model ...\n",
      "tensor(3.4347, grad_fn=<MeanBackward0>)\n",
      "[ 917/1500] train_loss: 19.04262 valid_loss: 197.92125\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(4.5114, grad_fn=<MeanBackward0>)\n",
      "[ 918/1500] train_loss: 34.51594 valid_loss: 38.29804\n",
      "EarlyStopping counter: 2 out of 600\n",
      "tensor(6.7215, grad_fn=<MeanBackward0>)\n",
      "[ 919/1500] train_loss: 78.60325 valid_loss: 106.88525\n",
      "EarlyStopping counter: 3 out of 600\n",
      "tensor(3.9196, grad_fn=<MeanBackward0>)\n",
      "[ 920/1500] train_loss: 21.45588 valid_loss: 82.63251\n",
      "EarlyStopping counter: 4 out of 600\n",
      "tensor(5.4627, grad_fn=<MeanBackward0>)\n",
      "[ 921/1500] train_loss: 133.33414 valid_loss: 15.14283\n",
      "EarlyStopping counter: 5 out of 600\n",
      "tensor(5.2064, grad_fn=<MeanBackward0>)\n",
      "[ 922/1500] train_loss: 58.38873 valid_loss: 28.50662\n",
      "EarlyStopping counter: 6 out of 600\n",
      "tensor(3.4291, grad_fn=<MeanBackward0>)\n",
      "[ 923/1500] train_loss: 124.55744 valid_loss: 49.75950\n",
      "EarlyStopping counter: 7 out of 600\n",
      "tensor(6.6211, grad_fn=<MeanBackward0>)\n",
      "[ 924/1500] train_loss: 107.67451 valid_loss: 186.41957\n",
      "EarlyStopping counter: 8 out of 600\n",
      "tensor(5.5630, grad_fn=<MeanBackward0>)\n",
      "[ 925/1500] train_loss: 281.35802 valid_loss: 21.65735\n",
      "EarlyStopping counter: 9 out of 600\n",
      "tensor(5.4957, grad_fn=<MeanBackward0>)\n",
      "[ 926/1500] train_loss: 47.07474 valid_loss: 61.35315\n",
      "EarlyStopping counter: 10 out of 600\n",
      "tensor(5.2701, grad_fn=<MeanBackward0>)\n",
      "[ 927/1500] train_loss: 128.25380 valid_loss: 38.91635\n",
      "EarlyStopping counter: 11 out of 600\n",
      "tensor(3.2838, grad_fn=<MeanBackward0>)\n",
      "[ 928/1500] train_loss: 35.21514 valid_loss: 71.96296\n",
      "EarlyStopping counter: 12 out of 600\n",
      "tensor(5.8572, grad_fn=<MeanBackward0>)\n",
      "[ 929/1500] train_loss: 47.65362 valid_loss: 72.50656\n",
      "EarlyStopping counter: 13 out of 600\n",
      "tensor(4.5485, grad_fn=<MeanBackward0>)\n",
      "[ 930/1500] train_loss: 57.23764 valid_loss: 115.43790\n",
      "EarlyStopping counter: 14 out of 600\n",
      "tensor(5.9173, grad_fn=<MeanBackward0>)\n",
      "[ 931/1500] train_loss: 105.36214 valid_loss: 90.49049\n",
      "EarlyStopping counter: 15 out of 600\n",
      "tensor(4.1303, grad_fn=<MeanBackward0>)\n",
      "[ 932/1500] train_loss: 85.07699 valid_loss: 48.91997\n",
      "EarlyStopping counter: 16 out of 600\n",
      "tensor(4.0416, grad_fn=<MeanBackward0>)\n",
      "[ 933/1500] train_loss: 153.24356 valid_loss: 17.68916\n",
      "EarlyStopping counter: 17 out of 600\n",
      "tensor(3.5473, grad_fn=<MeanBackward0>)\n",
      "[ 934/1500] train_loss: 42.25559 valid_loss: 10.97332\n",
      "EarlyStopping counter: 18 out of 600\n",
      "tensor(6.3346, grad_fn=<MeanBackward0>)\n",
      "[ 935/1500] train_loss: 63.43241 valid_loss: 39.07598\n",
      "EarlyStopping counter: 19 out of 600\n",
      "tensor(3.5770, grad_fn=<MeanBackward0>)\n",
      "[ 936/1500] train_loss: 22.11386 valid_loss: 44.97366\n",
      "EarlyStopping counter: 20 out of 600\n",
      "tensor(4.0128, grad_fn=<MeanBackward0>)\n",
      "[ 937/1500] train_loss: 40.78639 valid_loss: 41.00297\n",
      "EarlyStopping counter: 21 out of 600\n",
      "tensor(6.3127, grad_fn=<MeanBackward0>)\n",
      "[ 938/1500] train_loss: 50.00842 valid_loss: 18.94135\n",
      "EarlyStopping counter: 22 out of 600\n",
      "tensor(5.8124, grad_fn=<MeanBackward0>)\n",
      "[ 939/1500] train_loss: 43.28833 valid_loss: 119.02497\n",
      "EarlyStopping counter: 23 out of 600\n",
      "tensor(4.0052, grad_fn=<MeanBackward0>)\n",
      "[ 940/1500] train_loss: 81.35749 valid_loss: 29.99318\n",
      "EarlyStopping counter: 24 out of 600\n",
      "tensor(4.3582, grad_fn=<MeanBackward0>)\n",
      "[ 941/1500] train_loss: 65.92092 valid_loss: 96.14064\n",
      "EarlyStopping counter: 25 out of 600\n",
      "tensor(6.8031, grad_fn=<MeanBackward0>)\n",
      "[ 942/1500] train_loss: 111.29910 valid_loss: 42.47524\n",
      "EarlyStopping counter: 26 out of 600\n",
      "tensor(6.1723, grad_fn=<MeanBackward0>)\n",
      "[ 943/1500] train_loss: 158.72091 valid_loss: 35.26795\n",
      "EarlyStopping counter: 27 out of 600\n",
      "tensor(4.1848, grad_fn=<MeanBackward0>)\n",
      "[ 944/1500] train_loss: 88.74187 valid_loss: 125.10787\n",
      "EarlyStopping counter: 28 out of 600\n",
      "tensor(5.3645, grad_fn=<MeanBackward0>)\n",
      "[ 945/1500] train_loss: 144.75735 valid_loss: 112.81311\n",
      "EarlyStopping counter: 29 out of 600\n",
      "tensor(4.4723, grad_fn=<MeanBackward0>)\n",
      "[ 946/1500] train_loss: 33.43526 valid_loss: 58.51280\n",
      "EarlyStopping counter: 30 out of 600\n",
      "tensor(3.2868, grad_fn=<MeanBackward0>)\n",
      "[ 947/1500] train_loss: 41.10916 valid_loss: 70.68508\n",
      "EarlyStopping counter: 31 out of 600\n",
      "tensor(4.1381, grad_fn=<MeanBackward0>)\n",
      "[ 948/1500] train_loss: 125.58183 valid_loss: 40.33555\n",
      "EarlyStopping counter: 32 out of 600\n",
      "tensor(5.6759, grad_fn=<MeanBackward0>)\n",
      "[ 949/1500] train_loss: 111.75284 valid_loss: 267.34989\n",
      "EarlyStopping counter: 33 out of 600\n",
      "tensor(6.5193, grad_fn=<MeanBackward0>)\n",
      "[ 950/1500] train_loss: 89.54441 valid_loss: 11.94690\n",
      "EarlyStopping counter: 34 out of 600\n",
      "tensor(4.6761, grad_fn=<MeanBackward0>)\n",
      "[ 951/1500] train_loss: 92.19922 valid_loss: 50.52686\n",
      "EarlyStopping counter: 35 out of 600\n",
      "tensor(5.0888, grad_fn=<MeanBackward0>)\n",
      "[ 952/1500] train_loss: 49.15106 valid_loss: 36.74289\n",
      "EarlyStopping counter: 36 out of 600\n",
      "tensor(4.4082, grad_fn=<MeanBackward0>)\n",
      "[ 953/1500] train_loss: 41.86669 valid_loss: 70.09527\n",
      "EarlyStopping counter: 37 out of 600\n",
      "tensor(6.7295, grad_fn=<MeanBackward0>)\n",
      "[ 954/1500] train_loss: 206.94101 valid_loss: 45.77562\n",
      "EarlyStopping counter: 38 out of 600\n",
      "tensor(5.8849, grad_fn=<MeanBackward0>)\n",
      "[ 955/1500] train_loss: 82.68232 valid_loss: 36.32818\n",
      "EarlyStopping counter: 39 out of 600\n",
      "tensor(3.2473, grad_fn=<MeanBackward0>)\n",
      "[ 956/1500] train_loss: 254.55794 valid_loss: 52.40793\n",
      "EarlyStopping counter: 40 out of 600\n",
      "tensor(5.3467, grad_fn=<MeanBackward0>)\n",
      "[ 957/1500] train_loss: 40.92768 valid_loss: 282.03916\n",
      "EarlyStopping counter: 41 out of 600\n",
      "tensor(3.6988, grad_fn=<MeanBackward0>)\n",
      "[ 958/1500] train_loss: 126.94734 valid_loss: 51.62509\n",
      "EarlyStopping counter: 42 out of 600\n",
      "tensor(5.6859, grad_fn=<MeanBackward0>)\n",
      "[ 959/1500] train_loss: 92.60060 valid_loss: 46.80477\n",
      "EarlyStopping counter: 43 out of 600\n",
      "tensor(4.4594, grad_fn=<MeanBackward0>)\n",
      "[ 960/1500] train_loss: 97.05619 valid_loss: 44.35792\n",
      "EarlyStopping counter: 44 out of 600\n",
      "tensor(4.0287, grad_fn=<MeanBackward0>)\n",
      "[ 961/1500] train_loss: 42.65884 valid_loss: 156.60420\n",
      "EarlyStopping counter: 45 out of 600\n",
      "tensor(4.7212, grad_fn=<MeanBackward0>)\n",
      "[ 962/1500] train_loss: 30.40790 valid_loss: 59.56763\n",
      "EarlyStopping counter: 46 out of 600\n",
      "tensor(3.0982, grad_fn=<MeanBackward0>)\n",
      "[ 963/1500] train_loss: 12.45011 valid_loss: 22.79772\n",
      "EarlyStopping counter: 47 out of 600\n",
      "tensor(3.6036, grad_fn=<MeanBackward0>)\n",
      "[ 964/1500] train_loss: 146.74150 valid_loss: 22.27236\n",
      "EarlyStopping counter: 48 out of 600\n",
      "tensor(4.3400, grad_fn=<MeanBackward0>)\n",
      "[ 965/1500] train_loss: 35.65918 valid_loss: 73.32239\n",
      "EarlyStopping counter: 49 out of 600\n",
      "tensor(3.7886, grad_fn=<MeanBackward0>)\n",
      "[ 966/1500] train_loss: 159.27904 valid_loss: 32.71774\n",
      "EarlyStopping counter: 50 out of 600\n",
      "tensor(3.1541, grad_fn=<MeanBackward0>)\n",
      "[ 967/1500] train_loss: 37.18785 valid_loss: 21.65892\n",
      "EarlyStopping counter: 51 out of 600\n",
      "tensor(4.0583, grad_fn=<MeanBackward0>)\n",
      "[ 968/1500] train_loss: 45.30982 valid_loss: 59.02891\n",
      "EarlyStopping counter: 52 out of 600\n",
      "tensor(5.9761, grad_fn=<MeanBackward0>)\n",
      "[ 969/1500] train_loss: 77.08806 valid_loss: 29.10448\n",
      "EarlyStopping counter: 53 out of 600\n",
      "tensor(4.0642, grad_fn=<MeanBackward0>)\n",
      "[ 970/1500] train_loss: 40.98866 valid_loss: 45.20850\n",
      "EarlyStopping counter: 54 out of 600\n",
      "tensor(4.5613, grad_fn=<MeanBackward0>)\n",
      "[ 971/1500] train_loss: 82.21961 valid_loss: 11.83978\n",
      "EarlyStopping counter: 55 out of 600\n",
      "tensor(3.4501, grad_fn=<MeanBackward0>)\n",
      "[ 972/1500] train_loss: 30.61263 valid_loss: 50.11034\n",
      "EarlyStopping counter: 56 out of 600\n",
      "tensor(4.0303, grad_fn=<MeanBackward0>)\n",
      "[ 973/1500] train_loss: 54.60274 valid_loss: 49.80966\n",
      "EarlyStopping counter: 57 out of 600\n",
      "tensor(3.2287, grad_fn=<MeanBackward0>)\n",
      "[ 974/1500] train_loss: 155.34297 valid_loss: 27.51133\n",
      "EarlyStopping counter: 58 out of 600\n",
      "tensor(4.7641, grad_fn=<MeanBackward0>)\n",
      "[ 975/1500] train_loss: 92.58215 valid_loss: 29.62425\n",
      "EarlyStopping counter: 59 out of 600\n",
      "tensor(3.2116, grad_fn=<MeanBackward0>)\n",
      "[ 976/1500] train_loss: 30.46092 valid_loss: 51.79602\n",
      "EarlyStopping counter: 60 out of 600\n",
      "tensor(4.4473, grad_fn=<MeanBackward0>)\n",
      "[ 977/1500] train_loss: 23.68195 valid_loss: 49.15817\n",
      "EarlyStopping counter: 61 out of 600\n",
      "tensor(5.3926, grad_fn=<MeanBackward0>)\n",
      "[ 978/1500] train_loss: 147.79376 valid_loss: 40.59733\n",
      "EarlyStopping counter: 62 out of 600\n",
      "tensor(4.3592, grad_fn=<MeanBackward0>)\n",
      "[ 979/1500] train_loss: 25.98086 valid_loss: 99.37423\n",
      "EarlyStopping counter: 63 out of 600\n",
      "tensor(3.7867, grad_fn=<MeanBackward0>)\n",
      "[ 980/1500] train_loss: 24.43435 valid_loss: 47.31702\n",
      "EarlyStopping counter: 64 out of 600\n",
      "tensor(3.7059, grad_fn=<MeanBackward0>)\n",
      "[ 981/1500] train_loss: 33.00417 valid_loss: 19.34698\n",
      "EarlyStopping counter: 65 out of 600\n",
      "tensor(5.2304, grad_fn=<MeanBackward0>)\n",
      "[ 982/1500] train_loss: 25.73343 valid_loss: 57.83834\n",
      "EarlyStopping counter: 66 out of 600\n",
      "tensor(5.4415, grad_fn=<MeanBackward0>)\n",
      "[ 983/1500] train_loss: 39.06640 valid_loss: 13.85881\n",
      "EarlyStopping counter: 67 out of 600\n",
      "tensor(5.7813, grad_fn=<MeanBackward0>)\n",
      "[ 984/1500] train_loss: 117.56793 valid_loss: 12.24140\n",
      "EarlyStopping counter: 68 out of 600\n",
      "tensor(4.3501, grad_fn=<MeanBackward0>)\n",
      "[ 985/1500] train_loss: 22.49523 valid_loss: 80.80411\n",
      "EarlyStopping counter: 69 out of 600\n",
      "tensor(5.1869, grad_fn=<MeanBackward0>)\n",
      "[ 986/1500] train_loss: 32.54328 valid_loss: 45.68146\n",
      "EarlyStopping counter: 70 out of 600\n",
      "tensor(3.9343, grad_fn=<MeanBackward0>)\n",
      "[ 987/1500] train_loss: 12.26123 valid_loss: 29.59643\n",
      "EarlyStopping counter: 71 out of 600\n",
      "tensor(5.4960, grad_fn=<MeanBackward0>)\n",
      "[ 988/1500] train_loss: 33.40865 valid_loss: 21.10467\n",
      "EarlyStopping counter: 72 out of 600\n",
      "tensor(3.7456, grad_fn=<MeanBackward0>)\n",
      "[ 989/1500] train_loss: 33.65757 valid_loss: 46.47964\n",
      "EarlyStopping counter: 73 out of 600\n",
      "tensor(6.5679, grad_fn=<MeanBackward0>)\n",
      "[ 990/1500] train_loss: 50.64042 valid_loss: 67.18618\n",
      "EarlyStopping counter: 74 out of 600\n",
      "tensor(5.7151, grad_fn=<MeanBackward0>)\n",
      "[ 991/1500] train_loss: 60.51574 valid_loss: 19.53182\n",
      "EarlyStopping counter: 75 out of 600\n",
      "tensor(3.5891, grad_fn=<MeanBackward0>)\n",
      "[ 992/1500] train_loss: 25.95308 valid_loss: 14.98256\n",
      "EarlyStopping counter: 76 out of 600\n",
      "tensor(3.1601, grad_fn=<MeanBackward0>)\n",
      "[ 993/1500] train_loss: 26.91023 valid_loss: 19.02020\n",
      "EarlyStopping counter: 77 out of 600\n",
      "tensor(3.6798, grad_fn=<MeanBackward0>)\n",
      "[ 994/1500] train_loss: 46.47649 valid_loss: 32.44936\n",
      "EarlyStopping counter: 78 out of 600\n",
      "tensor(3.8047, grad_fn=<MeanBackward0>)\n",
      "[ 995/1500] train_loss: 57.28302 valid_loss: 28.26678\n",
      "EarlyStopping counter: 79 out of 600\n",
      "tensor(4.3662, grad_fn=<MeanBackward0>)\n",
      "[ 996/1500] train_loss: 25.79792 valid_loss: 53.68482\n",
      "EarlyStopping counter: 80 out of 600\n",
      "tensor(5.9420, grad_fn=<MeanBackward0>)\n",
      "[ 997/1500] train_loss: 63.19273 valid_loss: 42.67935\n",
      "EarlyStopping counter: 81 out of 600\n",
      "tensor(4.3959, grad_fn=<MeanBackward0>)\n",
      "[ 998/1500] train_loss: 34.25196 valid_loss: 34.73984\n",
      "EarlyStopping counter: 82 out of 600\n",
      "tensor(3.3634, grad_fn=<MeanBackward0>)\n",
      "[ 999/1500] train_loss: 131.13305 valid_loss: 54.63002\n",
      "EarlyStopping counter: 83 out of 600\n",
      "tensor(4.4026, grad_fn=<MeanBackward0>)\n",
      "[1000/1500] train_loss: 49.41471 valid_loss: 23.68811\n",
      "EarlyStopping counter: 84 out of 600\n",
      "tensor(5.3000, grad_fn=<MeanBackward0>)\n",
      "[1001/1500] train_loss: 25.90211 valid_loss: 33.63346\n",
      "EarlyStopping counter: 85 out of 600\n",
      "tensor(4.4736, grad_fn=<MeanBackward0>)\n",
      "[1002/1500] train_loss: 25.34759 valid_loss: 18.77306\n",
      "EarlyStopping counter: 86 out of 600\n",
      "tensor(4.7251, grad_fn=<MeanBackward0>)\n",
      "[1003/1500] train_loss: 149.01115 valid_loss: 45.86418\n",
      "EarlyStopping counter: 87 out of 600\n",
      "tensor(5.1419, grad_fn=<MeanBackward0>)\n",
      "[1004/1500] train_loss: 34.29749 valid_loss: 54.01633\n",
      "EarlyStopping counter: 88 out of 600\n",
      "tensor(3.0554, grad_fn=<MeanBackward0>)\n",
      "[1005/1500] train_loss: 71.09483 valid_loss: 68.84401\n",
      "EarlyStopping counter: 89 out of 600\n",
      "tensor(4.7634, grad_fn=<MeanBackward0>)\n",
      "[1006/1500] train_loss: 76.41507 valid_loss: 57.82265\n",
      "EarlyStopping counter: 90 out of 600\n",
      "tensor(3.2798, grad_fn=<MeanBackward0>)\n",
      "[1007/1500] train_loss: 25.04849 valid_loss: 63.75816\n",
      "EarlyStopping counter: 91 out of 600\n",
      "tensor(5.8297, grad_fn=<MeanBackward0>)\n",
      "[1008/1500] train_loss: 53.80940 valid_loss: 31.40744\n",
      "EarlyStopping counter: 92 out of 600\n",
      "tensor(5.7980, grad_fn=<MeanBackward0>)\n",
      "[1009/1500] train_loss: 78.58402 valid_loss: 46.22229\n",
      "EarlyStopping counter: 93 out of 600\n",
      "tensor(5.6092, grad_fn=<MeanBackward0>)\n",
      "[1010/1500] train_loss: 46.20357 valid_loss: 40.01105\n",
      "EarlyStopping counter: 94 out of 600\n",
      "tensor(4.2031, grad_fn=<MeanBackward0>)\n",
      "[1011/1500] train_loss: 67.58492 valid_loss: 42.52413\n",
      "EarlyStopping counter: 95 out of 600\n",
      "tensor(5.6138, grad_fn=<MeanBackward0>)\n",
      "[1012/1500] train_loss: 46.04877 valid_loss: 30.51370\n",
      "EarlyStopping counter: 96 out of 600\n",
      "tensor(5.0960, grad_fn=<MeanBackward0>)\n",
      "[1013/1500] train_loss: 33.42282 valid_loss: 32.14739\n",
      "EarlyStopping counter: 97 out of 600\n",
      "tensor(4.6743, grad_fn=<MeanBackward0>)\n",
      "[1014/1500] train_loss: 42.02751 valid_loss: 10.20323\n",
      "EarlyStopping counter: 98 out of 600\n",
      "tensor(3.3748, grad_fn=<MeanBackward0>)\n",
      "[1015/1500] train_loss: 48.13067 valid_loss: 15.08947\n",
      "EarlyStopping counter: 99 out of 600\n",
      "tensor(3.4304, grad_fn=<MeanBackward0>)\n",
      "[1016/1500] train_loss: 41.59501 valid_loss: 46.89575\n",
      "EarlyStopping counter: 100 out of 600\n",
      "tensor(5.1832, grad_fn=<MeanBackward0>)\n",
      "[1017/1500] train_loss: 28.42277 valid_loss: 24.50985\n",
      "EarlyStopping counter: 101 out of 600\n",
      "tensor(4.6589, grad_fn=<MeanBackward0>)\n",
      "[1018/1500] train_loss: 24.05903 valid_loss: 43.72333\n",
      "EarlyStopping counter: 102 out of 600\n",
      "tensor(3.8924, grad_fn=<MeanBackward0>)\n",
      "[1019/1500] train_loss: 31.74409 valid_loss: 51.44963\n",
      "EarlyStopping counter: 103 out of 600\n",
      "tensor(3.1042, grad_fn=<MeanBackward0>)\n",
      "[1020/1500] train_loss: 45.11068 valid_loss: 44.43506\n",
      "EarlyStopping counter: 104 out of 600\n",
      "tensor(6.0002, grad_fn=<MeanBackward0>)\n",
      "[1021/1500] train_loss: 114.71221 valid_loss: 56.03752\n",
      "EarlyStopping counter: 105 out of 600\n",
      "tensor(6.0613, grad_fn=<MeanBackward0>)\n",
      "[1022/1500] train_loss: 56.63447 valid_loss: 23.39072\n",
      "EarlyStopping counter: 106 out of 600\n",
      "tensor(3.1941, grad_fn=<MeanBackward0>)\n",
      "[1023/1500] train_loss: 66.84801 valid_loss: 15.89391\n",
      "EarlyStopping counter: 107 out of 600\n",
      "tensor(4.5149, grad_fn=<MeanBackward0>)\n",
      "[1024/1500] train_loss: 18.06584 valid_loss: 20.66819\n",
      "EarlyStopping counter: 108 out of 600\n",
      "tensor(3.9420, grad_fn=<MeanBackward0>)\n",
      "[1025/1500] train_loss: 30.07659 valid_loss: 15.51249\n",
      "EarlyStopping counter: 109 out of 600\n",
      "tensor(6.1831, grad_fn=<MeanBackward0>)\n",
      "[1026/1500] train_loss: 126.66094 valid_loss: 32.24604\n",
      "EarlyStopping counter: 110 out of 600\n",
      "tensor(6.5302, grad_fn=<MeanBackward0>)\n",
      "[1027/1500] train_loss: 120.40197 valid_loss: 22.73576\n",
      "EarlyStopping counter: 111 out of 600\n",
      "tensor(4.6132, grad_fn=<MeanBackward0>)\n",
      "[1028/1500] train_loss: 24.27133 valid_loss: 23.85695\n",
      "EarlyStopping counter: 112 out of 600\n",
      "tensor(6.2285, grad_fn=<MeanBackward0>)\n",
      "[1029/1500] train_loss: 49.17742 valid_loss: 41.29672\n",
      "EarlyStopping counter: 113 out of 600\n",
      "tensor(4.0084, grad_fn=<MeanBackward0>)\n",
      "[1030/1500] train_loss: 21.54682 valid_loss: 23.70998\n",
      "EarlyStopping counter: 114 out of 600\n",
      "tensor(3.9662, grad_fn=<MeanBackward0>)\n",
      "[1031/1500] train_loss: 35.50888 valid_loss: 21.49892\n",
      "EarlyStopping counter: 115 out of 600\n",
      "tensor(5.4012, grad_fn=<MeanBackward0>)\n",
      "[1032/1500] train_loss: 74.74491 valid_loss: 44.17519\n",
      "EarlyStopping counter: 116 out of 600\n",
      "tensor(4.7221, grad_fn=<MeanBackward0>)\n",
      "[1033/1500] train_loss: 56.49891 valid_loss: 33.91819\n",
      "EarlyStopping counter: 117 out of 600\n",
      "tensor(5.4536, grad_fn=<MeanBackward0>)\n",
      "[1034/1500] train_loss: 98.74686 valid_loss: 42.17477\n",
      "EarlyStopping counter: 118 out of 600\n",
      "tensor(5.2270, grad_fn=<MeanBackward0>)\n",
      "[1035/1500] train_loss: 114.54770 valid_loss: 46.68273\n",
      "EarlyStopping counter: 119 out of 600\n",
      "tensor(3.7287, grad_fn=<MeanBackward0>)\n",
      "[1036/1500] train_loss: 68.31926 valid_loss: 43.60786\n",
      "EarlyStopping counter: 120 out of 600\n",
      "tensor(3.2306, grad_fn=<MeanBackward0>)\n",
      "[1037/1500] train_loss: 81.45394 valid_loss: 198.81802\n",
      "EarlyStopping counter: 121 out of 600\n",
      "tensor(4.0740, grad_fn=<MeanBackward0>)\n",
      "[1038/1500] train_loss: 38.36744 valid_loss: 102.68296\n",
      "EarlyStopping counter: 122 out of 600\n",
      "tensor(4.6058, grad_fn=<MeanBackward0>)\n",
      "[1039/1500] train_loss: 37.00336 valid_loss: 285.21000\n",
      "EarlyStopping counter: 123 out of 600\n",
      "tensor(2.9589, grad_fn=<MeanBackward0>)\n",
      "[1040/1500] train_loss: 28.91734 valid_loss: 160.85052\n",
      "EarlyStopping counter: 124 out of 600\n",
      "tensor(3.2447, grad_fn=<MeanBackward0>)\n",
      "[1041/1500] train_loss: 13.40615 valid_loss: 50.03166\n",
      "EarlyStopping counter: 125 out of 600\n",
      "tensor(3.2028, grad_fn=<MeanBackward0>)\n",
      "[1042/1500] train_loss: 27.90239 valid_loss: 116.80556\n",
      "EarlyStopping counter: 126 out of 600\n",
      "tensor(4.3205, grad_fn=<MeanBackward0>)\n",
      "[1043/1500] train_loss: 30.05263 valid_loss: 31.79597\n",
      "EarlyStopping counter: 127 out of 600\n",
      "tensor(3.4499, grad_fn=<MeanBackward0>)\n",
      "[1044/1500] train_loss: 150.51075 valid_loss: 150.32690\n",
      "EarlyStopping counter: 128 out of 600\n",
      "tensor(5.0936, grad_fn=<MeanBackward0>)\n",
      "[1045/1500] train_loss: 141.03844 valid_loss: 92.15677\n",
      "EarlyStopping counter: 129 out of 600\n",
      "tensor(4.2272, grad_fn=<MeanBackward0>)\n",
      "[1046/1500] train_loss: 115.29725 valid_loss: 37.29361\n",
      "EarlyStopping counter: 130 out of 600\n",
      "tensor(4.4014, grad_fn=<MeanBackward0>)\n",
      "[1047/1500] train_loss: 67.02072 valid_loss: 56.04453\n",
      "EarlyStopping counter: 131 out of 600\n",
      "tensor(4.6752, grad_fn=<MeanBackward0>)\n",
      "[1048/1500] train_loss: 156.17162 valid_loss: 23.64550\n",
      "EarlyStopping counter: 132 out of 600\n",
      "tensor(2.9297, grad_fn=<MeanBackward0>)\n",
      "[1049/1500] train_loss: 14.08689 valid_loss: 229.33055\n",
      "EarlyStopping counter: 133 out of 600\n",
      "tensor(6.5473, grad_fn=<MeanBackward0>)\n",
      "[1050/1500] train_loss: 206.91483 valid_loss: 31.32354\n",
      "EarlyStopping counter: 134 out of 600\n",
      "tensor(4.2690, grad_fn=<MeanBackward0>)\n",
      "[1051/1500] train_loss: 65.13154 valid_loss: 80.16554\n",
      "EarlyStopping counter: 135 out of 600\n",
      "tensor(6.2134, grad_fn=<MeanBackward0>)\n",
      "[1052/1500] train_loss: 118.80860 valid_loss: 102.01910\n",
      "EarlyStopping counter: 136 out of 600\n",
      "tensor(5.2841, grad_fn=<MeanBackward0>)\n",
      "[1053/1500] train_loss: 45.84404 valid_loss: 43.09799\n",
      "EarlyStopping counter: 137 out of 600\n",
      "tensor(5.0188, grad_fn=<MeanBackward0>)\n",
      "[1054/1500] train_loss: 62.46153 valid_loss: 157.78234\n",
      "EarlyStopping counter: 138 out of 600\n",
      "tensor(5.6231, grad_fn=<MeanBackward0>)\n",
      "[1055/1500] train_loss: 77.50496 valid_loss: 98.89096\n",
      "EarlyStopping counter: 139 out of 600\n",
      "tensor(3.7642, grad_fn=<MeanBackward0>)\n",
      "[1056/1500] train_loss: 124.23294 valid_loss: 112.56217\n",
      "EarlyStopping counter: 140 out of 600\n",
      "tensor(3.8153, grad_fn=<MeanBackward0>)\n",
      "[1057/1500] train_loss: 102.35907 valid_loss: 110.20607\n",
      "EarlyStopping counter: 141 out of 600\n",
      "tensor(2.6264, grad_fn=<MeanBackward0>)\n",
      "[1058/1500] train_loss: 134.68183 valid_loss: 47.28631\n",
      "EarlyStopping counter: 142 out of 600\n",
      "tensor(5.5633, grad_fn=<MeanBackward0>)\n",
      "[1059/1500] train_loss: 64.15308 valid_loss: 42.06696\n",
      "EarlyStopping counter: 143 out of 600\n",
      "tensor(3.1937, grad_fn=<MeanBackward0>)\n",
      "[1060/1500] train_loss: 41.42587 valid_loss: 19.07445\n",
      "EarlyStopping counter: 144 out of 600\n",
      "tensor(3.9494, grad_fn=<MeanBackward0>)\n",
      "[1061/1500] train_loss: 57.87075 valid_loss: 39.49016\n",
      "EarlyStopping counter: 145 out of 600\n",
      "tensor(5.1160, grad_fn=<MeanBackward0>)\n",
      "[1062/1500] train_loss: 22.30721 valid_loss: 21.31308\n",
      "EarlyStopping counter: 146 out of 600\n",
      "tensor(4.1774, grad_fn=<MeanBackward0>)\n",
      "[1063/1500] train_loss: 78.68811 valid_loss: 10.46032\n",
      "EarlyStopping counter: 147 out of 600\n",
      "tensor(3.1283, grad_fn=<MeanBackward0>)\n",
      "[1064/1500] train_loss: 39.44144 valid_loss: 39.67647\n",
      "EarlyStopping counter: 148 out of 600\n",
      "tensor(3.2663, grad_fn=<MeanBackward0>)\n",
      "[1065/1500] train_loss: 23.87025 valid_loss: 49.93748\n",
      "EarlyStopping counter: 149 out of 600\n",
      "tensor(5.1562, grad_fn=<MeanBackward0>)\n",
      "[1066/1500] train_loss: 59.71303 valid_loss: 33.32993\n",
      "EarlyStopping counter: 150 out of 600\n",
      "tensor(5.7635, grad_fn=<MeanBackward0>)\n",
      "[1067/1500] train_loss: 304.66308 valid_loss: 55.19633\n",
      "EarlyStopping counter: 151 out of 600\n",
      "tensor(3.5414, grad_fn=<MeanBackward0>)\n",
      "[1068/1500] train_loss: 53.14266 valid_loss: 70.41733\n",
      "EarlyStopping counter: 152 out of 600\n",
      "tensor(4.0785, grad_fn=<MeanBackward0>)\n",
      "[1069/1500] train_loss: 59.82950 valid_loss: 18.87479\n",
      "EarlyStopping counter: 153 out of 600\n",
      "tensor(3.4339, grad_fn=<MeanBackward0>)\n",
      "[1070/1500] train_loss: 24.90083 valid_loss: 66.76739\n",
      "EarlyStopping counter: 154 out of 600\n",
      "tensor(3.6717, grad_fn=<MeanBackward0>)\n",
      "[1071/1500] train_loss: 40.26040 valid_loss: 58.00451\n",
      "EarlyStopping counter: 155 out of 600\n",
      "tensor(4.6789, grad_fn=<MeanBackward0>)\n",
      "[1072/1500] train_loss: 143.38082 valid_loss: 61.72519\n",
      "EarlyStopping counter: 156 out of 600\n",
      "tensor(6.8387, grad_fn=<MeanBackward0>)\n",
      "[1073/1500] train_loss: 106.88773 valid_loss: 148.84415\n",
      "EarlyStopping counter: 157 out of 600\n",
      "tensor(3.8935, grad_fn=<MeanBackward0>)\n",
      "[1074/1500] train_loss: 59.20353 valid_loss: 216.29552\n",
      "EarlyStopping counter: 158 out of 600\n",
      "tensor(5.1705, grad_fn=<MeanBackward0>)\n",
      "[1075/1500] train_loss: 213.67877 valid_loss: 15.56619\n",
      "EarlyStopping counter: 159 out of 600\n",
      "tensor(3.0548, grad_fn=<MeanBackward0>)\n",
      "[1076/1500] train_loss: 13.02837 valid_loss: 24.80429\n",
      "EarlyStopping counter: 160 out of 600\n",
      "tensor(3.3542, grad_fn=<MeanBackward0>)\n",
      "[1077/1500] train_loss: 25.80977 valid_loss: 22.08888\n",
      "EarlyStopping counter: 161 out of 600\n",
      "tensor(3.3457, grad_fn=<MeanBackward0>)\n",
      "[1078/1500] train_loss: 27.63316 valid_loss: 75.27530\n",
      "EarlyStopping counter: 162 out of 600\n",
      "tensor(5.6691, grad_fn=<MeanBackward0>)\n",
      "[1079/1500] train_loss: 93.34197 valid_loss: 15.93924\n",
      "EarlyStopping counter: 163 out of 600\n",
      "tensor(3.4132, grad_fn=<MeanBackward0>)\n",
      "[1080/1500] train_loss: 70.90542 valid_loss: 60.14027\n",
      "EarlyStopping counter: 164 out of 600\n",
      "tensor(3.0877, grad_fn=<MeanBackward0>)\n",
      "[1081/1500] train_loss: 13.69773 valid_loss: 108.51285\n",
      "EarlyStopping counter: 165 out of 600\n",
      "tensor(3.9657, grad_fn=<MeanBackward0>)\n",
      "[1082/1500] train_loss: 32.65304 valid_loss: 52.44607\n",
      "EarlyStopping counter: 166 out of 600\n",
      "tensor(3.7665, grad_fn=<MeanBackward0>)\n",
      "[1083/1500] train_loss: 20.50884 valid_loss: 16.45729\n",
      "EarlyStopping counter: 167 out of 600\n",
      "tensor(4.2290, grad_fn=<MeanBackward0>)\n",
      "[1084/1500] train_loss: 160.37632 valid_loss: 46.84171\n",
      "EarlyStopping counter: 168 out of 600\n",
      "tensor(3.3581, grad_fn=<MeanBackward0>)\n",
      "[1085/1500] train_loss: 58.65464 valid_loss: 50.36297\n",
      "EarlyStopping counter: 169 out of 600\n",
      "tensor(4.9565, grad_fn=<MeanBackward0>)\n",
      "[1086/1500] train_loss: 63.19114 valid_loss: 22.67807\n",
      "EarlyStopping counter: 170 out of 600\n",
      "tensor(2.8998, grad_fn=<MeanBackward0>)\n",
      "[1087/1500] train_loss: 34.48561 valid_loss: 12.83481\n",
      "EarlyStopping counter: 171 out of 600\n",
      "tensor(3.1063, grad_fn=<MeanBackward0>)\n",
      "[1088/1500] train_loss: 31.60231 valid_loss: 47.88851\n",
      "EarlyStopping counter: 172 out of 600\n",
      "tensor(3.4588, grad_fn=<MeanBackward0>)\n",
      "[1089/1500] train_loss: 17.59459 valid_loss: 38.72305\n",
      "EarlyStopping counter: 173 out of 600\n",
      "tensor(3.5739, grad_fn=<MeanBackward0>)\n",
      "[1090/1500] train_loss: 39.47142 valid_loss: 60.57844\n",
      "EarlyStopping counter: 174 out of 600\n",
      "tensor(3.2889, grad_fn=<MeanBackward0>)\n",
      "[1091/1500] train_loss: 86.81234 valid_loss: 40.02836\n",
      "EarlyStopping counter: 175 out of 600\n",
      "tensor(4.8983, grad_fn=<MeanBackward0>)\n",
      "[1092/1500] train_loss: 31.98277 valid_loss: 39.09623\n",
      "EarlyStopping counter: 176 out of 600\n",
      "tensor(3.8824, grad_fn=<MeanBackward0>)\n",
      "[1093/1500] train_loss: 47.81549 valid_loss: 38.93836\n",
      "EarlyStopping counter: 177 out of 600\n",
      "tensor(3.2528, grad_fn=<MeanBackward0>)\n",
      "[1094/1500] train_loss: 25.40710 valid_loss: 13.73789\n",
      "EarlyStopping counter: 178 out of 600\n",
      "tensor(4.7971, grad_fn=<MeanBackward0>)\n",
      "[1095/1500] train_loss: 50.20264 valid_loss: 20.88322\n",
      "EarlyStopping counter: 179 out of 600\n",
      "tensor(4.7337, grad_fn=<MeanBackward0>)\n",
      "[1096/1500] train_loss: 40.47821 valid_loss: 21.49915\n",
      "EarlyStopping counter: 180 out of 600\n",
      "tensor(3.1814, grad_fn=<MeanBackward0>)\n",
      "[1097/1500] train_loss: 11.27420 valid_loss: 39.28148\n",
      "EarlyStopping counter: 181 out of 600\n",
      "tensor(4.3093, grad_fn=<MeanBackward0>)\n",
      "[1098/1500] train_loss: 27.72304 valid_loss: 22.93854\n",
      "EarlyStopping counter: 182 out of 600\n",
      "tensor(5.7575, grad_fn=<MeanBackward0>)\n",
      "[1099/1500] train_loss: 70.06790 valid_loss: 20.98959\n",
      "EarlyStopping counter: 183 out of 600\n",
      "tensor(3.5853, grad_fn=<MeanBackward0>)\n",
      "[1100/1500] train_loss: 39.45481 valid_loss: 48.58460\n",
      "EarlyStopping counter: 184 out of 600\n",
      "tensor(3.8421, grad_fn=<MeanBackward0>)\n",
      "[1101/1500] train_loss: 72.11587 valid_loss: 80.77495\n",
      "EarlyStopping counter: 185 out of 600\n",
      "tensor(4.6244, grad_fn=<MeanBackward0>)\n",
      "[1102/1500] train_loss: 70.09015 valid_loss: 44.94768\n",
      "EarlyStopping counter: 186 out of 600\n",
      "tensor(4.8593, grad_fn=<MeanBackward0>)\n",
      "[1103/1500] train_loss: 39.71400 valid_loss: 14.53071\n",
      "EarlyStopping counter: 187 out of 600\n",
      "tensor(3.9757, grad_fn=<MeanBackward0>)\n",
      "[1104/1500] train_loss: 26.87173 valid_loss: 27.35992\n",
      "EarlyStopping counter: 188 out of 600\n",
      "tensor(4.7002, grad_fn=<MeanBackward0>)\n",
      "[1105/1500] train_loss: 59.29979 valid_loss: 61.64082\n",
      "EarlyStopping counter: 189 out of 600\n",
      "tensor(4.2901, grad_fn=<MeanBackward0>)\n",
      "[1106/1500] train_loss: 48.84049 valid_loss: 97.42687\n",
      "EarlyStopping counter: 190 out of 600\n",
      "tensor(5.8826, grad_fn=<MeanBackward0>)\n",
      "[1107/1500] train_loss: 134.97865 valid_loss: 178.32170\n",
      "EarlyStopping counter: 191 out of 600\n",
      "tensor(4.3562, grad_fn=<MeanBackward0>)\n",
      "[1108/1500] train_loss: 28.84891 valid_loss: 299.43628\n",
      "EarlyStopping counter: 192 out of 600\n",
      "tensor(3.6810, grad_fn=<MeanBackward0>)\n",
      "[1109/1500] train_loss: 42.77008 valid_loss: 222.72763\n",
      "EarlyStopping counter: 193 out of 600\n",
      "tensor(5.2316, grad_fn=<MeanBackward0>)\n",
      "[1110/1500] train_loss: 240.38202 valid_loss: 62.28237\n",
      "EarlyStopping counter: 194 out of 600\n",
      "tensor(3.8645, grad_fn=<MeanBackward0>)\n",
      "[1111/1500] train_loss: 21.62207 valid_loss: 14.40399\n",
      "EarlyStopping counter: 195 out of 600\n",
      "tensor(3.2695, grad_fn=<MeanBackward0>)\n",
      "[1112/1500] train_loss: 48.64783 valid_loss: 47.85373\n",
      "EarlyStopping counter: 196 out of 600\n",
      "tensor(6.2534, grad_fn=<MeanBackward0>)\n",
      "[1113/1500] train_loss: 54.46563 valid_loss: 11.02092\n",
      "EarlyStopping counter: 197 out of 600\n",
      "tensor(5.4850, grad_fn=<MeanBackward0>)\n",
      "[1114/1500] train_loss: 67.49688 valid_loss: 32.87543\n",
      "EarlyStopping counter: 198 out of 600\n",
      "tensor(5.4888, grad_fn=<MeanBackward0>)\n",
      "[1115/1500] train_loss: 116.15714 valid_loss: 19.36783\n",
      "EarlyStopping counter: 199 out of 600\n",
      "tensor(5.2633, grad_fn=<MeanBackward0>)\n",
      "[1116/1500] train_loss: 84.28773 valid_loss: 86.27772\n",
      "EarlyStopping counter: 200 out of 600\n",
      "tensor(3.7758, grad_fn=<MeanBackward0>)\n",
      "[1117/1500] train_loss: 42.82316 valid_loss: 121.63327\n",
      "EarlyStopping counter: 201 out of 600\n",
      "tensor(2.9663, grad_fn=<MeanBackward0>)\n",
      "[1118/1500] train_loss: 78.45812 valid_loss: 62.27802\n",
      "EarlyStopping counter: 202 out of 600\n",
      "tensor(4.1289, grad_fn=<MeanBackward0>)\n",
      "[1119/1500] train_loss: 39.41491 valid_loss: 80.79683\n",
      "EarlyStopping counter: 203 out of 600\n",
      "tensor(3.4181, grad_fn=<MeanBackward0>)\n",
      "[1120/1500] train_loss: 17.56551 valid_loss: 61.08640\n",
      "EarlyStopping counter: 204 out of 600\n",
      "tensor(5.2898, grad_fn=<MeanBackward0>)\n",
      "[1121/1500] train_loss: 81.30827 valid_loss: 96.22120\n",
      "EarlyStopping counter: 205 out of 600\n",
      "tensor(5.7954, grad_fn=<MeanBackward0>)\n",
      "[1122/1500] train_loss: 85.24358 valid_loss: 20.45533\n",
      "EarlyStopping counter: 206 out of 600\n",
      "tensor(4.8728, grad_fn=<MeanBackward0>)\n",
      "[1123/1500] train_loss: 77.58011 valid_loss: 65.14655\n",
      "EarlyStopping counter: 207 out of 600\n",
      "tensor(5.7297, grad_fn=<MeanBackward0>)\n",
      "[1124/1500] train_loss: 37.71299 valid_loss: 63.04458\n",
      "EarlyStopping counter: 208 out of 600\n",
      "tensor(3.1292, grad_fn=<MeanBackward0>)\n",
      "[1125/1500] train_loss: 22.09136 valid_loss: 16.25305\n",
      "EarlyStopping counter: 209 out of 600\n",
      "tensor(2.9887, grad_fn=<MeanBackward0>)\n",
      "[1126/1500] train_loss: 22.25369 valid_loss: 63.74915\n",
      "EarlyStopping counter: 210 out of 600\n",
      "tensor(5.5656, grad_fn=<MeanBackward0>)\n",
      "[1127/1500] train_loss: 194.24133 valid_loss: 66.22273\n",
      "EarlyStopping counter: 211 out of 600\n",
      "tensor(3.2844, grad_fn=<MeanBackward0>)\n",
      "[1128/1500] train_loss: 23.33733 valid_loss: 17.53569\n",
      "EarlyStopping counter: 212 out of 600\n",
      "tensor(3.4614, grad_fn=<MeanBackward0>)\n",
      "[1129/1500] train_loss: 79.12277 valid_loss: 61.81357\n",
      "EarlyStopping counter: 213 out of 600\n",
      "tensor(2.9083, grad_fn=<MeanBackward0>)\n",
      "[1130/1500] train_loss: 43.72385 valid_loss: 79.18247\n",
      "EarlyStopping counter: 214 out of 600\n",
      "tensor(3.2870, grad_fn=<MeanBackward0>)\n",
      "[1131/1500] train_loss: 55.20508 valid_loss: 55.98703\n",
      "EarlyStopping counter: 215 out of 600\n",
      "tensor(3.5420, grad_fn=<MeanBackward0>)\n",
      "[1132/1500] train_loss: 44.00953 valid_loss: 282.10620\n",
      "EarlyStopping counter: 216 out of 600\n",
      "tensor(3.7663, grad_fn=<MeanBackward0>)\n",
      "[1133/1500] train_loss: 51.09769 valid_loss: 34.13427\n",
      "EarlyStopping counter: 217 out of 600\n",
      "tensor(3.1098, grad_fn=<MeanBackward0>)\n",
      "[1134/1500] train_loss: 10.45406 valid_loss: 34.10438\n",
      "EarlyStopping counter: 218 out of 600\n",
      "tensor(3.1822, grad_fn=<MeanBackward0>)\n",
      "[1135/1500] train_loss: 22.47890 valid_loss: 138.99097\n",
      "EarlyStopping counter: 219 out of 600\n",
      "tensor(3.2539, grad_fn=<MeanBackward0>)\n",
      "[1136/1500] train_loss: 26.90096 valid_loss: 104.59577\n",
      "EarlyStopping counter: 220 out of 600\n",
      "tensor(3.2496, grad_fn=<MeanBackward0>)\n",
      "[1137/1500] train_loss: 13.74910 valid_loss: 184.40302\n",
      "EarlyStopping counter: 221 out of 600\n",
      "tensor(3.2879, grad_fn=<MeanBackward0>)\n",
      "[1138/1500] train_loss: 33.74139 valid_loss: 205.36876\n",
      "EarlyStopping counter: 222 out of 600\n",
      "tensor(3.2533, grad_fn=<MeanBackward0>)\n",
      "[1139/1500] train_loss: 32.73442 valid_loss: 17.13023\n",
      "EarlyStopping counter: 223 out of 600\n",
      "tensor(3.9808, grad_fn=<MeanBackward0>)\n",
      "[1140/1500] train_loss: 34.04056 valid_loss: 53.57907\n",
      "EarlyStopping counter: 224 out of 600\n",
      "tensor(5.1404, grad_fn=<MeanBackward0>)\n",
      "[1141/1500] train_loss: 63.38236 valid_loss: 16.90662\n",
      "EarlyStopping counter: 225 out of 600\n",
      "tensor(3.2998, grad_fn=<MeanBackward0>)\n",
      "[1142/1500] train_loss: 9.31144 valid_loss: 22.43341\n",
      "EarlyStopping counter: 226 out of 600\n",
      "tensor(4.1346, grad_fn=<MeanBackward0>)\n",
      "[1143/1500] train_loss: 14.25879 valid_loss: 21.73813\n",
      "EarlyStopping counter: 227 out of 600\n",
      "tensor(3.2269, grad_fn=<MeanBackward0>)\n",
      "[1144/1500] train_loss: 18.41936 valid_loss: 60.24699\n",
      "EarlyStopping counter: 228 out of 600\n",
      "tensor(4.7346, grad_fn=<MeanBackward0>)\n",
      "[1145/1500] train_loss: 31.81584 valid_loss: 74.19231\n",
      "EarlyStopping counter: 229 out of 600\n",
      "tensor(3.1909, grad_fn=<MeanBackward0>)\n",
      "[1146/1500] train_loss: 93.68377 valid_loss: 27.26502\n",
      "EarlyStopping counter: 230 out of 600\n",
      "tensor(5.7792, grad_fn=<MeanBackward0>)\n",
      "[1147/1500] train_loss: 68.95185 valid_loss: 27.83175\n",
      "EarlyStopping counter: 231 out of 600\n",
      "tensor(4.4934, grad_fn=<MeanBackward0>)\n",
      "[1148/1500] train_loss: 77.06676 valid_loss: 42.07198\n",
      "EarlyStopping counter: 232 out of 600\n",
      "tensor(3.1187, grad_fn=<MeanBackward0>)\n",
      "[1149/1500] train_loss: 39.74051 valid_loss: 51.66218\n",
      "EarlyStopping counter: 233 out of 600\n",
      "tensor(4.7972, grad_fn=<MeanBackward0>)\n",
      "[1150/1500] train_loss: 52.28520 valid_loss: 40.00932\n",
      "EarlyStopping counter: 234 out of 600\n",
      "tensor(4.6053, grad_fn=<MeanBackward0>)\n",
      "[1151/1500] train_loss: 36.89427 valid_loss: 32.49887\n",
      "EarlyStopping counter: 235 out of 600\n",
      "tensor(6.1416, grad_fn=<MeanBackward0>)\n",
      "[1152/1500] train_loss: 49.89224 valid_loss: 31.11002\n",
      "EarlyStopping counter: 236 out of 600\n",
      "tensor(5.3565, grad_fn=<MeanBackward0>)\n",
      "[1153/1500] train_loss: 216.07196 valid_loss: 33.37575\n",
      "EarlyStopping counter: 237 out of 600\n",
      "tensor(4.1677, grad_fn=<MeanBackward0>)\n",
      "[1154/1500] train_loss: 63.61846 valid_loss: 43.85941\n",
      "EarlyStopping counter: 238 out of 600\n",
      "tensor(6.7847, grad_fn=<MeanBackward0>)\n",
      "[1155/1500] train_loss: 43.32891 valid_loss: 87.10932\n",
      "EarlyStopping counter: 239 out of 600\n",
      "tensor(3.5362, grad_fn=<MeanBackward0>)\n",
      "[1156/1500] train_loss: 106.37588 valid_loss: 37.50601\n",
      "EarlyStopping counter: 240 out of 600\n",
      "tensor(3.6960, grad_fn=<MeanBackward0>)\n",
      "[1157/1500] train_loss: 76.65963 valid_loss: 112.69661\n",
      "EarlyStopping counter: 241 out of 600\n",
      "tensor(4.1560, grad_fn=<MeanBackward0>)\n",
      "[1158/1500] train_loss: 66.71791 valid_loss: 50.61719\n",
      "EarlyStopping counter: 242 out of 600\n",
      "tensor(4.5266, grad_fn=<MeanBackward0>)\n",
      "[1159/1500] train_loss: 106.65998 valid_loss: 34.16974\n",
      "EarlyStopping counter: 243 out of 600\n",
      "tensor(3.9382, grad_fn=<MeanBackward0>)\n",
      "[1160/1500] train_loss: 25.84910 valid_loss: 37.05251\n",
      "EarlyStopping counter: 244 out of 600\n",
      "tensor(3.3992, grad_fn=<MeanBackward0>)\n",
      "[1161/1500] train_loss: 33.07060 valid_loss: 103.65255\n",
      "EarlyStopping counter: 245 out of 600\n",
      "tensor(4.9624, grad_fn=<MeanBackward0>)\n",
      "[1162/1500] train_loss: 99.95035 valid_loss: 136.72283\n",
      "EarlyStopping counter: 246 out of 600\n",
      "tensor(4.0289, grad_fn=<MeanBackward0>)\n",
      "[1163/1500] train_loss: 77.21839 valid_loss: 48.15242\n",
      "EarlyStopping counter: 247 out of 600\n",
      "tensor(3.3045, grad_fn=<MeanBackward0>)\n",
      "[1164/1500] train_loss: 77.79507 valid_loss: 26.63996\n",
      "EarlyStopping counter: 248 out of 600\n",
      "tensor(6.4916, grad_fn=<MeanBackward0>)\n",
      "[1165/1500] train_loss: 97.23729 valid_loss: 80.38588\n",
      "EarlyStopping counter: 249 out of 600\n",
      "tensor(5.6160, grad_fn=<MeanBackward0>)\n",
      "[1166/1500] train_loss: 62.35929 valid_loss: 31.64629\n",
      "EarlyStopping counter: 250 out of 600\n",
      "tensor(4.8677, grad_fn=<MeanBackward0>)\n",
      "[1167/1500] train_loss: 29.93076 valid_loss: 181.21588\n",
      "EarlyStopping counter: 251 out of 600\n",
      "tensor(5.3166, grad_fn=<MeanBackward0>)\n",
      "[1168/1500] train_loss: 33.72547 valid_loss: 154.37102\n",
      "EarlyStopping counter: 252 out of 600\n",
      "tensor(5.6399, grad_fn=<MeanBackward0>)\n",
      "[1169/1500] train_loss: 73.81860 valid_loss: 30.55134\n",
      "EarlyStopping counter: 253 out of 600\n",
      "tensor(3.2835, grad_fn=<MeanBackward0>)\n",
      "[1170/1500] train_loss: 26.36009 valid_loss: 24.95182\n",
      "EarlyStopping counter: 254 out of 600\n",
      "tensor(3.5256, grad_fn=<MeanBackward0>)\n",
      "[1171/1500] train_loss: 40.11731 valid_loss: 1144.01830\n",
      "EarlyStopping counter: 255 out of 600\n",
      "tensor(3.6824, grad_fn=<MeanBackward0>)\n",
      "[1172/1500] train_loss: 26.76659 valid_loss: 243.43138\n",
      "EarlyStopping counter: 256 out of 600\n",
      "tensor(6.3513, grad_fn=<MeanBackward0>)\n",
      "[1173/1500] train_loss: 223.66620 valid_loss: 232.11140\n",
      "EarlyStopping counter: 257 out of 600\n",
      "tensor(3.1463, grad_fn=<MeanBackward0>)\n",
      "[1174/1500] train_loss: 53.62295 valid_loss: 1302.54933\n",
      "EarlyStopping counter: 258 out of 600\n",
      "tensor(3.3278, grad_fn=<MeanBackward0>)\n",
      "[1175/1500] train_loss: 42.66030 valid_loss: 1024.89677\n",
      "EarlyStopping counter: 259 out of 600\n",
      "tensor(5.5022, grad_fn=<MeanBackward0>)\n",
      "[1176/1500] train_loss: 152.34533 valid_loss: 440.23669\n",
      "EarlyStopping counter: 260 out of 600\n",
      "tensor(6.1771, grad_fn=<MeanBackward0>)\n",
      "[1177/1500] train_loss: 163.62639 valid_loss: 20.25458\n",
      "EarlyStopping counter: 261 out of 600\n",
      "tensor(3.3735, grad_fn=<MeanBackward0>)\n",
      "[1178/1500] train_loss: 515.02711 valid_loss: 210.23669\n",
      "EarlyStopping counter: 262 out of 600\n",
      "tensor(4.5605, grad_fn=<MeanBackward0>)\n",
      "[1179/1500] train_loss: 23.58763 valid_loss: 305.65914\n",
      "EarlyStopping counter: 263 out of 600\n",
      "tensor(3.6329, grad_fn=<MeanBackward0>)\n",
      "[1180/1500] train_loss: 29.40946 valid_loss: 512.97501\n",
      "EarlyStopping counter: 264 out of 600\n",
      "tensor(3.2701, grad_fn=<MeanBackward0>)\n",
      "[1181/1500] train_loss: 775.39551 valid_loss: 69.72403\n",
      "EarlyStopping counter: 265 out of 600\n",
      "tensor(5.7009, grad_fn=<MeanBackward0>)\n",
      "[1182/1500] train_loss: 195.40880 valid_loss: 47.11948\n",
      "EarlyStopping counter: 266 out of 600\n",
      "tensor(3.1504, grad_fn=<MeanBackward0>)\n",
      "[1183/1500] train_loss: 41.29131 valid_loss: 241.42764\n",
      "EarlyStopping counter: 267 out of 600\n",
      "tensor(3.3662, grad_fn=<MeanBackward0>)\n",
      "[1184/1500] train_loss: 19.91843 valid_loss: 43.57762\n",
      "EarlyStopping counter: 268 out of 600\n",
      "tensor(6.0512, grad_fn=<MeanBackward0>)\n",
      "[1185/1500] train_loss: 54.02420 valid_loss: 204.13325\n",
      "EarlyStopping counter: 269 out of 600\n",
      "tensor(4.0664, grad_fn=<MeanBackward0>)\n",
      "[1186/1500] train_loss: 73.07940 valid_loss: 58.30211\n",
      "EarlyStopping counter: 270 out of 600\n",
      "tensor(2.9159, grad_fn=<MeanBackward0>)\n",
      "[1187/1500] train_loss: 203.36096 valid_loss: 117.51381\n",
      "EarlyStopping counter: 271 out of 600\n",
      "tensor(4.6712, grad_fn=<MeanBackward0>)\n",
      "[1188/1500] train_loss: 203.32805 valid_loss: 71.27235\n",
      "EarlyStopping counter: 272 out of 600\n",
      "tensor(6.9844, grad_fn=<MeanBackward0>)\n",
      "[1189/1500] train_loss: 524.12162 valid_loss: 137.26556\n",
      "EarlyStopping counter: 273 out of 600\n",
      "tensor(3.2655, grad_fn=<MeanBackward0>)\n",
      "[1190/1500] train_loss: 14.85215 valid_loss: 182.81580\n",
      "EarlyStopping counter: 274 out of 600\n",
      "tensor(2.9997, grad_fn=<MeanBackward0>)\n",
      "[1191/1500] train_loss: 167.00516 valid_loss: 39.57296\n",
      "EarlyStopping counter: 275 out of 600\n",
      "tensor(3.3578, grad_fn=<MeanBackward0>)\n",
      "[1192/1500] train_loss: 13.32983 valid_loss: 116.17852\n",
      "EarlyStopping counter: 276 out of 600\n",
      "tensor(4.3827, grad_fn=<MeanBackward0>)\n",
      "[1193/1500] train_loss: 143.42564 valid_loss: 62.50599\n",
      "EarlyStopping counter: 277 out of 600\n",
      "tensor(4.9819, grad_fn=<MeanBackward0>)\n",
      "[1194/1500] train_loss: 158.80146 valid_loss: 232.91981\n",
      "EarlyStopping counter: 278 out of 600\n",
      "tensor(5.4669, grad_fn=<MeanBackward0>)\n",
      "[1195/1500] train_loss: 558.53700 valid_loss: 263.91142\n",
      "EarlyStopping counter: 279 out of 600\n",
      "tensor(3.3867, grad_fn=<MeanBackward0>)\n",
      "[1196/1500] train_loss: 193.82500 valid_loss: 46.31585\n",
      "EarlyStopping counter: 280 out of 600\n",
      "tensor(3.3348, grad_fn=<MeanBackward0>)\n",
      "[1197/1500] train_loss: 44.12616 valid_loss: 76.38702\n",
      "EarlyStopping counter: 281 out of 600\n",
      "tensor(3.4672, grad_fn=<MeanBackward0>)\n",
      "[1198/1500] train_loss: 79.11145 valid_loss: 163.17884\n",
      "EarlyStopping counter: 282 out of 600\n",
      "tensor(3.0985, grad_fn=<MeanBackward0>)\n",
      "[1199/1500] train_loss: 120.24212 valid_loss: 103.82976\n",
      "EarlyStopping counter: 283 out of 600\n",
      "tensor(3.3290, grad_fn=<MeanBackward0>)\n",
      "[1200/1500] train_loss: 33.53585 valid_loss: 155.26724\n",
      "EarlyStopping counter: 284 out of 600\n",
      "tensor(3.4070, grad_fn=<MeanBackward0>)\n",
      "[1201/1500] train_loss: 59.48172 valid_loss: 109.50892\n",
      "EarlyStopping counter: 285 out of 600\n",
      "tensor(3.9507, grad_fn=<MeanBackward0>)\n",
      "[1202/1500] train_loss: 47.30245 valid_loss: 388.09668\n",
      "EarlyStopping counter: 286 out of 600\n",
      "tensor(6.3570, grad_fn=<MeanBackward0>)\n",
      "[1203/1500] train_loss: 548.14478 valid_loss: 24.32236\n",
      "EarlyStopping counter: 287 out of 600\n",
      "tensor(4.2056, grad_fn=<MeanBackward0>)\n",
      "[1204/1500] train_loss: 64.92752 valid_loss: 56.66266\n",
      "EarlyStopping counter: 288 out of 600\n",
      "tensor(6.5628, grad_fn=<MeanBackward0>)\n",
      "[1205/1500] train_loss: 344.08459 valid_loss: 32.43768\n",
      "EarlyStopping counter: 289 out of 600\n",
      "tensor(4.1234, grad_fn=<MeanBackward0>)\n",
      "[1206/1500] train_loss: 65.33114 valid_loss: 105.51630\n",
      "EarlyStopping counter: 290 out of 600\n",
      "tensor(5.4213, grad_fn=<MeanBackward0>)\n",
      "[1207/1500] train_loss: 61.34840 valid_loss: 59.88339\n",
      "EarlyStopping counter: 291 out of 600\n",
      "tensor(3.6550, grad_fn=<MeanBackward0>)\n",
      "[1208/1500] train_loss: 80.42556 valid_loss: 203.62322\n",
      "EarlyStopping counter: 292 out of 600\n",
      "tensor(4.4169, grad_fn=<MeanBackward0>)\n",
      "[1209/1500] train_loss: 77.42951 valid_loss: 70.58907\n",
      "EarlyStopping counter: 293 out of 600\n",
      "tensor(4.3816, grad_fn=<MeanBackward0>)\n",
      "[1210/1500] train_loss: 593.86071 valid_loss: 582.88554\n",
      "EarlyStopping counter: 294 out of 600\n",
      "tensor(5.4668, grad_fn=<MeanBackward0>)\n",
      "[1211/1500] train_loss: 757.04601 valid_loss: 276.75097\n",
      "EarlyStopping counter: 295 out of 600\n",
      "tensor(4.0136, grad_fn=<MeanBackward0>)\n",
      "[1212/1500] train_loss: 39.00892 valid_loss: 35.25908\n",
      "EarlyStopping counter: 296 out of 600\n",
      "tensor(3.2895, grad_fn=<MeanBackward0>)\n",
      "[1213/1500] train_loss: 45.44088 valid_loss: 177.39456\n",
      "EarlyStopping counter: 297 out of 600\n",
      "tensor(6.2143, grad_fn=<MeanBackward0>)\n",
      "[1214/1500] train_loss: 77.85603 valid_loss: 65.98502\n",
      "EarlyStopping counter: 298 out of 600\n",
      "tensor(3.9190, grad_fn=<MeanBackward0>)\n",
      "[1215/1500] train_loss: 237.78220 valid_loss: 131.06404\n",
      "EarlyStopping counter: 299 out of 600\n",
      "tensor(3.3177, grad_fn=<MeanBackward0>)\n",
      "[1216/1500] train_loss: 31.01368 valid_loss: 55.50994\n",
      "EarlyStopping counter: 300 out of 600\n",
      "tensor(6.1018, grad_fn=<MeanBackward0>)\n",
      "[1217/1500] train_loss: 367.65742 valid_loss: 171.22279\n",
      "EarlyStopping counter: 301 out of 600\n",
      "tensor(3.0601, grad_fn=<MeanBackward0>)\n",
      "[1218/1500] train_loss: 121.34192 valid_loss: 38.73430\n",
      "EarlyStopping counter: 302 out of 600\n",
      "tensor(3.5816, grad_fn=<MeanBackward0>)\n",
      "[1219/1500] train_loss: 73.85569 valid_loss: 122.70378\n",
      "EarlyStopping counter: 303 out of 600\n",
      "tensor(3.5125, grad_fn=<MeanBackward0>)\n",
      "[1220/1500] train_loss: 81.44343 valid_loss: 48.55065\n",
      "EarlyStopping counter: 304 out of 600\n",
      "tensor(2.9799, grad_fn=<MeanBackward0>)\n",
      "[1221/1500] train_loss: 59.50938 valid_loss: 80.88999\n",
      "EarlyStopping counter: 305 out of 600\n",
      "tensor(6.1455, grad_fn=<MeanBackward0>)\n",
      "[1222/1500] train_loss: 261.08392 valid_loss: 33.12982\n",
      "EarlyStopping counter: 306 out of 600\n",
      "tensor(4.2026, grad_fn=<MeanBackward0>)\n",
      "[1223/1500] train_loss: 35.34147 valid_loss: 47.40149\n",
      "EarlyStopping counter: 307 out of 600\n",
      "tensor(4.1229, grad_fn=<MeanBackward0>)\n",
      "[1224/1500] train_loss: 84.04436 valid_loss: 69.15487\n",
      "EarlyStopping counter: 308 out of 600\n",
      "tensor(5.8264, grad_fn=<MeanBackward0>)\n",
      "[1225/1500] train_loss: 60.15310 valid_loss: 52.69686\n",
      "EarlyStopping counter: 309 out of 600\n",
      "tensor(3.4811, grad_fn=<MeanBackward0>)\n",
      "[1226/1500] train_loss: 176.03857 valid_loss: 85.91807\n",
      "EarlyStopping counter: 310 out of 600\n",
      "tensor(3.2896, grad_fn=<MeanBackward0>)\n",
      "[1227/1500] train_loss: 21.10437 valid_loss: 53.44281\n",
      "EarlyStopping counter: 311 out of 600\n",
      "tensor(3.5106, grad_fn=<MeanBackward0>)\n",
      "[1228/1500] train_loss: 42.48653 valid_loss: 51.25463\n",
      "EarlyStopping counter: 312 out of 600\n",
      "tensor(5.6658, grad_fn=<MeanBackward0>)\n",
      "[1229/1500] train_loss: 344.82693 valid_loss: 21.23424\n",
      "EarlyStopping counter: 313 out of 600\n",
      "tensor(5.9578, grad_fn=<MeanBackward0>)\n",
      "[1230/1500] train_loss: 729.64835 valid_loss: 44.24013\n",
      "EarlyStopping counter: 314 out of 600\n",
      "tensor(5.0149, grad_fn=<MeanBackward0>)\n",
      "[1231/1500] train_loss: 38.35545 valid_loss: 112.28533\n",
      "EarlyStopping counter: 315 out of 600\n",
      "tensor(4.5177, grad_fn=<MeanBackward0>)\n",
      "[1232/1500] train_loss: 79.21863 valid_loss: 12.10238\n",
      "EarlyStopping counter: 316 out of 600\n",
      "tensor(3.7211, grad_fn=<MeanBackward0>)\n",
      "[1233/1500] train_loss: 80.40648 valid_loss: 99.22190\n",
      "EarlyStopping counter: 317 out of 600\n",
      "tensor(6.8483, grad_fn=<MeanBackward0>)\n",
      "[1234/1500] train_loss: 165.05235 valid_loss: 18.20916\n",
      "EarlyStopping counter: 318 out of 600\n",
      "tensor(6.6183, grad_fn=<MeanBackward0>)\n",
      "[1235/1500] train_loss: 465.30813 valid_loss: 19.96133\n",
      "EarlyStopping counter: 319 out of 600\n",
      "tensor(3.5497, grad_fn=<MeanBackward0>)\n",
      "[1236/1500] train_loss: 9.83802 valid_loss: 12.37734\n",
      "EarlyStopping counter: 320 out of 600\n",
      "tensor(4.2904, grad_fn=<MeanBackward0>)\n",
      "[1237/1500] train_loss: 108.40421 valid_loss: 32.36605\n",
      "EarlyStopping counter: 321 out of 600\n",
      "tensor(3.6899, grad_fn=<MeanBackward0>)\n",
      "[1238/1500] train_loss: 103.91348 valid_loss: 180.95538\n",
      "EarlyStopping counter: 322 out of 600\n",
      "tensor(5.2100, grad_fn=<MeanBackward0>)\n",
      "[1239/1500] train_loss: 140.64406 valid_loss: 129.46368\n",
      "EarlyStopping counter: 323 out of 600\n",
      "tensor(5.0170, grad_fn=<MeanBackward0>)\n",
      "[1240/1500] train_loss: 76.08982 valid_loss: 21.56392\n",
      "EarlyStopping counter: 324 out of 600\n",
      "tensor(3.1830, grad_fn=<MeanBackward0>)\n",
      "[1241/1500] train_loss: 20.35753 valid_loss: 29.81993\n",
      "EarlyStopping counter: 325 out of 600\n",
      "tensor(3.9566, grad_fn=<MeanBackward0>)\n",
      "[1242/1500] train_loss: 26.01634 valid_loss: 64.73747\n",
      "EarlyStopping counter: 326 out of 600\n",
      "tensor(3.4143, grad_fn=<MeanBackward0>)\n",
      "[1243/1500] train_loss: 59.68876 valid_loss: 30.08111\n",
      "EarlyStopping counter: 327 out of 600\n",
      "tensor(4.0002, grad_fn=<MeanBackward0>)\n",
      "[1244/1500] train_loss: 51.27658 valid_loss: 204.56463\n",
      "EarlyStopping counter: 328 out of 600\n",
      "tensor(4.6424, grad_fn=<MeanBackward0>)\n",
      "[1245/1500] train_loss: 40.69021 valid_loss: 46.34535\n",
      "EarlyStopping counter: 329 out of 600\n",
      "tensor(3.6538, grad_fn=<MeanBackward0>)\n",
      "[1246/1500] train_loss: 38.81471 valid_loss: 168.78957\n",
      "EarlyStopping counter: 330 out of 600\n",
      "tensor(3.8909, grad_fn=<MeanBackward0>)\n",
      "[1247/1500] train_loss: 34.30772 valid_loss: 194.80028\n",
      "EarlyStopping counter: 331 out of 600\n",
      "tensor(3.3098, grad_fn=<MeanBackward0>)\n",
      "[1248/1500] train_loss: 38.38669 valid_loss: 35.93694\n",
      "EarlyStopping counter: 332 out of 600\n",
      "tensor(5.6550, grad_fn=<MeanBackward0>)\n",
      "[1249/1500] train_loss: 126.94266 valid_loss: 46.29671\n",
      "EarlyStopping counter: 333 out of 600\n",
      "tensor(3.8186, grad_fn=<MeanBackward0>)\n",
      "[1250/1500] train_loss: 142.38666 valid_loss: 73.98198\n",
      "EarlyStopping counter: 334 out of 600\n",
      "tensor(4.5619, grad_fn=<MeanBackward0>)\n",
      "[1251/1500] train_loss: 25.94135 valid_loss: 280.75836\n",
      "EarlyStopping counter: 335 out of 600\n",
      "tensor(6.1039, grad_fn=<MeanBackward0>)\n",
      "[1252/1500] train_loss: 78.29390 valid_loss: 34.97246\n",
      "EarlyStopping counter: 336 out of 600\n",
      "tensor(4.6138, grad_fn=<MeanBackward0>)\n",
      "[1253/1500] train_loss: 36.10165 valid_loss: 49.42484\n",
      "EarlyStopping counter: 337 out of 600\n",
      "tensor(5.5051, grad_fn=<MeanBackward0>)\n",
      "[1254/1500] train_loss: 149.44833 valid_loss: 47.59149\n",
      "EarlyStopping counter: 338 out of 600\n",
      "tensor(4.1643, grad_fn=<MeanBackward0>)\n",
      "[1255/1500] train_loss: 75.71766 valid_loss: 24.41722\n",
      "EarlyStopping counter: 339 out of 600\n",
      "tensor(4.2678, grad_fn=<MeanBackward0>)\n",
      "[1256/1500] train_loss: 24.69046 valid_loss: 40.98210\n",
      "EarlyStopping counter: 340 out of 600\n",
      "tensor(3.2760, grad_fn=<MeanBackward0>)\n",
      "[1257/1500] train_loss: 33.42499 valid_loss: 94.04156\n",
      "EarlyStopping counter: 341 out of 600\n",
      "tensor(6.5274, grad_fn=<MeanBackward0>)\n",
      "[1258/1500] train_loss: 94.72101 valid_loss: 84.27148\n",
      "EarlyStopping counter: 342 out of 600\n",
      "tensor(4.1521, grad_fn=<MeanBackward0>)\n",
      "[1259/1500] train_loss: 156.47426 valid_loss: 117.05688\n",
      "EarlyStopping counter: 343 out of 600\n",
      "tensor(3.2013, grad_fn=<MeanBackward0>)\n",
      "[1260/1500] train_loss: 33.59610 valid_loss: 98.46156\n",
      "EarlyStopping counter: 344 out of 600\n",
      "tensor(6.3329, grad_fn=<MeanBackward0>)\n",
      "[1261/1500] train_loss: 83.22536 valid_loss: 62.00746\n",
      "EarlyStopping counter: 345 out of 600\n",
      "tensor(7.1678, grad_fn=<MeanBackward0>)\n",
      "[1262/1500] train_loss: 234.58628 valid_loss: 75.27192\n",
      "EarlyStopping counter: 346 out of 600\n",
      "tensor(3.1704, grad_fn=<MeanBackward0>)\n",
      "[1263/1500] train_loss: 34.40871 valid_loss: 87.24535\n",
      "EarlyStopping counter: 347 out of 600\n",
      "tensor(4.9176, grad_fn=<MeanBackward0>)\n",
      "[1264/1500] train_loss: 66.34638 valid_loss: 118.52243\n",
      "EarlyStopping counter: 348 out of 600\n",
      "tensor(5.3010, grad_fn=<MeanBackward0>)\n",
      "[1265/1500] train_loss: 149.66519 valid_loss: 40.36323\n",
      "EarlyStopping counter: 349 out of 600\n",
      "tensor(3.0812, grad_fn=<MeanBackward0>)\n",
      "[1266/1500] train_loss: 34.47892 valid_loss: 65.83989\n",
      "EarlyStopping counter: 350 out of 600\n",
      "tensor(2.8398, grad_fn=<MeanBackward0>)\n",
      "[1267/1500] train_loss: 41.19385 valid_loss: 83.24437\n",
      "EarlyStopping counter: 351 out of 600\n",
      "tensor(4.1409, grad_fn=<MeanBackward0>)\n",
      "[1268/1500] train_loss: 71.03771 valid_loss: 101.04205\n",
      "EarlyStopping counter: 352 out of 600\n",
      "tensor(3.6885, grad_fn=<MeanBackward0>)\n",
      "[1269/1500] train_loss: 40.12052 valid_loss: 112.65251\n",
      "EarlyStopping counter: 353 out of 600\n",
      "tensor(3.2533, grad_fn=<MeanBackward0>)\n",
      "[1270/1500] train_loss: 34.21806 valid_loss: 40.58758\n",
      "EarlyStopping counter: 354 out of 600\n",
      "tensor(5.0713, grad_fn=<MeanBackward0>)\n",
      "[1271/1500] train_loss: 147.45748 valid_loss: 28.82219\n",
      "EarlyStopping counter: 355 out of 600\n",
      "tensor(3.2383, grad_fn=<MeanBackward0>)\n",
      "[1272/1500] train_loss: 11.27239 valid_loss: 46.88497\n",
      "EarlyStopping counter: 356 out of 600\n",
      "tensor(3.3620, grad_fn=<MeanBackward0>)\n",
      "[1273/1500] train_loss: 15.09389 valid_loss: 33.64501\n",
      "EarlyStopping counter: 357 out of 600\n",
      "tensor(3.3696, grad_fn=<MeanBackward0>)\n",
      "[1274/1500] train_loss: 108.26695 valid_loss: 77.31842\n",
      "EarlyStopping counter: 358 out of 600\n",
      "tensor(3.1857, grad_fn=<MeanBackward0>)\n",
      "[1275/1500] train_loss: 28.62656 valid_loss: 61.11711\n",
      "EarlyStopping counter: 359 out of 600\n",
      "tensor(4.7072, grad_fn=<MeanBackward0>)\n",
      "[1276/1500] train_loss: 40.03878 valid_loss: 40.37115\n",
      "EarlyStopping counter: 360 out of 600\n",
      "tensor(3.2359, grad_fn=<MeanBackward0>)\n",
      "[1277/1500] train_loss: 26.95252 valid_loss: 21.65581\n",
      "EarlyStopping counter: 361 out of 600\n",
      "tensor(3.7571, grad_fn=<MeanBackward0>)\n",
      "[1278/1500] train_loss: 26.70442 valid_loss: 55.58957\n",
      "EarlyStopping counter: 362 out of 600\n",
      "tensor(3.1843, grad_fn=<MeanBackward0>)\n",
      "[1279/1500] train_loss: 27.88122 valid_loss: 22.44481\n",
      "EarlyStopping counter: 363 out of 600\n",
      "tensor(3.9783, grad_fn=<MeanBackward0>)\n",
      "[1280/1500] train_loss: 44.06860 valid_loss: 26.91655\n",
      "EarlyStopping counter: 364 out of 600\n",
      "tensor(3.5025, grad_fn=<MeanBackward0>)\n",
      "[1281/1500] train_loss: 22.67153 valid_loss: 72.90145\n",
      "EarlyStopping counter: 365 out of 600\n",
      "tensor(5.0566, grad_fn=<MeanBackward0>)\n",
      "[1282/1500] train_loss: 59.80733 valid_loss: 37.70829\n",
      "EarlyStopping counter: 366 out of 600\n",
      "tensor(5.2073, grad_fn=<MeanBackward0>)\n",
      "[1283/1500] train_loss: 51.45982 valid_loss: 113.07416\n",
      "EarlyStopping counter: 367 out of 600\n",
      "tensor(3.5830, grad_fn=<MeanBackward0>)\n",
      "[1284/1500] train_loss: 24.26049 valid_loss: 27.08935\n",
      "EarlyStopping counter: 368 out of 600\n",
      "tensor(3.2064, grad_fn=<MeanBackward0>)\n",
      "[1285/1500] train_loss: 71.77657 valid_loss: 67.79339\n",
      "EarlyStopping counter: 369 out of 600\n",
      "tensor(3.6321, grad_fn=<MeanBackward0>)\n",
      "[1286/1500] train_loss: 48.93044 valid_loss: 58.34728\n",
      "EarlyStopping counter: 370 out of 600\n",
      "tensor(4.1468, grad_fn=<MeanBackward0>)\n",
      "[1287/1500] train_loss: 17.50432 valid_loss: 39.80733\n",
      "EarlyStopping counter: 371 out of 600\n",
      "tensor(3.5608, grad_fn=<MeanBackward0>)\n",
      "[1288/1500] train_loss: 24.81405 valid_loss: 14.02064\n",
      "EarlyStopping counter: 372 out of 600\n",
      "tensor(3.2953, grad_fn=<MeanBackward0>)\n",
      "[1289/1500] train_loss: 30.35263 valid_loss: 14.24433\n",
      "EarlyStopping counter: 373 out of 600\n",
      "tensor(3.7944, grad_fn=<MeanBackward0>)\n",
      "[1290/1500] train_loss: 15.46040 valid_loss: 20.33016\n",
      "EarlyStopping counter: 374 out of 600\n",
      "tensor(5.4782, grad_fn=<MeanBackward0>)\n",
      "[1291/1500] train_loss: 43.76047 valid_loss: 61.72731\n",
      "EarlyStopping counter: 375 out of 600\n",
      "tensor(4.8938, grad_fn=<MeanBackward0>)\n",
      "[1292/1500] train_loss: 43.72927 valid_loss: 25.32668\n",
      "EarlyStopping counter: 376 out of 600\n",
      "tensor(5.9886, grad_fn=<MeanBackward0>)\n",
      "[1293/1500] train_loss: 175.82417 valid_loss: 28.41331\n",
      "EarlyStopping counter: 377 out of 600\n",
      "tensor(3.1450, grad_fn=<MeanBackward0>)\n",
      "[1294/1500] train_loss: 85.30638 valid_loss: 51.73715\n",
      "EarlyStopping counter: 378 out of 600\n",
      "tensor(5.6029, grad_fn=<MeanBackward0>)\n",
      "[1295/1500] train_loss: 129.67779 valid_loss: 64.56880\n",
      "EarlyStopping counter: 379 out of 600\n",
      "tensor(6.0066, grad_fn=<MeanBackward0>)\n",
      "[1296/1500] train_loss: 58.65788 valid_loss: 106.40428\n",
      "EarlyStopping counter: 380 out of 600\n",
      "tensor(5.8269, grad_fn=<MeanBackward0>)\n",
      "[1297/1500] train_loss: 58.22977 valid_loss: 69.96349\n",
      "EarlyStopping counter: 381 out of 600\n",
      "tensor(5.9139, grad_fn=<MeanBackward0>)\n",
      "[1298/1500] train_loss: 33.14403 valid_loss: 45.49624\n",
      "EarlyStopping counter: 382 out of 600\n",
      "tensor(3.1994, grad_fn=<MeanBackward0>)\n",
      "[1299/1500] train_loss: 15.13470 valid_loss: 65.59626\n",
      "EarlyStopping counter: 383 out of 600\n",
      "tensor(3.7083, grad_fn=<MeanBackward0>)\n",
      "[1300/1500] train_loss: 46.27770 valid_loss: 71.47655\n",
      "EarlyStopping counter: 384 out of 600\n",
      "tensor(4.7958, grad_fn=<MeanBackward0>)\n",
      "[1301/1500] train_loss: 66.70759 valid_loss: 35.97810\n",
      "EarlyStopping counter: 385 out of 600\n",
      "tensor(5.8760, grad_fn=<MeanBackward0>)\n",
      "[1302/1500] train_loss: 95.48108 valid_loss: 100.62999\n",
      "EarlyStopping counter: 386 out of 600\n",
      "tensor(4.5787, grad_fn=<MeanBackward0>)\n",
      "[1303/1500] train_loss: 102.22174 valid_loss: 24.34738\n",
      "EarlyStopping counter: 387 out of 600\n",
      "tensor(3.6886, grad_fn=<MeanBackward0>)\n",
      "[1304/1500] train_loss: 24.83987 valid_loss: 52.37366\n",
      "EarlyStopping counter: 388 out of 600\n",
      "tensor(4.5951, grad_fn=<MeanBackward0>)\n",
      "[1305/1500] train_loss: 30.00418 valid_loss: 214.95260\n",
      "EarlyStopping counter: 389 out of 600\n",
      "tensor(3.7888, grad_fn=<MeanBackward0>)\n",
      "[1306/1500] train_loss: 33.94323 valid_loss: 38.97424\n",
      "EarlyStopping counter: 390 out of 600\n",
      "tensor(5.7496, grad_fn=<MeanBackward0>)\n",
      "[1307/1500] train_loss: 271.97952 valid_loss: 116.84874\n",
      "EarlyStopping counter: 391 out of 600\n",
      "tensor(3.3129, grad_fn=<MeanBackward0>)\n",
      "[1308/1500] train_loss: 29.01503 valid_loss: 54.47187\n",
      "EarlyStopping counter: 392 out of 600\n",
      "tensor(4.6572, grad_fn=<MeanBackward0>)\n",
      "[1309/1500] train_loss: 41.56910 valid_loss: 59.49284\n",
      "EarlyStopping counter: 393 out of 600\n",
      "tensor(4.2955, grad_fn=<MeanBackward0>)\n",
      "[1310/1500] train_loss: 37.30468 valid_loss: 54.66991\n",
      "EarlyStopping counter: 394 out of 600\n",
      "tensor(5.3814, grad_fn=<MeanBackward0>)\n",
      "[1311/1500] train_loss: 47.82742 valid_loss: 20.32730\n",
      "EarlyStopping counter: 395 out of 600\n",
      "tensor(5.4473, grad_fn=<MeanBackward0>)\n",
      "[1312/1500] train_loss: 101.12961 valid_loss: 63.52178\n",
      "EarlyStopping counter: 396 out of 600\n",
      "tensor(4.0855, grad_fn=<MeanBackward0>)\n",
      "[1313/1500] train_loss: 22.17294 valid_loss: 67.72649\n",
      "EarlyStopping counter: 397 out of 600\n",
      "tensor(4.6036, grad_fn=<MeanBackward0>)\n",
      "[1314/1500] train_loss: 73.32994 valid_loss: 72.30538\n",
      "EarlyStopping counter: 398 out of 600\n",
      "tensor(3.9906, grad_fn=<MeanBackward0>)\n",
      "[1315/1500] train_loss: 26.10393 valid_loss: 110.82044\n",
      "EarlyStopping counter: 399 out of 600\n",
      "tensor(3.9337, grad_fn=<MeanBackward0>)\n",
      "[1316/1500] train_loss: 16.69848 valid_loss: 34.58944\n",
      "EarlyStopping counter: 400 out of 600\n",
      "tensor(5.8327, grad_fn=<MeanBackward0>)\n",
      "[1317/1500] train_loss: 184.68939 valid_loss: 116.49798\n",
      "EarlyStopping counter: 401 out of 600\n",
      "tensor(5.8481, grad_fn=<MeanBackward0>)\n",
      "[1318/1500] train_loss: 134.88812 valid_loss: 31.96696\n",
      "EarlyStopping counter: 402 out of 600\n",
      "tensor(3.8525, grad_fn=<MeanBackward0>)\n",
      "[1319/1500] train_loss: 55.89666 valid_loss: 19.04079\n",
      "EarlyStopping counter: 403 out of 600\n",
      "tensor(5.7530, grad_fn=<MeanBackward0>)\n",
      "[1320/1500] train_loss: 53.19472 valid_loss: 42.62098\n",
      "EarlyStopping counter: 404 out of 600\n",
      "tensor(4.4283, grad_fn=<MeanBackward0>)\n",
      "[1321/1500] train_loss: 84.78524 valid_loss: 48.71358\n",
      "EarlyStopping counter: 405 out of 600\n",
      "tensor(3.5595, grad_fn=<MeanBackward0>)\n",
      "[1322/1500] train_loss: 57.40077 valid_loss: 71.55977\n",
      "EarlyStopping counter: 406 out of 600\n",
      "tensor(4.8949, grad_fn=<MeanBackward0>)\n",
      "[1323/1500] train_loss: 68.68818 valid_loss: 74.31790\n",
      "EarlyStopping counter: 407 out of 600\n",
      "tensor(4.4808, grad_fn=<MeanBackward0>)\n",
      "[1324/1500] train_loss: 44.52707 valid_loss: 234.45165\n",
      "EarlyStopping counter: 408 out of 600\n",
      "tensor(4.1479, grad_fn=<MeanBackward0>)\n",
      "[1325/1500] train_loss: 27.37700 valid_loss: 36.71622\n",
      "EarlyStopping counter: 409 out of 600\n",
      "tensor(5.0212, grad_fn=<MeanBackward0>)\n",
      "[1326/1500] train_loss: 47.23178 valid_loss: 33.12274\n",
      "EarlyStopping counter: 410 out of 600\n",
      "tensor(4.2518, grad_fn=<MeanBackward0>)\n",
      "[1327/1500] train_loss: 34.28659 valid_loss: 228.56738\n",
      "EarlyStopping counter: 411 out of 600\n",
      "tensor(3.9138, grad_fn=<MeanBackward0>)\n",
      "[1328/1500] train_loss: 37.75182 valid_loss: 19.90284\n",
      "EarlyStopping counter: 412 out of 600\n",
      "tensor(5.3984, grad_fn=<MeanBackward0>)\n",
      "[1329/1500] train_loss: 40.03015 valid_loss: 21.56334\n",
      "EarlyStopping counter: 413 out of 600\n",
      "tensor(5.6700, grad_fn=<MeanBackward0>)\n",
      "[1330/1500] train_loss: 34.35757 valid_loss: 22.18948\n",
      "EarlyStopping counter: 414 out of 600\n",
      "tensor(5.2917, grad_fn=<MeanBackward0>)\n",
      "[1331/1500] train_loss: 45.95541 valid_loss: 17.26892\n",
      "EarlyStopping counter: 415 out of 600\n",
      "tensor(4.9664, grad_fn=<MeanBackward0>)\n",
      "[1332/1500] train_loss: 53.37414 valid_loss: 36.17532\n",
      "EarlyStopping counter: 416 out of 600\n",
      "tensor(5.9448, grad_fn=<MeanBackward0>)\n",
      "[1333/1500] train_loss: 64.84998 valid_loss: 27.90253\n",
      "EarlyStopping counter: 417 out of 600\n",
      "tensor(4.0882, grad_fn=<MeanBackward0>)\n",
      "[1334/1500] train_loss: 38.11256 valid_loss: 33.78370\n",
      "EarlyStopping counter: 418 out of 600\n",
      "tensor(3.1758, grad_fn=<MeanBackward0>)\n",
      "[1335/1500] train_loss: 38.35654 valid_loss: 57.96276\n",
      "EarlyStopping counter: 419 out of 600\n",
      "tensor(5.1646, grad_fn=<MeanBackward0>)\n",
      "[1336/1500] train_loss: 72.56995 valid_loss: 48.40740\n",
      "EarlyStopping counter: 420 out of 600\n",
      "tensor(5.6025, grad_fn=<MeanBackward0>)\n",
      "[1337/1500] train_loss: 42.28630 valid_loss: 24.34843\n",
      "EarlyStopping counter: 421 out of 600\n",
      "tensor(3.6128, grad_fn=<MeanBackward0>)\n",
      "[1338/1500] train_loss: 42.18747 valid_loss: 37.72869\n",
      "EarlyStopping counter: 422 out of 600\n",
      "tensor(6.6767, grad_fn=<MeanBackward0>)\n",
      "[1339/1500] train_loss: 180.58275 valid_loss: 43.90312\n",
      "EarlyStopping counter: 423 out of 600\n",
      "tensor(4.1917, grad_fn=<MeanBackward0>)\n",
      "[1340/1500] train_loss: 52.10450 valid_loss: 20.55779\n",
      "EarlyStopping counter: 424 out of 600\n",
      "tensor(3.1282, grad_fn=<MeanBackward0>)\n",
      "[1341/1500] train_loss: 23.79260 valid_loss: 11.12611\n",
      "EarlyStopping counter: 425 out of 600\n",
      "tensor(3.2760, grad_fn=<MeanBackward0>)\n",
      "[1342/1500] train_loss: 18.60437 valid_loss: 43.35592\n",
      "EarlyStopping counter: 426 out of 600\n",
      "tensor(4.3167, grad_fn=<MeanBackward0>)\n",
      "[1343/1500] train_loss: 55.64836 valid_loss: 68.75432\n",
      "EarlyStopping counter: 427 out of 600\n",
      "tensor(4.5923, grad_fn=<MeanBackward0>)\n",
      "[1344/1500] train_loss: 47.78510 valid_loss: 66.29782\n",
      "EarlyStopping counter: 428 out of 600\n",
      "tensor(3.9833, grad_fn=<MeanBackward0>)\n",
      "[1345/1500] train_loss: 51.42699 valid_loss: 14.70395\n",
      "EarlyStopping counter: 429 out of 600\n",
      "tensor(6.0192, grad_fn=<MeanBackward0>)\n",
      "[1346/1500] train_loss: 88.14455 valid_loss: 49.27589\n",
      "EarlyStopping counter: 430 out of 600\n",
      "tensor(5.2085, grad_fn=<MeanBackward0>)\n",
      "[1347/1500] train_loss: 60.11270 valid_loss: 108.97275\n",
      "EarlyStopping counter: 431 out of 600\n",
      "tensor(3.8800, grad_fn=<MeanBackward0>)\n",
      "[1348/1500] train_loss: 37.21338 valid_loss: 28.39822\n",
      "EarlyStopping counter: 432 out of 600\n",
      "tensor(3.3072, grad_fn=<MeanBackward0>)\n",
      "[1349/1500] train_loss: 223.97795 valid_loss: 37.79516\n",
      "EarlyStopping counter: 433 out of 600\n",
      "tensor(5.3537, grad_fn=<MeanBackward0>)\n",
      "[1350/1500] train_loss: 26.05561 valid_loss: 17.38838\n",
      "EarlyStopping counter: 434 out of 600\n",
      "tensor(4.3630, grad_fn=<MeanBackward0>)\n",
      "[1351/1500] train_loss: 30.06012 valid_loss: 83.77617\n",
      "EarlyStopping counter: 435 out of 600\n",
      "tensor(5.4178, grad_fn=<MeanBackward0>)\n",
      "[1352/1500] train_loss: 94.88064 valid_loss: 33.73637\n",
      "EarlyStopping counter: 436 out of 600\n",
      "tensor(2.9921, grad_fn=<MeanBackward0>)\n",
      "[1353/1500] train_loss: 24.61521 valid_loss: 37.45976\n",
      "EarlyStopping counter: 437 out of 600\n",
      "tensor(3.6975, grad_fn=<MeanBackward0>)\n",
      "[1354/1500] train_loss: 25.34785 valid_loss: 55.46948\n",
      "EarlyStopping counter: 438 out of 600\n",
      "tensor(3.4934, grad_fn=<MeanBackward0>)\n",
      "[1355/1500] train_loss: 9.70963 valid_loss: 183.51234\n",
      "EarlyStopping counter: 439 out of 600\n",
      "tensor(4.8462, grad_fn=<MeanBackward0>)\n",
      "[1356/1500] train_loss: 39.77686 valid_loss: 103.04763\n",
      "EarlyStopping counter: 440 out of 600\n",
      "tensor(4.4251, grad_fn=<MeanBackward0>)\n",
      "[1357/1500] train_loss: 29.11538 valid_loss: 78.24723\n",
      "EarlyStopping counter: 441 out of 600\n",
      "tensor(3.4416, grad_fn=<MeanBackward0>)\n",
      "[1358/1500] train_loss: 148.14906 valid_loss: 70.59811\n",
      "EarlyStopping counter: 442 out of 600\n",
      "tensor(3.5577, grad_fn=<MeanBackward0>)\n",
      "[1359/1500] train_loss: 16.16809 valid_loss: 326.91321\n",
      "EarlyStopping counter: 443 out of 600\n",
      "tensor(3.4405, grad_fn=<MeanBackward0>)\n",
      "[1360/1500] train_loss: 52.88042 valid_loss: 90.25121\n",
      "EarlyStopping counter: 444 out of 600\n",
      "tensor(6.3148, grad_fn=<MeanBackward0>)\n",
      "[1361/1500] train_loss: 133.94209 valid_loss: 21.43549\n",
      "EarlyStopping counter: 445 out of 600\n",
      "tensor(3.7029, grad_fn=<MeanBackward0>)\n",
      "[1362/1500] train_loss: 71.80176 valid_loss: 217.05456\n",
      "EarlyStopping counter: 446 out of 600\n",
      "tensor(6.3429, grad_fn=<MeanBackward0>)\n",
      "[1363/1500] train_loss: 105.46762 valid_loss: 40.75186\n",
      "EarlyStopping counter: 447 out of 600\n",
      "tensor(3.3213, grad_fn=<MeanBackward0>)\n",
      "[1364/1500] train_loss: 41.45719 valid_loss: 118.49451\n",
      "EarlyStopping counter: 448 out of 600\n",
      "tensor(5.6500, grad_fn=<MeanBackward0>)\n",
      "[1365/1500] train_loss: 216.59930 valid_loss: 43.53761\n",
      "EarlyStopping counter: 449 out of 600\n",
      "tensor(4.9875, grad_fn=<MeanBackward0>)\n",
      "[1366/1500] train_loss: 570.18769 valid_loss: 79.02187\n",
      "EarlyStopping counter: 450 out of 600\n",
      "tensor(5.0545, grad_fn=<MeanBackward0>)\n",
      "[1367/1500] train_loss: 36.31853 valid_loss: 141.29937\n",
      "EarlyStopping counter: 451 out of 600\n",
      "tensor(5.0289, grad_fn=<MeanBackward0>)\n",
      "[1368/1500] train_loss: 112.48620 valid_loss: 45.37518\n",
      "EarlyStopping counter: 452 out of 600\n",
      "tensor(5.7182, grad_fn=<MeanBackward0>)\n",
      "[1369/1500] train_loss: 234.21616 valid_loss: 371.24085\n",
      "EarlyStopping counter: 453 out of 600\n",
      "tensor(3.8262, grad_fn=<MeanBackward0>)\n",
      "[1370/1500] train_loss: 40.82924 valid_loss: 33.38857\n",
      "EarlyStopping counter: 454 out of 600\n",
      "tensor(3.6853, grad_fn=<MeanBackward0>)\n",
      "[1371/1500] train_loss: 14.22794 valid_loss: 126.41103\n",
      "EarlyStopping counter: 455 out of 600\n",
      "tensor(4.7114, grad_fn=<MeanBackward0>)\n",
      "[1372/1500] train_loss: 29.64710 valid_loss: 40.09060\n",
      "EarlyStopping counter: 456 out of 600\n",
      "tensor(3.1067, grad_fn=<MeanBackward0>)\n",
      "[1373/1500] train_loss: 77.18408 valid_loss: 163.21402\n",
      "EarlyStopping counter: 457 out of 600\n",
      "tensor(6.6320, grad_fn=<MeanBackward0>)\n",
      "[1374/1500] train_loss: 354.42643 valid_loss: 116.25100\n",
      "EarlyStopping counter: 458 out of 600\n",
      "tensor(3.0243, grad_fn=<MeanBackward0>)\n",
      "[1375/1500] train_loss: 128.72339 valid_loss: 95.38515\n",
      "EarlyStopping counter: 459 out of 600\n",
      "tensor(3.0301, grad_fn=<MeanBackward0>)\n",
      "[1376/1500] train_loss: 82.23004 valid_loss: 42.11952\n",
      "EarlyStopping counter: 460 out of 600\n",
      "tensor(3.1110, grad_fn=<MeanBackward0>)\n",
      "[1377/1500] train_loss: 65.00153 valid_loss: 103.01461\n",
      "EarlyStopping counter: 461 out of 600\n",
      "tensor(4.2203, grad_fn=<MeanBackward0>)\n",
      "[1378/1500] train_loss: 104.95236 valid_loss: 6.14180\n",
      "Validation loss decreased (10.028363 --> 6.141795).  Saving model ...\n",
      "tensor(5.1469, grad_fn=<MeanBackward0>)\n",
      "[1379/1500] train_loss: 70.47832 valid_loss: 86.97667\n",
      "EarlyStopping counter: 1 out of 600\n",
      "tensor(5.3644, grad_fn=<MeanBackward0>)\n",
      "[1380/1500] train_loss: 138.05649 valid_loss: 42.70896\n",
      "EarlyStopping counter: 2 out of 600\n",
      "tensor(5.6680, grad_fn=<MeanBackward0>)\n",
      "[1381/1500] train_loss: 63.10470 valid_loss: 169.52029\n",
      "EarlyStopping counter: 3 out of 600\n",
      "tensor(3.8066, grad_fn=<MeanBackward0>)\n",
      "[1382/1500] train_loss: 30.54600 valid_loss: 30.58494\n",
      "EarlyStopping counter: 4 out of 600\n",
      "tensor(5.0644, grad_fn=<MeanBackward0>)\n",
      "[1383/1500] train_loss: 49.32036 valid_loss: 26.32531\n",
      "EarlyStopping counter: 5 out of 600\n",
      "tensor(5.2286, grad_fn=<MeanBackward0>)\n",
      "[1384/1500] train_loss: 95.38301 valid_loss: 66.30395\n",
      "EarlyStopping counter: 6 out of 600\n",
      "tensor(3.3946, grad_fn=<MeanBackward0>)\n",
      "[1385/1500] train_loss: 77.80437 valid_loss: 31.94439\n",
      "EarlyStopping counter: 7 out of 600\n",
      "tensor(4.9315, grad_fn=<MeanBackward0>)\n",
      "[1386/1500] train_loss: 40.03607 valid_loss: 150.90185\n",
      "EarlyStopping counter: 8 out of 600\n",
      "tensor(3.8312, grad_fn=<MeanBackward0>)\n",
      "[1387/1500] train_loss: 194.96270 valid_loss: 53.57343\n",
      "EarlyStopping counter: 9 out of 600\n",
      "tensor(6.0637, grad_fn=<MeanBackward0>)\n",
      "[1388/1500] train_loss: 152.69792 valid_loss: 35.50464\n",
      "EarlyStopping counter: 10 out of 600\n",
      "tensor(3.7075, grad_fn=<MeanBackward0>)\n",
      "[1389/1500] train_loss: 341.32037 valid_loss: 82.44061\n",
      "EarlyStopping counter: 11 out of 600\n",
      "tensor(4.4067, grad_fn=<MeanBackward0>)\n",
      "[1390/1500] train_loss: 182.86861 valid_loss: 42.76443\n",
      "EarlyStopping counter: 12 out of 600\n",
      "tensor(4.3363, grad_fn=<MeanBackward0>)\n",
      "[1391/1500] train_loss: 45.83971 valid_loss: 40.37475\n",
      "EarlyStopping counter: 13 out of 600\n",
      "tensor(6.0052, grad_fn=<MeanBackward0>)\n",
      "[1392/1500] train_loss: 51.63363 valid_loss: 57.86409\n",
      "EarlyStopping counter: 14 out of 600\n",
      "tensor(6.1820, grad_fn=<MeanBackward0>)\n",
      "[1393/1500] train_loss: 68.00141 valid_loss: 33.72789\n",
      "EarlyStopping counter: 15 out of 600\n",
      "tensor(3.6816, grad_fn=<MeanBackward0>)\n",
      "[1394/1500] train_loss: 43.06436 valid_loss: 47.78472\n",
      "EarlyStopping counter: 16 out of 600\n",
      "tensor(5.6578, grad_fn=<MeanBackward0>)\n",
      "[1395/1500] train_loss: 46.05878 valid_loss: 112.48129\n",
      "EarlyStopping counter: 17 out of 600\n",
      "tensor(2.5473, grad_fn=<MeanBackward0>)\n",
      "[1396/1500] train_loss: 626.72765 valid_loss: 182.64035\n",
      "EarlyStopping counter: 18 out of 600\n",
      "tensor(4.0211, grad_fn=<MeanBackward0>)\n",
      "[1397/1500] train_loss: 175.31104 valid_loss: 157.03079\n",
      "EarlyStopping counter: 19 out of 600\n",
      "tensor(5.7149, grad_fn=<MeanBackward0>)\n",
      "[1398/1500] train_loss: 40.42627 valid_loss: 109.37594\n",
      "EarlyStopping counter: 20 out of 600\n",
      "tensor(5.7519, grad_fn=<MeanBackward0>)\n",
      "[1399/1500] train_loss: 62.03254 valid_loss: 158.39114\n",
      "EarlyStopping counter: 21 out of 600\n",
      "tensor(2.6567, grad_fn=<MeanBackward0>)\n",
      "[1400/1500] train_loss: 83.86957 valid_loss: 208.23992\n",
      "EarlyStopping counter: 22 out of 600\n",
      "tensor(6.3516, grad_fn=<MeanBackward0>)\n",
      "[1401/1500] train_loss: 81.68457 valid_loss: 128.51786\n",
      "EarlyStopping counter: 23 out of 600\n",
      "tensor(4.1348, grad_fn=<MeanBackward0>)\n",
      "[1402/1500] train_loss: 163.77721 valid_loss: 343.29535\n",
      "EarlyStopping counter: 24 out of 600\n",
      "tensor(3.1046, grad_fn=<MeanBackward0>)\n",
      "[1403/1500] train_loss: 108.93971 valid_loss: 116.20009\n",
      "EarlyStopping counter: 25 out of 600\n",
      "tensor(4.9959, grad_fn=<MeanBackward0>)\n",
      "[1404/1500] train_loss: 48.53699 valid_loss: 319.12816\n",
      "EarlyStopping counter: 26 out of 600\n",
      "tensor(3.8341, grad_fn=<MeanBackward0>)\n",
      "[1405/1500] train_loss: 58.49518 valid_loss: 44.66525\n",
      "EarlyStopping counter: 27 out of 600\n",
      "tensor(4.6332, grad_fn=<MeanBackward0>)\n",
      "[1406/1500] train_loss: 86.67583 valid_loss: 102.43515\n",
      "EarlyStopping counter: 28 out of 600\n",
      "tensor(5.2084, grad_fn=<MeanBackward0>)\n",
      "[1407/1500] train_loss: 37.04938 valid_loss: 40.31694\n",
      "EarlyStopping counter: 29 out of 600\n",
      "tensor(4.0653, grad_fn=<MeanBackward0>)\n",
      "[1408/1500] train_loss: 17.70339 valid_loss: 39.89598\n",
      "EarlyStopping counter: 30 out of 600\n",
      "tensor(3.5987, grad_fn=<MeanBackward0>)\n",
      "[1409/1500] train_loss: 376.65752 valid_loss: 36.52341\n",
      "EarlyStopping counter: 31 out of 600\n",
      "tensor(4.3511, grad_fn=<MeanBackward0>)\n",
      "[1410/1500] train_loss: 49.41741 valid_loss: 63.97112\n",
      "EarlyStopping counter: 32 out of 600\n",
      "tensor(4.9928, grad_fn=<MeanBackward0>)\n",
      "[1411/1500] train_loss: 50.75793 valid_loss: 37.39979\n",
      "EarlyStopping counter: 33 out of 600\n",
      "tensor(3.5204, grad_fn=<MeanBackward0>)\n",
      "[1412/1500] train_loss: 18.39610 valid_loss: 124.87413\n",
      "EarlyStopping counter: 34 out of 600\n",
      "tensor(3.3423, grad_fn=<MeanBackward0>)\n",
      "[1413/1500] train_loss: 56.30658 valid_loss: 165.28465\n",
      "EarlyStopping counter: 35 out of 600\n",
      "tensor(4.1894, grad_fn=<MeanBackward0>)\n",
      "[1414/1500] train_loss: 36.32068 valid_loss: 16.31508\n",
      "EarlyStopping counter: 36 out of 600\n",
      "tensor(5.7148, grad_fn=<MeanBackward0>)\n",
      "[1415/1500] train_loss: 88.35950 valid_loss: 24.53788\n",
      "EarlyStopping counter: 37 out of 600\n",
      "tensor(3.5364, grad_fn=<MeanBackward0>)\n",
      "[1416/1500] train_loss: 30.15666 valid_loss: 16.04394\n",
      "EarlyStopping counter: 38 out of 600\n",
      "tensor(4.1364, grad_fn=<MeanBackward0>)\n",
      "[1417/1500] train_loss: 174.59380 valid_loss: 116.44136\n",
      "EarlyStopping counter: 39 out of 600\n",
      "tensor(3.9943, grad_fn=<MeanBackward0>)\n",
      "[1418/1500] train_loss: 22.85183 valid_loss: 74.02366\n",
      "EarlyStopping counter: 40 out of 600\n",
      "tensor(4.5591, grad_fn=<MeanBackward0>)\n",
      "[1419/1500] train_loss: 31.24800 valid_loss: 24.31030\n",
      "EarlyStopping counter: 41 out of 600\n",
      "tensor(6.1988, grad_fn=<MeanBackward0>)\n",
      "[1420/1500] train_loss: 100.79493 valid_loss: 18.95834\n",
      "EarlyStopping counter: 42 out of 600\n",
      "tensor(3.1034, grad_fn=<MeanBackward0>)\n",
      "[1421/1500] train_loss: 105.63971 valid_loss: 33.50264\n",
      "EarlyStopping counter: 43 out of 600\n",
      "tensor(3.9287, grad_fn=<MeanBackward0>)\n",
      "[1422/1500] train_loss: 97.38504 valid_loss: 31.13819\n",
      "EarlyStopping counter: 44 out of 600\n",
      "tensor(3.8818, grad_fn=<MeanBackward0>)\n",
      "[1423/1500] train_loss: 94.19308 valid_loss: 26.66453\n",
      "EarlyStopping counter: 45 out of 600\n",
      "tensor(3.0909, grad_fn=<MeanBackward0>)\n",
      "[1424/1500] train_loss: 51.78043 valid_loss: 54.13486\n",
      "EarlyStopping counter: 46 out of 600\n",
      "tensor(3.0107, grad_fn=<MeanBackward0>)\n",
      "[1425/1500] train_loss: 93.70227 valid_loss: 19.54969\n",
      "EarlyStopping counter: 47 out of 600\n",
      "tensor(6.3382, grad_fn=<MeanBackward0>)\n",
      "[1426/1500] train_loss: 91.10694 valid_loss: 29.07208\n",
      "EarlyStopping counter: 48 out of 600\n",
      "tensor(4.7467, grad_fn=<MeanBackward0>)\n",
      "[1427/1500] train_loss: 67.42167 valid_loss: 22.70484\n",
      "EarlyStopping counter: 49 out of 600\n",
      "tensor(6.4954, grad_fn=<MeanBackward0>)\n",
      "[1428/1500] train_loss: 152.72076 valid_loss: 50.26502\n",
      "EarlyStopping counter: 50 out of 600\n",
      "tensor(2.8341, grad_fn=<MeanBackward0>)\n",
      "[1429/1500] train_loss: 161.98431 valid_loss: 62.90531\n",
      "EarlyStopping counter: 51 out of 600\n",
      "tensor(3.9181, grad_fn=<MeanBackward0>)\n",
      "[1430/1500] train_loss: 134.45791 valid_loss: 8.98582\n",
      "EarlyStopping counter: 52 out of 600\n",
      "tensor(5.6718, grad_fn=<MeanBackward0>)\n",
      "[1431/1500] train_loss: 87.89018 valid_loss: 110.33402\n",
      "EarlyStopping counter: 53 out of 600\n",
      "tensor(5.5276, grad_fn=<MeanBackward0>)\n",
      "[1432/1500] train_loss: 65.13977 valid_loss: 35.37763\n",
      "EarlyStopping counter: 54 out of 600\n",
      "tensor(5.5555, grad_fn=<MeanBackward0>)\n",
      "[1433/1500] train_loss: 47.53371 valid_loss: 32.46478\n",
      "EarlyStopping counter: 55 out of 600\n",
      "tensor(3.1858, grad_fn=<MeanBackward0>)\n",
      "[1434/1500] train_loss: 17.84953 valid_loss: 188.02473\n",
      "EarlyStopping counter: 56 out of 600\n",
      "tensor(6.1700, grad_fn=<MeanBackward0>)\n",
      "[1435/1500] train_loss: 64.67423 valid_loss: 27.37690\n",
      "EarlyStopping counter: 57 out of 600\n",
      "tensor(3.8383, grad_fn=<MeanBackward0>)\n",
      "[1436/1500] train_loss: 26.50183 valid_loss: 19.00995\n",
      "EarlyStopping counter: 58 out of 600\n",
      "tensor(4.9593, grad_fn=<MeanBackward0>)\n",
      "[1437/1500] train_loss: 265.80003 valid_loss: 19.86590\n",
      "EarlyStopping counter: 59 out of 600\n",
      "tensor(5.1600, grad_fn=<MeanBackward0>)\n",
      "[1438/1500] train_loss: 200.34357 valid_loss: 28.03385\n",
      "EarlyStopping counter: 60 out of 600\n",
      "tensor(4.3314, grad_fn=<MeanBackward0>)\n",
      "[1439/1500] train_loss: 38.52331 valid_loss: 30.68399\n",
      "EarlyStopping counter: 61 out of 600\n",
      "tensor(3.5288, grad_fn=<MeanBackward0>)\n",
      "[1440/1500] train_loss: 30.19867 valid_loss: 65.32449\n",
      "EarlyStopping counter: 62 out of 600\n",
      "tensor(3.5309, grad_fn=<MeanBackward0>)\n",
      "[1441/1500] train_loss: 20.44280 valid_loss: 165.75085\n",
      "EarlyStopping counter: 63 out of 600\n",
      "tensor(4.6352, grad_fn=<MeanBackward0>)\n",
      "[1442/1500] train_loss: 96.67857 valid_loss: 25.53938\n",
      "EarlyStopping counter: 64 out of 600\n",
      "tensor(3.6422, grad_fn=<MeanBackward0>)\n",
      "[1443/1500] train_loss: 104.76897 valid_loss: 196.96053\n",
      "EarlyStopping counter: 65 out of 600\n",
      "tensor(5.1605, grad_fn=<MeanBackward0>)\n",
      "[1444/1500] train_loss: 250.61717 valid_loss: 43.65306\n",
      "EarlyStopping counter: 66 out of 600\n",
      "tensor(2.9691, grad_fn=<MeanBackward0>)\n",
      "[1445/1500] train_loss: 84.75965 valid_loss: 14.63223\n",
      "EarlyStopping counter: 67 out of 600\n",
      "tensor(3.1761, grad_fn=<MeanBackward0>)\n",
      "[1446/1500] train_loss: 20.90961 valid_loss: 63.79678\n",
      "EarlyStopping counter: 68 out of 600\n",
      "tensor(3.9230, grad_fn=<MeanBackward0>)\n",
      "[1447/1500] train_loss: 41.54314 valid_loss: 15.92585\n",
      "EarlyStopping counter: 69 out of 600\n",
      "tensor(4.7534, grad_fn=<MeanBackward0>)\n",
      "[1448/1500] train_loss: 33.16635 valid_loss: 56.39543\n",
      "EarlyStopping counter: 70 out of 600\n",
      "tensor(4.0638, grad_fn=<MeanBackward0>)\n",
      "[1449/1500] train_loss: 45.79426 valid_loss: 67.40191\n",
      "EarlyStopping counter: 71 out of 600\n",
      "tensor(6.0584, grad_fn=<MeanBackward0>)\n",
      "[1450/1500] train_loss: 63.35760 valid_loss: 50.50831\n",
      "EarlyStopping counter: 72 out of 600\n",
      "tensor(4.5831, grad_fn=<MeanBackward0>)\n",
      "[1451/1500] train_loss: 25.77877 valid_loss: 30.36607\n",
      "EarlyStopping counter: 73 out of 600\n",
      "tensor(3.5964, grad_fn=<MeanBackward0>)\n",
      "[1452/1500] train_loss: 60.26915 valid_loss: 34.09493\n",
      "EarlyStopping counter: 74 out of 600\n",
      "tensor(3.2643, grad_fn=<MeanBackward0>)\n",
      "[1453/1500] train_loss: 35.73280 valid_loss: 66.00258\n",
      "EarlyStopping counter: 75 out of 600\n",
      "tensor(3.8417, grad_fn=<MeanBackward0>)\n",
      "[1454/1500] train_loss: 61.72269 valid_loss: 36.87911\n",
      "EarlyStopping counter: 76 out of 600\n",
      "tensor(5.8751, grad_fn=<MeanBackward0>)\n",
      "[1455/1500] train_loss: 94.69298 valid_loss: 125.02871\n",
      "EarlyStopping counter: 77 out of 600\n",
      "tensor(5.4064, grad_fn=<MeanBackward0>)\n",
      "[1456/1500] train_loss: 33.79561 valid_loss: 86.11016\n",
      "EarlyStopping counter: 78 out of 600\n",
      "tensor(3.3825, grad_fn=<MeanBackward0>)\n",
      "[1457/1500] train_loss: 50.33456 valid_loss: 17.33306\n",
      "EarlyStopping counter: 79 out of 600\n",
      "tensor(3.2006, grad_fn=<MeanBackward0>)\n",
      "[1458/1500] train_loss: 34.42887 valid_loss: 45.05472\n",
      "EarlyStopping counter: 80 out of 600\n",
      "tensor(3.0652, grad_fn=<MeanBackward0>)\n",
      "[1459/1500] train_loss: 26.17882 valid_loss: 19.78970\n",
      "EarlyStopping counter: 81 out of 600\n",
      "tensor(6.1062, grad_fn=<MeanBackward0>)\n",
      "[1460/1500] train_loss: 80.21640 valid_loss: 8.81330\n",
      "EarlyStopping counter: 82 out of 600\n",
      "tensor(3.0248, grad_fn=<MeanBackward0>)\n",
      "[1461/1500] train_loss: 41.47444 valid_loss: 149.08602\n",
      "EarlyStopping counter: 83 out of 600\n",
      "tensor(6.5593, grad_fn=<MeanBackward0>)\n",
      "[1462/1500] train_loss: 53.74184 valid_loss: 33.54985\n",
      "EarlyStopping counter: 84 out of 600\n",
      "tensor(3.0699, grad_fn=<MeanBackward0>)\n",
      "[1463/1500] train_loss: 24.22215 valid_loss: 49.82403\n",
      "EarlyStopping counter: 85 out of 600\n",
      "tensor(6.4708, grad_fn=<MeanBackward0>)\n",
      "[1464/1500] train_loss: 168.36362 valid_loss: 44.53250\n",
      "EarlyStopping counter: 86 out of 600\n",
      "tensor(6.1970, grad_fn=<MeanBackward0>)\n",
      "[1465/1500] train_loss: 78.14584 valid_loss: 24.56497\n",
      "EarlyStopping counter: 87 out of 600\n",
      "tensor(4.7550, grad_fn=<MeanBackward0>)\n",
      "[1466/1500] train_loss: 146.62419 valid_loss: 31.56883\n",
      "EarlyStopping counter: 88 out of 600\n",
      "tensor(3.5760, grad_fn=<MeanBackward0>)\n",
      "[1467/1500] train_loss: 42.16229 valid_loss: 23.65501\n",
      "EarlyStopping counter: 89 out of 600\n",
      "tensor(3.2508, grad_fn=<MeanBackward0>)\n",
      "[1468/1500] train_loss: 90.83350 valid_loss: 29.73111\n",
      "EarlyStopping counter: 90 out of 600\n",
      "tensor(4.6534, grad_fn=<MeanBackward0>)\n",
      "[1469/1500] train_loss: 25.76723 valid_loss: 52.01856\n",
      "EarlyStopping counter: 91 out of 600\n",
      "tensor(5.4784, grad_fn=<MeanBackward0>)\n",
      "[1470/1500] train_loss: 66.38805 valid_loss: 176.94492\n",
      "EarlyStopping counter: 92 out of 600\n",
      "tensor(3.5092, grad_fn=<MeanBackward0>)\n",
      "[1471/1500] train_loss: 14.20119 valid_loss: 26.75760\n",
      "EarlyStopping counter: 93 out of 600\n",
      "tensor(6.1236, grad_fn=<MeanBackward0>)\n",
      "[1472/1500] train_loss: 46.20807 valid_loss: 17.44498\n",
      "EarlyStopping counter: 94 out of 600\n",
      "tensor(5.3990, grad_fn=<MeanBackward0>)\n",
      "[1473/1500] train_loss: 75.04553 valid_loss: 35.90754\n",
      "EarlyStopping counter: 95 out of 600\n",
      "tensor(5.4488, grad_fn=<MeanBackward0>)\n",
      "[1474/1500] train_loss: 63.98234 valid_loss: 68.48383\n",
      "EarlyStopping counter: 96 out of 600\n",
      "tensor(4.2075, grad_fn=<MeanBackward0>)\n",
      "[1475/1500] train_loss: 51.93485 valid_loss: 140.35821\n",
      "EarlyStopping counter: 97 out of 600\n",
      "tensor(6.1111, grad_fn=<MeanBackward0>)\n",
      "[1476/1500] train_loss: 176.93682 valid_loss: 148.28918\n",
      "EarlyStopping counter: 98 out of 600\n",
      "tensor(2.9593, grad_fn=<MeanBackward0>)\n",
      "[1477/1500] train_loss: 35.40821 valid_loss: 22.38057\n",
      "EarlyStopping counter: 99 out of 600\n",
      "tensor(3.3407, grad_fn=<MeanBackward0>)\n",
      "[1478/1500] train_loss: 116.18605 valid_loss: 24.14484\n",
      "EarlyStopping counter: 100 out of 600\n",
      "tensor(4.2533, grad_fn=<MeanBackward0>)\n",
      "[1479/1500] train_loss: 84.69859 valid_loss: 78.40881\n",
      "EarlyStopping counter: 101 out of 600\n",
      "tensor(3.4737, grad_fn=<MeanBackward0>)\n",
      "[1480/1500] train_loss: 65.44488 valid_loss: 91.54668\n",
      "EarlyStopping counter: 102 out of 600\n",
      "tensor(4.3962, grad_fn=<MeanBackward0>)\n",
      "[1481/1500] train_loss: 47.19644 valid_loss: 38.82824\n",
      "EarlyStopping counter: 103 out of 600\n",
      "tensor(3.0438, grad_fn=<MeanBackward0>)\n",
      "[1482/1500] train_loss: 37.34034 valid_loss: 33.86228\n",
      "EarlyStopping counter: 104 out of 600\n",
      "tensor(4.8067, grad_fn=<MeanBackward0>)\n",
      "[1483/1500] train_loss: 54.49473 valid_loss: 64.44386\n",
      "EarlyStopping counter: 105 out of 600\n",
      "tensor(3.2635, grad_fn=<MeanBackward0>)\n",
      "[1484/1500] train_loss: 41.32978 valid_loss: 50.71099\n",
      "EarlyStopping counter: 106 out of 600\n",
      "tensor(3.5350, grad_fn=<MeanBackward0>)\n",
      "[1485/1500] train_loss: 86.19247 valid_loss: 25.44917\n",
      "EarlyStopping counter: 107 out of 600\n",
      "tensor(4.9680, grad_fn=<MeanBackward0>)\n",
      "[1486/1500] train_loss: 93.20882 valid_loss: 37.77238\n",
      "EarlyStopping counter: 108 out of 600\n",
      "tensor(3.9084, grad_fn=<MeanBackward0>)\n",
      "[1487/1500] train_loss: 13.15697 valid_loss: 45.98281\n",
      "EarlyStopping counter: 109 out of 600\n",
      "tensor(4.0997, grad_fn=<MeanBackward0>)\n",
      "[1488/1500] train_loss: 29.86291 valid_loss: 34.82942\n",
      "EarlyStopping counter: 110 out of 600\n",
      "tensor(5.4803, grad_fn=<MeanBackward0>)\n",
      "[1489/1500] train_loss: 167.62451 valid_loss: 16.32472\n",
      "EarlyStopping counter: 111 out of 600\n",
      "tensor(4.2732, grad_fn=<MeanBackward0>)\n",
      "[1490/1500] train_loss: 20.57925 valid_loss: 35.47093\n",
      "EarlyStopping counter: 112 out of 600\n",
      "tensor(3.3028, grad_fn=<MeanBackward0>)\n",
      "[1491/1500] train_loss: 38.49729 valid_loss: 64.67598\n",
      "EarlyStopping counter: 113 out of 600\n",
      "tensor(4.9096, grad_fn=<MeanBackward0>)\n",
      "[1492/1500] train_loss: 114.61587 valid_loss: 98.06531\n",
      "EarlyStopping counter: 114 out of 600\n",
      "tensor(5.9905, grad_fn=<MeanBackward0>)\n",
      "[1493/1500] train_loss: 89.27316 valid_loss: 123.23317\n",
      "EarlyStopping counter: 115 out of 600\n",
      "tensor(2.8291, grad_fn=<MeanBackward0>)\n",
      "[1494/1500] train_loss: 61.68742 valid_loss: 18.66759\n",
      "EarlyStopping counter: 116 out of 600\n",
      "tensor(5.7279, grad_fn=<MeanBackward0>)\n",
      "[1495/1500] train_loss: 52.41410 valid_loss: 33.99661\n",
      "EarlyStopping counter: 117 out of 600\n",
      "tensor(6.1897, grad_fn=<MeanBackward0>)\n",
      "[1496/1500] train_loss: 117.79444 valid_loss: 39.56536\n",
      "EarlyStopping counter: 118 out of 600\n",
      "tensor(4.9310, grad_fn=<MeanBackward0>)\n",
      "[1497/1500] train_loss: 28.22759 valid_loss: 13.13621\n",
      "EarlyStopping counter: 119 out of 600\n",
      "tensor(3.7069, grad_fn=<MeanBackward0>)\n",
      "[1498/1500] train_loss: 25.92665 valid_loss: 18.47770\n",
      "EarlyStopping counter: 120 out of 600\n",
      "tensor(4.2864, grad_fn=<MeanBackward0>)\n",
      "[1499/1500] train_loss: 15.98895 valid_loss: 35.59508\n",
      "EarlyStopping counter: 121 out of 600\n",
      "tensor(5.8074, grad_fn=<MeanBackward0>)\n",
      "[1500/1500] train_loss: 57.08575 valid_loss: 55.22574\n",
      "EarlyStopping counter: 122 out of 600\n",
      "--- 58.20164084434509 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# define the structure of the Recurrent Neural Network model\n",
    "model_PINN = RNN(3, 20, 256, 3)\n",
    "model_PINN.to(device)\n",
    "\n",
    "print(model_PINN)\n",
    "\n",
    "optimizer = torch.optim.Adam(model_PINN.parameters(),lr=1e-3) #1e-3\n",
    "\n",
    "n_epochs = 1500 # can be changed\n",
    "\n",
    "# early stopping patience; how long to wait after last time validation loss improved.\n",
    "patience = 600\n",
    "\n",
    "model, train_loss, valid_loss = train_model(model_PINN, patience, n_epochs)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2cac89",
   "metadata": {},
   "source": [
    "# Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f0d701d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 out of 1600\n",
      "2 out of 1600\n",
      "3 out of 1600\n",
      "4 out of 1600\n",
      "5 out of 1600\n",
      "6 out of 1600\n",
      "7 out of 1600\n",
      "8 out of 1600\n",
      "9 out of 1600\n",
      "10 out of 1600\n",
      "11 out of 1600\n",
      "12 out of 1600\n",
      "13 out of 1600\n",
      "14 out of 1600\n",
      "15 out of 1600\n",
      "16 out of 1600\n",
      "17 out of 1600\n",
      "18 out of 1600\n",
      "19 out of 1600\n",
      "20 out of 1600\n",
      "21 out of 1600\n",
      "22 out of 1600\n",
      "23 out of 1600\n",
      "24 out of 1600\n",
      "25 out of 1600\n",
      "26 out of 1600\n",
      "27 out of 1600\n",
      "28 out of 1600\n",
      "29 out of 1600\n",
      "30 out of 1600\n",
      "31 out of 1600\n",
      "32 out of 1600\n",
      "33 out of 1600\n",
      "34 out of 1600\n",
      "35 out of 1600\n",
      "36 out of 1600\n",
      "37 out of 1600\n",
      "38 out of 1600\n",
      "39 out of 1600\n",
      "40 out of 1600\n",
      "41 out of 1600\n",
      "42 out of 1600\n",
      "43 out of 1600\n",
      "44 out of 1600\n",
      "45 out of 1600\n",
      "46 out of 1600\n",
      "47 out of 1600\n",
      "48 out of 1600\n",
      "49 out of 1600\n",
      "50 out of 1600\n",
      "51 out of 1600\n",
      "52 out of 1600\n",
      "53 out of 1600\n",
      "54 out of 1600\n",
      "55 out of 1600\n",
      "56 out of 1600\n",
      "57 out of 1600\n",
      "58 out of 1600\n",
      "59 out of 1600\n",
      "60 out of 1600\n",
      "61 out of 1600\n",
      "62 out of 1600\n",
      "63 out of 1600\n",
      "64 out of 1600\n",
      "65 out of 1600\n",
      "66 out of 1600\n",
      "67 out of 1600\n",
      "68 out of 1600\n",
      "69 out of 1600\n",
      "70 out of 1600\n",
      "71 out of 1600\n",
      "72 out of 1600\n",
      "73 out of 1600\n",
      "74 out of 1600\n",
      "75 out of 1600\n",
      "76 out of 1600\n",
      "77 out of 1600\n",
      "78 out of 1600\n",
      "79 out of 1600\n",
      "80 out of 1600\n",
      "81 out of 1600\n",
      "82 out of 1600\n",
      "83 out of 1600\n",
      "84 out of 1600\n",
      "85 out of 1600\n",
      "86 out of 1600\n",
      "87 out of 1600\n",
      "88 out of 1600\n",
      "89 out of 1600\n",
      "90 out of 1600\n",
      "91 out of 1600\n",
      "92 out of 1600\n",
      "93 out of 1600\n",
      "94 out of 1600\n",
      "95 out of 1600\n",
      "96 out of 1600\n",
      "97 out of 1600\n",
      "98 out of 1600\n",
      "99 out of 1600\n",
      "100 out of 1600\n",
      "101 out of 1600\n",
      "102 out of 1600\n",
      "103 out of 1600\n",
      "104 out of 1600\n",
      "105 out of 1600\n",
      "106 out of 1600\n",
      "107 out of 1600\n",
      "108 out of 1600\n",
      "109 out of 1600\n",
      "110 out of 1600\n",
      "111 out of 1600\n",
      "112 out of 1600\n",
      "113 out of 1600\n",
      "114 out of 1600\n",
      "115 out of 1600\n",
      "116 out of 1600\n",
      "117 out of 1600\n",
      "118 out of 1600\n",
      "119 out of 1600\n",
      "120 out of 1600\n",
      "121 out of 1600\n",
      "122 out of 1600\n",
      "123 out of 1600\n",
      "124 out of 1600\n",
      "125 out of 1600\n",
      "126 out of 1600\n",
      "127 out of 1600\n",
      "128 out of 1600\n",
      "129 out of 1600\n",
      "130 out of 1600\n",
      "131 out of 1600\n",
      "132 out of 1600\n",
      "133 out of 1600\n",
      "134 out of 1600\n",
      "135 out of 1600\n",
      "136 out of 1600\n",
      "137 out of 1600\n",
      "138 out of 1600\n",
      "139 out of 1600\n",
      "140 out of 1600\n",
      "141 out of 1600\n",
      "142 out of 1600\n",
      "143 out of 1600\n",
      "144 out of 1600\n",
      "145 out of 1600\n",
      "146 out of 1600\n",
      "147 out of 1600\n",
      "148 out of 1600\n",
      "149 out of 1600\n",
      "150 out of 1600\n",
      "151 out of 1600\n",
      "152 out of 1600\n",
      "153 out of 1600\n",
      "154 out of 1600\n",
      "155 out of 1600\n",
      "156 out of 1600\n",
      "157 out of 1600\n",
      "158 out of 1600\n",
      "159 out of 1600\n",
      "160 out of 1600\n",
      "161 out of 1600\n",
      "162 out of 1600\n",
      "163 out of 1600\n",
      "164 out of 1600\n",
      "165 out of 1600\n",
      "166 out of 1600\n",
      "167 out of 1600\n",
      "168 out of 1600\n",
      "169 out of 1600\n",
      "170 out of 1600\n",
      "171 out of 1600\n",
      "172 out of 1600\n",
      "173 out of 1600\n",
      "174 out of 1600\n",
      "175 out of 1600\n",
      "176 out of 1600\n",
      "177 out of 1600\n",
      "178 out of 1600\n",
      "179 out of 1600\n",
      "180 out of 1600\n",
      "181 out of 1600\n",
      "182 out of 1600\n",
      "183 out of 1600\n",
      "184 out of 1600\n",
      "185 out of 1600\n",
      "186 out of 1600\n",
      "187 out of 1600\n",
      "188 out of 1600\n",
      "189 out of 1600\n",
      "190 out of 1600\n",
      "191 out of 1600\n",
      "192 out of 1600\n",
      "193 out of 1600\n",
      "194 out of 1600\n",
      "195 out of 1600\n",
      "196 out of 1600\n",
      "197 out of 1600\n",
      "198 out of 1600\n",
      "199 out of 1600\n",
      "200 out of 1600\n",
      "201 out of 1600\n",
      "202 out of 1600\n",
      "203 out of 1600\n",
      "204 out of 1600\n",
      "205 out of 1600\n",
      "206 out of 1600\n",
      "207 out of 1600\n",
      "208 out of 1600\n",
      "209 out of 1600\n",
      "210 out of 1600\n",
      "211 out of 1600\n",
      "212 out of 1600\n",
      "213 out of 1600\n",
      "214 out of 1600\n",
      "215 out of 1600\n",
      "216 out of 1600\n",
      "217 out of 1600\n",
      "218 out of 1600\n",
      "219 out of 1600\n",
      "220 out of 1600\n",
      "221 out of 1600\n",
      "222 out of 1600\n",
      "223 out of 1600\n",
      "224 out of 1600\n",
      "225 out of 1600\n",
      "226 out of 1600\n",
      "227 out of 1600\n",
      "228 out of 1600\n",
      "229 out of 1600\n",
      "230 out of 1600\n",
      "231 out of 1600\n",
      "232 out of 1600\n",
      "233 out of 1600\n",
      "234 out of 1600\n",
      "235 out of 1600\n",
      "236 out of 1600\n",
      "237 out of 1600\n",
      "238 out of 1600\n",
      "239 out of 1600\n",
      "240 out of 1600\n",
      "241 out of 1600\n",
      "242 out of 1600\n",
      "243 out of 1600\n",
      "244 out of 1600\n",
      "245 out of 1600\n",
      "246 out of 1600\n",
      "247 out of 1600\n",
      "248 out of 1600\n",
      "249 out of 1600\n",
      "250 out of 1600\n",
      "251 out of 1600\n",
      "252 out of 1600\n",
      "253 out of 1600\n",
      "254 out of 1600\n",
      "255 out of 1600\n",
      "256 out of 1600\n",
      "257 out of 1600\n",
      "258 out of 1600\n",
      "259 out of 1600\n",
      "260 out of 1600\n",
      "261 out of 1600\n",
      "262 out of 1600\n",
      "263 out of 1600\n",
      "264 out of 1600\n",
      "265 out of 1600\n",
      "266 out of 1600\n",
      "267 out of 1600\n",
      "268 out of 1600\n",
      "269 out of 1600\n",
      "270 out of 1600\n",
      "271 out of 1600\n",
      "272 out of 1600\n",
      "273 out of 1600\n",
      "274 out of 1600\n",
      "275 out of 1600\n",
      "276 out of 1600\n",
      "277 out of 1600\n",
      "278 out of 1600\n",
      "279 out of 1600\n",
      "280 out of 1600\n",
      "281 out of 1600\n",
      "282 out of 1600\n",
      "283 out of 1600\n",
      "284 out of 1600\n",
      "285 out of 1600\n",
      "286 out of 1600\n",
      "287 out of 1600\n",
      "288 out of 1600\n",
      "289 out of 1600\n",
      "290 out of 1600\n",
      "291 out of 1600\n",
      "292 out of 1600\n",
      "293 out of 1600\n",
      "294 out of 1600\n",
      "295 out of 1600\n",
      "296 out of 1600\n",
      "297 out of 1600\n",
      "298 out of 1600\n",
      "299 out of 1600\n",
      "300 out of 1600\n",
      "301 out of 1600\n",
      "302 out of 1600\n",
      "303 out of 1600\n",
      "304 out of 1600\n",
      "305 out of 1600\n",
      "306 out of 1600\n",
      "307 out of 1600\n",
      "308 out of 1600\n",
      "309 out of 1600\n",
      "310 out of 1600\n",
      "311 out of 1600\n",
      "312 out of 1600\n",
      "313 out of 1600\n",
      "314 out of 1600\n",
      "315 out of 1600\n",
      "316 out of 1600\n",
      "317 out of 1600\n",
      "318 out of 1600\n",
      "319 out of 1600\n",
      "320 out of 1600\n",
      "321 out of 1600\n",
      "322 out of 1600\n",
      "323 out of 1600\n",
      "324 out of 1600\n",
      "325 out of 1600\n",
      "326 out of 1600\n",
      "327 out of 1600\n",
      "328 out of 1600\n",
      "329 out of 1600\n",
      "330 out of 1600\n",
      "331 out of 1600\n",
      "332 out of 1600\n",
      "333 out of 1600\n",
      "334 out of 1600\n",
      "335 out of 1600\n",
      "336 out of 1600\n",
      "337 out of 1600\n",
      "338 out of 1600\n",
      "339 out of 1600\n",
      "340 out of 1600\n",
      "341 out of 1600\n",
      "342 out of 1600\n",
      "343 out of 1600\n",
      "344 out of 1600\n",
      "345 out of 1600\n",
      "346 out of 1600\n",
      "347 out of 1600\n",
      "348 out of 1600\n",
      "349 out of 1600\n",
      "350 out of 1600\n",
      "351 out of 1600\n",
      "352 out of 1600\n",
      "353 out of 1600\n",
      "354 out of 1600\n",
      "355 out of 1600\n",
      "356 out of 1600\n",
      "357 out of 1600\n",
      "358 out of 1600\n",
      "359 out of 1600\n",
      "360 out of 1600\n",
      "361 out of 1600\n",
      "362 out of 1600\n",
      "363 out of 1600\n",
      "364 out of 1600\n",
      "365 out of 1600\n",
      "366 out of 1600\n",
      "367 out of 1600\n",
      "368 out of 1600\n",
      "369 out of 1600\n",
      "370 out of 1600\n",
      "371 out of 1600\n",
      "372 out of 1600\n",
      "373 out of 1600\n",
      "374 out of 1600\n",
      "375 out of 1600\n",
      "376 out of 1600\n",
      "377 out of 1600\n",
      "378 out of 1600\n",
      "379 out of 1600\n",
      "380 out of 1600\n",
      "381 out of 1600\n",
      "382 out of 1600\n",
      "383 out of 1600\n",
      "384 out of 1600\n",
      "385 out of 1600\n",
      "386 out of 1600\n",
      "387 out of 1600\n",
      "388 out of 1600\n",
      "389 out of 1600\n",
      "390 out of 1600\n",
      "391 out of 1600\n",
      "392 out of 1600\n",
      "393 out of 1600\n",
      "394 out of 1600\n",
      "395 out of 1600\n",
      "396 out of 1600\n",
      "397 out of 1600\n",
      "398 out of 1600\n",
      "399 out of 1600\n",
      "400 out of 1600\n",
      "401 out of 1600\n",
      "402 out of 1600\n",
      "403 out of 1600\n",
      "404 out of 1600\n",
      "405 out of 1600\n",
      "406 out of 1600\n",
      "407 out of 1600\n",
      "408 out of 1600\n",
      "409 out of 1600\n",
      "410 out of 1600\n",
      "411 out of 1600\n",
      "412 out of 1600\n",
      "413 out of 1600\n",
      "414 out of 1600\n",
      "415 out of 1600\n",
      "416 out of 1600\n",
      "417 out of 1600\n",
      "418 out of 1600\n",
      "419 out of 1600\n",
      "420 out of 1600\n",
      "421 out of 1600\n",
      "422 out of 1600\n",
      "423 out of 1600\n",
      "424 out of 1600\n",
      "425 out of 1600\n",
      "426 out of 1600\n",
      "427 out of 1600\n",
      "428 out of 1600\n",
      "429 out of 1600\n",
      "430 out of 1600\n",
      "431 out of 1600\n",
      "432 out of 1600\n",
      "433 out of 1600\n",
      "434 out of 1600\n",
      "435 out of 1600\n",
      "436 out of 1600\n",
      "437 out of 1600\n",
      "438 out of 1600\n",
      "439 out of 1600\n",
      "440 out of 1600\n",
      "441 out of 1600\n",
      "442 out of 1600\n",
      "443 out of 1600\n",
      "444 out of 1600\n",
      "445 out of 1600\n",
      "446 out of 1600\n",
      "447 out of 1600\n",
      "448 out of 1600\n",
      "449 out of 1600\n",
      "450 out of 1600\n",
      "451 out of 1600\n",
      "452 out of 1600\n",
      "453 out of 1600\n",
      "454 out of 1600\n",
      "455 out of 1600\n",
      "456 out of 1600\n",
      "457 out of 1600\n",
      "458 out of 1600\n",
      "459 out of 1600\n",
      "460 out of 1600\n",
      "461 out of 1600\n",
      "462 out of 1600\n",
      "463 out of 1600\n",
      "464 out of 1600\n",
      "465 out of 1600\n",
      "466 out of 1600\n",
      "467 out of 1600\n",
      "468 out of 1600\n",
      "469 out of 1600\n",
      "470 out of 1600\n",
      "471 out of 1600\n",
      "472 out of 1600\n",
      "473 out of 1600\n",
      "474 out of 1600\n",
      "475 out of 1600\n",
      "476 out of 1600\n",
      "477 out of 1600\n",
      "478 out of 1600\n",
      "479 out of 1600\n",
      "480 out of 1600\n",
      "481 out of 1600\n",
      "482 out of 1600\n",
      "483 out of 1600\n",
      "484 out of 1600\n",
      "485 out of 1600\n",
      "486 out of 1600\n",
      "487 out of 1600\n",
      "488 out of 1600\n",
      "489 out of 1600\n",
      "490 out of 1600\n",
      "491 out of 1600\n",
      "492 out of 1600\n",
      "493 out of 1600\n",
      "494 out of 1600\n",
      "495 out of 1600\n",
      "496 out of 1600\n",
      "497 out of 1600\n",
      "498 out of 1600\n",
      "499 out of 1600\n",
      "500 out of 1600\n",
      "501 out of 1600\n",
      "502 out of 1600\n",
      "503 out of 1600\n",
      "504 out of 1600\n",
      "505 out of 1600\n",
      "506 out of 1600\n",
      "507 out of 1600\n",
      "508 out of 1600\n",
      "509 out of 1600\n",
      "510 out of 1600\n",
      "511 out of 1600\n",
      "512 out of 1600\n",
      "513 out of 1600\n",
      "514 out of 1600\n",
      "515 out of 1600\n",
      "516 out of 1600\n",
      "517 out of 1600\n",
      "518 out of 1600\n",
      "519 out of 1600\n",
      "520 out of 1600\n",
      "521 out of 1600\n",
      "522 out of 1600\n",
      "523 out of 1600\n",
      "524 out of 1600\n",
      "525 out of 1600\n",
      "526 out of 1600\n",
      "527 out of 1600\n",
      "528 out of 1600\n",
      "529 out of 1600\n",
      "530 out of 1600\n",
      "531 out of 1600\n",
      "532 out of 1600\n",
      "533 out of 1600\n",
      "534 out of 1600\n",
      "535 out of 1600\n",
      "536 out of 1600\n",
      "537 out of 1600\n",
      "538 out of 1600\n",
      "539 out of 1600\n",
      "540 out of 1600\n",
      "541 out of 1600\n",
      "542 out of 1600\n",
      "543 out of 1600\n",
      "544 out of 1600\n",
      "545 out of 1600\n",
      "546 out of 1600\n",
      "547 out of 1600\n",
      "548 out of 1600\n",
      "549 out of 1600\n",
      "550 out of 1600\n",
      "551 out of 1600\n",
      "552 out of 1600\n",
      "553 out of 1600\n",
      "554 out of 1600\n",
      "555 out of 1600\n",
      "556 out of 1600\n",
      "557 out of 1600\n",
      "558 out of 1600\n",
      "559 out of 1600\n",
      "560 out of 1600\n",
      "561 out of 1600\n",
      "562 out of 1600\n",
      "563 out of 1600\n",
      "564 out of 1600\n",
      "565 out of 1600\n",
      "566 out of 1600\n",
      "567 out of 1600\n",
      "568 out of 1600\n",
      "569 out of 1600\n",
      "570 out of 1600\n",
      "571 out of 1600\n",
      "572 out of 1600\n",
      "573 out of 1600\n",
      "574 out of 1600\n",
      "575 out of 1600\n",
      "576 out of 1600\n",
      "577 out of 1600\n",
      "578 out of 1600\n",
      "579 out of 1600\n",
      "580 out of 1600\n",
      "581 out of 1600\n",
      "582 out of 1600\n",
      "583 out of 1600\n",
      "584 out of 1600\n",
      "585 out of 1600\n",
      "586 out of 1600\n",
      "587 out of 1600\n",
      "588 out of 1600\n",
      "589 out of 1600\n",
      "590 out of 1600\n",
      "591 out of 1600\n",
      "592 out of 1600\n",
      "593 out of 1600\n",
      "594 out of 1600\n",
      "595 out of 1600\n",
      "596 out of 1600\n",
      "597 out of 1600\n",
      "598 out of 1600\n",
      "599 out of 1600\n",
      "600 out of 1600\n",
      "601 out of 1600\n",
      "602 out of 1600\n",
      "603 out of 1600\n",
      "604 out of 1600\n",
      "605 out of 1600\n",
      "606 out of 1600\n",
      "607 out of 1600\n",
      "608 out of 1600\n",
      "609 out of 1600\n",
      "610 out of 1600\n",
      "611 out of 1600\n",
      "612 out of 1600\n",
      "613 out of 1600\n",
      "614 out of 1600\n",
      "615 out of 1600\n",
      "616 out of 1600\n",
      "617 out of 1600\n",
      "618 out of 1600\n",
      "619 out of 1600\n",
      "620 out of 1600\n",
      "621 out of 1600\n",
      "622 out of 1600\n",
      "623 out of 1600\n",
      "624 out of 1600\n",
      "625 out of 1600\n",
      "626 out of 1600\n",
      "627 out of 1600\n",
      "628 out of 1600\n",
      "629 out of 1600\n",
      "630 out of 1600\n",
      "631 out of 1600\n",
      "632 out of 1600\n",
      "633 out of 1600\n",
      "634 out of 1600\n",
      "635 out of 1600\n",
      "636 out of 1600\n",
      "637 out of 1600\n",
      "638 out of 1600\n",
      "639 out of 1600\n",
      "640 out of 1600\n",
      "641 out of 1600\n",
      "642 out of 1600\n",
      "643 out of 1600\n",
      "644 out of 1600\n",
      "645 out of 1600\n",
      "646 out of 1600\n",
      "647 out of 1600\n",
      "648 out of 1600\n",
      "649 out of 1600\n",
      "650 out of 1600\n",
      "651 out of 1600\n",
      "652 out of 1600\n",
      "653 out of 1600\n",
      "654 out of 1600\n",
      "655 out of 1600\n",
      "656 out of 1600\n",
      "657 out of 1600\n",
      "658 out of 1600\n",
      "659 out of 1600\n",
      "660 out of 1600\n",
      "661 out of 1600\n",
      "662 out of 1600\n",
      "663 out of 1600\n",
      "664 out of 1600\n",
      "665 out of 1600\n",
      "666 out of 1600\n",
      "667 out of 1600\n",
      "668 out of 1600\n",
      "669 out of 1600\n",
      "670 out of 1600\n",
      "671 out of 1600\n",
      "672 out of 1600\n",
      "673 out of 1600\n",
      "674 out of 1600\n",
      "675 out of 1600\n",
      "676 out of 1600\n",
      "677 out of 1600\n",
      "678 out of 1600\n",
      "679 out of 1600\n",
      "680 out of 1600\n",
      "681 out of 1600\n",
      "682 out of 1600\n",
      "683 out of 1600\n",
      "684 out of 1600\n",
      "685 out of 1600\n",
      "686 out of 1600\n",
      "687 out of 1600\n",
      "688 out of 1600\n",
      "689 out of 1600\n",
      "690 out of 1600\n",
      "691 out of 1600\n",
      "692 out of 1600\n",
      "693 out of 1600\n",
      "694 out of 1600\n",
      "695 out of 1600\n",
      "696 out of 1600\n",
      "697 out of 1600\n",
      "698 out of 1600\n",
      "699 out of 1600\n",
      "700 out of 1600\n",
      "701 out of 1600\n",
      "702 out of 1600\n",
      "703 out of 1600\n",
      "704 out of 1600\n",
      "705 out of 1600\n",
      "706 out of 1600\n",
      "707 out of 1600\n",
      "708 out of 1600\n",
      "709 out of 1600\n",
      "710 out of 1600\n",
      "711 out of 1600\n",
      "712 out of 1600\n",
      "713 out of 1600\n",
      "714 out of 1600\n",
      "715 out of 1600\n",
      "716 out of 1600\n",
      "717 out of 1600\n",
      "718 out of 1600\n",
      "719 out of 1600\n",
      "720 out of 1600\n",
      "721 out of 1600\n",
      "722 out of 1600\n",
      "723 out of 1600\n",
      "724 out of 1600\n",
      "725 out of 1600\n",
      "726 out of 1600\n",
      "727 out of 1600\n",
      "728 out of 1600\n",
      "729 out of 1600\n",
      "730 out of 1600\n",
      "731 out of 1600\n",
      "732 out of 1600\n",
      "733 out of 1600\n",
      "734 out of 1600\n",
      "735 out of 1600\n",
      "736 out of 1600\n",
      "737 out of 1600\n",
      "738 out of 1600\n",
      "739 out of 1600\n",
      "740 out of 1600\n",
      "741 out of 1600\n",
      "742 out of 1600\n",
      "743 out of 1600\n",
      "744 out of 1600\n",
      "745 out of 1600\n",
      "746 out of 1600\n",
      "747 out of 1600\n",
      "748 out of 1600\n",
      "749 out of 1600\n",
      "750 out of 1600\n",
      "751 out of 1600\n",
      "752 out of 1600\n",
      "753 out of 1600\n",
      "754 out of 1600\n",
      "755 out of 1600\n",
      "756 out of 1600\n",
      "757 out of 1600\n",
      "758 out of 1600\n",
      "759 out of 1600\n",
      "760 out of 1600\n",
      "761 out of 1600\n",
      "762 out of 1600\n",
      "763 out of 1600\n",
      "764 out of 1600\n",
      "765 out of 1600\n",
      "766 out of 1600\n",
      "767 out of 1600\n",
      "768 out of 1600\n",
      "769 out of 1600\n",
      "770 out of 1600\n",
      "771 out of 1600\n",
      "772 out of 1600\n",
      "773 out of 1600\n",
      "774 out of 1600\n",
      "775 out of 1600\n",
      "776 out of 1600\n",
      "777 out of 1600\n",
      "778 out of 1600\n",
      "779 out of 1600\n",
      "780 out of 1600\n",
      "781 out of 1600\n",
      "782 out of 1600\n",
      "783 out of 1600\n",
      "784 out of 1600\n",
      "785 out of 1600\n",
      "786 out of 1600\n",
      "787 out of 1600\n",
      "788 out of 1600\n",
      "789 out of 1600\n",
      "790 out of 1600\n",
      "791 out of 1600\n",
      "792 out of 1600\n",
      "793 out of 1600\n",
      "794 out of 1600\n",
      "795 out of 1600\n",
      "796 out of 1600\n",
      "797 out of 1600\n",
      "798 out of 1600\n",
      "799 out of 1600\n",
      "800 out of 1600\n",
      "801 out of 1600\n",
      "802 out of 1600\n",
      "803 out of 1600\n",
      "804 out of 1600\n",
      "805 out of 1600\n",
      "806 out of 1600\n",
      "807 out of 1600\n",
      "808 out of 1600\n",
      "809 out of 1600\n",
      "810 out of 1600\n",
      "811 out of 1600\n",
      "812 out of 1600\n",
      "813 out of 1600\n",
      "814 out of 1600\n",
      "815 out of 1600\n",
      "816 out of 1600\n",
      "817 out of 1600\n",
      "818 out of 1600\n",
      "819 out of 1600\n",
      "820 out of 1600\n",
      "821 out of 1600\n",
      "822 out of 1600\n",
      "823 out of 1600\n",
      "824 out of 1600\n",
      "825 out of 1600\n",
      "826 out of 1600\n",
      "827 out of 1600\n",
      "828 out of 1600\n",
      "829 out of 1600\n",
      "830 out of 1600\n",
      "831 out of 1600\n",
      "832 out of 1600\n",
      "833 out of 1600\n",
      "834 out of 1600\n",
      "835 out of 1600\n",
      "836 out of 1600\n",
      "837 out of 1600\n",
      "838 out of 1600\n",
      "839 out of 1600\n",
      "840 out of 1600\n",
      "841 out of 1600\n",
      "842 out of 1600\n",
      "843 out of 1600\n",
      "844 out of 1600\n",
      "845 out of 1600\n",
      "846 out of 1600\n",
      "847 out of 1600\n",
      "848 out of 1600\n",
      "849 out of 1600\n",
      "850 out of 1600\n",
      "851 out of 1600\n",
      "852 out of 1600\n",
      "853 out of 1600\n",
      "854 out of 1600\n",
      "855 out of 1600\n",
      "856 out of 1600\n",
      "857 out of 1600\n",
      "858 out of 1600\n",
      "859 out of 1600\n",
      "860 out of 1600\n",
      "861 out of 1600\n",
      "862 out of 1600\n",
      "863 out of 1600\n",
      "864 out of 1600\n",
      "865 out of 1600\n",
      "866 out of 1600\n",
      "867 out of 1600\n",
      "868 out of 1600\n",
      "869 out of 1600\n",
      "870 out of 1600\n",
      "871 out of 1600\n",
      "872 out of 1600\n",
      "873 out of 1600\n",
      "874 out of 1600\n",
      "875 out of 1600\n",
      "876 out of 1600\n",
      "877 out of 1600\n",
      "878 out of 1600\n",
      "879 out of 1600\n",
      "880 out of 1600\n",
      "881 out of 1600\n",
      "882 out of 1600\n",
      "883 out of 1600\n",
      "884 out of 1600\n",
      "885 out of 1600\n",
      "886 out of 1600\n",
      "887 out of 1600\n",
      "888 out of 1600\n",
      "889 out of 1600\n",
      "890 out of 1600\n",
      "891 out of 1600\n",
      "892 out of 1600\n",
      "893 out of 1600\n",
      "894 out of 1600\n",
      "895 out of 1600\n",
      "896 out of 1600\n",
      "897 out of 1600\n",
      "898 out of 1600\n",
      "899 out of 1600\n",
      "900 out of 1600\n",
      "901 out of 1600\n",
      "902 out of 1600\n",
      "903 out of 1600\n",
      "904 out of 1600\n",
      "905 out of 1600\n",
      "906 out of 1600\n",
      "907 out of 1600\n",
      "908 out of 1600\n",
      "909 out of 1600\n",
      "910 out of 1600\n",
      "911 out of 1600\n",
      "912 out of 1600\n",
      "913 out of 1600\n",
      "914 out of 1600\n",
      "915 out of 1600\n",
      "916 out of 1600\n",
      "917 out of 1600\n",
      "918 out of 1600\n",
      "919 out of 1600\n",
      "920 out of 1600\n",
      "921 out of 1600\n",
      "922 out of 1600\n",
      "923 out of 1600\n",
      "924 out of 1600\n",
      "925 out of 1600\n",
      "926 out of 1600\n",
      "927 out of 1600\n",
      "928 out of 1600\n",
      "929 out of 1600\n",
      "930 out of 1600\n",
      "931 out of 1600\n",
      "932 out of 1600\n",
      "933 out of 1600\n",
      "934 out of 1600\n",
      "935 out of 1600\n",
      "936 out of 1600\n",
      "937 out of 1600\n",
      "938 out of 1600\n",
      "939 out of 1600\n",
      "940 out of 1600\n",
      "941 out of 1600\n",
      "942 out of 1600\n",
      "943 out of 1600\n",
      "944 out of 1600\n",
      "945 out of 1600\n",
      "946 out of 1600\n",
      "947 out of 1600\n",
      "948 out of 1600\n",
      "949 out of 1600\n",
      "950 out of 1600\n",
      "951 out of 1600\n",
      "952 out of 1600\n",
      "953 out of 1600\n",
      "954 out of 1600\n",
      "955 out of 1600\n",
      "956 out of 1600\n",
      "957 out of 1600\n",
      "958 out of 1600\n",
      "959 out of 1600\n",
      "960 out of 1600\n",
      "961 out of 1600\n",
      "962 out of 1600\n",
      "963 out of 1600\n",
      "964 out of 1600\n",
      "965 out of 1600\n",
      "966 out of 1600\n",
      "967 out of 1600\n",
      "968 out of 1600\n",
      "969 out of 1600\n",
      "970 out of 1600\n",
      "971 out of 1600\n",
      "972 out of 1600\n",
      "973 out of 1600\n",
      "974 out of 1600\n",
      "975 out of 1600\n",
      "976 out of 1600\n",
      "977 out of 1600\n",
      "978 out of 1600\n",
      "979 out of 1600\n",
      "980 out of 1600\n",
      "981 out of 1600\n",
      "982 out of 1600\n",
      "983 out of 1600\n",
      "984 out of 1600\n",
      "985 out of 1600\n",
      "986 out of 1600\n",
      "987 out of 1600\n",
      "988 out of 1600\n",
      "989 out of 1600\n",
      "990 out of 1600\n",
      "991 out of 1600\n",
      "992 out of 1600\n",
      "993 out of 1600\n",
      "994 out of 1600\n",
      "995 out of 1600\n",
      "996 out of 1600\n",
      "997 out of 1600\n",
      "998 out of 1600\n",
      "999 out of 1600\n",
      "1000 out of 1600\n",
      "1001 out of 1600\n",
      "1002 out of 1600\n",
      "1003 out of 1600\n",
      "1004 out of 1600\n",
      "1005 out of 1600\n",
      "1006 out of 1600\n",
      "1007 out of 1600\n",
      "1008 out of 1600\n",
      "1009 out of 1600\n",
      "1010 out of 1600\n",
      "1011 out of 1600\n",
      "1012 out of 1600\n",
      "1013 out of 1600\n",
      "1014 out of 1600\n",
      "1015 out of 1600\n",
      "1016 out of 1600\n",
      "1017 out of 1600\n",
      "1018 out of 1600\n",
      "1019 out of 1600\n",
      "1020 out of 1600\n",
      "1021 out of 1600\n",
      "1022 out of 1600\n",
      "1023 out of 1600\n",
      "1024 out of 1600\n",
      "1025 out of 1600\n",
      "1026 out of 1600\n",
      "1027 out of 1600\n",
      "1028 out of 1600\n",
      "1029 out of 1600\n",
      "1030 out of 1600\n",
      "1031 out of 1600\n",
      "1032 out of 1600\n",
      "1033 out of 1600\n",
      "1034 out of 1600\n",
      "1035 out of 1600\n",
      "1036 out of 1600\n",
      "1037 out of 1600\n",
      "1038 out of 1600\n",
      "1039 out of 1600\n",
      "1040 out of 1600\n",
      "1041 out of 1600\n",
      "1042 out of 1600\n",
      "1043 out of 1600\n",
      "1044 out of 1600\n",
      "1045 out of 1600\n",
      "1046 out of 1600\n",
      "1047 out of 1600\n",
      "1048 out of 1600\n",
      "1049 out of 1600\n",
      "1050 out of 1600\n",
      "1051 out of 1600\n",
      "1052 out of 1600\n",
      "1053 out of 1600\n",
      "1054 out of 1600\n",
      "1055 out of 1600\n",
      "1056 out of 1600\n",
      "1057 out of 1600\n",
      "1058 out of 1600\n",
      "1059 out of 1600\n",
      "1060 out of 1600\n",
      "1061 out of 1600\n",
      "1062 out of 1600\n",
      "1063 out of 1600\n",
      "1064 out of 1600\n",
      "1065 out of 1600\n",
      "1066 out of 1600\n",
      "1067 out of 1600\n",
      "1068 out of 1600\n",
      "1069 out of 1600\n",
      "1070 out of 1600\n",
      "1071 out of 1600\n",
      "1072 out of 1600\n",
      "1073 out of 1600\n",
      "1074 out of 1600\n",
      "1075 out of 1600\n",
      "1076 out of 1600\n",
      "1077 out of 1600\n",
      "1078 out of 1600\n",
      "1079 out of 1600\n",
      "1080 out of 1600\n",
      "1081 out of 1600\n",
      "1082 out of 1600\n",
      "1083 out of 1600\n",
      "1084 out of 1600\n",
      "1085 out of 1600\n",
      "1086 out of 1600\n",
      "1087 out of 1600\n",
      "1088 out of 1600\n",
      "1089 out of 1600\n",
      "1090 out of 1600\n",
      "1091 out of 1600\n",
      "1092 out of 1600\n",
      "1093 out of 1600\n",
      "1094 out of 1600\n",
      "1095 out of 1600\n",
      "1096 out of 1600\n",
      "1097 out of 1600\n",
      "1098 out of 1600\n",
      "1099 out of 1600\n",
      "1100 out of 1600\n",
      "1101 out of 1600\n",
      "1102 out of 1600\n",
      "1103 out of 1600\n",
      "1104 out of 1600\n",
      "1105 out of 1600\n",
      "1106 out of 1600\n",
      "1107 out of 1600\n",
      "1108 out of 1600\n",
      "1109 out of 1600\n",
      "1110 out of 1600\n",
      "1111 out of 1600\n",
      "1112 out of 1600\n",
      "1113 out of 1600\n",
      "1114 out of 1600\n",
      "1115 out of 1600\n",
      "1116 out of 1600\n",
      "1117 out of 1600\n",
      "1118 out of 1600\n",
      "1119 out of 1600\n",
      "1120 out of 1600\n",
      "1121 out of 1600\n",
      "1122 out of 1600\n",
      "1123 out of 1600\n",
      "1124 out of 1600\n",
      "1125 out of 1600\n",
      "1126 out of 1600\n",
      "1127 out of 1600\n",
      "1128 out of 1600\n",
      "1129 out of 1600\n",
      "1130 out of 1600\n",
      "1131 out of 1600\n",
      "1132 out of 1600\n",
      "1133 out of 1600\n",
      "1134 out of 1600\n",
      "1135 out of 1600\n",
      "1136 out of 1600\n",
      "1137 out of 1600\n",
      "1138 out of 1600\n",
      "1139 out of 1600\n",
      "1140 out of 1600\n",
      "1141 out of 1600\n",
      "1142 out of 1600\n",
      "1143 out of 1600\n",
      "1144 out of 1600\n",
      "1145 out of 1600\n",
      "1146 out of 1600\n",
      "1147 out of 1600\n",
      "1148 out of 1600\n",
      "1149 out of 1600\n",
      "1150 out of 1600\n",
      "1151 out of 1600\n",
      "1152 out of 1600\n",
      "1153 out of 1600\n",
      "1154 out of 1600\n",
      "1155 out of 1600\n",
      "1156 out of 1600\n",
      "1157 out of 1600\n",
      "1158 out of 1600\n",
      "1159 out of 1600\n",
      "1160 out of 1600\n",
      "1161 out of 1600\n",
      "1162 out of 1600\n",
      "1163 out of 1600\n",
      "1164 out of 1600\n",
      "1165 out of 1600\n",
      "1166 out of 1600\n",
      "1167 out of 1600\n",
      "1168 out of 1600\n",
      "1169 out of 1600\n",
      "1170 out of 1600\n",
      "1171 out of 1600\n",
      "1172 out of 1600\n",
      "1173 out of 1600\n",
      "1174 out of 1600\n",
      "1175 out of 1600\n",
      "1176 out of 1600\n",
      "1177 out of 1600\n",
      "1178 out of 1600\n",
      "1179 out of 1600\n",
      "1180 out of 1600\n",
      "1181 out of 1600\n",
      "1182 out of 1600\n",
      "1183 out of 1600\n",
      "1184 out of 1600\n",
      "1185 out of 1600\n",
      "1186 out of 1600\n",
      "1187 out of 1600\n",
      "1188 out of 1600\n",
      "1189 out of 1600\n",
      "1190 out of 1600\n",
      "1191 out of 1600\n",
      "1192 out of 1600\n",
      "1193 out of 1600\n",
      "1194 out of 1600\n",
      "1195 out of 1600\n",
      "1196 out of 1600\n",
      "1197 out of 1600\n",
      "1198 out of 1600\n",
      "1199 out of 1600\n",
      "1200 out of 1600\n",
      "1201 out of 1600\n",
      "1202 out of 1600\n",
      "1203 out of 1600\n",
      "1204 out of 1600\n",
      "1205 out of 1600\n",
      "1206 out of 1600\n",
      "1207 out of 1600\n",
      "1208 out of 1600\n",
      "1209 out of 1600\n",
      "1210 out of 1600\n",
      "1211 out of 1600\n",
      "1212 out of 1600\n",
      "1213 out of 1600\n",
      "1214 out of 1600\n",
      "1215 out of 1600\n",
      "1216 out of 1600\n",
      "1217 out of 1600\n",
      "1218 out of 1600\n",
      "1219 out of 1600\n",
      "1220 out of 1600\n",
      "1221 out of 1600\n",
      "1222 out of 1600\n",
      "1223 out of 1600\n",
      "1224 out of 1600\n",
      "1225 out of 1600\n",
      "1226 out of 1600\n",
      "1227 out of 1600\n",
      "1228 out of 1600\n",
      "1229 out of 1600\n",
      "1230 out of 1600\n",
      "1231 out of 1600\n",
      "1232 out of 1600\n",
      "1233 out of 1600\n",
      "1234 out of 1600\n",
      "1235 out of 1600\n",
      "1236 out of 1600\n",
      "1237 out of 1600\n",
      "1238 out of 1600\n",
      "1239 out of 1600\n",
      "1240 out of 1600\n",
      "1241 out of 1600\n",
      "1242 out of 1600\n",
      "1243 out of 1600\n",
      "1244 out of 1600\n",
      "1245 out of 1600\n",
      "1246 out of 1600\n",
      "1247 out of 1600\n",
      "1248 out of 1600\n",
      "1249 out of 1600\n",
      "1250 out of 1600\n",
      "1251 out of 1600\n",
      "1252 out of 1600\n",
      "1253 out of 1600\n",
      "1254 out of 1600\n",
      "1255 out of 1600\n",
      "1256 out of 1600\n",
      "1257 out of 1600\n",
      "1258 out of 1600\n",
      "1259 out of 1600\n",
      "1260 out of 1600\n",
      "1261 out of 1600\n",
      "1262 out of 1600\n",
      "1263 out of 1600\n",
      "1264 out of 1600\n",
      "1265 out of 1600\n",
      "1266 out of 1600\n",
      "1267 out of 1600\n",
      "1268 out of 1600\n",
      "1269 out of 1600\n",
      "1270 out of 1600\n",
      "1271 out of 1600\n",
      "1272 out of 1600\n",
      "1273 out of 1600\n",
      "1274 out of 1600\n",
      "1275 out of 1600\n",
      "1276 out of 1600\n",
      "1277 out of 1600\n",
      "1278 out of 1600\n",
      "1279 out of 1600\n",
      "1280 out of 1600\n",
      "1281 out of 1600\n",
      "1282 out of 1600\n",
      "1283 out of 1600\n",
      "1284 out of 1600\n",
      "1285 out of 1600\n",
      "1286 out of 1600\n",
      "1287 out of 1600\n",
      "1288 out of 1600\n",
      "1289 out of 1600\n",
      "1290 out of 1600\n",
      "1291 out of 1600\n",
      "1292 out of 1600\n",
      "1293 out of 1600\n",
      "1294 out of 1600\n",
      "1295 out of 1600\n",
      "1296 out of 1600\n",
      "1297 out of 1600\n",
      "1298 out of 1600\n",
      "1299 out of 1600\n",
      "1300 out of 1600\n",
      "1301 out of 1600\n",
      "1302 out of 1600\n",
      "1303 out of 1600\n",
      "1304 out of 1600\n",
      "1305 out of 1600\n",
      "1306 out of 1600\n",
      "1307 out of 1600\n",
      "1308 out of 1600\n",
      "1309 out of 1600\n",
      "1310 out of 1600\n",
      "1311 out of 1600\n",
      "1312 out of 1600\n",
      "1313 out of 1600\n",
      "1314 out of 1600\n",
      "1315 out of 1600\n",
      "1316 out of 1600\n",
      "1317 out of 1600\n",
      "1318 out of 1600\n",
      "1319 out of 1600\n",
      "1320 out of 1600\n",
      "1321 out of 1600\n",
      "1322 out of 1600\n",
      "1323 out of 1600\n",
      "1324 out of 1600\n",
      "1325 out of 1600\n",
      "1326 out of 1600\n",
      "1327 out of 1600\n",
      "1328 out of 1600\n",
      "1329 out of 1600\n",
      "1330 out of 1600\n",
      "1331 out of 1600\n",
      "1332 out of 1600\n",
      "1333 out of 1600\n",
      "1334 out of 1600\n",
      "1335 out of 1600\n",
      "1336 out of 1600\n",
      "1337 out of 1600\n",
      "1338 out of 1600\n",
      "1339 out of 1600\n",
      "1340 out of 1600\n",
      "1341 out of 1600\n",
      "1342 out of 1600\n",
      "1343 out of 1600\n",
      "1344 out of 1600\n",
      "1345 out of 1600\n",
      "1346 out of 1600\n",
      "1347 out of 1600\n",
      "1348 out of 1600\n",
      "1349 out of 1600\n",
      "1350 out of 1600\n",
      "1351 out of 1600\n",
      "1352 out of 1600\n",
      "1353 out of 1600\n",
      "1354 out of 1600\n",
      "1355 out of 1600\n",
      "1356 out of 1600\n",
      "1357 out of 1600\n",
      "1358 out of 1600\n",
      "1359 out of 1600\n",
      "1360 out of 1600\n",
      "1361 out of 1600\n",
      "1362 out of 1600\n",
      "1363 out of 1600\n",
      "1364 out of 1600\n",
      "1365 out of 1600\n",
      "1366 out of 1600\n",
      "1367 out of 1600\n",
      "1368 out of 1600\n",
      "1369 out of 1600\n",
      "1370 out of 1600\n",
      "1371 out of 1600\n",
      "1372 out of 1600\n",
      "1373 out of 1600\n",
      "1374 out of 1600\n",
      "1375 out of 1600\n",
      "1376 out of 1600\n",
      "1377 out of 1600\n",
      "1378 out of 1600\n",
      "1379 out of 1600\n",
      "1380 out of 1600\n",
      "1381 out of 1600\n",
      "1382 out of 1600\n",
      "1383 out of 1600\n",
      "1384 out of 1600\n",
      "1385 out of 1600\n",
      "1386 out of 1600\n",
      "1387 out of 1600\n",
      "1388 out of 1600\n",
      "1389 out of 1600\n",
      "1390 out of 1600\n",
      "1391 out of 1600\n",
      "1392 out of 1600\n",
      "1393 out of 1600\n",
      "1394 out of 1600\n",
      "1395 out of 1600\n",
      "1396 out of 1600\n",
      "1397 out of 1600\n",
      "1398 out of 1600\n",
      "1399 out of 1600\n",
      "1400 out of 1600\n",
      "1401 out of 1600\n",
      "1402 out of 1600\n",
      "1403 out of 1600\n",
      "1404 out of 1600\n",
      "1405 out of 1600\n",
      "1406 out of 1600\n",
      "1407 out of 1600\n",
      "1408 out of 1600\n",
      "1409 out of 1600\n",
      "1410 out of 1600\n",
      "1411 out of 1600\n",
      "1412 out of 1600\n",
      "1413 out of 1600\n",
      "1414 out of 1600\n",
      "1415 out of 1600\n",
      "1416 out of 1600\n",
      "1417 out of 1600\n",
      "1418 out of 1600\n",
      "1419 out of 1600\n",
      "1420 out of 1600\n",
      "1421 out of 1600\n",
      "1422 out of 1600\n",
      "1423 out of 1600\n",
      "1424 out of 1600\n",
      "1425 out of 1600\n",
      "1426 out of 1600\n",
      "1427 out of 1600\n",
      "1428 out of 1600\n",
      "1429 out of 1600\n",
      "1430 out of 1600\n",
      "1431 out of 1600\n",
      "1432 out of 1600\n",
      "1433 out of 1600\n",
      "1434 out of 1600\n",
      "1435 out of 1600\n",
      "1436 out of 1600\n",
      "1437 out of 1600\n",
      "1438 out of 1600\n",
      "1439 out of 1600\n",
      "1440 out of 1600\n",
      "1441 out of 1600\n",
      "1442 out of 1600\n",
      "1443 out of 1600\n",
      "1444 out of 1600\n",
      "1445 out of 1600\n",
      "1446 out of 1600\n",
      "1447 out of 1600\n",
      "1448 out of 1600\n",
      "1449 out of 1600\n",
      "1450 out of 1600\n",
      "1451 out of 1600\n",
      "1452 out of 1600\n",
      "1453 out of 1600\n",
      "1454 out of 1600\n",
      "1455 out of 1600\n",
      "1456 out of 1600\n",
      "1457 out of 1600\n",
      "1458 out of 1600\n",
      "1459 out of 1600\n",
      "1460 out of 1600\n",
      "1461 out of 1600\n",
      "1462 out of 1600\n",
      "1463 out of 1600\n",
      "1464 out of 1600\n",
      "1465 out of 1600\n",
      "1466 out of 1600\n",
      "1467 out of 1600\n",
      "1468 out of 1600\n",
      "1469 out of 1600\n",
      "1470 out of 1600\n",
      "1471 out of 1600\n",
      "1472 out of 1600\n",
      "1473 out of 1600\n",
      "1474 out of 1600\n",
      "1475 out of 1600\n",
      "1476 out of 1600\n",
      "1477 out of 1600\n",
      "1478 out of 1600\n",
      "1479 out of 1600\n",
      "1480 out of 1600\n",
      "1481 out of 1600\n",
      "1482 out of 1600\n",
      "1483 out of 1600\n",
      "1484 out of 1600\n",
      "1485 out of 1600\n",
      "1486 out of 1600\n",
      "1487 out of 1600\n",
      "1488 out of 1600\n",
      "1489 out of 1600\n",
      "1490 out of 1600\n",
      "1491 out of 1600\n",
      "1492 out of 1600\n",
      "1493 out of 1600\n",
      "1494 out of 1600\n",
      "1495 out of 1600\n",
      "1496 out of 1600\n",
      "1497 out of 1600\n",
      "1498 out of 1600\n",
      "1499 out of 1600\n",
      "1500 out of 1600\n",
      "1501 out of 1600\n",
      "1502 out of 1600\n",
      "1503 out of 1600\n",
      "1504 out of 1600\n",
      "1505 out of 1600\n",
      "1506 out of 1600\n",
      "1507 out of 1600\n",
      "1508 out of 1600\n",
      "1509 out of 1600\n",
      "1510 out of 1600\n",
      "1511 out of 1600\n",
      "1512 out of 1600\n",
      "1513 out of 1600\n",
      "1514 out of 1600\n",
      "1515 out of 1600\n",
      "1516 out of 1600\n",
      "1517 out of 1600\n",
      "1518 out of 1600\n",
      "1519 out of 1600\n",
      "1520 out of 1600\n",
      "1521 out of 1600\n",
      "1522 out of 1600\n",
      "1523 out of 1600\n",
      "1524 out of 1600\n",
      "1525 out of 1600\n",
      "1526 out of 1600\n",
      "1527 out of 1600\n",
      "1528 out of 1600\n",
      "1529 out of 1600\n",
      "1530 out of 1600\n",
      "1531 out of 1600\n",
      "1532 out of 1600\n",
      "1533 out of 1600\n",
      "1534 out of 1600\n",
      "1535 out of 1600\n",
      "1536 out of 1600\n",
      "1537 out of 1600\n",
      "1538 out of 1600\n",
      "1539 out of 1600\n",
      "1540 out of 1600\n",
      "1541 out of 1600\n",
      "1542 out of 1600\n",
      "1543 out of 1600\n",
      "1544 out of 1600\n",
      "1545 out of 1600\n",
      "1546 out of 1600\n",
      "1547 out of 1600\n",
      "1548 out of 1600\n",
      "1549 out of 1600\n",
      "1550 out of 1600\n",
      "1551 out of 1600\n",
      "1552 out of 1600\n",
      "1553 out of 1600\n",
      "1554 out of 1600\n",
      "1555 out of 1600\n",
      "1556 out of 1600\n",
      "1557 out of 1600\n",
      "1558 out of 1600\n",
      "1559 out of 1600\n",
      "1560 out of 1600\n",
      "1561 out of 1600\n",
      "1562 out of 1600\n",
      "1563 out of 1600\n",
      "1564 out of 1600\n",
      "1565 out of 1600\n",
      "1566 out of 1600\n",
      "1567 out of 1600\n",
      "1568 out of 1600\n",
      "1569 out of 1600\n",
      "1570 out of 1600\n",
      "1571 out of 1600\n",
      "1572 out of 1600\n",
      "1573 out of 1600\n",
      "1574 out of 1600\n",
      "1575 out of 1600\n",
      "1576 out of 1600\n",
      "1577 out of 1600\n",
      "1578 out of 1600\n",
      "1579 out of 1600\n",
      "1580 out of 1600\n",
      "1581 out of 1600\n",
      "1582 out of 1600\n",
      "1583 out of 1600\n",
      "1584 out of 1600\n",
      "1585 out of 1600\n",
      "1586 out of 1600\n",
      "1587 out of 1600\n",
      "1588 out of 1600\n",
      "1589 out of 1600\n",
      "1590 out of 1600\n",
      "1591 out of 1600\n",
      "1592 out of 1600\n",
      "1593 out of 1600\n",
      "1594 out of 1600\n",
      "1595 out of 1600\n",
      "1596 out of 1600\n",
      "1597 out of 1600\n",
      "1598 out of 1600\n",
      "1599 out of 1600\n",
      "1600 out of 1600\n"
     ]
    }
   ],
   "source": [
    "y_test_error = list()\n",
    "total_batch_num = y_test.shape[0]\n",
    "\n",
    "for batch_num, (x_batch_test, y_test_batch) in enumerate(dataloader_physics_test, 1):\n",
    "    print(f\"{batch_num} out of {total_batch_num}\")\n",
    "    model.eval()\n",
    "    model.to(\"cpu\")\n",
    "    \n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    x_batch_test = x_batch_test[0]\n",
    "    y_test_batch = y_test_batch[0].to(device)\n",
    "    NN_output = model(x_batch_test)\n",
    "\n",
    "    \n",
    "    # Data-driven loss\n",
    "    loss1 = torch.mean((NN_output[:, :10] -  y_test_batch[:, :10])**2)  # use mean squared error\n",
    "    loss1_1 = torch.mean((NN_output[:, 10:] - y_test_batch[:, 10:])**2)  # use mean squared error\n",
    "        \n",
    "    \n",
    "    # for inital condition\n",
    "    loss2 = torch.mean((NN_output[0, :] - y_test_batch[0, :])**2)    \n",
    "    \n",
    "    # collocation point loss\n",
    "    loss21 = torch.mean((NN_output[0, [0,10]] - x_batch_test[0, 1:])**2)\n",
    "    \n",
    "    \n",
    "    # compute the \"physics loss\"\n",
    "    Tc = x_batch_test[:, 0] * std_Tc + mean_Tc + Tc_s\n",
    "            \n",
    "\n",
    "    # Reversing standardization\n",
    "    NN_output = NN_output * std_y.to(device) + mean_y.to(device)\n",
    "            \n",
    "            \n",
    "    dCA_first = (NN_output[ 1:2, :10] - NN_output[0:1, :10]) / (t_step)\n",
    "    dT_first = (NN_output[ 1:2, 10:] - NN_output[ 0:1, 10:]) / (t_step)\n",
    "            \n",
    "            \n",
    "    dCA_center = (NN_output[ 2:, :10] - NN_output[ :-2, :10]) / (2*t_step)\n",
    "    dT_center = (NN_output[ 2:, 10:] - NN_output[:-2, 10:]) / (2*t_step)\n",
    "            \n",
    "            \n",
    "    dCA_last = (NN_output[ -1:, :10] - NN_output[ -2:-1, :10]) / (t_step)\n",
    "    dT_last = (NN_output[ -1:, 10:] - NN_output[ -2:-1, 10:]) / (t_step)\n",
    "\n",
    "\n",
    "    dCA = torch.cat((dCA_first, dCA_center, dCA_last), 0)\n",
    "    dT = torch.cat((dT_first, dT_center, dT_last), 0)\n",
    "                        \n",
    "    #taking in first point\n",
    "    loss3_1 = dCA[:,1:] - (-u * torch.from_numpy(np.diff(NN_output[ :, :10].detach().numpy(force=True)) / np.diff(z)) - k_0 * torch.exp(-E_by_R/NN_output[ :, 11:]) * NN_output[:, 1:10])            \n",
    "    loss3_2 = dCA[:,0] - 0\n",
    "    loss3_2 = torch.reshape(loss3_2,(6,1))\n",
    "    loss3 = torch.cat((loss3_2, loss3_1),1)\n",
    "    loss3 = torch.mean(loss3_1**2)            \n",
    "            \n",
    "    #taking in first point\n",
    "    loss4_1 = dT[:,1:] - (-u * torch.from_numpy(np.diff(NN_output[ :, 10:].detach().numpy(force=True)) / np.diff(z)) + (-delH_term/(rho_L*C_p)) * k_0 * torch.exp(-E_by_R/NN_output[ :, 11:]) * NN_output[ :, 1:10] - (U/(rho_L*C_p*A)) * At * (NN_output[:, 11:]-Tc[0]))            \n",
    "    loss4_2 = dT[:,0] - 0\n",
    "    loss4_2 = torch.reshape(loss4_2,(6,1))\n",
    "    loss4 = torch.cat((loss4_2, loss4_1),1)           \n",
    "    loss4 = torch.mean(loss4_1**2)\n",
    "    \n",
    "    \n",
    "    # Partial PIRNN (Assuming we only have Temperature data available)\n",
    "    loss = 10e3*(loss1_1) + loss21 + 10e3*loss2 + 10e0*loss3 # add all loss terms together \n",
    "\n",
    " \n",
    "    # record validation loss\n",
    "    y_test_error.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3741b14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean error is 75.12906284766929, std is 58.51800833658045\n"
     ]
    }
   ],
   "source": [
    "# Evaluation of the Test dataset\n",
    "\n",
    "print(f\"mean error is {np.mean(y_test_error)}, std is {np.std(y_test_error)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "134ed9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb3393ab370>,\n",
       " <matplotlib.lines.Line2D at 0x7fb3393ab2b0>,\n",
       " <matplotlib.lines.Line2D at 0x7fb3393ab910>,\n",
       " <matplotlib.lines.Line2D at 0x7fb3393aaf20>,\n",
       " <matplotlib.lines.Line2D at 0x7fb3393aab60>,\n",
       " <matplotlib.lines.Line2D at 0x7fb3393ab610>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data visualization between Test and Predicted data for the time-series data of a few sample datapoints\n",
    "\n",
    "y_pred1 = model(X_physics_test)\n",
    "\n",
    "y_pred1 = y_pred1 * std_y.to('cpu') + mean_y.to('cpu')\n",
    "\n",
    "y_pred1 = y_pred1.detach().numpy()\n",
    "\n",
    "plt.plot(y_pred1[0:50:5, :, 1], y_pred1[0:50:5, :, 11], color='blue', ls='--')\n",
    "plt.plot(y_test[0:50:5, :, 1], y_test[0:50:5, :, 11], color='cyan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be94ac61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.324767643593388\n"
     ]
    }
   ],
   "source": [
    "# Measures the similarity between the above predicted and test data profile\n",
    "\n",
    "import similaritymeasures\n",
    "\n",
    "conpred = np.concatenate((y_pred1[0:50:5, :, 1], y_pred1[0:50:5, :, 11]),1)\n",
    "conpred = conpred.reshape(10,6,2)\n",
    "\n",
    "contest = np.concatenate((y_test[0:50:5, :, 1], y_test[0:50:5, :, 11]),1)\n",
    "contest = contest.reshape(10,6,2)\n",
    "\n",
    "mseA = similaritymeasures.mse(contest, conpred)\n",
    "print(mseA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79f3fc9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_PINN.eval()\n",
    "model_PINN.to('cpu')\n",
    "y_predict_test = model_PINN(X_physics_test[:500, :, :]).detach().numpy()\n",
    "y_predict_test = y_predict_test  * (std_y).detach().numpy() + (mean_y).detach().numpy()\n",
    "y_test = y_test[:500, :, :] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20088484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb3391ce200>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the concentration profile of the test and predicted data for entire time-length\n",
    "\n",
    "for i in range(6):\n",
    "    if i == 0:\n",
    "        plt.plot(z, y_test[1, i, :10], color='cyan', lw=2, label='Test')\n",
    "        plt.plot(z, y_predict_test[1, i, :10],color='black', lw=2, ls=':', label='Predicted')\n",
    "    else:\n",
    "        plt.plot(z, y_test[1, i, :10], color='cyan', lw=2)\n",
    "        plt.plot(z, y_predict_test[1, i, :10], color='black', lw=2, ls=':') \n",
    "\n",
    "plt.ylabel(\"C_A\")\n",
    "plt.xlabel(\"length\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18646718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb3392125f0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the temperature profile of the test and predicted data for entire time-length\n",
    "\n",
    "for i in range(6):\n",
    "    if i == 0:\n",
    "        plt.plot(z, y_test[1, i, 10:],  color='cyan', lw=2, label='Test')\n",
    "        plt.plot(z, y_predict_test[1, i, 10:], color='black', lw=2, ls=':', label='Predicted')\n",
    "    else:\n",
    "        plt.plot(z, y_test[1, i, 10:],  color='cyan', lw=2)\n",
    "        plt.plot(z, y_predict_test[1, i, 10:], color='black', lw=2, ls=':') \n",
    "\n",
    "plt.ylabel(\"Temp\")\n",
    "plt.xlabel(\"length\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34d296be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0029669499919898128\n",
      " C profile error is 0.0029669499919898128\n",
      "3.881458023679665\n",
      " T profile error is 3.881458023679665\n"
     ]
    }
   ],
   "source": [
    "# Measuring the similarity between the test and predicted data fot both the concentration and temperature profile\n",
    "\n",
    "import similaritymeasures\n",
    "\n",
    "mseC = similaritymeasures.mse(y_test[1, i, :10], y_predict_test[1, i, :10])\n",
    "print(mseC)\n",
    "print(f\" C profile error is {mseC}\")\n",
    "\n",
    "mseT = similaritymeasures.mse(y_test[1, :, 10:], y_predict_test[1, :, 10:])\n",
    "print(mseT)\n",
    "print(f\" T profile error is {mseT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ba5f48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
